[
    {
        "repo_url": "github.com/google-research/google-research",
        "filepath": "agile_modeling/load_clip.py",
        "commit_date": "2024-01-23T00:22:24Z",
        "message": "Open-sourcing the code for \"CLIP as RNN: Segment Countless Visual Concepts without Training Endeavor\".\nhttps://arxiv.org/abs/2312.07661\n\nPiperOrigin-RevId: 600601383"
    },
    {
        "repo_url": "github.com/google-research/google-research",
        "filepath": "agile_modeling/load_clip.py",
        "commit_date": "2023-09-15T18:25:10Z",
        "message": "Steps 1-3 (up to initial model training) ported to external colab.\n\nPiperOrigin-RevId: 565729930"
    },
    {
        "repo_url": "github.com/langchain-ai/langchain",
        "filepath": "libs/experimental/langchain_experimental/open_clip/open_clip.py",
        "commit_date": "2024-02-24T02:24:16Z",
        "message": "experimental: docstrings update (#18048)\n\nAdded missed docstrings. Formatted docsctrings to the consistent format."
    },
    {
        "repo_url": "github.com/langchain-ai/langchain",
        "filepath": "libs/experimental/langchain_experimental/open_clip/open_clip.py",
        "commit_date": "2024-01-02T20:09:45Z",
        "message": "langchain[patch], experimental[patch]: replace langchain.schema imports (#15410)\n\nImport from core instead.\n\nRan:\n```bash\ngit grep -l 'from langchain.schema\\.output_parser' | xargs -L 1 sed -i '' \"s/from\\ langchain\\.schema\\.output_parser/from\\ langchain_core.output_parsers/g\"\ngit grep -l 'from langchain.schema\\.messages' | xargs -L 1 sed -i '' \"s/from\\ langchain\\.schema\\.messages/from\\ langchain_core.messages/g\"\ngit grep -l 'from langchain.schema\\.document' | xargs -L 1 sed -i '' \"s/from\\ langchain\\.schema\\.document/from\\ langchain_core.documents/g\"\ngit grep -l 'from langchain.schema\\.runnable' | xargs -L 1 sed -i '' \"s/from\\ langchain\\.schema\\.runnable/from\\ langchain_core.runnables/g\"\ngit grep -l 'from langchain.schema\\.vectorstore' | xargs -L 1 sed -i '' \"s/from\\ langchain\\.schema\\.vectorstore/from\\ langchain_core.vectorstores/g\"\ngit grep -l 'from langchain.schema\\.language_model' | xargs -L 1 sed -i '' \"s/from\\ langchain\\.schema\\.language_model/from\\ langchain_core.language_models/g\"\ngit grep -l 'from langchain.schema\\.embeddings' | xargs -L 1 sed -i '' \"s/from\\ langchain\\.schema\\.embeddings/from\\ langchain_core.embeddings/g\"\ngit grep -l 'from langchain.schema\\.storage' | xargs -L 1 sed -i '' \"s/from\\ langchain\\.schema\\.storage/from\\ langchain_core.stores/g\"\ngit checkout master libs/langchain/tests/unit_tests/schema/\nmake format\ncd libs/experimental\nmake format\ncd ../langchain\nmake format\n```"
    },
    {
        "repo_url": "github.com/langchain-ai/langchain",
        "filepath": "libs/experimental/langchain_experimental/open_clip/open_clip.py",
        "commit_date": "2023-12-05T21:36:38Z",
        "message": "Multi-modal RAG template (#14186)\n\n* OpenCLIP embeddings\n* GPT-4V\n\n---------\n\nCo-authored-by: Erick Friis <erick@langchain.dev>"
    },
    {
        "repo_url": "github.com/langchain-ai/langchain",
        "filepath": "libs/experimental/langchain_experimental/open_clip/open_clip.py",
        "commit_date": "2023-12-01T23:13:20Z",
        "message": "Update Open CLIP embd (#14155)\n\nPrior default model required a large amt of RAM and often crashed\nJupyter ntbk kernel."
    },
    {
        "repo_url": "github.com/langchain-ai/langchain",
        "filepath": "libs/experimental/langchain_experimental/open_clip/open_clip.py",
        "commit_date": "2023-11-10T17:43:10Z",
        "message": "Add Chroma multimodal cookbook (#12952)\n\nPending:\n* https://github.com/chroma-core/chroma/pull/1294\n* https://github.com/chroma-core/chroma/pull/1293\n\n---------\n\nCo-authored-by: Erick Friis <erick@langchain.dev>\nCo-authored-by: Bagatur <baskaryan@gmail.com>"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2024-02-21T21:37:25Z",
        "message": "[ENH] Remove ONNX Logspam (#1747)\n\n## Description of changes\n\nAfter 1.17, ONNXRuntime produces scary warnings on mac platforms,\nbecause it tries to put our default embedding function into the CoreML\nexecution environment, where it doesn't fit.\n\nThis PR suppresses warnings from ONNX within the default embedding\nfunction so that users don't see scary warnings.\n\n## Test plan\n\nLocally tested via the `start_here` notebook.\n\n## Documentation Changes\nN/A"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2024-01-17T17:13:57Z",
        "message": "[WIP] [ENH] add exponential backoff and jitter to embedding calls (#1526)\n\nThis is a WIP, closes https://github.com/chroma-core/chroma/issues/1524\n\n*Summarize the changes made by this PR.*\n - Improvements & Bug fixes\n\t - Use `tenacity` to add exponential backoff and jitter\n - New functionality\n- control the parameters of the exponential backoff and jitter and allow\nthe user to use their own wait functions from `tenacity`'s API\n\n## Test plan\n*How are these changes tested?*\n\n- [x] Tests pass locally with `pytest` for python, `yarn test` for js\n\n## Documentation Changes\nNone"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2024-01-11T21:13:27Z",
        "message": "[BUG]Type errors in embading function #1169 (#1517)\n\n## Description of changes\n\n- Added correct type annotations for these methods #1169 \n\n## Test plan\n*How are these changes tested?*\n\n- [ ] Tests pass locally with `pytest` for python, `yarn test` for js\n\n## Documentation Changes\n*Are all docstrings for user-facing APIs updated if required? Do we need\nto make documentation changes in the [docs\nrepository](https://github.com/chroma-core/docs)?*\n\n---------\n\nCo-authored-by: Ran <rccalman@gmail.com>\nCo-authored-by: Ben Eggers <64657842+beggers@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2024-01-05T18:14:56Z",
        "message": "Replace ONNXMiniLM_L6_V2._init_model_and_tokenizer with tokenizer and model cached properties (#1194)\n\n## Description of changes\n\n*Summarize the changes made by this PR.*\n - Improvements & Bug fixes\n- Fixes #1193: race condition in\n`ONNXMiniLM_L6_V2._init_model_and_tokenizer`\n\n## Test plan\n*How are these changes tested?*\n\n- [x] Tests pass locally with `pytest` for python, `yarn test` for js"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2024-01-04T17:11:40Z",
        "message": "[CLN] Import json at top-level in embedding_functions (#1562)\n\n## Description of changes\n\n*Summarize the changes made by this PR.*\n - Improvements & Bug fixes\n\t - Move `import json` out of Amazon Bedrock EF and to top-level imports\n\n## Test plan\n*How are these changes tested?*\n\n- [x] Tests pass locally with `pytest` for python, `yarn test` for js\n\n## Documentation Changes\n*Are all docstrings for user-facing APIs updated if required? Do we need\nto make documentation changes in the [docs\nrepository](https://github.com/chroma-core/docs)?*"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-12-23T21:46:19Z",
        "message": "identity to equality check (#1566)\n\n## Description of changes\n\nChanges identity `is` to equality `==` check\n\nCo-authored-by: Jeffrey Huber <jeff@trychroma.com>"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-12-20T23:26:50Z",
        "message": "Add Amazon Bedrock Embedding function (#1361)\n\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/embeddings.html\n\n## Description of changes\n\n - New functionality\n\t - Support Amazon Bedrock embedding function\n\n## Test plan\n\n- [ ] Tests pass locally with `pytest` for python, `yarn test` for js\n\nTested locally by given profile_name with appropreate `~/.aws/config`\n\n```py\n>>> import boto3\n>>> from chromadb.utils.embedding_functions import AmazonBedrockEmbeddingFunction\n>>> session = boto3.Session(profile_name=\"myprofile\", region_name=\"us-east-1\")\n>>> ef = AmazonBedrockEmbeddingFunction(session=session)\n>>> ef([\"Hello Bedrock\"])\n[[-0.73046875, 0.390625, 0.24511719, 0.111816406, 0.83203125, 0.79296875,...,]]\n```\n\n## Documentation Changes\nWritten docstrings as much as possible.\n\n---------\n\nCo-authored-by: Ben Eggers <64657842+beggers@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-12-19T21:56:33Z",
        "message": "[ENH]: SHA256 sum check of Chroma's onnx model. (#1493)\n\nRefs: #883\n\n## Description of changes\n\n*Summarize the changes made by this PR.*\n - Improvements & Bug fixes\n- Verify ONNX all-MiniLM-L6 model model download from s3 with static\nSHA256 (within the python code)\n\n## Test plan\n*How are these changes tested?*\n\n- [x] Tests pass locally with `pytest` for python\n\n## Documentation Changes\nN/A"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-12-15T01:19:37Z",
        "message": "Gemini (#1520)\n\nThis adds a Google Gemini embedding function and an RAG chat example \n\nTODO\n- [x] JS support\n- [x] Docs PR"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-11-29T18:53:09Z",
        "message": "[ENH]: Embedding Function - Hugging Face Text Embedding Server (#1371)\n\nRefs: [Feature Request]: Hugging Face text embedding inference custom\nembedding #1367\n\n## Description of changes\n\n*Summarize the changes made by this PR.*\n - New functionality\n\t - New Embedding Function for HF Text Embedding Server\n\t - Added sample docker compose to run things locally\n\t - Added example notebook\n\n## Test plan\n*How are these changes tested?*\n\n- [x] Tests pass locally with `pytest` for python\n\n## Documentation Changes\nTBD\n\nhttps://github.com/huggingface/text-embeddings-inference"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-11-28T22:58:15Z",
        "message": "Remove redundant check for \"requests\" module (#1427)\n\n`requests` is imported in line 17, and hence required:\n\n\nhttps://github.com/chroma-core/chroma/blob/33289e8c5b0b5d65132a2995ab7199e83eaeacdf/chromadb/utils/embedding_functions.py#L17"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-11-17T18:01:17Z",
        "message": "Pass input_type to cohere embedding models (#1407)\n\n## Description of changes\n\n*Summarize the changes made by this PR.*\n - Improvements & Bug fixes\n\t - Fixes https://github.com/chroma-core/chroma/issues/1385\n - New functionality\n\t - ...\n\n## Test plan\n*How are these changes tested?*\n\nGot a Cohere API key and repro'd the issue locally. With this change,\ncalling the embedding function no longer breaks.\n\n- [x] Tests pass locally with `pytest` for python, `yarn test` for js\n\n## Documentation Changes\n*Are all docstrings for user-facing APIs updated if required? Do we need\nto make documentation changes in the [docs\nrepository](https://github.com/chroma-core/docs)?*"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-11-17T06:32:03Z",
        "message": "feat: add Jina AI embedding function (#1324)\n\n## Description of changes\n\nHey Chroma team!\n\nWe just launched [Jina Embeddings](https://jina.ai/embeddings/) and\nwould love to add a possibilty for the community to use it with\nJinaEmbeddingFunctions.\n\nThanks!\n\n## Documentation Changes\nLink to docs PR: https://github.com/chroma-core/docs/pull/153\n\n---------\n\nSigned-off-by: Joan Fontanals Martinez <joan.martinez@jina.ai>"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-11-16T05:55:58Z",
        "message": "ENH: Allow default headers to be passed to OpenAI API (#1397)\n\n## Description of changes\n\n*Summarize the changes made by this PR.*\n - Improvements & Bug fixes\n- Allows users to pass custom headers to OpenAI API, enabling\nintermediary proxies with different authentication methods.\n - New functionality\n- New optional `default_headers` input at the `OpenAIEmbeddingFunction`\nclass.\n\n## Test plan\n*How are these changes tested?*\n\n- [x] Tests pass locally with `pytest` for python, `yarn test` for js\n\n## Documentation Changes\n*Are all docstrings for user-facing APIs updated if required? Do we need\nto make documentation changes in the [docs\nrepository](https://github.com/chroma-core/docs)?*\n\nSince this is a relatively specific feature, I believe it won't require\nan usage example in the docs.\n\nCo-authored-by: Gustavo Antoniassi <gustavo.antoniassi@ifood.com.br>"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-11-08T22:22:58Z",
        "message": "support of OpenAI package v1.X.X for utils.OpenAIEmbeddingFunction, deployment_id parameter for openai v0.X.X (#1338)\n\n## Description of changes\n- Add support of OpenAI package v1.X.X for utils.OpenAIEmbeddingFunction\n- Add Azure OpenAI Deployment ID parameter for openai v0.X.X lib in\nutils.OpenAIEmbeddingFunction\n\n## Test plan\n*How are these changes tested?*\n\nTested as dependency of https://github.com/Nayjest/ai-microcore with\nAzure & openai packages v0.28.1 & v1.0.1, v1.1.0"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-11-07T22:07:53Z",
        "message": "[ENH] Multimodal Embedding Functions (#1345)\n\n## Description of changes\n\nThis PR introduces multi-modal embeddings into Chroma. \n- It adds the generic `EmbeddingFunction` which can take various data\ntypes. Existing functions take the `Documents` type.\n- Adds `Images` as a type (numpy NDArray taking ints or floats)\n- Add `OpenCLIPEmbeddingFunction` which is an\n`EmbeddingFunction[Union[Documents, Images]]`\n\n## Test\n\nIntegration tests pass. \n\nA new test for multimodal embedding functions:\n[chromadb/test/ef/test_multimodal_ef.py](https://github.com/chroma-core/chroma/blob/86a9e2620352ee0b2844bc3233f9e001cc4aa3d9/chromadb/test/ef/test_multimodal_ef.py)\n\n## Documentation\n\nSee https://github.com/chroma-core/chroma/pull/1294\n\n## TODOs\n- [x] Tests\n- [x] ~Wiring through FastAPI~ Nothing to wire through\n- [x] Documentation\n- [x] Telemetry\n- [ ] JavaScript"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-11-07T18:00:00Z",
        "message": "Revert \"[ENH] Multimodal Embeddings\" (#1344)\n\nReverts chroma-core/chroma#1293"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-11-07T17:57:00Z",
        "message": "[ENH] Multimodal Embeddings (#1293)\n\n## Description of changes\n\nThis PR introduces multi-modal embeddings into Chroma. \n- It adds the generic `EmbeddingFunction` which can take various data\ntypes. Existing functions take the `Documents` type.\n- Adds `Images` as a type (numpy NDArray taking ints or floats)\n- Add `OpenCLIPEmbeddingFunction` which is an\n`EmbeddingFunction[Union[Documents, Images]]`\n\n## Test\n\nIntegration tests pass. \n\nA new test for multimodal embedding functions:\n[chromadb/test/ef/test_multimodal_ef.py](https://github.com/chroma-core/chroma/blob/86a9e2620352ee0b2844bc3233f9e001cc4aa3d9/chromadb/test/ef/test_multimodal_ef.py)\n\n## Documentation\n\nSee https://github.com/chroma-core/chroma/pull/1294\n\n## TODOs\n- [x] Tests\n- [x] ~Wiring through FastAPI~ Nothing to wire through\n- [x] Documentation\n- [x] Telemetry\n- [ ] ~JavaScript~"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-09-22T22:49:58Z",
        "message": "[ENH] Metric batching and more metrics (#1163)\n\n## Description of changes\nThis PR accomplishes two things:\n- Adds batching to metrics to decrease load to Posthog\n- Adds more metric instrumentation\n\nEach `TelemetryEvent` type now has a `batch_size` member defining how\nmany of that Event to include in a batch. `TelemetryEvent`s with\n`batch_size > 1` must also define `can_batch()` and `batch()` methods to\ndo the actual batching -- our posthog client can't do this itself since\ndifferent `TelemetryEvent`s use different count fields. The Posthog\nclient combines events until they hit their `batch_size` then fires them\noff as one event.\n\nNB: this means we can drop up to `batch_size` events -- since we only\nbatch `add()` calls right now this seems fine, though we may want to\naddress it in the future.\n\nAs for the additional telemetry, I pretty much copied Anton's draft\nhttps://github.com/chroma-core/chroma/pull/859 with some minor changes.\n\nOther considerations: Maybe we should implement `can_batch()` and\n`batch()` on all events, even those which don't currently use them? I'd\nprefer not to leave dead code hanging around but happy to go either way.\n\nI created a ticket for the type ignores:\nhttps://github.com/chroma-core/chroma/issues/1169\n\n## Test plan\npytest passes modulo a couple unrelated failures\n\nWith `print(event.properties)` in posthog client's `_direct_capture()`:\n```\n>>> import chromadb\n>>> client = chromadb.Client()\n{'batch_size': 1}\n>>> collection = client.create_collection(\"sample_collection\")\n{'batch_size': 1, 'collection_uuid': 'bb19d790-4ec7-436c-b781-46dab047625d', 'embedding_function': 'ONNXMiniLM_L6_V2'}\n>>> collection.add(\n...     documents=[\"This is document1\", \"This is document2\"], # we embed for you, or bring your own\n...     metadatas=[{\"source\": \"notion\"}, {\"source\": \"google-docs\"}], # filter on arbitrary metadata!\n...     ids=[\"doc1\", \"doc2\"], # must be unique for each doc \n... )\n{'batch_size': 1, 'collection_uuid': 'bb19d790-4ec7-436c-b781-46dab047625d', 'add_amount': 2, 'with_documents': 2, 'with_metadata': 2}\n>>> for i in range(50):\n...   collection.add(documents=[str(i)], ids=[str(i)])\n... \n{'batch_size': 20, 'collection_uuid': 'bb19d790-4ec7-436c-b781-46dab047625d', 'add_amount': 20, 'with_documents': 20, 'with_metadata': 0}\n{'batch_size': 20, 'collection_uuid': 'bb19d790-4ec7-436c-b781-46dab047625d', 'add_amount': 20, 'with_documents': 20, 'with_metadata': 0}\n>>> for i in range(50):\n...   collection.add(documents=[str(i) + ' ' + str(n) for n in range(20)], ids=[str(i) + ' ' + str(n) for n in range(20)])\n... \n{'batch_size': 20, 'collection_uuid': 'bb19d790-4ec7-436c-b781-46dab047625d', 'add_amount': 210, 'with_documents': 210, 'with_metadata': 0}\n{'batch_size': 20, 'collection_uuid': 'bb19d790-4ec7-436c-b781-46dab047625d', 'add_amount': 400, 'with_documents': 400, 'with_metadata': 0}\n{'batch_size': 20, 'collection_uuid': 'bb19d790-4ec7-436c-b781-46dab047625d', 'add_amount': 400, 'with_documents': 400, 'with_metadata': 0}\n```\n\n## Documentation Changes\nhttps://github.com/chroma-core/docs/pull/139\n\nhttps://github.com/chroma-core/docs/commit/a4fd57d4d2cc3cae00cbb4a9245b938e2f0d1842"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-08-29T17:18:53Z",
        "message": "[ENH] Added providers to onnx runtime session (#1006)\n\nRefs:  https://onnxruntime.ai/docs/api/python/api_summary.html\n\nRefs: #1004\n\n## Description of changes\n\n*Summarize the changes made by this PR.*\n - Improvements & Bug fixes\n- In multi-provider envs Onnyx Runtime requires that providers are\nspecified (with order of preference) as input to the InferrenceSession\n\n## Test plan\nIdeally, we'll need a GPU runners for testing -\nhttps://github.com/github/roadmap/issues/505\n\n## Documentation Changes\nNo change to docs is required.\n\n> Note: Sorry for the unsigned commit, I tried using GH Codespaces for\nthis one."
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-08-15T01:18:11Z",
        "message": "Fix model download for ONNX embedder (#976)\n\n## Description of changes\nThe current function is looking for the tar.gz file instead of checking\nif the folder already exists, so if the tar.gz gets deleted after\nextraction, it downloads it again.. This PR resolves this and checks for\nthe model in the extracted folder before attempting to download or\nextract again.\n\n## Test plan\nBy using it\n\n## Documentation Changes\nI didn't find any documentation about how this does the download."
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-07-28T21:35:31Z",
        "message": "fix: update api request (#890)\n\n## Description of changes\n\n*Summarize the changes made by this PR.*\n - Improvements & Bug fixes\n\t - Update the API endpoint for Google VertexEmbedding\n - New functionality\n\t - ...\n\n## Test plan\n*How are these changes tested?*\nAt the moment, there is any unit test for embedding function. However I\nhave tested the new code change locally and it worked.\n\n## Documentation Changes\n*Are all docstrings for user-facing APIs updated if required? Do we need\nto make documentation changes in the [docs\nrepository](https://github.com/chroma-core/docs)?*\n\n1. The default model_name should be textembedding-gecko instead of\ntextembedding-gecko-001\n2. The _api_url should be changed to\n3. The json payload should take in only 1 string instead of array of\nstrings. Thus I made a for loop to call the api endpoint in the event\nthere are arrays of text documents passed into the _call() function"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-07-27T23:09:43Z",
        "message": "add azure openai api_version param (#832)\n\n## Description of changes\n\n*Summarize the changes made by this PR.*\n - Improvements & Bug fixes\nFix the bug that causes functionality to be unavailable when using\nazure-openai due to missing api version parameter.\nopenai examples:\nhttps://github.com/openai/openai-cookbook/blob/main/examples/azure/embeddings.ipynb\n - New functionality\n\t - ...\n\n## Test plan\n*How are these changes tested?*\n\n## Documentation Changes\n*Are all docstrings for user-facing APIs updated if required? Do we need\nto make documentation changes in the [docs\nrepository](https://github.com/chroma-core/docs)?*\n\nfix https://github.com/chroma-core/chroma/issues/698\n\n---------\n\nCo-authored-by: litong <you@example.com>"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-07-27T23:06:23Z",
        "message": "Update chromadb/utils/embedding_functions.py (#816)\n\nThis is a copy of https://github.com/kevinlu1248/chroma/pull/7, written\nby Sweep, an AI junior dev.\n\n## Description of changes\nThis PR adds documentation for the HuggingFace embeddings feature in the\nchroma repository. The HuggingFaceEmbeddingFunction class is already\nimplemented in the `chromadb/utils/embedding_functions.py` file, but it\nis currently undocumented. This PR adds docstrings to the class and\nupdates the README.md file to explain how to use the class and what it\ndoes.\n\n## Changes Made\n- Added docstrings to the HuggingFaceEmbeddingFunction class in\n`chromadb/utils/embedding_functions.py`\n- Updated the README.md file to include a section about the\nHuggingFaceEmbeddingFunction class, explaining its usage and providing\nan example\n- Mentioned that the requests package is required and provided the\ncommand to install it\n\n---------\n\nCo-authored-by: sweep-ai[bot] <128439645+sweep-ai[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-06-28T17:16:06Z",
        "message": "Normalized embeddings (#737)\n\n## Description of changes\nAdded support to the use of normalize embeddings in the\n`SentenceTransformerEmbeddingFunction` class by adding a new attribute\nto the class and use it when calling the `encode` function.\n\n## Test plan\nI was planning to add a new test case where an object was created with\n`normalize_embeddings=True` but I haven't found any test which is\ncurrently testing `SentenceTransformerEmbeddingFunction` (I guess that\nshould be in the folder `test/utils`).\n\n## Documentation Changes\nThe document talking about [embeddings] should be changed. In the\nsection *Sentence Transformers* it should be mentioned the possiblitiy\nof using an optional parameter `normalize_embeddings`. A similar text to\nthe one in the SentenceTransformer documentation could be used (or\nadapted):\n\n> If set to True, returned vectors will have length 1. In that case, the\nfaster dot-product (util.dot_score) instead of cosine similarity can be\nused."
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-06-21T21:01:34Z",
        "message": "fix wrong return type (#613)\n\n## Description of changes\nRelated issue: #594\n*Summarize the changes made by this PR.*\n - Improvements & Bug fixes\n- HuggingFaceEmbeddingFunction: fix wrong return type from List to\nList[List]\n- GoogleVertexEmbeddingFunction: fix wrong return type of empty dict to\nempty List\n\n## Test plan\n*How are these changes tested?*\n\n## Documentation Changes\n*Are all docstrings for user-facing APIs updated if required? Do we need\nto make documentation changes in the [docs\nrepository](https://github.com/chroma-core/docs)?*\n\n---------\n\nCo-authored-by: Tegar Dani Pratama <tegar.dani@hukumonline.com>\nCo-authored-by: Jeffrey Huber <jeff@trychroma.com>"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-05-31T21:23:10Z",
        "message": "Add a thin client (#610)\n\n## Description of changes\n*Summarize the changes made by this PR.*\n - Improvements & Bug fixes\n\t - Typing cleanup\n- Changes embedding function defaults to work through the default params\nas opposed to via None so that None now means - NO embedding function as\nopposed to use the default. This is technically a breaking change.\n - New functionality\n- Adds a thin client that restricts what you can create to the REST api\nclient and builds it separately so it can be published to its own pypi\npackage. The thin client restricts the default embedding function to be\nNone always - forcing manual specification of the embedding function\nwhile using the thin client.\n- The thin client is built with its own pyproject.toml with a limited\nset of dependencies and a is_thin_client.py file that acts as a compile\nflag. The build script stages the toml, places the two files in the\nright place, performs the build and then tears down the changes.\n\t \nAddresses #289 \n\n## Test plan\nThe existing tests should cover this configuration. We can add CI for\nthe thin-client in the future.\n\n## Documentation Changes\nWe will add a section on the docs that explains the thin client and its\nlimitations."
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-05-19T22:07:41Z",
        "message": "Add Google Vertex Embedding Function (#528)\n\nAdd Google Vertex Embedding Function\n\n\nhttps://console.cloud.google.com/vertex-ai/publishers/google/model-garden/textembedding-gecko?project=noted-victory-383712\n\n## Description of changes\nAdded Google Vertex Embedding Function\n\n## Test plan\nBy providing the API key and project ID.\n\n## Documentation Changes\nHas as much documentation as the others in that file.\n\n---------\n\nCo-authored-by: Jeffrey Huber <jeff@trychroma.com>"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-05-19T22:06:46Z",
        "message": "Add task instruction pairing to InstructorEmbeddingFunction (#556)\n\n## Description of changes\n\n- Add an optional `instruction` constructor parameter to\nInstructorEmbeddingFunction to allow `instruction` and Document pairs to\nbe encoded.\n\n## Test plan\n\n\n## Documentation Changes\nAdded examples to the Alternative Embedding notebook.\n\nNot sure if this is a good implementation, since you'll need a separate\nCollection for each instruction you want to use (or reassign\n`self._instruction`), but at least the change is pretty minimal. For my\nuse case, two instructions are enough (one for storing, one for\nretrieving). For a scenario where you need lots of different\ninstructions, perhaps \"Represent the <Science|Financial|Political|etc.>\narticle: \", another solution is needed.\n\nFeature Request #546\n\n---------\n\nCo-authored-by: Jeffrey Huber <jeff@trychroma.com>"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-05-19T07:30:04Z",
        "message": "Switch to ONNX model for default embedding model (#267)\n\n## Description of changes\n\n*Summarize the changes made by this PR.* \n - Improvements & Bug fixes\n\t - None\n - New functionality\n- Adds a ONNX port of sentence-transformers all-MiniLM-L6-v2 in order to\nremove the dependencies on pytorch, sentence-transformers,\nsentence-piece and other heavy depdencies. This reduced the on disk\nenvironment size needed for dependencies to run chroma from ~900MB to\n~300MB\n- The ONNX port and verification of its accuracy live in\nhttps://github.com/chroma-core/onnx-embedding\n- The ONNX model is hosted on S3 after being generated in the above repo\n- The implementation here runs the model and applies mean-pooling using\nnumpy since that's the final layer.\n- The embedding model will download the model using tqdm to provide the\nsame download experience as before\n\t - If the model is cached it will not be downloaded. \n\t - In contrast to before, the model is now ONLY downloaded if used!\n- The net-new dependencies are onnxruntime and tokenizers, both are\nlightweight.\n\t - Updated the default model to be this one instead of ST.\n- We create a new DefaultEmbeddingFunction which aliases the ONNX\nembedding function\n\n## Test plan\nAdded a test to test multiple batches with the new model\n\n## Documentation Changes\n*Are all docstrings for user-facing APIs updated if required? Do we need\nto make documentation changes in the [docs\nrepository](https://github.com/chroma-core/docs)?*\nWe will need to change the documentation here\nhttps://docs.trychroma.com/embeddings#default-sentence-transformers to\nhighlight this fact."
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-05-19T05:11:55Z",
        "message": "Added api_base and api_type to the OpenAIEmbeddingFunction  (#517)\n\nAdded api_base and api_type to the OpenAIEmbeddingFunction to support\noutside the base openai deployment like Azure etc\n\n## Description of changes\n\nThis PR adds support for deploying the OpenAIEmbeddingFunction on\nplatforms other than the base OpenAI deployment, such as Azure, by\nallowing users to specify the `api_base` and `api_type` parameters.\n\n### Improvements & Bug fixes\n- None\n\n### New functionality\n- Added `api_base` and `api_type` as optional parameters to the\n`OpenAIEmbeddingFunction` to support deployment on other platforms like\nAzure, etc.\n\n## Test plan\n\nTo test the changes made in this PR, the following steps can be taken:\n\n### Test against Azure\n1. Set up the OpenAIEmbeddingFunction with the new `api_base` and\n`api_type` parameters.\n2. Deploy the embedding model on the desired platform (e.g., Azure).\n3. Run sample embeddings and test the new deployment against the Azure\ndeployment instance.\n\n### Test against Base Open AI\n1. Set up the OpenAIEmbeddingFunction with just the `api_key and without\nthe new `api_base` and `api_type` parameters.\n2. Run sample embeddings and test the new deployment against the OpenAI\ninstance.\n\n## Documentation Changes\n\nAll docstrings for user-facing APIs needs to be updated to reflect the\nnew `api_base` and `api_type` parameters. Additionally, documentation in\nthe [docs repository](https://github.com/chroma-core/docs) should be\nupdated to provide guidance on how to use the new parameters for\ndeploying the OpenAIEmbeddingFunction on platforms other than the base\nOpenAI deployment. This change will be submitted as a separate pull\nrequest.\n\n---------\n\nCo-authored-by: Jeff Huber <jeff@trychroma.com>"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-05-18T04:49:54Z",
        "message": "Add organization_id to openai embeddings (#548)\n\n## Description of changes\nThis related to #547 issue.\n - New functionality added:\n\t - add optional organization_id parameter to OpenAIEmbeddingFunction.\n\n## Test plan\n- Create the class object without organization_id and no errors\nexpected.\n- Create the class object with organization_id.\n\n## Documentation Changes\n*Are all docstrings for user-facing APIs updated if required? Do we need\nto make documentation changes in the [docs\nrepository](https://github.com/chroma-core/docs)?*\n- The class optional parameters are not mentioned explicitly."
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-05-12T23:43:17Z",
        "message": "Add Text2VecEmbeddingFunction (#417)\n\nAdd Text2VecEmbeddingFunction for Chinese sentence embedding.\n\nCo-authored-by: hammadb <hammad@trychroma.com>"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-05-11T21:50:57Z",
        "message": "Merge branch 'main' into main"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-05-10T05:52:12Z",
        "message": "Add precommit hooks (#483)\n\nAdds precommit hooks based on #433 to our repository. Only one file here is new - the configuration for the hooks, everything else is linting/formatting fixes. We do not run the typechecker globally since that would be quite lengthy to clean up - instead we will have to incrementally clean up type check issues as we go."
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-05-09T18:23:22Z",
        "message": "Add Google PaLM embedding function. (#445)\n\n* Add Google PaLM embedding function.\n\n* Address feedback by @markmcd.\n\n* Default model, import failure string\n\n---------\n\nCo-authored-by: atroyn <anton.troynikov@gmail.com>"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-05-06T04:03:15Z",
        "message": "Team/hypothesis tests (#474)\n\nMerges the team/hypothesis-tests branch to main. Which adds a robust property-based testing suite to Chroma. lfg."
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-04-18T00:59:45Z",
        "message": "make api_key in OpenAIEmbeddingFunction optional (#320)\n\n* make api_key in OpenAIEmbeddingFunction optional\n\n* make optional api_key actually work\n\n* Early error\n\n---------\n\nCo-authored-by: atroyn <anton.troynikov@gmail.com>"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-04-18T00:54:53Z",
        "message": "[bugfix] Ensure Openai batch embeddings are sorted by index (#344)\n\n* Ensure openai batch embeddings are sorted by index\n\n* Use lambda\n\n---------\n\nCo-authored-by: atroyn <anton.troynikov@gmail.com>"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-04-11T21:04:25Z",
        "message": "Adds option to pass compute device like cpu, cuda, cuda:1 to SentenceTransformerEmbeddingFunction"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-04-03T19:37:16Z",
        "message": "Add flake8 linter, address linter issues (#287)\n\nAdds the flake8 linter configured to run with black in vscode"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-03-24T03:07:13Z",
        "message": "added embedding function for the Instructor models."
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-03-17T05:46:48Z",
        "message": "Merge pull request #206 from danielgross/patch-2\n\nIn my experience T5 is much better, add comment with that as an option."
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-03-17T05:35:25Z",
        "message": "Update embedding_functions.py"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-03-16T02:42:15Z",
        "message": "use requests Session object to keep requests imported"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-03-16T02:02:25Z",
        "message": "need to access instance variables"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-03-16T01:48:52Z",
        "message": "add wrapper for hugging faces embedding api"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-03-07T19:45:19Z",
        "message": "In my experience T5 is much better, add comment with that as an option."
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-03-03T18:40:46Z",
        "message": "Unified error messages (#199)\n\nUnifies error messages across the project to make them more useful and consistent\nImproves the error message for invalid collection names\n\n---------\n\nCo-authored-by: Hammad Bashir <HammadB@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-02-17T18:06:08Z",
        "message": "Add support for cohere embeddings (#141)\n\n* Add support for cohere embeddings\n\n* Keep newlines"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-02-15T20:13:22Z",
        "message": "Remove newlines to improve performance\n\nPer OpenAI's get_embedding function here: https://github.com/openai/openai-python/blob/main/openai/embeddings_utils.py"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-02-14T03:45:38Z",
        "message": "OpenAI Embeddings (#117)\n\n* Adding OpenAI embedding functions\n\n* OpenAI"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-02-13T01:08:56Z",
        "message": "Default embedding function (#26)"
    },
    {
        "repo_url": "github.com/chroma-core/chroma",
        "filepath": "chromadb/utils/embedding_functions.py",
        "commit_date": "2023-02-11T05:58:44Z",
        "message": "Add embedding functions (#19)\n\n* Pass in embedding function.\n\n* Embedding function\n\n* Text-only queries\n\n* Add correct result and types for get (#15)\n\n* Reactor get result to client (#16)\n\n* Add query result (#17)\n\n* fix\n\n* Nit\n\n---------\n\nCo-authored-by: Hammad Bashir <HammadB@users.noreply.github.com>\nCo-authored-by: Jeffrey Huber <jeff@trychroma.com>"
    },
    {
        "repo_url": "github.com/open-mmlab/mmsegmentation",
        "filepath": "projects/CAT-Seg/cat_seg/models/clip_ovseg.py",
        "commit_date": "2023-08-09T15:57:30Z",
        "message": "[Project] Support CAT-Seg from CVPR2023 (#3098)\n\nThanks for your contribution and we appreciate it a lot. The following\ninstructions would make your pull request more healthy and more easily\nget feedback. If you do not understand some items, don't worry, just\nmake the pull request and seek help from maintainers.\n\n## Motivation\n\nSupport CAT-Seg open-vocabulary semantic segmentation (CVPR2023).\n\n## Modification\n\nSupport CAT-Seg open-vocabulary semantic segmentation (CVPR2023).\n- [x] Support CAT-Seg model training.\n- [x] CLIP model based `backbone` (R101 & Swin-B), aggregation layers\nbased `neck`, and `decoder` head.\n  - [x] Provide customized coco-stuff164k_384x384 training configs.\n- [x] Language model supports for `open vocabulary` (OV) tasks. \n  - [x] Support CLIP-based pretrained language model (LM) inference.\n  - [x] Add commonly used prompts templates. \n- [x] Add README tutorials.\n- [x] Add zero-shot testing scripts.\n\n**Working on the following tasks.**\n- [x] Add unit test.\n\n## BC-breaking (Optional)\n\nDoes the modification introduce changes that break the\nbackward-compatibility of the downstream repos?\nIf so, please describe how it breaks the compatibility and how the\ndownstream projects should modify their code to keep compatibility with\nthis PR.\n\n## Use cases (Optional)\n\nIf this PR introduces a new feature, it is better to list some use cases\nhere, and update the documentation.\n\n## Checklist\n\n1. Pre-commit or other linting tools are used to fix the potential lint\nissues.\n2. The modification is covered by complete unit tests. If not, please\nadd more unit test to ensure the correctness.\n3. If the modification has potential influence on downstream projects,\nthis PR should be tested with downstream projects, like MMDet or\nMMDet3D.\n4. The documentation has been modified accordingly, like docstring or\nexample tutorials.\n\n---------\n\nCo-authored-by: xiexinch <xiexinch@outlook.com>"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2024-01-07T23:34:40Z",
        "message": "Improve error handling and API error codes (#656)\n\nCo-authored-by: Farshid Zavareh <farshid@marqo.ai>"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-07-26T07:35:54Z",
        "message": "Improve image download validation and resource management (#551)\n\nExplicitly close streaming HTTP connections and PIL images. Ensure _id is never treated as an image URL. Error out if _id is specified as a tensor field by the user."
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-06-26T13:10:20Z",
        "message": "download integrity (#502)\n\n* catch automodel.pretrained error\n\n* finished open_clip part\n\n* finished open_clip part\n\n* catch mainline\n\n* finish the test\n\n* finish the test\n\n* raise internal errors now.\n\n* update string\n\n* update error message\n\n* update error message\n\n* update error message\n\n* update error message\n\n* update error catching\n\n* update error catching for loading clip model into openclip\n\n* update error handling in s2_inference\n\n* update error handling in s2_inference\n\n* catch mainline\n\n* catch mainline"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-06-23T06:31:19Z",
        "message": "Consolidating default device to CUDA when available (#508)\n\n* preliminary replacement work\n\n* changed a few cpus to cuda\n\n* add defaults in tensor search, bulk search, add docs, also added env var\n\n* 1st sweep of removing device params, on parallel now\n\n* transferred default calc from add docs to orch\n\n* replaced defaults in clip_utils.py\n\n* replaced defaults in s2_inference, clip_utils, onnx_utils\n\n* removed defaults everywhere\n\n* added device to vectorise, CLIP calls\n\n* updated device in other models, aux functions\n\n* added device for vectorise and encoding tests\n\n* added device to everything before test_add_documents\n\n* more test fixes\n\n* fixed more test, hardcoded cpu for _float_tensor_to_list\n\n* hardcoded cpu for _float_tensor_to_list\n\n* removed debug message for best available device\n\n* changed comment on vector text search\n\n* all tensor_search tests pass\n\n* fixed errors raised\n\n* added new unit tests, changed env var name\n\n* util env var, replace with empty dict\n\n* updated bulk search default and utils tests\n\n* separated on start method, added search test\n\n* updated validation and more tests\n\n* added unit tests for all internal func validations\n\n* added tests for add docs mp and batch request\n\n* removed validation from Model. Added to SBERT and HF models instead\n\n* added tests to fail if no default orch, search, bulk search\n\n* removed Model test\n\n* moved validation back to Model parent class\n\n* added Model no device test back in"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-06-22T06:09:05Z",
        "message": "Return metrics (#506)\n\n* basic Request level metrics/telemetry\n\n* add unit tests for telemetry\n\n* add request metrics to add/search APIs\n\n* python 3.8 fixes\n\n* simplify threaded metrics in download_images\n\n* fix bug\n\n* simplify tests\n\n* fix None in tests\n\n* make tests extra clean\n\n* make metric names more user friendly\n\n* add image download for search. Other improvements\n\n* fix unit tests for clip_utils\n\n* remove 'vector_inference'\n\n* search.create_vectors -> search.vector_inference_full_pipeline\n\n* preprocess -> processing_before_opensearch\n\n* better naming for RequestMetric(s)"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-06-13T00:07:26Z",
        "message": "remove autocast for cpu (#491)\n\n* remove autocast for cpu\n\n* add tests\n\n* add tests"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-05-22T03:01:11Z",
        "message": "Refactor `tensor_search::search` to use shared functions from `tensor_search::bulk_search` (#469)\n\n* refactor tensor_search/search\n\n* move SearchQuery.context and SearchQuery.scoreModifiers to pydantic\n\n* fix removed SearchContext object\n\n* fix tests\n\n* fix inference for model auth tests\n\n* PR fixes\n\n* add more tests\n\n* multi modal test +1"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-05-19T07:08:17Z",
        "message": "custom hf model loading with authentication  (#474)\n\n* custom hf model loading with authentication for hf model\n\n* custom hf model loading with authentication for hf model\n\n* custom hf model loading with authentication for hf model\n\n* custom hf model loading with authentication for hf model\n\n* custom hf model loading with authentication for hf model\n\n* pass the loading from huggingface repo directly test\n\n* test for loading model\n\n* only need to test variants\n\n* add more tests\n\n* add more tests\n\n* fix a test and remove pring\n\n* fix a test and remove pring\n\n* fix a test and remove pring\n\n* fix a test and remove pring\n\n* fix a test and remove pring\n\n* fix a test and remove pring\n\n* fix a test and remove pring\n\n* fix a test and remove pring\n\n* use repo_id instead of name now\n\n* use repo_id instead of name now\n\n* revise from jack\n\n* revise from pandu\n\n* revise from pandu\n\n* update code\n\n* catch automodel.pretrained error\n\n* catch automodel.pretrained error\n\n* catch automodel.pretrained error\n\n* catch automodel.pretrained error\n\n* catch automodel.pretrained error\n\n* catch automodel.pretrained error\n\n* reivise\n\n* add extra tests\n\n* bug fix"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-05-11T00:35:53Z",
        "message": "Stateless model auth (#460)\n\n* added model auth\n\n* Added objects for structure\n\n* introducing AddDocsParams object for addDocuments calls\n\nuntested\n\n* added pydantic plugin advice to dev guide\n\n* refactored test_add_docs to use AddDocsParams class\n\n* updated tensor search docstring\n\n* refactored tests to work with new AddDocsParams object\n\n* Commit for refactoring done to test_add_documents_use_existing_tensors.py\n\n* refactored delete_documents to use the add_documents wrapper\n\n* added transitional add_docs wrapper\n\n* added transition add docs wrappers to add_documents calls in these test cases\n\n* added transition add docs wrappers to add_documents calls in these test cases\n\n* test updated to use new add_docs param object\n\n* cleaning up tests with issues\n\n* made progress integrating s3\n\n* add docs, s3 works\n\n* search seems to work (it at least passes through the auth info OK)\n\n* added boto to reqs add hf skeleton funcs\n\n* added changes\n\n* fixed test_bulk_search_different_models_separate_vectorise_calls\n\n* created test_model_auth_s3 ()\n\n* test_model_auth_s3() asserts boto3 client instantiation\n\n* made assertions about the presence of the model file\n\n* added hf loading tests\n\n* added tests for hf, s3 search\n\n* added test for s3/hf mismatch\n\n* test refactor\n\n* added cuda test\n\n* add_docs parses model auth str\n\n* corrected add_docs derivatives test\n\n* removed unused vectorise params\n\n* fixed bug, not passing through auth in multimodal_combination\n\n* added test for no creds\n\n* added test_bad_creds_error_s3\n\n* test for access to non existent hf repo\n\n* Added test_after_downloading_search_doesnt_redownload\n\n* fixed checking loaded models\n\n* added from_s3 tests\n\n* added from_hf tests\n\n* added test_custom_clip_utils.py\n\nneed to fix tests\n\n* added call to search before add docs parallel\n\n* Added search call before parallel add_docs\n\n* fixed casing issue in SearchQuery\n\n* fixed tests\n\n* completed custom clip utils test\n\n* updated version\n\n* improved error msg, added bulk search tests\n\n* made custom clip tests stricter\n\n* added device to model auth cuda setup\n\n* added tests for CLIP._download_from_repo\n\n* added CLIP.load() tests\n\n* added OPEN_CLIP.load() tests\n\n* fixed private model and test\n\n* corrected HF auth and location inheritance\n\n* removed test_put_documents_orchestrator() as put_documents is deprecated\n\n* corrected version"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-02-28T03:18:22Z",
        "message": "[feature] Multimodal tensor combination (#332)\n\n* draft PR\n\n* add test\n\n* delete comments and prints\n\n* new design\n\n* adding test\n\n* add assertion\n\n* change comments\n\n* add more args\n\n* add more test\n\n* remove print\n\n* catch mainline\n\n* catch mainline\n\n* catch mainline\n\n* catch mainline\n\n* catch mainline\n\n* catch mainline\n\n* adding test\n\n* adding test\n\n* change _infer_opensearch_data_type\n\n* support dictionary\n\n* fix text\n\n* add test\n\n* revise parameters\n\n* add to image repo\n\n* revise again.\n\n* revised\n\n* add batch downloading.\n\n* revise test\n\n* add new test\n\n* remove space\n\n* revised.\n\n* revised.\n\n* revised.\n\n* revised.\n\n* update index info\n\n* update index info\n\n* update validation\n\n* update test for new api\n\n* updated\n\n* updated\n\n* add validate mappings\n\n* add todo\n\n* revised\n\n* revised\n\n* revised\n\n* revised\n\n* revised\n\n* revised\n\n* revised\n\n* add test\n\n* add test\n\n* add test\n\n* Mappings for add_docs (#355)\n\n* Update CONTRIBUTING.md\n\n* Update CONTRIBUTING.md\n\n* Adding mappings validation\n\n* mappings validation within add_documents\n\n* added mappings to endpoint and orchestrator: untested\n\n* add test\n\n* add more tests\n\n* add more tests\n\n* add more tests\n\n* finalise\n\n* add open_search test\n\n* update all the error messages.\n\n* update all the error messages.\n\n---------\n\nCo-authored-by: pandu-k <107458762+pandu-k@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-02-27T05:04:57Z",
        "message": "Update clip_utils.py (#351)\n\nupdate custom open_clip models to use open_clip base tokenizer instead of clip"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-02-20T11:09:11Z",
        "message": "Image download headings (#336)\n\n* add header for authentication\n\n* update load image path tests\n\n* remove headers as a required argument\n\n* update tests and image utils\n\n* fixed bugs\n\n* Changed headers type to dict internally\n\n* Image download headers propagated for search()\n\n* changed remaining image_download_headers param defaults to None\n\n---------\n\nCo-authored-by: Tom Hamer <tom@marqo.ai>"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-02-16T23:42:55Z",
        "message": "Fp16 clip update (#331)\n\n* update fp16 model and add tests\n\n* update fp16 model and add tests"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-02-14T00:39:38Z",
        "message": "[features] Open clip update (#305)\n\n* update open_clip models\n\n* update open_clip models\n\n* update open_clip models\n\n* update open_clip models\n\n* update open_clip models\n\n* add auto_cast to open_clip\n\n* add auto_cast to open_clip\n\n* convert to float32 at output to normalize it.\n\n* convert to float32 at output to normalize it.\n\n* add onnx32/open_clip/ViT-L-14/openai and\nonnx16/open_clip/ViT-L-14/openai"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-02-13T23:17:02Z",
        "message": "Broaden catch download error (#321)\n\n* RequestException is excepted, which is the super class of all requests errors\n\n* Fixed unit tests"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-02-12T23:14:31Z",
        "message": "bug fix (#315)"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-02-10T04:30:25Z",
        "message": "Concurrent image downloads  (#281)\n\n* added changed files from branch concurrent download img 2\n\n* refactored model registry/multilingual clip to prevent circular import\n\n* Fixed bug where a bounding box is returned rather than highlights\n\n* added test cases\n\n* removed unnecessary extra call\n\n* remove unused circular reference\n\n* added timeout of 3 seconds to image downloads\n\n* added timeout and unit tests\n\n* added timeout test to clip_utils\n\n* Widened the net of image download errors\n\n* Specific image retrieval error is passed to user"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-02-02T22:55:01Z",
        "message": "change downloading path for clip"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-02-01T23:52:19Z",
        "message": "revised based on pandu's comments"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-02-01T06:51:40Z",
        "message": "change error message"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-02-01T06:51:28Z",
        "message": "change error message"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-02-01T06:47:39Z",
        "message": "remove space"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-02-01T06:37:28Z",
        "message": "revise error style!"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-30T07:22:21Z",
        "message": "Separate clip and open_clip load"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-30T07:18:29Z",
        "message": "Separate clip and open_clip load"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-30T04:50:53Z",
        "message": "add test"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-30T04:46:12Z",
        "message": "add test"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-30T03:21:40Z",
        "message": "add test"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-27T01:59:01Z",
        "message": "add test"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-27T01:58:11Z",
        "message": "add test"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-27T01:57:31Z",
        "message": "add test"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-27T01:38:27Z",
        "message": "add test"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-27T01:29:58Z",
        "message": "add test"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-27T01:27:12Z",
        "message": "add test"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-27T01:20:08Z",
        "message": "open_clip finish"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-27T01:15:07Z",
        "message": "open_clip finish"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-25T07:40:14Z",
        "message": "add generic clip model tests"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-25T03:26:41Z",
        "message": "generic clip revise"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-25T03:13:52Z",
        "message": "generic clip revise"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-25T03:12:50Z",
        "message": "generic clip revise"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-25T03:11:16Z",
        "message": "generic clip revise"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-25T03:00:54Z",
        "message": "generic clip revise"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-25T02:52:44Z",
        "message": "add fp16 model support"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-25T01:02:11Z",
        "message": "add fp16 model support"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-25T00:21:15Z",
        "message": "add fp16 model support"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-24T09:50:24Z",
        "message": "add fp16 model support"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-24T02:43:56Z",
        "message": "add fp16 model support"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-24T02:40:26Z",
        "message": "add fp16 model support"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-24T02:34:39Z",
        "message": "add fp16 model support"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-24T02:25:40Z",
        "message": "add fp16 model support"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-24T01:01:04Z",
        "message": "add large scale test"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-11T05:42:19Z",
        "message": "only load visual in clip"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-11T05:39:20Z",
        "message": "only load visual in clip"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-10T23:00:56Z",
        "message": "add unit test for multilingual clip"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-10T07:20:56Z",
        "message": "add multilingual clip"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-10T07:18:59Z",
        "message": "add multilingual clip"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-10T05:31:24Z",
        "message": "add model registry"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-10T05:30:47Z",
        "message": "add model registry"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2023-01-06T07:28:22Z",
        "message": "Onnx refactor: adding open_clip onnx support, decouple image preprocess (#255)\n\n* merge model properties\n\n* add transform and open_clip support for onnx_clip\n\n* add transform and open_clip support for onnx_clip\n\n* add transform and open_clip support for onnx_clip\n\n* add transform and open_clip support for onnx_clip\n\n* add transform and open_clip support for onnx_clip\n\n* add transform and open_clip support for onnx_clip\n\n* update open_clip tokenizer function\n\n* update open_clip tokenizer function\n\n* add \"onnx32/open_clip/ViT-L-14/laionb_s32b_b82k\" and \"onnx16/open_clip/ViT-L-14/laionb_s32b_b82k\"\n\n* add \"onnx32/open_clip/ViT-L-14/laionb_s32b_b82k\" and \"onnx16/open_clip/ViT-L-14/laionb_s32b_b82k\"\n\n* add \"onnx32/open_clip/ViT-L-14/laionb_s32b_b82k\" and \"onnx16/open_clip/ViT-L-14/laionb_s32b_b82k\"\n\n* add \"onnx32/open_clip/ViT-L-14/laionb_s32b_b82k\" and \"onnx16/open_clip/ViT-L-14/laionb_s32b_b82k\"\n\n* add \"onnx32/open_clip/ViT-L-14/laionb_s32b_b82k\" and \"onnx16/open_clip/ViT-L-14/laionb_s32b_b82k\"\n\n* add \"onnx32/open_clip/ViT-L-14/laionb_s32b_b82k\" and \"onnx16/open_clip/ViT-L-14/laionb_s32b_b82k\"\n\n* add \"onnx32/open_clip/ViT-L-14-336/openai\"\n\n* add \"onnx32/open_clip/ViT-L-14-336/openai\"\n\n* onnx/open_clip/ViT-B-32/openai\n\n* onnx/open_clip/ViT-B-32/laion400m_e31\n\n* onnx/open_clip/ViT-B-32/laion400m_e31\n\n* onnx/open_clip/ViT-B-32/laion400m_e31\n\n* 'onnx32/open_clip/ViT-B-32-quickgelu/laion400m_e31'\n\n* 'onnx32/open_clip/ViT-B-32-quickgelu/laion400m_e32'\n\n* 'onnx32/open_clip/ViT-B-16/openai'\n\n* ViT-B-16/laion400m_e31\n\n* ViT-B-16/laion400m_e32\n\n* onnx32/open_clip/ViT-B-16-plus-240/laion400m_e31\n\n* ViT-B-16-plus-240/laion400m_e32\n\n* onnx32/open_clip/ViT-H-14/laion2b_s32b_b79k\n\n* adding zip, unzip logic\n\n* adding zip, unzip logic\n\n* adding zip, unzip logic\n\n* adding zip, unzip logic\n\n* adding zip, unzip logic\n\n* adding zip, unzip logic\n\n* adding zip, unzip logic\n\n* adding zip, unzip logic\n\n* adding zip, unzip logic\n\n* 'onnx32/open_clip/ViT-g-14/laion2b_s12b_b42k'\n\n* finish all the open_clip onnx model card\n\n* add test for onnx/open_clip\n\n* add test for onnx/open_clip\n\n* clear loaded models in encoding test\n\n* clear loaded models in encoding test\n\n* clear loaded models in encoding test\n\n* revise space between functions\n\n* revise space between functions"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2022-12-13T22:45:12Z",
        "message": "Visual search update release (#214)\n\n* Visual search update (#210)\n\n* add parametrisation for chunking, overlapping boxes and combined model+boxes\n\n* add more tests\n\n* integrate yolox and simple grid changes\n\n* helper functions for opencv and yolox\n\n* add yolox patch class and helper functions\n\n* update to use opencv\n\n* update model cache and add logging\n\n* fix model caching and device selection\n\n* device conflicts\n\n* add attention based bb generation\n\n* update bboxes and test yolo\n\n* refactor and add attention based ViT for bb determination\n\n* create dino specific utils file for vit attention\n\n* include dino files\n\n* split the image file into seperate utils\n\n* refactor, split into seperate files and use a proper base class\n\n* add more tests\n\n* update and add more tests\n\n* refactor and clean up\n\n* add more packages\n\n* clean up and refactor\n\n* update tests\n\n* docker and cloud versions\n\n* change\n\n* fix device for owl\n\n* update types and dco strings\n\n* rename file\n\n* rename file\n\n* move tests\n\n* pytorch utils test\n\n* add another error for model loading\n\n* update functions to handle some edge cases and update types\n\n* add more tests\n\n* update the yolox utils to download the proper model\n\n* add yolox specific tests\n\n* update reqs and setup to be on the latest\n\n* update dockerfile to be same as new one\n\n* clean up\n\n* add the example and app\n\n* update file locations\n\n* update demo\n\n* bump model version\n\n* update demo\n\n* minor text edits\n\n* update demo\n\n* update demo\n\n* better error handling\n\n* update tests\n\n* change to PIL error\n\n* add more error types\n\n* small fixes for errors\n\n* error handling\n\n* update tests\n\n* remove models\n\n* clean up, doc strings and formatting\n\n* update tests\n\n* minor formatting\n\nCo-authored-by: Jesse Clark <jesse@s2search.io>\n\n* update some function names after merge\n\n* clean up and rename\n\n* Pinning tox ci (#211)\n\n* Branch aware ci tests (#209)\n\n* set the MQ_API_TEST_BRANCH to the current branch\n\n* setting github ref to just branch name\n\n* Adding quotes around env var\n\n* fixed syntax error\n\n* parsing the github.ref string\n\n* exporting just before running\n\n* added image_to_test input\n\n* fix: typo\n\n* default image to test is now explicit\n\n* updated documentation for image_to_test var\n\n* Update unit_test_CI.yml\n\n* tox pinned to 3.26\n\nCo-authored-by: pandu-k <107458762+pandu-k@users.noreply.github.com>\nCo-authored-by: Pandu Oliver Kerr <pandu@s2search.io>\n\n* Update Dockerfile\n\nremove space\n\n* clean up\n\n* move to headless opencv\n\n* tidying up\n\n* update error\n\n* minor edits\n\n* fix PR feedback and add more descriptions in the docstrings\n\n* use literal type\n\n* clean up, make the names more descriptive\n\n* change logging level to debug for some messages\n\nCo-authored-by: Jesse Clark <jesse@s2search.io>\nCo-authored-by: pandu-k <107458762+pandu-k@users.noreply.github.com>\nCo-authored-by: Pandu Oliver Kerr <pandu@s2search.io>"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2022-12-02T06:30:39Z",
        "message": "use UnidentifiedImageError if it cannot be loaded from URL source"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2022-11-29T01:36:55Z",
        "message": "Check HTTP status for remote image paths"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2022-10-10T00:06:42Z",
        "message": "finish several comments"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2022-10-10T00:02:54Z",
        "message": "finish several comments"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2022-10-07T05:10:32Z",
        "message": "\"using clip model from open_clip\""
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2022-08-26T04:27:24Z",
        "message": "split the image load to be used elsewhere"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/clip_utils.py",
        "commit_date": "2022-08-02T09:06:24Z",
        "message": "init commit"
    },
    {
        "repo_url": "github.com/modelscope/modelscope",
        "filepath": "modelscope/models/multi_modal/clip_interrogator/model.py",
        "commit_date": "2024-02-21T06:24:24Z",
        "message": "Fix word pubicly -> publicly (#748)"
    },
    {
        "repo_url": "github.com/modelscope/modelscope",
        "filepath": "modelscope/models/multi_modal/clip_interrogator/model.py",
        "commit_date": "2023-05-22T02:53:18Z",
        "message": "add 1.6"
    },
    {
        "repo_url": "github.com/Docta-ai/docta",
        "filepath": "docta/core/preprocess.py",
        "commit_date": "2023-05-08T06:35:08Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/onnx_clip_utils.py",
        "commit_date": "2024-01-07T23:34:40Z",
        "message": "Improve error handling and API error codes (#656)\n\nCo-authored-by: Farshid Zavareh <farshid@marqo.ai>"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/onnx_clip_utils.py",
        "commit_date": "2023-06-23T06:31:19Z",
        "message": "Consolidating default device to CUDA when available (#508)\n\n* preliminary replacement work\n\n* changed a few cpus to cuda\n\n* add defaults in tensor search, bulk search, add docs, also added env var\n\n* 1st sweep of removing device params, on parallel now\n\n* transferred default calc from add docs to orch\n\n* replaced defaults in clip_utils.py\n\n* replaced defaults in s2_inference, clip_utils, onnx_utils\n\n* removed defaults everywhere\n\n* added device to vectorise, CLIP calls\n\n* updated device in other models, aux functions\n\n* added device for vectorise and encoding tests\n\n* added device to everything before test_add_documents\n\n* more test fixes\n\n* fixed more test, hardcoded cpu for _float_tensor_to_list\n\n* hardcoded cpu for _float_tensor_to_list\n\n* removed debug message for best available device\n\n* changed comment on vector text search\n\n* all tensor_search tests pass\n\n* fixed errors raised\n\n* added new unit tests, changed env var name\n\n* util env var, replace with empty dict\n\n* updated bulk search default and utils tests\n\n* separated on start method, added search test\n\n* updated validation and more tests\n\n* added unit tests for all internal func validations\n\n* added tests for add docs mp and batch request\n\n* removed validation from Model. Added to SBERT and HF models instead\n\n* added tests to fail if no default orch, search, bulk search\n\n* removed Model test\n\n* moved validation back to Model parent class\n\n* added Model no device test back in"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/onnx_clip_utils.py",
        "commit_date": "2023-04-19T11:17:59Z",
        "message": "Automatic model ejection (#372)\n\n* revise\n\n* revise\n\n* revise\n\n* revised\n\n* revised\n\n* revised\n\n* revised\n\n* revised\n\n* revised\n\n* revised\n\n* revised\n\n* revised\n\n* revised\n\n* revised\n\n* revised\n\n* revised\n\n* add time_stamps to all models\n\n* add time_stamps to all models\n\n* add time_stamps to all models\n\n* datetime\n\n* update\n\n* update\n\n* update\n\n* revise\n\n* revise\n\n* revise\n\n* revise\n\n* revise\n\n* typo\n\n* typo\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* add test\n\n* typo\n\n* updated\n\n* updated\n\n* updated\n\n* updated\n\n* revised.\n\n* revised.\n\n* revised.\n\n* revised.\n\n* revised.\n\n* revised.\n\n* revised.\n\n* revised.\n\n* revised.\n\n* revised.\n\n* revised.\n\n* revised.\n\n* revised.\n\n* revised.\n\n* revised.\n\n* update mock\n\n* update mock\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* update lock error\n\n* change error to 4xx\n\n* replace _load_model\n\n* updated\n\n* add lock\n\n* add lock\n\n* add lock\n\n* add lock\n\n* add lock\n\n* add lock\n\n* add lock\n\n* add lock\n\n* update to float\n\n* update to float\n\n* update to float\n\n* update to float\n\n* update to float\n\n* revised\n\n* revised\n\n* add a new test\n\n* revise the threading test\n\n* revise the threading test\n\n* revise the threading test\n\n* revised\n\n* revised\n\n* update errors\n\n* catch mainline\n\n* catch mainline\n\n* revised\n\n* finish the tensor_search.py\n\n* update comments\n\n* update unittest\n\n* update unittest\n\n* update unittest\n\n* update unittest\n\n* modify create index\n\n* modify create index\n\n* modify create index\n\n* modify create index\n\n* modify create index\n\n* modify create index\n\n* modify create index\n\n* modify create index\n\n* modify create index\n\n* update unittest\n\n* update unittest\n\n* update unittest\n\n* update unittest\n\n* update unittest\n\n* update unittest\n\n* update unittest\n\n* update unittest\n\n* update unittest\n\n* add torch.cuda.empty cache\n\n* update unit test\n\n* update unit test\n\n* updating unittest\n\n* updating unittest\n\n* updating unittest\n\n* update models are onnx can't be tested in tox\n\n* update models are onnx can't be tested in tox\n\n* update models as onnx can't be tested in cuda in tox\n\n* update models as onnx can't be tested in cuda in tox\n\n* update clear loaded models\n\n* update clear loaded models\n\n* update clear loaded models\n\n* update clear loaded models\n\n* update clear loaded models\n\n* update device\n\n* update device\n\n* update device\n\n* update device\n\n* update device\n\n* update device\n\n* update device\n\n* update device\n\n* update device\n\n* update device\n\n* update device\n\n* update test\n\n* change device\n\n* change form\n\n* stop multilingual clip\n\n* update onnxruntime-gpu version\n\n* update unittest model\n\n* revise onnx\n\n* revise onnx\n\n* revise onnx\n\n* revise onnx\n\n* revise onnx\n\n* address pandu comments."
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/onnx_clip_utils.py",
        "commit_date": "2023-02-20T11:09:11Z",
        "message": "Image download headings (#336)\n\n* add header for authentication\n\n* update load image path tests\n\n* remove headers as a required argument\n\n* update tests and image utils\n\n* fixed bugs\n\n* Changed headers type to dict internally\n\n* Image download headers propagated for search()\n\n* changed remaining image_download_headers param defaults to None\n\n---------\n\nCo-authored-by: Tom Hamer <tom@marqo.ai>"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/onnx_clip_utils.py",
        "commit_date": "2023-01-06T07:28:22Z",
        "message": "Onnx refactor: adding open_clip onnx support, decouple image preprocess (#255)\n\n* merge model properties\n\n* add transform and open_clip support for onnx_clip\n\n* add transform and open_clip support for onnx_clip\n\n* add transform and open_clip support for onnx_clip\n\n* add transform and open_clip support for onnx_clip\n\n* add transform and open_clip support for onnx_clip\n\n* add transform and open_clip support for onnx_clip\n\n* update open_clip tokenizer function\n\n* update open_clip tokenizer function\n\n* add \"onnx32/open_clip/ViT-L-14/laionb_s32b_b82k\" and \"onnx16/open_clip/ViT-L-14/laionb_s32b_b82k\"\n\n* add \"onnx32/open_clip/ViT-L-14/laionb_s32b_b82k\" and \"onnx16/open_clip/ViT-L-14/laionb_s32b_b82k\"\n\n* add \"onnx32/open_clip/ViT-L-14/laionb_s32b_b82k\" and \"onnx16/open_clip/ViT-L-14/laionb_s32b_b82k\"\n\n* add \"onnx32/open_clip/ViT-L-14/laionb_s32b_b82k\" and \"onnx16/open_clip/ViT-L-14/laionb_s32b_b82k\"\n\n* add \"onnx32/open_clip/ViT-L-14/laionb_s32b_b82k\" and \"onnx16/open_clip/ViT-L-14/laionb_s32b_b82k\"\n\n* add \"onnx32/open_clip/ViT-L-14/laionb_s32b_b82k\" and \"onnx16/open_clip/ViT-L-14/laionb_s32b_b82k\"\n\n* add \"onnx32/open_clip/ViT-L-14-336/openai\"\n\n* add \"onnx32/open_clip/ViT-L-14-336/openai\"\n\n* onnx/open_clip/ViT-B-32/openai\n\n* onnx/open_clip/ViT-B-32/laion400m_e31\n\n* onnx/open_clip/ViT-B-32/laion400m_e31\n\n* onnx/open_clip/ViT-B-32/laion400m_e31\n\n* 'onnx32/open_clip/ViT-B-32-quickgelu/laion400m_e31'\n\n* 'onnx32/open_clip/ViT-B-32-quickgelu/laion400m_e32'\n\n* 'onnx32/open_clip/ViT-B-16/openai'\n\n* ViT-B-16/laion400m_e31\n\n* ViT-B-16/laion400m_e32\n\n* onnx32/open_clip/ViT-B-16-plus-240/laion400m_e31\n\n* ViT-B-16-plus-240/laion400m_e32\n\n* onnx32/open_clip/ViT-H-14/laion2b_s32b_b79k\n\n* adding zip, unzip logic\n\n* adding zip, unzip logic\n\n* adding zip, unzip logic\n\n* adding zip, unzip logic\n\n* adding zip, unzip logic\n\n* adding zip, unzip logic\n\n* adding zip, unzip logic\n\n* adding zip, unzip logic\n\n* adding zip, unzip logic\n\n* 'onnx32/open_clip/ViT-g-14/laion2b_s12b_b42k'\n\n* finish all the open_clip onnx model card\n\n* add test for onnx/open_clip\n\n* add test for onnx/open_clip\n\n* clear loaded models in encoding test\n\n* clear loaded models in encoding test\n\n* clear loaded models in encoding test\n\n* revise space between functions\n\n* revise space between functions"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/onnx_clip_utils.py",
        "commit_date": "2022-12-30T01:33:57Z",
        "message": "delete printing lines (#252)"
    },
    {
        "repo_url": "github.com/marqo-ai/marqo",
        "filepath": "src/marqo/s2_inference/onnx_clip_utils.py",
        "commit_date": "2022-12-29T06:50:14Z",
        "message": "[Onnx clip]Adding the clip_onnx to our avaible models for faster inference (#245)\n\n* onnx32/openai/ViT-L/14\n\n* onnx32/openai/ViT-L/14\n\n* onnx32/openai/ViT-L/14\n\n* onnx32/openai/ViT-L/14\n\n* add a timer\n\n* add a timer\n\n* add a timer\n\n* add a timer\n\n* add a timer\n\n* add a timer\n\n* add a timer\n\n* add a timer\n\n* add a timer\n\n* add a timer\n\n* add a timer\n\n* add a timer\n\n* add a timer\n\n* add a timer\n\n* add a timer\n\n* cleaning\n\n* add test for onnx_clip\n\n* make sure onnx-16 model still use float32 for textual inference for best accuracy.\n\n* make sure onnx-16 model still use float32 for textual inference for best accuracy.\n\n* we merge the hf models.\n\n* update id to _device_id"
    },
    {
        "repo_url": "github.com/microsoft/Cream",
        "filepath": "TinyCLIP/inference.py",
        "commit_date": "2023-10-25T15:21:08Z",
        "message": "[TinyCLIP] Inference Example (#196)\n\n* [TinyCLIP] Inference Example"
    },
    {
        "repo_url": "github.com/mlfoundations/open_clip",
        "filepath": "tests/util_test.py",
        "commit_date": "2023-05-12T18:35:41Z",
        "message": "Add EVA models (via timm backbone), torch.compile support, more (#500)\n\n* Add EVA models (via timm backbone), torch.compile support, pure bf16/fp16 mode, safetensors push support\n\n* Fix optional type refinement for torchscript\n\n* Back torchcompile changes out of factory, needs to be closer to use for various reasons\n\n* Fix output_dict + jit regression, remove native OpenAI jit load as it's not working reliably in PyTorch 2.0, always extract state-dict, load model, re-jit (if enabled)"
    },
    {
        "repo_url": "github.com/mlfoundations/open_clip",
        "filepath": "tests/util_test.py",
        "commit_date": "2023-01-29T00:41:42Z",
        "message": "Add coca trained (#307) (#308)\n\n* Add coca trained (#307)\n\n* initial setup\n\n* add coca loss\n\n* remove loss from the model\n\n* fix loss\n\n* add underscores\n\n* name changes\n\n* add cross attention to Residual and CustomResidual\n\n* fix if\n\n* \u00e4dd transformer 'decoder'\n\n* minor fix\n\n* looks better\n\n* initlize coca model structure\n\n* clean\n\n* typo and format\n\n* checkpoint signature\n\n* adjust multimodal decoder and add CoCaTransformer\n\n* keep older logic\n\n* remove chunk\n\n* typo\n\n* fix\n\n* make chunk dim explicit\n\n* adjust cfg names\n\n* add attentionalpooling\n\n* add attentional pooling to coca\n\n* small change\n\n* add cocatransformer variants and AttentionPooling\n\n* remoive older attention pooler\n\n* adapt embed text to coca text transformer\n\n* rm coca layers\n\n* rename and remove useless CoCa models\n\n* make attentionpooler pooler only\n\n* refactor for one transformer only\n\n* coca forward works\n\n* separatae context and n_queries\n\n* add inital coca_base config\n\n* remove config\n\n* small loss change\n\n* init training file\n\n* make variable order right\n\n* remove print\n\n* uniform names\n\n* renaming\n\n* add coca funcs to init\n\n* add coca config and exclude from testing\n\n* add and comment simple test (no trained model)\n\n* add L2 norm\n\n* make L2 same as in clip\n\n* remove unused temperature\n\n* type\n\n* clean\n\n* fix config\n\n* make rename and move cfg\n\n* rename\n\n* temptative add coca to factory\n\n* fix config\n\n* update config\n\n* embed contrastive cls token in model\n\n* remove unused arg\n\n* import create_loss\n\n* make factory accept coca\n\n* make caption loss distributed\n\n* make loss customizable\n\n* pass loss trhough training_epoch\n\n* add coca specific params to params\n\n* removed decoder unused parameters\n\n* remove unused attributes\n\n* adjust coca_config\n\n* fix config and remove unused parameters\n\n* remove comment\n\n* remove more comments\n\n* rename attention pooler\n\n* rename TransformerDecoder\n\n* make AttentionalPooler clearer\n\n* add local loss logic to cocaloss\n\n* only create loss if train in data\n\n* remove wrong file\n\n* fix attentional pooler call\n\n* not ready for testing\n\n* really not ready for testing\n\n* eof lien\n\n* uniform names\n\n* add possible generative loss to evaluate\n\n* change _build function names\n\n* remove wrong import\n\n* remove local_loss from captioning loss\n\n* indexing error\n\n* finish renaming\n\n* adjust configs\n\n* add training test for coca\n\n* simplify captioning loss\n\n* remove hf\n\n* fix evaluate and loss\n\n* remove print\n\n* move projection\n\n* add coca vit 32 config\n\n* test on new config\n\n* adjust coca_base config\n\n* remove coca from test_inference\n\n* maybe fix regression test\n\n* make logits and labels contiguous\n\n* simpler logic\n\n* make contiguous after transpose\n\n* last test\n\n* try fix loss\n\n* CoCa PR: loss fix + rename file\n\n* wait for feedback on this\n\n* cleanup\n\n* CoCa PR: add set_grad_checkpointing + fix checkpoint API\n\n* CoCa PR: fix eval (which uses encode_x instead of forward)\n\n* move making space for CLS token into encode_text\n\n* rever zs changes + fix\n\nCo-authored-by: gpucce <g.puccetti92@gmail.com>\nCo-authored-by: gpucce <g.puccetti@gmail.com>\nCo-authored-by: iejmac <iejmac@ip-172-31-44-155.ec2.internal>\n\n* Add coca to CI\n\n* Add coca to CI pr\n\n* simplify encode_iamge (#313)\n\nCo-authored-by: Romain Beaumont <romain.rom1@gmail.com>\n\n* Add cls mask (#312)\n\n* buil_cls_mask\n\n* add cls_mask to encode_text\n\n* add model properties\n\nCo-authored-by: Romain Beaumont <romain.rom1@gmail.com>\nCo-authored-by: gpucce <g.puccetti@gmail.com>\n\n* Ignore pad tokens in captioning loss (#316)\n\n* add ignore_index\n\n* just need to pick right index\n\nCo-authored-by: gpucce <g.puccetti@gmail.com>\n\n* add `generate` to coca model (#314)\n\n* add initial generative support\n\n* make generation context_length independend\n\n* remove kwargs\n\n* last positional embeddings for CLS\n\n* typo\n\n* fix mask len\n\n* add comment\n\n* remove unused args\n\n* simpler logic for input shorter than context length\n\nCo-authored-by: gpucce <g.puccetti@gmail.com>\n\n* use `TextEncoder` in coca `encode_image` (#321)\n\n* use self.text in encode image\n\n* unused var\n\n* rever aAtention and CustoResidualAttentionBlock\n\n* remove whiteline\n\n* add dict output\n\n* bintegrate self.text attributes\n\n* HF compatibility\n\n* better config and minor fixes\n\n* clean\n\n* remove eembed_cls option from HF\n\n* use cls_token_position\n\n* fix cls masking\n\n* resize labels\n\n* text -> self.text\n\n* split loss logging\n\n* add total loss\n\n* minor logs formatting\n\n* fix generate\n\n* simpler logic\n\n* disentangle proj for HF too\n\n* adjust config\n\n* only norm cls\n\n* move attn_pool to VisionTransformer\n\n* adjust coca_base config\n\n* fix grad checkpointing in MultimodalTransformer\n\nCo-authored-by: gpucce <g.puccetti@gmail.com>\nCo-authored-by: iejMac <kilianmaciej6@gmail.com>\n\n* Get some basic PEP changes out of the way\n\n* Add tests bis (#355)\n\n* make jit compilable\n\n* redundant annotation\n\n* less tests\n\n* less annotations\n\n* even less annotations\n\n* fix name check in ci\n\n* some annotations back\n\n* make it simpler\n\n* make hf simpler too\n\n* better jit support with tests\n\n* remove extra line\n\n* add customtextclip\n\n* more jit tests\n\n* missing assert\n\n* add eval\n\n* typo\n\n* rever forward changes\n\n* clean coca model\n\n* more cleaning\n\n* last cleaning\n\n* train.py: fix is_clip when doing distributed (#364)\n\n* add README (#365)\n\n* add README\n\n* multimodal_cfg info\n\n* multimodal\n\n* remove output_dict argument (#368)\n\n* remove output_dict argument\n\n* cleaner\n\n* do same thing for _encode_image (#366)\n\n* do same thing for _encode_image\n\n* encoder\n\n* try this\n\n* adjust inference tests\n\n* fix syntax\n\n* True not None\n\n* dumb\n\n* CoCa/forward: remove unused output_dict param\n\n* Revert \"do same thing for _encode_image (#366)\"\n\nThis reverts commit de343fb73e9512c63bcbf3d902359c652580aef0.\n\n* refactor\n\n* white space\n\n* remove extra layer norm\n\n* move to_logits into decoder\n\n* leave for later\n\n* better torchscript\n\n* annotate hf too\n\n* Add CoCa-ViT-L/14 config (#379)\n\n* Remove dead LN code, refactor attn_pool conditional for more clarity, minor formatting tweaks\n\n* latent_dim to embed_dim\n\n* remove extra cfg\n\n* A bit more cleanup, keep context_length as context len, 'num_pos' to incl extra tokens. None type check for embed_cls instead of getattr\n\n* CoCa: add B/32 pretrained (#389)\n\n* add B/32 pretrained\n\n* fix\n\n* no capital\n\n* slash\n\n* remove coca from ci.yml\n\n---------\n\nCo-authored-by: gpucce <g.puccetti92@gmail.com>\nCo-authored-by: gpucce <g.puccetti@gmail.com>\nCo-authored-by: iejmac <iejmac@ip-172-31-44-155.ec2.internal>\nCo-authored-by: iejMac <kilianmaciej6@gmail.com>\nCo-authored-by: Ross Wightman <rwightman@gmail.com>"
    },
    {
        "repo_url": "github.com/mlfoundations/open_clip",
        "filepath": "tests/util_test.py",
        "commit_date": "2022-12-09T00:40:09Z",
        "message": "CI: on-the-fly data generation for regression test determinism (#260)\n\n* CI on-the-fly data generation for regression tests\n\n* delete old reg test data\n\n* util_test.py option to create test data for specific git revision\nskip instead of fail regression tests if data not found\nregister pytest markers in pytest.ini\n\n* use sha instead of branch name if on a detached HEAD\nfixed typo\n\n* CI: save model list util_test to ensure no model names leak from test to reference\n\n* CI: use marker instead of name filter to collect model names from pytest\n\n* CI: use manual revision for checkout action\n\n* util_test: avoid nested exception to make sure working tree is being restored on failure\n\n* cache venv with minor version specific python\nensure durations file exists\n\n* only pop stash if changes were stashed\n\n* keep naming for env and durations cache the same\n\nCo-authored-by: Romain Beaumont <romain.rom1@gmail.com>"
    },
    {
        "repo_url": "github.com/mlfoundations/open_clip",
        "filepath": "tests/util_test.py",
        "commit_date": "2022-11-20T00:03:34Z",
        "message": "create HF models without pretrained weights (#235)\n\nHF model inference tests on random models"
    },
    {
        "repo_url": "github.com/mlfoundations/open_clip",
        "filepath": "tests/util_test.py",
        "commit_date": "2022-11-17T17:32:24Z",
        "message": "Parallelize CI tests (#228)\n\n* parallelize CI tests\n\n* disable macos testing for now, as it's slow\n\n* typo\n\n* util_test only import argparse if called as script"
    },
    {
        "repo_url": "github.com/mlfoundations/open_clip",
        "filepath": "tests/util_test.py",
        "commit_date": "2022-11-12T17:49:07Z",
        "message": "inference testing using pre-generated data"
    },
    {
        "repo_url": "github.com/mlfoundations/open_clip",
        "filepath": "tests/test_inference_simple.py",
        "commit_date": "2023-01-30T22:38:24Z",
        "message": "Cover jit and force_custom_text in simple tests"
    },
    {
        "repo_url": "github.com/mlfoundations/open_clip",
        "filepath": "tests/test_inference_simple.py",
        "commit_date": "2022-11-13T10:51:10Z",
        "message": "Add roberta base ViT-B/32 pretrained. (#221)\n\n* Add roberta base ViT-B/32 pretrained.\n\nA ViT-B/32 with roberta base encoder with a 61.7% top-1 ImageNet-1k zero-shot was trained on stability. See model details here https://huggingface.co/laion/CLIP-ViT-B-32-roberta-base-laion2B-s12B-b32k\nThis is the first openclip model using a HF text tower. It has better performance on a range of tasks compared to the standard text encoder, see [metrics](https://huggingface.co/laion/CLIP-ViT-B-32-roberta-base-laion2B-s12B-b32k/blob/main/unknown.png)\n\n* test"
    },
    {
        "repo_url": "github.com/mlfoundations/open_clip",
        "filepath": "tests/test_inference_simple.py",
        "commit_date": "2022-11-10T10:23:24Z",
        "message": "training/params.py: remove hf params and get them from model config (#215)\n\n* zero_shot.py: set correct tokenizer based on args\n\n* training/params.py: remove HF specific params, get those automatically from config\n\n* set tokenizer in PreTrainedTextEncoder\n\n* fix CsvDataset\n\n* take tokenizer name from tokenizer\n\n* Fix\n\n* add tok name to test\n\n* None\n\n* update\n\n* no need to store this anymore\n\n* upadte README\n\n* add tokenizer attribute\n\n* remove useless code\n\n* update example\n\n* use model.tokenizer in test inference simple\n\n* trying getattr\n\n* syntax\n\n* get_tokenizer\n\n* factory fix\n\n* fix test\n\n* fix\n\n* fix'\n\n* add get-tokenizer to README + update exmaple\n\n* update README\n\n* zero-shot get_tokenizer\n\nCo-authored-by: Romain Beaumont <romain.rom1@gmail.com>\nCo-authored-by: iejmac <iejmac@gpu-st-p4d-24xlarge-4.hpc-1click-sandbox.pcluster>"
    },
    {
        "repo_url": "github.com/mlfoundations/open_clip",
        "filepath": "tests/test_inference_simple.py",
        "commit_date": "2022-11-07T18:58:43Z",
        "message": "Implement simple training test. (#203)\n\nOnly runs the training, no actual check except no crashes.\n\nFor #198"
    },
    {
        "repo_url": "github.com/mlfoundations/open_clip",
        "filepath": "tests/test_download_pretrained.py",
        "commit_date": "2023-01-23T23:59:33Z",
        "message": "Fetch from Hugging Face Hub using hf_hub: prefix"
    },
    {
        "repo_url": "github.com/mlfoundations/open_clip",
        "filepath": "tests/test_download_pretrained.py",
        "commit_date": "2022-11-07T13:49:38Z",
        "message": "fix download pretrained test"
    },
    {
        "repo_url": "github.com/mlfoundations/open_clip",
        "filepath": "tests/test_download_pretrained.py",
        "commit_date": "2022-11-07T13:34:49Z",
        "message": "Add checksum verification for pretrained model weights downloaded from mlfoundations github releases url (#145)"
    },
    {
        "repo_url": "github.com/eric-ai-lab/MiniGPT-5",
        "filepath": "metric.py",
        "commit_date": "2023-10-04T02:05:44Z",
        "message": "init push"
    },
    {
        "repo_url": "github.com/GoogleCloudPlatform/vertex-ai-samples",
        "filepath": "community-content/vertex_model_garden/model_oss/open_clip/handler.py",
        "commit_date": "2024-02-20T15:17:32Z",
        "message": "Unify the model name as MODEL_ID in related containers and notebooks. (#2720)"
    },
    {
        "repo_url": "github.com/GoogleCloudPlatform/vertex-ai-samples",
        "filepath": "community-content/vertex_model_garden/model_oss/open_clip/handler.py",
        "commit_date": "2023-12-04T15:11:07Z",
        "message": "copy vertex_vision_model_garden as vertex_model_garden (#2565)"
    },
    {
        "repo_url": "github.com/YuxinWenRick/hard-prompts-made-easy",
        "filepath": "optim_utils.py",
        "commit_date": "2023-04-02T16:02:47Z",
        "message": "optim tru stable diffusion"
    },
    {
        "repo_url": "github.com/YuxinWenRick/hard-prompts-made-easy",
        "filepath": "optim_utils.py",
        "commit_date": "2023-02-16T23:01:21Z",
        "message": "update negative prompt example"
    },
    {
        "repo_url": "github.com/YuxinWenRick/hard-prompts-made-easy",
        "filepath": "optim_utils.py",
        "commit_date": "2023-02-10T01:54:36Z",
        "message": "add CLI script, clean up readme, clean up printing"
    },
    {
        "repo_url": "github.com/YuxinWenRick/hard-prompts-made-easy",
        "filepath": "optim_utils.py",
        "commit_date": "2023-02-07T17:13:46Z",
        "message": "init commit"
    },
    {
        "repo_url": "github.com/Algolzw/daclip-uir",
        "filepath": "da-clip/src/evaluate.py",
        "commit_date": "2023-10-07T09:22:47Z",
        "message": "update readme"
    },
    {
        "repo_url": "github.com/UMass-Foundation-Model/3D-LLM",
        "filepath": "three_steps_3d_feature/second_step/clip_sam.py",
        "commit_date": "2023-07-25T20:48:41Z",
        "message": "change_format"
    },
    {
        "repo_url": "github.com/UMass-Foundation-Model/3D-LLM",
        "filepath": "three_steps_3d_feature/second_step/clip_sam.py",
        "commit_date": "2023-07-25T16:21:20Z",
        "message": "3d_recon_readme"
    },
    {
        "repo_url": "github.com/UMass-Foundation-Model/3D-LLM",
        "filepath": "three_steps_3d_feature/second_step/clip_sam.py",
        "commit_date": "2023-07-24T22:31:18Z",
        "message": "features"
    },
    {
        "repo_url": "github.com/zideliu/StyleDrop-PyTorch",
        "filepath": "predict.py",
        "commit_date": "2023-07-07T21:06:29Z",
        "message": "replicate"
    },
    {
        "repo_url": "github.com/alaamaalouf/FollowAnything",
        "filepath": "follow_anything.py",
        "commit_date": "2023-12-05T19:37:20Z",
        "message": "fix threshold"
    },
    {
        "repo_url": "github.com/alaamaalouf/FollowAnything",
        "filepath": "follow_anything.py",
        "commit_date": "2023-08-13T15:15:37Z",
        "message": "follow_anything stop once it finishes reading offline video"
    },
    {
        "repo_url": "github.com/alaamaalouf/FollowAnything",
        "filepath": "follow_anything.py",
        "commit_date": "2023-08-01T14:18:07Z",
        "message": "code for detect, track, and follow + code for creating query features using DINO"
    },
    {
        "repo_url": "github.com/roatienza/Deep-Learning-Experiments",
        "filepath": "versions/2023/model_serving/demo/triton/server.py",
        "commit_date": "2023-11-18T02:20:33Z",
        "message": "model serving"
    },
    {
        "repo_url": "github.com/zideliu/StyleDrop-PyTorch",
        "filepath": "gradio_demo.py",
        "commit_date": "2023-08-23T09:45:07Z",
        "message": "Update gradio_demo.py"
    },
    {
        "repo_url": "github.com/zideliu/StyleDrop-PyTorch",
        "filepath": "gradio_demo.py",
        "commit_date": "2023-08-23T09:41:19Z",
        "message": "Update gradio_demo.py"
    },
    {
        "repo_url": "github.com/zideliu/StyleDrop-PyTorch",
        "filepath": "gradio_demo.py",
        "commit_date": "2023-08-23T09:29:52Z",
        "message": "Update gradio_demo.py"
    },
    {
        "repo_url": "github.com/zideliu/StyleDrop-PyTorch",
        "filepath": "gradio_demo.py",
        "commit_date": "2023-07-09T00:52:03Z",
        "message": "update for colab"
    },
    {
        "repo_url": "github.com/zideliu/StyleDrop-PyTorch",
        "filepath": "gradio_demo.py",
        "commit_date": "2023-07-09T00:07:07Z",
        "message": "update gradio demo"
    },
    {
        "repo_url": "github.com/zideliu/StyleDrop-PyTorch",
        "filepath": "gradio_demo.py",
        "commit_date": "2023-07-05T05:09:29Z",
        "message": "fix some bugs"
    },
    {
        "repo_url": "github.com/zideliu/StyleDrop-PyTorch",
        "filepath": "gradio_demo.py",
        "commit_date": "2023-07-05T03:49:03Z",
        "message": "ADD set_seed"
    },
    {
        "repo_url": "github.com/zideliu/StyleDrop-PyTorch",
        "filepath": "gradio_demo.py",
        "commit_date": "2023-07-04T03:10:02Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/UMass-Foundation-Model/3D-LLM",
        "filepath": "three_steps_3d_feature/second_step/clip_maskformer.py",
        "commit_date": "2023-07-25T20:48:41Z",
        "message": "change_format"
    },
    {
        "repo_url": "github.com/UMass-Foundation-Model/3D-LLM",
        "filepath": "three_steps_3d_feature/second_step/clip_maskformer.py",
        "commit_date": "2023-07-25T16:21:20Z",
        "message": "3d_recon_readme"
    },
    {
        "repo_url": "github.com/AnyLoc/AnyLoc",
        "filepath": "clip_wrapper.py",
        "commit_date": "2023-08-02T17:09:32Z",
        "message": "Created first (public) release"
    },
    {
        "repo_url": "github.com/VoltaML/voltaML-fast-stable-diffusion",
        "filepath": "core/interrogation/clip.py",
        "commit_date": "2023-11-21T18:05:16Z",
        "message": "float8 support"
    },
    {
        "repo_url": "github.com/VoltaML/voltaML-fast-stable-diffusion",
        "filepath": "core/interrogation/clip.py",
        "commit_date": "2023-11-07T21:11:27Z",
        "message": "Redo imports from diffusers to satisfy Pylance"
    },
    {
        "repo_url": "github.com/VoltaML/voltaML-fast-stable-diffusion",
        "filepath": "core/interrogation/clip.py",
        "commit_date": "2023-10-18T19:33:19Z",
        "message": "Remove pylint"
    },
    {
        "repo_url": "github.com/VoltaML/voltaML-fast-stable-diffusion",
        "filepath": "core/interrogation/clip.py",
        "commit_date": "2023-08-02T17:36:09Z",
        "message": "Purge rich.progress and replace it with tqdm, queue progress added"
    },
    {
        "repo_url": "github.com/VoltaML/voltaML-fast-stable-diffusion",
        "filepath": "core/interrogation/clip.py",
        "commit_date": "2023-08-01T18:35:14Z",
        "message": "Arbitrary size + Inference cleanup (#128)\n\nCleaned the inference backend code a little bit, now it should have less\nredundant/copy-pasted code.\n\nAlso made odd/non-8-aligned sizes possible to do with PyTorch.\n*AIT - arbitrary sizes at the very least - has some peculiar issues with\nControlNet so I decided to drop it from this PR*\n\n---------\n\nCo-authored-by: Stax124 <tamoncz@gmail.com>\nCo-authored-by: Stax124 <60222162+Stax124@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/VoltaML/voltaML-fast-stable-diffusion",
        "filepath": "core/interrogation/clip.py",
        "commit_date": "2023-07-29T09:20:23Z",
        "message": "Quantized CLIP (#123)\n\n# TL;DR;\n- `/api/hardware/capabilities`\n- drops support for IREE (may come back later, just don't have the time\nto support it)\n- CLIP quantization\n- frontend: settings ui revamp\n  - more *optional, **disappearing*** settings based on conditions\n  - dynamic options based on capabilities of host machine\n# \nIn an attempt to further lower latency, I've tried to quantize the text\nencoder to 8bit/4bit.\nThis PR also includes some revamps to the settings menu and a new API\nendpoint `/hardware/capabilities`.\nThe endpoint returns a short run-down of what the hardware can do, an\nexample response is the following:\n```json5\n{\n\t\"supported_backends\": [\"cpu\", \"cuda\"],\n\t\"supported_precisions_cpu\": [\"float32\", \"bfloat16\"],\n\t\"supported_precisions_gpu\": [\"float32\", \"bfloat16\", \"float16\"],\n\t\"supported_torch_compile_backends\": [\"aot_ts_nvfuser\", \"cudagraphs\", \"inductor\", \"nvprims_nvfuser\", \"onnxrt\"],\n\t\"has_tensorfloat\": true, // true if user has ampere+\n\t\"has_tensor_cores\": true, // true if user has volta+\n\t\"supports_xformers\": false, // true if current installation supports xformers, false for torch nightlies\n\t\"supports_int8\": true // true if a basic quantized matmul is successful\n}\n```\nQuantization requires the installation of\n[bitsandbytes](https://github.com/TimDettmers/bitsandbytes/), however it\nis completely optional. Attached is the same generation (40 steps,\nDPMSolverSinglestep, seed: 123123, prompt: \"1girl\") at different\nquantization levels.\n\nTODO:\n\n- [ ] Update capabilities when something changes\n- [ ] Investigate print-out when loading models with quantization\n\nFull precision:\n\n![f711ee6d-c547-4880-886a-7b3c0b054f03-0](https://github.com/VoltaML/voltaML-fast-stable-diffusion/assets/22561485/0f5b2c96-cc95-4b73-b798-604b18dcb84a)\n\n8-bit quantization:\n\n![58a32c8f-735e-4640-aec9-2239bab7bb6d-0](https://github.com/VoltaML/voltaML-fast-stable-diffusion/assets/22561485/218b3697-408c-4df6-985c-17685ea28fff)\n\n4-bit quantization:\n\n![8fe123f0-8246-42c7-b14e-42f6538db7f3-0](https://github.com/VoltaML/voltaML-fast-stable-diffusion/assets/22561485/afb06e0b-b467-47cc-adba-d4c41766327b)\n\n---------\n\nCo-authored-by: Stax124 <tamoncz@gmail.com>"
    },
    {
        "repo_url": "github.com/VoltaML/voltaML-fast-stable-diffusion",
        "filepath": "core/interrogation/clip.py",
        "commit_date": "2023-06-18T11:41:08Z",
        "message": "Affix deps, fix AITemplate, set SDPA as default attention"
    },
    {
        "repo_url": "github.com/VoltaML/voltaML-fast-stable-diffusion",
        "filepath": "core/interrogation/clip.py",
        "commit_date": "2023-05-18T17:14:47Z",
        "message": "Autocast, VAE tiling & fix offload (#82)\n\n* autocast stuff\n\n* autocast pt. 2\n\n* enable offload\n\n* autocast\n\n* frontend\n\n* Fix model offload... again...\n\n* Precision changes & autocast fixes\n\n* fix model offload in img2img\n\n* fix no-offload\n\n* only initialize autocast if directml autocast is needed\n\n* fix disable=True on torch.dml.autocast\n\n* Build frontend with locked deps\n\n* onnx fix\n\n* fix ait\n\n* reorder sorts\n\n---------\n\nCo-authored-by: Stax124 <tamoncz@gmail.com>"
    },
    {
        "repo_url": "github.com/VoltaML/voltaML-fast-stable-diffusion",
        "filepath": "core/interrogation/clip.py",
        "commit_date": "2023-05-06T17:10:05Z",
        "message": "Multiple device support & PyTorch optimizations (#62)\n\n* Start work on further jit trace options\n\n* format\n\n* AMD gpu info support & memory clear option\n\n* clear_memory_policy\n\n* Fix manager\n\n* Cuda flags\n\n* Pyamdgpuinfo\n\n* format\n\n* Cleanup, refactor\n\n* format\n\n* oops\n\n* fix perf_loop\n\n* format\n\n* fix everything\n\n* format\n\n* Formatting, support for extra requirement check for Linux\n\n* trace\n\n* format\n\n* UI, renames, cleanup\n\n* PyLint cleanups\n\n* Rebuild frontend\n\n* no more one-way\n\n* only enable reduced prec on ampere+\n\n* Cleaning stuff up & HW Scheduling check on Windows\n\n* format\n\n* Add DirectML support\n\n* fix stuffix stuff\n\n* a\n\n* ipex stuff pt. 1\n\n* Revamp #install_pytorch() and further IPEX optimizations\n\n* try & fix xpu\n\n* fix pt2\n\n* fix requirements\n\n* ipex fix\n\n* XPU changes\n\n* Revamp install_requirements.py & fix config order\n\n* fix interrogators on directml\n\n* start work on iree\n\n* fix things\n\n* iree progress\n\nI GOT PAST TORCH-MLIR :tada:\nnow I just need to get iree to work as well :)\n\n* cleanup\n\n* basic profiling\n\n* Black, fix some merge issues\n\n* Get rid of the profiler\n\n* Reformat\n\n* Fix .vscode/settings.json\n\n* Cleanup, purge unnecessary stuff\n\n* Fix TextualInversions on Windows\n\n* Get rid of duped file, add spinner to optimization\n\n* Frontend add more backend settings\n\n---------\n\nCo-authored-by: Stax124 <tamoncz@gmail.com>"
    },
    {
        "repo_url": "github.com/VoltaML/voltaML-fast-stable-diffusion",
        "filepath": "core/interrogation/clip.py",
        "commit_date": "2023-04-23T10:48:33Z",
        "message": "Interrogators (#56)\n\n* try to quantize things\n\n* Start work on interrogators\n\n(Deepdanbooru is the only one tested, and it works)\n\n* finish interrogation work\n\n* Revert lwp_sd.py\n\n* Refactor\n\n* Partial Frontend for tagger\n\n* Fix requirement installer\n\n* Frontend functional\n\n---------\n\nCo-authored-by: Stax124 <tamoncz@gmail.com>"
    },
    {
        "repo_url": "github.com/lancedb/vectordb-recipes",
        "filepath": "examples/arxiv-recommender/main.py",
        "commit_date": "2024-02-01T16:01:42Z",
        "message": "linting  (#130)\n\n* talk with podcast\n\n* added talk-with-podcast\n\n* imgs\n\n* updated readme\n\n* added requirements file\n\n* added support for Langroid\n\n* typo\n\n* requirements update\n\n* path and colab fix\n\n* sentiment link fix\n\n* comments in colab\n\n* fix\n\n* description change\n\n* doc link fix\n\n* talk-with-wikipedia\n\n* added pylinting\n\n* added pylinting\n\n* removed pylint\n\n* lint test\n\n* lint path\n\n* added polar\n\n---------\n\nCo-authored-by: Ayush Chaurasia <ayush.chaurarsia@gmail.com>"
    },
    {
        "repo_url": "github.com/lancedb/vectordb-recipes",
        "filepath": "examples/arxiv-recommender/main.py",
        "commit_date": "2023-08-24T10:57:24Z",
        "message": "update"
    },
    {
        "repo_url": "github.com/lancedb/vectordb-recipes",
        "filepath": "examples/arxiv-recommender/main.py",
        "commit_date": "2023-08-17T11:52:40Z",
        "message": "add initial files"
    },
    {
        "repo_url": "github.com/ByChelsea/VAND-APRIL-GAN",
        "filepath": "train.py",
        "commit_date": "2023-07-05T08:35:29Z",
        "message": "faster"
    },
    {
        "repo_url": "github.com/ByChelsea/VAND-APRIL-GAN",
        "filepath": "train.py",
        "commit_date": "2023-06-28T07:24:16Z",
        "message": "Simpler Version"
    },
    {
        "repo_url": "github.com/ByChelsea/VAND-APRIL-GAN",
        "filepath": "train.py",
        "commit_date": "2023-06-21T13:53:00Z",
        "message": "bug fix"
    },
    {
        "repo_url": "github.com/ByChelsea/VAND-APRIL-GAN",
        "filepath": "train.py",
        "commit_date": "2023-06-13T08:38:14Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/altndrr/vic",
        "filepath": "src/models/clip.py",
        "commit_date": "2024-02-02T14:14:47Z",
        "message": "Improve metrics compute (#17)\n\n* Compute metrics once\n\n* Compute semantic iou and similarity on step\n\n* Ensure batch dim in `SentenceScore`"
    },
    {
        "repo_url": "github.com/altndrr/vic",
        "filepath": "src/models/clip.py",
        "commit_date": "2023-12-14T18:38:49Z",
        "message": "Major code overhaul (#16)\n\n* Remove `.yaml` extension from config files\n\n* Remove `.compile` in `train.py`\n\n* Print config tree as last of extras\n\n* Remove colorlogger\n\n* Add missing types and docstrings\n\n* Update data\n\n* Suppress kaggle `OSError`\n\n* Add requests header to avoid HTTP 406 errors in download\n\n* Update metrics\n\n* Support masking in `NearestNeighboursClassifier`\n\n* Refactor retrieval system\n\n* Refactor models\n\n* Support disabling loggers\n\n* Fix wandb hparams logging format\n\n* Remove optim from CLIP config\n\n* Add interrogate pre-commit\n\n* Fix pytype issues\n\n* Fix default models filepath\n\n* Set default CaSED alpha to `0.7`\n\n* Add new dependencies\n\n* Rename `databases.json` file\n\n* Update citation\n\n* Bump repo version\n\n* Add reference in method\n\n* Update HuggingFace inference code\n\n* Add logo"
    },
    {
        "repo_url": "github.com/altndrr/vic",
        "filepath": "src/models/clip.py",
        "commit_date": "2023-06-02T07:11:50Z",
        "message": "Initial commit"
    },
    {
        "repo_url": "github.com/UMass-Foundation-Model/3D-LLM",
        "filepath": "3DLanguage_data/ChatCaptioner_based/gen_features/clip_oa.py",
        "commit_date": "2023-09-09T04:51:38Z",
        "message": "refactor gen_features"
    },
    {
        "repo_url": "github.com/Newbeeer/diffusion_restart_sampling",
        "filepath": "diffuser/clip_score.py",
        "commit_date": "2023-06-25T03:07:36Z",
        "message": "update"
    },
    {
        "repo_url": "github.com/diffusion-classifier/diffusion-classifier",
        "filepath": "run_winoground.py",
        "commit_date": "2024-02-14T23:25:53Z",
        "message": "add DiT eval"
    },
    {
        "repo_url": "github.com/diffusion-classifier/diffusion-classifier",
        "filepath": "run_winoground.py",
        "commit_date": "2023-11-08T21:06:29Z",
        "message": "add Winoground evaluation script"
    },
    {
        "repo_url": "github.com/NVIDIA/tao_pytorch_backend",
        "filepath": "nvidia_tao_pytorch/cv/odise/modeling/backbone/clip.py",
        "commit_date": "2023-12-05T22:13:46Z",
        "message": "TAO 5.2 Release - PyTorch"
    },
    {
        "repo_url": "github.com/3DTopia/3DTopia",
        "filepath": "ldm/modules/encoders/modules.py",
        "commit_date": "2024-01-18T08:05:22Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/OpenGVLab/Instruct2Act",
        "filepath": "engine_robotic.py",
        "commit_date": "2023-05-18T12:21:58Z",
        "message": "update the readme && remove some useless lines"
    },
    {
        "repo_url": "github.com/OpenGVLab/Instruct2Act",
        "filepath": "engine_robotic.py",
        "commit_date": "2023-05-18T07:18:57Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/aim-uofa/StyleDrop-PyTorch",
        "filepath": "predict.py",
        "commit_date": "2023-07-07T21:06:29Z",
        "message": "replicate"
    },
    {
        "repo_url": "github.com/roatienza/Deep-Learning-Experiments",
        "filepath": "versions/2023/model_serving/demo/triton/openclip/server.py",
        "commit_date": "2023-11-18T02:20:33Z",
        "message": "model serving"
    },
    {
        "repo_url": "github.com/Newbeeer/diffusion_restart_sampling",
        "filepath": "diffuser/eval_clip_score.py",
        "commit_date": "2023-06-25T03:07:36Z",
        "message": "update"
    },
    {
        "repo_url": "github.com/Nerogar/OneTrainer",
        "filepath": "modules/module/HPSv2ScoreModel.py",
        "commit_date": "2023-10-25T16:38:57Z",
        "message": "load HPSv2 with the correct precision"
    },
    {
        "repo_url": "github.com/Nerogar/OneTrainer",
        "filepath": "modules/module/HPSv2ScoreModel.py",
        "commit_date": "2023-10-24T17:39:29Z",
        "message": "HPSv2 support for AlignProp"
    },
    {
        "repo_url": "github.com/aim-uofa/StyleDrop-PyTorch",
        "filepath": "gradio_demo.py",
        "commit_date": "2023-07-09T00:52:03Z",
        "message": "update for colab"
    },
    {
        "repo_url": "github.com/aim-uofa/StyleDrop-PyTorch",
        "filepath": "gradio_demo.py",
        "commit_date": "2023-07-09T00:07:07Z",
        "message": "update gradio demo"
    },
    {
        "repo_url": "github.com/aim-uofa/StyleDrop-PyTorch",
        "filepath": "gradio_demo.py",
        "commit_date": "2023-07-05T05:09:29Z",
        "message": "fix some bugs"
    },
    {
        "repo_url": "github.com/aim-uofa/StyleDrop-PyTorch",
        "filepath": "gradio_demo.py",
        "commit_date": "2023-07-05T03:49:03Z",
        "message": "ADD set_seed"
    },
    {
        "repo_url": "github.com/aim-uofa/StyleDrop-PyTorch",
        "filepath": "gradio_demo.py",
        "commit_date": "2023-07-04T03:10:02Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/Newbeeer/diffusion_restart_sampling",
        "filepath": "diffuser/coco_data_loader.py",
        "commit_date": "2023-06-25T03:07:36Z",
        "message": "update"
    },
    {
        "repo_url": "github.com/WalBouss/GEM",
        "filepath": "gem/gem.py",
        "commit_date": "2023-12-05T08:21:13Z",
        "message": "Initial commit :tada:"
    },
    {
        "repo_url": "github.com/gersteinlab/ML-Bench",
        "filepath": "MLAgent/repo/open_clip/tests/util_test.py",
        "commit_date": "2023-11-18T21:06:52Z",
        "message": "test"
    },
    {
        "repo_url": "github.com/gersteinlab/ML-Bench",
        "filepath": "MLAgent/repo/open_clip/tests/test_inference_simple.py",
        "commit_date": "2023-11-18T21:06:52Z",
        "message": "test"
    },
    {
        "repo_url": "github.com/gersteinlab/ML-Bench",
        "filepath": "MLAgent/repo/open_clip/tests/test_download_pretrained.py",
        "commit_date": "2023-11-18T21:06:52Z",
        "message": "test"
    },
    {
        "repo_url": "github.com/achao2013/deep3dmap",
        "filepath": "deep3dmap/models/modulars/ns_encoders/openclip_encoder.py",
        "commit_date": "2023-05-28T02:32:39Z",
        "message": "add lerf and related dependency"
    },
    {
        "repo_url": "github.com/minghanqin/LangSplat",
        "filepath": "preprocess.py",
        "commit_date": "2023-12-26T11:07:35Z",
        "message": "init"
    },
    {
        "repo_url": "github.com/wkcn/TinyCLIP",
        "filepath": "inference.py",
        "commit_date": "2024-03-01T02:15:21Z",
        "message": "[TinyCLIP] inference auto weight inheritance"
    },
    {
        "repo_url": "github.com/wkcn/TinyCLIP",
        "filepath": "inference.py",
        "commit_date": "2024-01-21T12:18:23Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/shenyunhang/APE",
        "filepath": "ape/modeling/text/clip_wrapper_open.py",
        "commit_date": "2023-12-05T02:34:21Z",
        "message": "This is the 1st commit"
    },
    {
        "repo_url": "github.com/Algolzw/daclip-uir",
        "filepath": "universal-image-restoration/config/daclip-sde/train.py",
        "commit_date": "2023-10-02T11:44:56Z",
        "message": "add uir code"
    },
    {
        "repo_url": "github.com/jianzhnie/GigaGAN",
        "filepath": "gigagan/open_clip.py",
        "commit_date": "2023-04-01T01:53:41Z",
        "message": "Update open_clip.py"
    },
    {
        "repo_url": "github.com/jianzhnie/GigaGAN",
        "filepath": "gigagan/open_clip.py",
        "commit_date": "2023-03-20T06:52:33Z",
        "message": "Create open_clip.py"
    },
    {
        "repo_url": "github.com/bytedance/fc-clip",
        "filepath": "fcclip/modeling/backbone/clip.py",
        "commit_date": "2023-08-10T23:29:33Z",
        "message": "add support for resnet"
    },
    {
        "repo_url": "github.com/bytedance/fc-clip",
        "filepath": "fcclip/modeling/backbone/clip.py",
        "commit_date": "2023-08-07T07:11:21Z",
        "message": "init commit"
    },
    {
        "repo_url": "github.com/ThereforeGames/unprompted",
        "filepath": "lib_unprompted/stable_diffusion/hard_prompts_made_easy.py",
        "commit_date": "2023-08-08T03:48:35Z",
        "message": "v9.15.0"
    },
    {
        "repo_url": "github.com/ThereforeGames/unprompted",
        "filepath": "lib_unprompted/stable_diffusion/hard_prompts_made_easy.py",
        "commit_date": "2023-02-13T05:44:46Z",
        "message": "v7.5.0"
    },
    {
        "repo_url": "github.com/zideliu/StyleDrop-PyTorch",
        "filepath": "train_t2i_colab_v2.py",
        "commit_date": "2023-07-08T07:33:12Z",
        "message": "updated colab train script"
    },
    {
        "repo_url": "github.com/NVIDIA-AI-IOT/jetson-intro-to-distillation",
        "filepath": "openclip_utils.py",
        "commit_date": "2023-08-01T20:53:22Z",
        "message": "license"
    },
    {
        "repo_url": "github.com/NVIDIA-AI-IOT/jetson-intro-to-distillation",
        "filepath": "openclip_utils.py",
        "commit_date": "2023-06-27T21:37:06Z",
        "message": "initial commit"
    },
    {
        "repo_url": "github.com/daveredrum/SceneTex",
        "filepath": "models/pipeline/texture_pipeline.py",
        "commit_date": "2023-11-28T15:38:19Z",
        "message": "Add code"
    },
    {
        "repo_url": "github.com/lucidrains/gigagan-pytorch",
        "filepath": "gigagan_pytorch/open_clip.py",
        "commit_date": "2023-07-21T00:26:47Z",
        "message": "for conditional training, complete the auxiliary clip contrastive loss"
    },
    {
        "repo_url": "github.com/lucidrains/gigagan-pytorch",
        "filepath": "gigagan_pytorch/open_clip.py",
        "commit_date": "2023-04-06T15:36:56Z",
        "message": "auxiliary losses almost all complete, save for text conditioning within vision aided discriminator"
    },
    {
        "repo_url": "github.com/lucidrains/gigagan-pytorch",
        "filepath": "gigagan_pytorch/open_clip.py",
        "commit_date": "2023-04-04T20:03:50Z",
        "message": "clean solution to reconstruction loss from any fmap resolution in the discriminator"
    },
    {
        "repo_url": "github.com/lucidrains/gigagan-pytorch",
        "filepath": "gigagan_pytorch/open_clip.py",
        "commit_date": "2023-04-03T18:07:28Z",
        "message": "make some headway into vision-aided gan loss"
    },
    {
        "repo_url": "github.com/lucidrains/gigagan-pytorch",
        "filepath": "gigagan_pytorch/open_clip.py",
        "commit_date": "2023-03-29T20:53:19Z",
        "message": "knock out two of the aux losses"
    },
    {
        "repo_url": "github.com/lucidrains/gigagan-pytorch",
        "filepath": "gigagan_pytorch/open_clip.py",
        "commit_date": "2023-03-13T20:39:51Z",
        "message": "prepare open clip"
    },
    {
        "repo_url": "github.com/Understanding-Visual-Datasets/VisDiff",
        "filepath": "serve/clip_server.py",
        "commit_date": "2023-11-29T20:48:05Z",
        "message": "initial release\n\nCo-Authored-By: Lisa Dunlap <25967790+lisadunlap@users.noreply.github.com>\nCo-Authored-By: Yuhui Zhang <yuhuiz@cs.stanford.edu>"
    },
    {
        "repo_url": "github.com/Nota-NetsPresso/BK-SDM",
        "filepath": "src/eval_clip_score.py",
        "commit_date": "2024-02-27T14:26:01Z",
        "message": "#51 update package and copyright info"
    },
    {
        "repo_url": "github.com/Nota-NetsPresso/BK-SDM",
        "filepath": "src/eval_clip_score.py",
        "commit_date": "2023-07-25T18:59:54Z",
        "message": "add initial codes"
    },
    {
        "repo_url": "github.com/zideliu/StyleDrop-PyTorch",
        "filepath": "train_t2i_custom_v2.py",
        "commit_date": "2023-07-08T03:34:00Z",
        "message": "fix bugs"
    },
    {
        "repo_url": "github.com/zideliu/StyleDrop-PyTorch",
        "filepath": "train_t2i_custom_v2.py",
        "commit_date": "2023-07-04T03:10:02Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/YuxinWenRick/tree-ring-watermark",
        "filepath": "run_tree_ring_watermark.py",
        "commit_date": "2023-10-28T03:10:40Z",
        "message": "corrected TPR@1%FPR, expect better performance"
    },
    {
        "repo_url": "github.com/YuxinWenRick/tree-ring-watermark",
        "filepath": "run_tree_ring_watermark.py",
        "commit_date": "2023-05-31T14:39:55Z",
        "message": "initial release"
    },
    {
        "repo_url": "github.com/LAION-AI/CLIP_benchmark",
        "filepath": "clip_benchmark/models/open_clip.py",
        "commit_date": "2023-01-05T22:50:20Z",
        "message": "Support Japanese CLIP by rinna (#50)\n\n* support japanese clip\n\n* Add comments\n\n* add `ja_clip` flag to base_args for passing tests\n\n* add japanese clip to features in readme\n\n* support japanese-clip for retrieval\n\n* load proper model by model_type\n\n* fix test\n\n* undo changes in metrics\n\n* add wrapper for ja_clip\n\n* Rename models.py to model_collection.py\n\n* use model_collection in cli.py\n\n* import os in cli.py\n\n* Update cli.py\n\n* delete duplicate of loading `model_collection`\n\n* rename a var `model` to `model_name` in models\n\n* small fixes for better name in japanese_clip.py\n\n* add How to add other CLIP models in readme\n\nCo-authored-by: Romain Beaumont <romain.rom1@gmail.com>"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-11-29T09:21:06Z",
        "message": "1.1"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-11-15T15:13:43Z",
        "message": "0.3.5"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-11-13T16:27:32Z",
        "message": "0.3.4"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-11-11T14:21:12Z",
        "message": "0.3.1"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-11-10T16:51:50Z",
        "message": "0.3.0"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-11-10T10:11:33Z",
        "message": "0.2.10"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-11-09T08:04:49Z",
        "message": "0.2.9.2"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-11-05T17:25:12Z",
        "message": "0.2.8"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-11-03T07:50:24Z",
        "message": "0.2.6"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-11-02T17:44:39Z",
        "message": "0.2.5"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-11-01T16:35:10Z",
        "message": "0.2.4"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-10-31T12:26:20Z",
        "message": "0.2.2"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-10-23T02:09:03Z",
        "message": "0.1.5"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-10-21T15:14:16Z",
        "message": "0.1.4"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-10-20T06:25:54Z",
        "message": "0.1.2"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-10-19T14:46:26Z",
        "message": "0.1.0"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-10-19T02:50:12Z",
        "message": "0.0.4"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-10-18T10:42:06Z",
        "message": "0.0.3"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-10-18T08:01:17Z",
        "message": "0.0.2"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "src/models/style_retrieval.py",
        "commit_date": "2023-10-17T15:14:06Z",
        "message": "0.0.1"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "imagenet_test/clip_test.py",
        "commit_date": "2023-11-15T15:13:43Z",
        "message": "0.3.5"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "imagenet_test/clip_test.py",
        "commit_date": "2023-11-13T16:27:32Z",
        "message": "0.3.4"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "imagenet_test/clip_test.py",
        "commit_date": "2023-11-13T10:27:54Z",
        "message": "0.3.3"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "imagenet_test/clip_test.py",
        "commit_date": "2023-11-07T16:36:49Z",
        "message": "0.2.9.1"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "comparison_test/clip_test.py",
        "commit_date": "2023-11-15T15:13:43Z",
        "message": "0.3.5"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "comparison_test/clip_test.py",
        "commit_date": "2023-11-13T16:27:32Z",
        "message": "0.3.4"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "comparison_test/clip_test.py",
        "commit_date": "2023-11-13T10:27:54Z",
        "message": "0.3.3"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "comparison_test/clip_test.py",
        "commit_date": "2023-11-11T14:21:12Z",
        "message": "0.3.1"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "comparison_test/clip_test.py",
        "commit_date": "2023-11-09T08:04:49Z",
        "message": "0.2.9.2"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "comparison_test/clip_test.py",
        "commit_date": "2023-11-06T17:31:00Z",
        "message": "0.2.9"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "comparison_test/prompt_model.py",
        "commit_date": "2023-11-13T10:27:54Z",
        "message": "0.3.3"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "comparison_test/prompt_model.py",
        "commit_date": "2023-11-11T14:21:12Z",
        "message": "0.3.1"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "comparison_test/prompt_model.py",
        "commit_date": "2023-11-10T16:51:50Z",
        "message": "0.3.0"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "comparison_test/prompt_model.py",
        "commit_date": "2023-11-10T10:11:33Z",
        "message": "0.2.10"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "comparison_test/prompt_model.py",
        "commit_date": "2023-11-06T17:31:00Z",
        "message": "0.2.9"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "imagenet_test/languagebind_test.py",
        "commit_date": "2023-11-15T15:13:43Z",
        "message": "0.3.5"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "imagenet_test/languagebind_test.py",
        "commit_date": "2023-11-13T16:27:32Z",
        "message": "0.3.4"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "comparison_test/languagebind_test.py",
        "commit_date": "2023-11-15T15:13:43Z",
        "message": "0.3.5"
    },
    {
        "repo_url": "github.com/CuriseJia/FreeStyleRet",
        "filepath": "comparison_test/languagebind_test.py",
        "commit_date": "2023-11-13T16:27:32Z",
        "message": "0.3.4"
    },
    {
        "repo_url": "github.com/wusize/CLIPSelf",
        "filepath": "tools/generate_text_embeddings.py",
        "commit_date": "2023-09-30T07:14:45Z",
        "message": "'init'"
    },
    {
        "repo_url": "github.com/OpenGVLab/InternVL",
        "filepath": "clip_benchmark/clip_benchmark/models/open_clip.py",
        "commit_date": "2023-12-25T18:38:14Z",
        "message": "Release code and models"
    },
    {
        "repo_url": "github.com/taesiri/ZoomIsAllYouNeed",
        "filepath": "src/ImageNet_Hard/benchmark-openclip.py",
        "commit_date": "2023-05-25T00:58:04Z",
        "message": "Add files via upload"
    },
    {
        "repo_url": "github.com/taesiri/ZoomIsAllYouNeed",
        "filepath": "src/ImageNet_Hard/benchmark_openclip.py",
        "commit_date": "2023-05-26T14:04:04Z",
        "message": "openclip benchmark"
    },
    {
        "repo_url": "github.com/taesiri/ZoomIsAllYouNeed",
        "filepath": "src/ImageNet_Hard/benchmark_openclip_datacomp.py",
        "commit_date": "2023-05-26T03:43:03Z",
        "message": "Added results for datacomp/commonpool"
    },
    {
        "repo_url": "github.com/aim-uofa/StyleDrop-PyTorch",
        "filepath": "train_t2i_colab_v2.py",
        "commit_date": "2023-07-08T07:33:12Z",
        "message": "updated colab train script"
    },
    {
        "repo_url": "github.com/leptonai/examples",
        "filepath": "advanced/open-clip/open-clip.py",
        "commit_date": "2023-08-16T03:44:55Z",
        "message": "black format"
    },
    {
        "repo_url": "github.com/leptonai/examples",
        "filepath": "advanced/open-clip/open-clip.py",
        "commit_date": "2023-08-16T03:29:08Z",
        "message": "more"
    },
    {
        "repo_url": "github.com/leptonai/examples",
        "filepath": "advanced/open-clip/open-clip.py",
        "commit_date": "2023-08-16T03:26:47Z",
        "message": "Fix lint error"
    },
    {
        "repo_url": "github.com/leptonai/examples",
        "filepath": "advanced/open-clip/open-clip.py",
        "commit_date": "2023-08-15T21:42:04Z",
        "message": "chore(examples): merge the clip model code form leptonai/lepton to here"
    },
    {
        "repo_url": "github.com/leptonai/examples",
        "filepath": "advanced/open-clip/open-clip.py",
        "commit_date": "2023-08-15T21:22:42Z",
        "message": "add type annotation"
    },
    {
        "repo_url": "github.com/leptonai/examples",
        "filepath": "advanced/open-clip/open-clip.py",
        "commit_date": "2023-08-14T23:48:44Z",
        "message": "feat(clip) : add clip as an example"
    },
    {
        "repo_url": "github.com/haoshao-nku/medical_seg",
        "filepath": "mmsegmentation/projects/CAT-Seg/cat_seg/models/clip_ovseg.py",
        "commit_date": "2023-12-15T14:20:47Z",
        "message": "update code"
    },
    {
        "repo_url": "github.com/zideliu/StyleDrop-PyTorch",
        "filepath": "extract_empty_feature.py",
        "commit_date": "2023-07-09T07:21:34Z",
        "message": "fixing memory overflow"
    },
    {
        "repo_url": "github.com/zideliu/StyleDrop-PyTorch",
        "filepath": "extract_empty_feature.py",
        "commit_date": "2023-07-04T03:10:02Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2023-09-10T00:15:11Z",
        "message": "Update CACHE_URL_BASE"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2023-04-12T16:56:37Z",
        "message": "change dribble to dribbble (#69)"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2023-03-20T03:43:46Z",
        "message": "Support for many different caption models:\nblip-base, blip-large, blip2-2.7b, blip2-flan-t5-xl, git-large-coco"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2023-03-20T01:02:23Z",
        "message": "Expose LabelTable and load_list and give example in README how they can be used to rank your own list of terms."
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2023-02-22T02:55:19Z",
        "message": "Move definition of clip_model_name (#52)"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2023-02-20T22:30:26Z",
        "message": "Minor fix to BLIP offloading"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2023-02-20T22:11:33Z",
        "message": "More safetensor, download, and VRAM improvements"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2023-02-19T04:29:36Z",
        "message": "When blip_offload enabled keep BLIP model on CPU to start."
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2023-02-18T21:31:45Z",
        "message": "add the negative cache url"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2023-02-18T20:53:02Z",
        "message": "safetensors!\n- store cached embeddings in safetensor format\n- updated huggingface ci-preprocess repo\n- bumped version to 0.5.0"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2023-02-05T18:31:12Z",
        "message": "."
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2023-02-05T18:18:12Z",
        "message": "0.4.2:\n- upgrade chain to take a min_count parameter so it won't early out until it has considered at least min_count flavors\n- interrogate method (\"best\" mode) also checks against classic and fast to use their output if it's better\n- fix bug of config.download_cache option not being used!\n- add notes on Config object to readme"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2023-02-05T00:32:49Z",
        "message": "Bunch of updates! (#40)\n\n- auto download the cache files from huggingface\n- experimental negative prompt mode\n- slight quality and performance improvement to best mode\n- analyze tab in Colab and run_gradio to get table of ranked terms"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2023-01-06T01:44:38Z",
        "message": "Make the BLIP model configurable, can set config.blip_model_type now to 'base' or 'large'"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2023-01-04T18:39:45Z",
        "message": "Update to nicer BLIP packaging"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2022-12-10T21:42:46Z",
        "message": "Fix for running on CPU"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2022-11-29T22:38:48Z",
        "message": "0.3.1 fix for running on cpu, update readme usage instructions"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2022-11-28T18:36:24Z",
        "message": "Handle exception trying to load cached table"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2022-11-28T18:30:39Z",
        "message": "Default to ViT-L, lower intermediate count for Colab with ViT-H"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2022-11-27T23:54:13Z",
        "message": "Ability to swap CLIP models (takes about 5s for ViTL and 10s for ViTH), update Replicate cog"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2022-11-26T23:59:00Z",
        "message": "More fixes, improvement and cleanup."
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2022-11-25T16:33:13Z",
        "message": "Handle differences in how open_clip does prompt truncation, run_gradio support for all the open_clip models and --share option."
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2022-11-25T15:26:00Z",
        "message": "Shuffle BLIP back to system RAM to help with 16GB Colab"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2022-11-24T21:27:28Z",
        "message": "First test version with OpenCLIP and ViTH!"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2022-11-21T20:17:36Z",
        "message": "Update notebook batch processing with option to rename files so can be used with [filewords] in Dreambooth!\n- new `quiet` config option so CLIP Interrogator doesn't print and tqdm\n- `max_flavors` option to each interrogate method"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2022-11-06T04:21:13Z",
        "message": "Gradio version plus classic and fast modes"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2022-11-06T02:41:08Z",
        "message": "CLIPInterrogator -> Interrogator"
    },
    {
        "repo_url": "github.com/pharmapsychotic/clip-interrogator",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2022-11-06T02:02:08Z",
        "message": "Add to pip!"
    },
    {
        "repo_url": "github.com/data2ml/all-clip",
        "filepath": "all_clip/open_clip.py",
        "commit_date": "2024-01-21T20:47:24Z",
        "message": "Split in one file per model."
    },
    {
        "repo_url": "github.com/tgxs002/align_sd",
        "filepath": "process_diffusiondb.py",
        "commit_date": "2023-05-10T12:34:17Z",
        "message": "highlight updates, fix typo, add regularization images"
    },
    {
        "repo_url": "github.com/aim-uofa/StyleDrop-PyTorch",
        "filepath": "train_t2i_custom_v2.py",
        "commit_date": "2023-07-08T03:34:00Z",
        "message": "fix bugs"
    },
    {
        "repo_url": "github.com/aim-uofa/StyleDrop-PyTorch",
        "filepath": "train_t2i_custom_v2.py",
        "commit_date": "2023-07-04T03:10:02Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/Vision-CAIR/ChatCaptioner",
        "filepath": "ChatCaptioner/chatcaptioner/clip.py",
        "commit_date": "2023-04-11T11:48:46Z",
        "message": "update"
    },
    {
        "repo_url": "github.com/matsui528/scs",
        "filepath": "search.py",
        "commit_date": "2023-10-23T11:28:50Z",
        "message": "readme update"
    },
    {
        "repo_url": "github.com/matsui528/scs",
        "filepath": "search.py",
        "commit_date": "2023-10-23T14:32:00Z",
        "message": "readme"
    },
    {
        "repo_url": "github.com/matsui528/scs",
        "filepath": "search.py",
        "commit_date": "2023-10-23T14:21:34Z",
        "message": "added comments"
    },
    {
        "repo_url": "github.com/matsui528/scs",
        "filepath": "search.py",
        "commit_date": "2023-10-23T14:11:39Z",
        "message": "initial finish"
    },
    {
        "repo_url": "github.com/matsui528/scs",
        "filepath": "search_streamlit.py",
        "commit_date": "2023-10-23T16:49:33Z",
        "message": "streamlit"
    },
    {
        "repo_url": "github.com/Algolzw/daclip-uir",
        "filepath": "universal-image-restoration/config/daclip-sde/test.py",
        "commit_date": "2023-10-02T11:44:56Z",
        "message": "add uir code"
    },
    {
        "repo_url": "github.com/naamiinepal/medvlsm",
        "filepath": "src/datamodules/datasets/image_text_mask.py",
        "commit_date": "2024-02-09T09:18:05Z",
        "message": "test: packages, cfgs, and integrity of the repo"
    },
    {
        "repo_url": "github.com/naamiinepal/medvlsm",
        "filepath": "src/datamodules/datasets/image_text_mask.py",
        "commit_date": "2024-02-09T05:18:21Z",
        "message": "BiomedCLIP* configured"
    },
    {
        "repo_url": "github.com/naamiinepal/medvlsm",
        "filepath": "src/datamodules/datasets/image_text_mask.py",
        "commit_date": "2023-12-27T14:37:51Z",
        "message": "feat!: integrated the ZS-Ref implementation"
    },
    {
        "repo_url": "github.com/naamiinepal/medvlsm",
        "filepath": "src/datamodules/datasets/image_text_mask.py",
        "commit_date": "2023-11-22T01:44:25Z",
        "message": "feat!: new configurable framework for vlsm"
    },
    {
        "repo_url": "github.com/AnyLoc/AnyLoc",
        "filepath": "examples/trivial_vpr_with_clip.py",
        "commit_date": "2023-08-02T17:09:32Z",
        "message": "Created first (public) release"
    },
    {
        "repo_url": "github.com/djghosh13/geneval",
        "filepath": "evaluation/evaluate_images.py",
        "commit_date": "2023-12-14T22:19:35Z",
        "message": "Updated README"
    },
    {
        "repo_url": "github.com/djghosh13/geneval",
        "filepath": "evaluation/evaluate_images.py",
        "commit_date": "2023-12-14T21:56:56Z",
        "message": "Fixed model download and path"
    },
    {
        "repo_url": "github.com/djghosh13/geneval",
        "filepath": "evaluation/evaluate_images.py",
        "commit_date": "2023-12-14T18:16:08Z",
        "message": "Updated scripts for single-GPU"
    },
    {
        "repo_url": "github.com/djghosh13/geneval",
        "filepath": "evaluation/evaluate_images.py",
        "commit_date": "2023-08-22T21:09:50Z",
        "message": "Initial code release"
    },
    {
        "repo_url": "github.com/mlfoundations/datacomp",
        "filepath": "eval_utils/wds_eval.py",
        "commit_date": "2023-07-22T20:33:48Z",
        "message": "Style fix (#35)\n\n* precommit changes\n\n* add precommit hook"
    },
    {
        "repo_url": "github.com/mlfoundations/datacomp",
        "filepath": "eval_utils/wds_eval.py",
        "commit_date": "2023-04-28T04:18:58Z",
        "message": "Initial commit"
    },
    {
        "repo_url": "github.com/dome272/Paella",
        "filepath": "src_distributed/utils.py",
        "commit_date": "2023-04-13T14:47:27Z",
        "message": "v3 main commit"
    },
    {
        "repo_url": "github.com/kerrj/lerf",
        "filepath": "lerf/encoders/openclip_encoder.py",
        "commit_date": "2024-01-18T00:12:46Z",
        "message": "Update paths+configs to nerfstudio 1.0 version"
    },
    {
        "repo_url": "github.com/kerrj/lerf",
        "filepath": "lerf/encoders/openclip_encoder.py",
        "commit_date": "2023-04-19T21:06:17Z",
        "message": "refactor to fix handle in callback"
    },
    {
        "repo_url": "github.com/kerrj/lerf",
        "filepath": "lerf/encoders/openclip_encoder.py",
        "commit_date": "2023-04-14T22:03:56Z",
        "message": "code for using new viewer with custom ViewerText"
    },
    {
        "repo_url": "github.com/kerrj/lerf",
        "filepath": "lerf/encoders/openclip_encoder.py",
        "commit_date": "2023-04-04T16:34:46Z",
        "message": "init commit"
    },
    {
        "repo_url": "github.com/carefree0910/carefree-learn",
        "filepath": "examples/reproduce/clip/run_open_clip.py",
        "commit_date": "2023-12-06T06:38:27Z",
        "message": "\u2705Re-introduced `reproduce/clip`"
    },
    {
        "repo_url": "github.com/carefree0910/carefree-learn",
        "filepath": "examples/reproduce/clip/run_open_clip.py",
        "commit_date": "2023-03-21T11:05:30Z",
        "message": "\ud83c\udf89Started `v0.4.x`"
    },
    {
        "repo_url": "github.com/carefree0910/carefree-learn",
        "filepath": "examples/reproduce/clip/run_open_clip.py",
        "commit_date": "2022-12-10T07:24:17Z",
        "message": "\ud83d\ude9aMove `reproduce` to `examples` root"
    },
    {
        "repo_url": "github.com/concept-graphs/concept-graphs",
        "filepath": "conceptgraph/scripts/eval_replica_semseg.py",
        "commit_date": "2024-01-16T06:40:59Z",
        "message": "add sem seg evaluation script on replica"
    },
    {
        "repo_url": "github.com/huggingface/api-inference-community",
        "filepath": "docker_images/open_clip/app/pipelines/zero_shot_image_classification.py",
        "commit_date": "2023-11-08T20:34:17Z",
        "message": "Missed the exp() on logit scale for OpenCLIP update (#349)"
    },
    {
        "repo_url": "github.com/huggingface/api-inference-community",
        "filepath": "docker_images/open_clip/app/pipelines/zero_shot_image_classification.py",
        "commit_date": "2023-11-08T06:06:41Z",
        "message": "Update OpenCLIP to latest version, bump other reqs (#347)\n\n* Update OpenCLIP to latest version, bump other reqs, add support for sigmoid scores for SigLIP models\n\n* Fix black complaints"
    },
    {
        "repo_url": "github.com/huggingface/api-inference-community",
        "filepath": "docker_images/open_clip/app/pipelines/zero_shot_image_classification.py",
        "commit_date": "2023-04-18T15:17:20Z",
        "message": "Initial open_clip zero-shot support. Test working locally but docker failing. (#232)\n\n* Initial open_clip support. Test working locally but docker failing.\n\n* Fixing zero-shot-cls\n\n* Fixing docker test.\n\n---------\n\nCo-authored-by: Nicolas Patry <patry.nicolas@protonmail.com>"
    },
    {
        "repo_url": "github.com/mlfoundations/datacomp",
        "filepath": "eval_utils/wino_eval.py",
        "commit_date": "2023-07-22T20:33:48Z",
        "message": "Style fix (#35)\n\n* precommit changes\n\n* add precommit hook"
    },
    {
        "repo_url": "github.com/mlfoundations/datacomp",
        "filepath": "eval_utils/wino_eval.py",
        "commit_date": "2023-05-31T23:11:13Z",
        "message": "Update HF evalset cache dir and download script (#21)\n\n* Update HF evalset cache and download script\n\n* Fix cache dir"
    },
    {
        "repo_url": "github.com/mlfoundations/datacomp",
        "filepath": "eval_utils/wino_eval.py",
        "commit_date": "2023-04-28T04:18:58Z",
        "message": "Initial commit"
    },
    {
        "repo_url": "github.com/concept-graphs/concept-graphs",
        "filepath": "conceptgraph/scripts/generate_gsa_results.py",
        "commit_date": "2024-02-28T04:49:23Z",
        "message": "refactor get clip feature function to be batched"
    },
    {
        "repo_url": "github.com/concept-graphs/concept-graphs",
        "filepath": "conceptgraph/scripts/generate_gsa_results.py",
        "commit_date": "2024-02-23T16:05:34Z",
        "message": "temp ugly bugfix"
    },
    {
        "repo_url": "github.com/concept-graphs/concept-graphs",
        "filepath": "conceptgraph/scripts/generate_gsa_results.py",
        "commit_date": "2024-02-23T04:44:09Z",
        "message": "added yolo world detection option"
    },
    {
        "repo_url": "github.com/concept-graphs/concept-graphs",
        "filepath": "conceptgraph/scripts/generate_gsa_results.py",
        "commit_date": "2024-02-23T04:39:42Z",
        "message": "change outdated tag2text stuff to ram stuff"
    },
    {
        "repo_url": "github.com/concept-graphs/concept-graphs",
        "filepath": "conceptgraph/scripts/generate_gsa_results.py",
        "commit_date": "2023-09-29T05:44:42Z",
        "message": "add initial public code"
    },
    {
        "repo_url": "github.com/aim-uofa/StyleDrop-PyTorch",
        "filepath": "extract_empty_feature.py",
        "commit_date": "2023-07-09T07:21:34Z",
        "message": "fixing memory overflow"
    },
    {
        "repo_url": "github.com/aim-uofa/StyleDrop-PyTorch",
        "filepath": "extract_empty_feature.py",
        "commit_date": "2023-07-04T03:10:02Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/frank-xwang/InstanceDiffusion",
        "filepath": "eval/eval_attribute_binding.py",
        "commit_date": "2024-02-11T00:40:51Z",
        "message": "add attribute binding"
    },
    {
        "repo_url": "github.com/mlfoundations/datacomp",
        "filepath": "eval_utils/retr_eval.py",
        "commit_date": "2023-07-22T20:33:48Z",
        "message": "Style fix (#35)\n\n* precommit changes\n\n* add precommit hook"
    },
    {
        "repo_url": "github.com/mlfoundations/datacomp",
        "filepath": "eval_utils/retr_eval.py",
        "commit_date": "2023-05-31T23:11:13Z",
        "message": "Update HF evalset cache dir and download script (#21)\n\n* Update HF evalset cache and download script\n\n* Fix cache dir"
    },
    {
        "repo_url": "github.com/mlfoundations/datacomp",
        "filepath": "eval_utils/retr_eval.py",
        "commit_date": "2023-04-28T05:30:27Z",
        "message": "Update retrieval metrics"
    },
    {
        "repo_url": "github.com/mlfoundations/datacomp",
        "filepath": "eval_utils/retr_eval.py",
        "commit_date": "2023-04-28T04:18:58Z",
        "message": "Initial commit"
    },
    {
        "repo_url": "github.com/lucidrains/perfusion-pytorch",
        "filepath": "perfusion_pytorch/open_clip.py",
        "commit_date": "2023-08-14T16:07:14Z",
        "message": "add a function that can accept open clip, a bunch of prompts as List[str], and return the C covariance matrix needed"
    },
    {
        "repo_url": "github.com/facebookresearch/PUG",
        "filepath": "PUG_SPAR/run_eval_vlms_on_spar.py",
        "commit_date": "2023-08-09T00:51:32Z",
        "message": "Initial commit"
    },
    {
        "repo_url": "github.com/zzc-1998/SJTU-H3D",
        "filepath": "quality_measure_utils/semantic_affinity_quality_measure.py",
        "commit_date": "2023-06-14T09:05:14Z",
        "message": "Add files via upload"
    },
    {
        "repo_url": "github.com/concept-graphs/concept-graphs",
        "filepath": "conceptgraph/scripts/streamlined_detections.py",
        "commit_date": "2024-02-28T04:49:58Z",
        "message": "add clip fts, add profiling code, other small updates"
    },
    {
        "repo_url": "github.com/concept-graphs/concept-graphs",
        "filepath": "conceptgraph/scripts/streamlined_detections.py",
        "commit_date": "2024-02-27T03:07:17Z",
        "message": "added streamlined detections script"
    },
    {
        "repo_url": "github.com/KU-CVLAB/CAT-Seg",
        "filepath": "cat_seg/modeling/transformer/cat_seg_predictor.py",
        "commit_date": "2023-03-21T12:14:05Z",
        "message": "initial commit"
    },
    {
        "repo_url": "github.com/chs20/RobustVLM",
        "filepath": "CLIP_benchmark/clip_benchmark/models/open_clip.py",
        "commit_date": "2024-02-19T18:17:12Z",
        "message": "Initial commit"
    },
    {
        "repo_url": "github.com/concept-graphs/concept-graphs",
        "filepath": "conceptgraph/scripts/visualize_cfslam_results.py",
        "commit_date": "2023-09-29T05:44:42Z",
        "message": "add initial public code"
    },
    {
        "repo_url": "github.com/Vision-CAIR/ChatCaptioner",
        "filepath": "Video_ChatCaptioner/chatcaptioner/clip.py",
        "commit_date": "2023-04-11T11:46:37Z",
        "message": "update"
    },
    {
        "repo_url": "github.com/Computer-Vision-in-the-Wild/UniCL-OpenCLIP",
        "filepath": "tests/util_test.py",
        "commit_date": "2022-12-09T03:23:32Z",
        "message": "update"
    },
    {
        "repo_url": "github.com/Computer-Vision-in-the-Wild/UniCL-OpenCLIP",
        "filepath": "tests/test_inference_simple.py",
        "commit_date": "2022-12-09T03:23:32Z",
        "message": "update"
    },
    {
        "repo_url": "github.com/tgxs002/HPSv2",
        "filepath": "hpsv2/tests/util_test.py",
        "commit_date": "2023-08-02T06:54:12Z",
        "message": "Implement Pypi package"
    },
    {
        "repo_url": "github.com/ParisNeo/lollms",
        "filepath": "lollms/image_gen_modules/clip_interrogator.py",
        "commit_date": "2023-11-28T15:46:16Z",
        "message": "Update clip_interrogator.py"
    },
    {
        "repo_url": "github.com/ParisNeo/lollms",
        "filepath": "lollms/image_gen_modules/clip_interrogator.py",
        "commit_date": "2023-11-28T01:03:58Z",
        "message": "added vision to all models"
    },
    {
        "repo_url": "github.com/tgxs002/HPSv2",
        "filepath": "hpsv2/tests/test_inference_simple.py",
        "commit_date": "2023-08-02T06:54:12Z",
        "message": "Implement Pypi package"
    },
    {
        "repo_url": "github.com/abhishekkrthakur/diffuzers",
        "filepath": "diffuzers/clip_interrogator.py",
        "commit_date": "2023-01-04T16:03:12Z",
        "message": "update"
    },
    {
        "repo_url": "github.com/tgxs002/HPSv2",
        "filepath": "hpsv2/tests/test_download_pretrained.py",
        "commit_date": "2023-08-02T06:54:12Z",
        "message": "Implement Pypi package"
    },
    {
        "repo_url": "github.com/facebookresearch/SIEVE",
        "filepath": "eval_utils/wds_eval.py",
        "commit_date": "2023-12-14T20:43:31Z",
        "message": "Initial commit"
    },
    {
        "repo_url": "github.com/facebookresearch/SIEVE",
        "filepath": "eval_utils/wino_eval.py",
        "commit_date": "2023-12-14T20:43:31Z",
        "message": "Initial commit"
    },
    {
        "repo_url": "github.com/facebookresearch/SIEVE",
        "filepath": "eval_utils/retr_eval.py",
        "commit_date": "2023-12-14T20:43:31Z",
        "message": "Initial commit"
    },
    {
        "repo_url": "github.com/d8ahazard/sd_smartprocess",
        "filepath": "clipinterrogator.py",
        "commit_date": "2023-01-03T02:59:28Z",
        "message": "Add min/max CLIP length, don't adjust image size unless we tell it to"
    },
    {
        "repo_url": "github.com/d8ahazard/sd_smartprocess",
        "filepath": "clipinterrogator.py",
        "commit_date": "2022-12-15T19:48:36Z",
        "message": "Code cleanup, fixes"
    },
    {
        "repo_url": "github.com/d8ahazard/sd_smartprocess",
        "filepath": "clipinterrogator.py",
        "commit_date": "2022-12-10T23:54:02Z",
        "message": "Moar fun"
    },
    {
        "repo_url": "github.com/d8ahazard/sd_smartprocess",
        "filepath": "clipinterrogator.py",
        "commit_date": "2022-12-10T23:33:34Z",
        "message": "Super Update\n\nAdd WD14 tagger.\nAdd CLIP v2.1 interrogator.\nAllow filtering wd14, booru tags by score.\nAdd don't rename option.\nUpdate ReallySafe\nBump BLIP version?\nRemove split image options.\nCompletely overhaul smartprocess..."
    },
    {
        "repo_url": "github.com/zideliu/StyleDrop-PyTorch",
        "filepath": "extract_test_prompt_feature.py",
        "commit_date": "2023-07-04T03:10:02Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/unum-cloud/coco-sm",
        "filepath": "modules/open_clip.py",
        "commit_date": "2023-08-17T14:18:53Z",
        "message": "Init: First commit"
    },
    {
        "repo_url": "github.com/ByChelsea/VAND-APRIL-GAN",
        "filepath": "test.py",
        "commit_date": "2023-07-05T08:36:13Z",
        "message": "faster"
    },
    {
        "repo_url": "github.com/ByChelsea/VAND-APRIL-GAN",
        "filepath": "test.py",
        "commit_date": "2023-06-28T15:04:39Z",
        "message": "support resnet"
    },
    {
        "repo_url": "github.com/ByChelsea/VAND-APRIL-GAN",
        "filepath": "test.py",
        "commit_date": "2023-06-28T07:24:16Z",
        "message": "Simpler Version"
    },
    {
        "repo_url": "github.com/ByChelsea/VAND-APRIL-GAN",
        "filepath": "test.py",
        "commit_date": "2023-06-22T09:18:51Z",
        "message": "fix bug"
    },
    {
        "repo_url": "github.com/ByChelsea/VAND-APRIL-GAN",
        "filepath": "test.py",
        "commit_date": "2023-06-21T14:48:45Z",
        "message": "fix bug"
    },
    {
        "repo_url": "github.com/ByChelsea/VAND-APRIL-GAN",
        "filepath": "test.py",
        "commit_date": "2023-06-21T13:53:00Z",
        "message": "bug fix"
    },
    {
        "repo_url": "github.com/ByChelsea/VAND-APRIL-GAN",
        "filepath": "test.py",
        "commit_date": "2023-06-13T08:38:14Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/KU-CVLAB/CAT-Seg",
        "filepath": "open_clip/tests/util_test.py",
        "commit_date": "2023-03-21T12:14:05Z",
        "message": "initial commit"
    },
    {
        "repo_url": "github.com/KU-CVLAB/CAT-Seg",
        "filepath": "open_clip/tests/test_inference_simple.py",
        "commit_date": "2023-03-21T12:14:05Z",
        "message": "initial commit"
    },
    {
        "repo_url": "github.com/KU-CVLAB/CAT-Seg",
        "filepath": "open_clip/tests/test_download_pretrained.py",
        "commit_date": "2023-03-21T12:14:05Z",
        "message": "initial commit"
    },
    {
        "repo_url": "github.com/aim-uofa/StyleDrop-PyTorch",
        "filepath": "extract_test_prompt_feature.py",
        "commit_date": "2023-07-04T03:10:02Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/aimagelab/open-fashion-clip",
        "filepath": "quick_start.py",
        "commit_date": "2023-08-31T11:45:14Z",
        "message": "Code and checkpoint release"
    },
    {
        "repo_url": "github.com/aimagelab/open-fashion-clip",
        "filepath": "quick_start.py",
        "commit_date": "2023-08-31T10:37:53Z",
        "message": "Code and checkpoint release"
    },
    {
        "repo_url": "github.com/UCSC-VLAA/vllm-safety-benchmark",
        "filepath": "safety_evaluations/redteaming/misleading_vision_attack/misleading_vis_attack.py",
        "commit_date": "2023-11-24T02:09:04Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/modelscope/normal-depth-diffusion",
        "filepath": "tools/compute_metric.py",
        "commit_date": "2023-12-11T02:42:52Z",
        "message": "init"
    },
    {
        "repo_url": "github.com/modelscope/normal-depth-diffusion",
        "filepath": "tools/compute_metric_curves.py",
        "commit_date": "2023-12-11T02:42:52Z",
        "message": "init"
    },
    {
        "repo_url": "github.com/modelscope/normal-depth-diffusion",
        "filepath": "tools/compute_clip_metric_curves.py",
        "commit_date": "2023-12-11T02:42:52Z",
        "message": "init"
    },
    {
        "repo_url": "github.com/modelscope/normal-depth-diffusion",
        "filepath": "tools/compute_objaverse_clipscore.py",
        "commit_date": "2023-12-11T02:42:52Z",
        "message": "init"
    },
    {
        "repo_url": "github.com/modelscope/normal-depth-diffusion",
        "filepath": "tools/compute_cfg_clip_metric_curves.py",
        "commit_date": "2023-12-11T02:42:52Z",
        "message": "init"
    },
    {
        "repo_url": "github.com/NeuralRealm/StableFusion",
        "filepath": "stablefusion/scripts/clip_interrogator.py",
        "commit_date": "2023-03-03T12:10:15Z",
        "message": "rearranged the file and add upscaler feature"
    },
    {
        "repo_url": "github.com/waltonfuture/InstructionGPT-4",
        "filepath": "cluster/kmeans++/kmeans_pp.py",
        "commit_date": "2023-10-09T07:45:22Z",
        "message": "codes"
    },
    {
        "repo_url": "github.com/waltonfuture/InstructionGPT-4",
        "filepath": "cluster/spectral/spectral_clustering.py",
        "commit_date": "2023-10-09T07:45:22Z",
        "message": "codes"
    },
    {
        "repo_url": "github.com/waltonfuture/InstructionGPT-4",
        "filepath": "cc_sbu_align_test/full_score.py",
        "commit_date": "2023-10-09T07:45:22Z",
        "message": "codes"
    },
    {
        "repo_url": "github.com/orrzohar/LOVM",
        "filepath": "modelGPT/create_models.py",
        "commit_date": "2023-06-14T18:52:24Z",
        "message": "init"
    },
    {
        "repo_url": "github.com/orrzohar/LOVM",
        "filepath": "modelGPT/encode_dataset.py",
        "commit_date": "2023-06-14T18:52:24Z",
        "message": "init"
    },
    {
        "repo_url": "github.com/orrzohar/LOVM",
        "filepath": "modelGPT/encode_syn_dataset.py",
        "commit_date": "2023-06-14T18:52:24Z",
        "message": "init"
    },
    {
        "repo_url": "github.com/yeongjoonJu/NeuroInspect",
        "filepath": "clip_illusion.py",
        "commit_date": "2023-10-19T02:56:24Z",
        "message": "requirements are modified"
    },
    {
        "repo_url": "github.com/yeongjoonJu/NeuroInspect",
        "filepath": "clip_illusion.py",
        "commit_date": "2023-09-07T01:56:16Z",
        "message": "add core relevance score"
    },
    {
        "repo_url": "github.com/yeongjoonJu/NeuroInspect",
        "filepath": "clip_illusion.py",
        "commit_date": "2023-07-23T06:38:35Z",
        "message": "adding extra neurou aug"
    },
    {
        "repo_url": "github.com/yeongjoonJu/NeuroInspect",
        "filepath": "clip_illusion.py",
        "commit_date": "2023-07-19T05:42:05Z",
        "message": "init repo"
    },
    {
        "repo_url": "github.com/yandex-research/adaptive-diffusion",
        "filepath": "consistency_models_sd/evaluations/clip_score.py",
        "commit_date": "2023-12-19T05:34:44Z",
        "message": "Initial update\n* two examples of t2i\n* arxiv link"
    },
    {
        "repo_url": "github.com/crystallee-ai/controlGIF",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2023-11-26T05:51:01Z",
        "message": "Update clip_interrogator.py"
    },
    {
        "repo_url": "github.com/crystallee-ai/controlGIF",
        "filepath": "clip_interrogator/clip_interrogator.py",
        "commit_date": "2023-11-25T09:12:55Z",
        "message": "v1"
    },
    {
        "repo_url": "github.com/hq-deng/AnoVL",
        "filepath": "vl_test.py",
        "commit_date": "2023-09-07T09:44:56Z",
        "message": "Add files via upload"
    },
    {
        "repo_url": "github.com/hq-deng/AnoVL",
        "filepath": "vis_test.py",
        "commit_date": "2023-09-07T09:44:56Z",
        "message": "Add files via upload"
    },
    {
        "repo_url": "github.com/huzeyann/MemoryEncodingModel",
        "filepath": "mem/backbone.py",
        "commit_date": "2023-08-10T06:34:06Z",
        "message": "rename files"
    },
    {
        "repo_url": "github.com/iejMac/clip-video-encode",
        "filepath": "clip_video_encode/simplemapper.py",
        "commit_date": "2023-09-13T02:54:38Z",
        "message": "clip-video-encode: add VQ-GAN frame tokenization (#77)\n\n* clip-video-encode: add VQ-GAN frame tokenization\n\n* it works\n\n* automatic is_gumbel\n\n* update\n\n* bigger bs\n\n* attempt at resuming\n\n* update tests\n\n* fix black\n\n* fix black\n\n* fix\n\n---------\n\nCo-authored-by: iejmac <iejmac@ip-26-0-151-20.us-west-2.compute.internal>\nCo-authored-by: iejmac <iejmac@ip-172-64-56-42.us-west-2.compute.internal>\nCo-authored-by: iejmac <iejmac@ip-26-0-146-117.us-west-2.compute.internal>\nCo-authored-by: iejmac <iejmac@ip-26-0-155-198.us-west-2.compute.internal>"
    },
    {
        "repo_url": "github.com/iejMac/clip-video-encode",
        "filepath": "clip_video_encode/simplemapper.py",
        "commit_date": "2023-04-26T07:35:37Z",
        "message": "captioning: allow setting params (#73)\n\n* captioning: allow setting params\n\n* fix black\n\n* docstring\n\n---------\n\nCo-authored-by: iejmac <iejmac@ip-26-0-151-112.us-west-2.compute.internal>"
    },
    {
        "repo_url": "github.com/iejMac/clip-video-encode",
        "filepath": "clip_video_encode/simplemapper.py",
        "commit_date": "2023-04-06T10:55:57Z",
        "message": "Add CLIP similarity if caption exists + add autocast in FrameMapper (#69)\n\n* Add CLIP similarity if caption exists\n\n* progress\n\n* fix lint\n\n* batch normalization of caption embs"
    },
    {
        "repo_url": "github.com/iejMac/clip-video-encode",
        "filepath": "clip_video_encode/simplemapper.py",
        "commit_date": "2023-04-02T10:43:30Z",
        "message": "Add CoCa captioning (#67)\n\n* Add CoCa captioning\n\n* works\n\n* fix black\n\n* req\n\n* fix lint\n\n* fix black\n\n* reset"
    },
    {
        "repo_url": "github.com/iejMac/clip-video-encode",
        "filepath": "clip_video_encode/simplemapper.py",
        "commit_date": "2022-07-31T20:45:12Z",
        "message": "LiveNumpyEncoder: waits for incoming frame arrays and encodes them with CLIP (1700 samples/s) (#31)\n\n* NumpyEncoder: waits for incoming frame arrays and encodes them with CLIP\n\n* works 1700 FPS\n\n* pass in dev\n\n* rename\n\n* add example\n\n* fix lint"
    },
    {
        "repo_url": "github.com/iejMac/clip-video-encode",
        "filepath": "clip_video_encode/simplemapper.py",
        "commit_date": "2022-06-15T06:52:42Z",
        "message": "Asynchronously Read and Encode frames for efficiency. (~4x speedup depending on target video FPS) (#7)\n\n* Asynchronously Load, Embed, and Save videos for efficiency\n\n* saver: initial version\n\n* that was supposed to be the loader\n\n* small update\n\n* small testing script\n\n* new idea\n\n* adding batcher\n\n* taking step back and reimplementing main in modules\n\n* Simple version of all 4 components\n\n* Move preprocessing to batcher + log perf in samples/s + batcher 2.7x performance improvement\n\n* Use multiprocessing to make Reader faster\n\n* simplereader -> reader\n\n* Batcher improvements + perf metrics update\n\n* add unit tests for all modules\n\n* add modules to package\n\n* Reading + Mapping parallelism\n\n* final version for update\n\n* Revert to regular preprocessing, channel dim might've been mixed up\n\n* tests updated\n\n* new clip_video_encode script\n\n* fix ci\n\n* ci fix\n\n* shared_memory not in python < 3.8\n\n* some linting + remove time prints\n\n* linting\n\n* lint fix\n\n* better default value for dest"
    },
    {
        "repo_url": "github.com/TIGER-AI-Lab/ImagenHub",
        "filepath": "src/imagen_hub/depend/clip_retrieval/load_clip.py",
        "commit_date": "2023-10-20T00:35:15Z",
        "message": "release 0.1.0"
    },
    {
        "repo_url": "github.com/Zhiyuan-R/ChatGPT-Powered-Hierarchical-Comparisons-for-Image-Classification",
        "filepath": "main.py",
        "commit_date": "2023-12-17T17:59:32Z",
        "message": "basic_files"
    },
    {
        "repo_url": "github.com/Ascend/ModelZoo-PyTorch",
        "filepath": "AscendIE/AscendIE/StableDiffusion/clip_score.py",
        "commit_date": "2023-10-09T12:26:20Z",
        "message": "!5610 [\u81ea\u7814][PyTorch\u79bb\u7ebf\u63a8\u7406][Text-to-Image][StableDiffusion] \u6dfb\u52a0AIE-SD\u7684unetparser\u529f\u80fd\u3001\u7cbe\u5ea6\u8ba1\u7b97\u529f\u80fd\u53caREADME\u63a8\u7406\u6307\u5bfc\n* fix bugs\n* Merge https://gitee.com/ascend/ModelZoo-PyTorch\n* fix codecheck issues\n* Merge https://gitee.com/ascend/ModelZoo-PyTorch\n* add unet_onnx_parser, clip score and readme"
    },
    {
        "repo_url": "github.com/Ascend/ModelZoo-PyTorch",
        "filepath": "ACL_PyTorch/built-in/foundation_models/stable_diffusion/clip_score.py",
        "commit_date": "2023-08-29T11:58:57Z",
        "message": "!5419 [\u81ea\u7814][PyTorch\u79bb\u7ebf\u63a8\u7406][Text-to-Image] StableDiffusion \u6dfb\u52a0\u7cbe\u5ea6\u9a8c\u8bc1\u3001\u4fee\u6539\u6539\u56fe\u811a\u672c\n* \u4fee\u590datc\u53c2\u6570\n* \u4fee\u6539main\u4f20\u53c2\u903b\u8f91\n* \u66ff\u6362\u4f7f\u7528fdopen\u8bfb\u53d6\u6587\u4ef6\n* \u4fee\u590d\u6539\u56fe\u811a\u672c\n* \u6dfb\u52a0\u7cbe\u5ea6\u8ba1\u7b97\u76f8\u5173\u5185\u5bb9\n* \u6dfb\u52a0\u7cbe\u5ea6\u8ba1\u7b97\u811a\u672c\n* \u6dfb\u52a0\u7cbe\u5ea6\u9a8c\u8bc1\u4f9d\u8d56\n* \u6dfb\u52a0\u652f\u6301\u8bfb\u53d6Parti\u6570\u636e\u96c6"
    },
    {
        "repo_url": "github.com/bentoml/CLIP-API-service",
        "filepath": "src/clip_api_service/models/openclip.py",
        "commit_date": "2023-10-11T18:33:36Z",
        "message": "fix: serve not using defined model"
    },
    {
        "repo_url": "github.com/bentoml/CLIP-API-service",
        "filepath": "src/clip_api_service/models/openclip.py",
        "commit_date": "2023-05-25T22:01:51Z",
        "message": "Added CLI"
    },
    {
        "repo_url": "github.com/bentoml/CLIP-API-service",
        "filepath": "src/clip_api_service/models/openclip.py",
        "commit_date": "2023-05-23T05:16:39Z",
        "message": "PDM, Ruff, Black - build WIP"
    },
    {
        "repo_url": "github.com/KaiyuYue/nxtp",
        "filepath": "src/evals/engine.py",
        "commit_date": "2023-12-04T19:15:15Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/r0mar0ma/sd-webui-pez-dispenser",
        "filepath": "scripts/optim_utils.py",
        "commit_date": "2023-09-18T19:35:23Z",
        "message": "missed file"
    },
    {
        "repo_url": "github.com/Ascend/ModelZoo-PyTorch",
        "filepath": "PyTorch/built-in/others/OpenCLIP_for_PyTorch/tests/util_test.py",
        "commit_date": "2023-05-17T12:47:36Z",
        "message": "!4706 [\u81ea\u7814][PyTorch] [OpenClip For Pytorch] \u521d\u6b21\u63d0\u4ea4\n* \u63d0\u4ea4open clip\u539f\u59cb\u4ee3\u7801"
    },
    {
        "repo_url": "github.com/Ascend/ModelZoo-PyTorch",
        "filepath": "PyTorch/built-in/others/OpenCLIP_for_PyTorch/tests/test_inference_simple.py",
        "commit_date": "2023-05-17T12:47:36Z",
        "message": "!4706 [\u81ea\u7814][PyTorch] [OpenClip For Pytorch] \u521d\u6b21\u63d0\u4ea4\n* \u63d0\u4ea4open clip\u539f\u59cb\u4ee3\u7801"
    },
    {
        "repo_url": "github.com/NVlabs/RADIO",
        "filepath": "radio/adaptors/open_clip_adaptor.py",
        "commit_date": "2024-02-14T17:08:56Z",
        "message": "Refactoring in preparation for RADIOv2 release (#25)"
    },
    {
        "repo_url": "github.com/NVlabs/RADIO",
        "filepath": "radio/adaptors/open_clip_adaptor.py",
        "commit_date": "2024-01-24T20:43:08Z",
        "message": "Add support for OpenCLIP adaptor (#17)\n\n* Add support for OpenCLIP adaptor\n\n* Working on zero-shot example script\n\n* Fixed inference\n\n* Make non-square processing the default\n\n* Update README\n\n* Update headers\n\n* MR comments\n\n* PR comments\n\n* Improve tqdm logging"
    },
    {
        "repo_url": "github.com/kyegomez/Gen1",
        "filepath": "gen1/clip.py",
        "commit_date": "2023-10-14T19:12:05Z",
        "message": "clean up"
    },
    {
        "repo_url": "github.com/kyegomez/Gen1",
        "filepath": "gen1/clip.py",
        "commit_date": "2023-09-24T01:07:35Z",
        "message": "clean upsss"
    },
    {
        "repo_url": "github.com/kyegomez/Gen1",
        "filepath": "gen1/clip.py",
        "commit_date": "2023-09-24T01:07:05Z",
        "message": "clean up requirements.txt"
    },
    {
        "repo_url": "github.com/kyegomez/Gen1",
        "filepath": "gen1/clip.py",
        "commit_date": "2023-09-23T23:53:59Z",
        "message": "pipeline, image, text, => midas =>"
    },
    {
        "repo_url": "github.com/kyegomez/Gen1",
        "filepath": "gen1/clip.py",
        "commit_date": "2023-09-23T23:50:34Z",
        "message": "clip"
    },
    {
        "repo_url": "github.com/wangyu-ustc/LM4CV",
        "filepath": "cluster.py",
        "commit_date": "2023-10-03T08:56:05Z",
        "message": "Add files via upload"
    },
    {
        "repo_url": "github.com/SKKU-ESLAB/Auto-Compression",
        "filepath": "pruning/UVP/Transformer/sparseml/integrations/clip/clip_onnx_export.py",
        "commit_date": "2023-06-19T04:13:43Z",
        "message": "[UVP] Add sparseml library"
    },
    {
        "repo_url": "github.com/technion-cs-nlp/ReFACT",
        "filepath": "test_clip_score.py",
        "commit_date": "2023-05-31T08:36:02Z",
        "message": "initial commit"
    },
    {
        "repo_url": "github.com/technion-cs-nlp/ReFACT",
        "filepath": "test_multiple_edits.py",
        "commit_date": "2023-05-31T08:36:02Z",
        "message": "initial commit"
    },
    {
        "repo_url": "github.com/Max-Fu/tvl",
        "filepath": "tvl_enc/tvl.py",
        "commit_date": "2024-02-20T21:25:56Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/google/storybench",
        "filepath": "metrics/vtm_clip.py",
        "commit_date": "2023-08-17T14:24:09Z",
        "message": "Initial version of StoryBench code."
    },
    {
        "repo_url": "github.com/MadryLab/dataset-interfaces",
        "filepath": "dataset_interfaces/inference_utils.py",
        "commit_date": "2023-02-24T20:28:10Z",
        "message": "add token download to notebook"
    },
    {
        "repo_url": "github.com/MadryLab/dataset-interfaces",
        "filepath": "dataset_interfaces/inference_utils.py",
        "commit_date": "2023-02-16T22:23:08Z",
        "message": "Refactor to make imports cleaner"
    },
    {
        "repo_url": "github.com/MadryLab/dataset-interfaces",
        "filepath": "dataset_interfaces/inference_utils.py",
        "commit_date": "2023-02-16T05:02:03Z",
        "message": "initial commit"
    },
    {
        "repo_url": "github.com/wusize/CLIM",
        "filepath": "tools/generate_text_embeddings.py",
        "commit_date": "2023-12-18T16:08:09Z",
        "message": "init"
    },
    {
        "repo_url": "github.com/wusize/CLIM",
        "filepath": "ovdet/tools/generate_text_embeddings.py",
        "commit_date": "2023-12-20T16:02:40Z",
        "message": "debug"
    },
    {
        "repo_url": "github.com/wusize/CLIM",
        "filepath": "ovdet/tools/generate_text_embeddings.py",
        "commit_date": "2023-12-20T10:03:41Z",
        "message": "fvlm"
    },
    {
        "repo_url": "github.com/emu1729/GIST",
        "filepath": "caption_matching.py",
        "commit_date": "2023-07-25T17:41:04Z",
        "message": "Fixed import"
    },
    {
        "repo_url": "github.com/emu1729/GIST",
        "filepath": "caption_matching.py",
        "commit_date": "2023-07-19T19:39:59Z",
        "message": "Cleaned up caption matching"
    },
    {
        "repo_url": "github.com/emu1729/GIST",
        "filepath": "caption_matching.py",
        "commit_date": "2023-07-19T19:06:41Z",
        "message": "Added caption matching script and example"
    },
    {
        "repo_url": "github.com/emu1729/GIST",
        "filepath": "caption_matching.py",
        "commit_date": "2023-07-19T18:38:25Z",
        "message": "Added datasets and sample metadata files"
    },
    {
        "repo_url": "github.com/yasserben/CLOUDS",
        "filepath": "clouds/modeling/backbone/clip.py",
        "commit_date": "2023-12-15T15:43:08Z",
        "message": "release CLOUDS"
    },
    {
        "repo_url": "github.com/yasserben/CLOUDS",
        "filepath": "clouds/modeling/backbone/trainable_clip.py",
        "commit_date": "2023-12-15T15:43:08Z",
        "message": "release CLOUDS"
    },
    {
        "repo_url": "github.com/baaivision/MUSE-Pytorch",
        "filepath": "extract_empty_feature.py",
        "commit_date": "2023-05-08T11:47:07Z",
        "message": "add cc ctx prepare"
    },
    {
        "repo_url": "github.com/baaivision/MUSE-Pytorch",
        "filepath": "extract_test_prompt_feature.py",
        "commit_date": "2023-05-08T11:47:07Z",
        "message": "add cc ctx prepare"
    },
    {
        "repo_url": "github.com/sail-sg/MMCBench",
        "filepath": "text2image/evaluate.py",
        "commit_date": "2024-01-23T02:53:44Z",
        "message": "update image2text"
    },
    {
        "repo_url": "github.com/sail-sg/MMCBench",
        "filepath": "text2image/evaluate.py",
        "commit_date": "2024-01-23T00:45:43Z",
        "message": "add text2speech"
    },
    {
        "repo_url": "github.com/sail-sg/MMCBench",
        "filepath": "text2image/evaluate.py",
        "commit_date": "2024-01-22T08:27:04Z",
        "message": "add text2image"
    },
    {
        "repo_url": "github.com/sail-sg/MMCBench",
        "filepath": "image2text/evaluate.py",
        "commit_date": "2024-01-23T02:53:44Z",
        "message": "update image2text"
    },
    {
        "repo_url": "github.com/NVIDIA-AI-IOT/clip-distillation",
        "filepath": "compute_openclip_text_embeddings.py",
        "commit_date": "2023-07-25T17:32:24Z",
        "message": "add license"
    },
    {
        "repo_url": "github.com/NVIDIA-AI-IOT/clip-distillation",
        "filepath": "compute_openclip_text_embeddings.py",
        "commit_date": "2023-06-27T21:38:18Z",
        "message": "remove intro"
    },
    {
        "repo_url": "github.com/workforai/SCAN",
        "filepath": "open_clip_training/tests/util_test.py",
        "commit_date": "2024-03-02T18:28:58Z",
        "message": "SCAN first commit"
    },
    {
        "repo_url": "github.com/workforai/SCAN",
        "filepath": "open_clip_training/tests/test_inference_simple.py",
        "commit_date": "2024-03-02T18:28:58Z",
        "message": "SCAN first commit"
    },
    {
        "repo_url": "github.com/workforai/SCAN",
        "filepath": "open_clip_training/tests/test_download_pretrained.py",
        "commit_date": "2024-03-02T18:28:58Z",
        "message": "SCAN first commit"
    },
    {
        "repo_url": "github.com/gregor-ge/mBLIP",
        "filepath": "data/pretrain/hard_examples.py",
        "commit_date": "2023-09-22T09:15:00Z",
        "message": "Updated for version 2 on arxiv"
    },
    {
        "repo_url": "github.com/gregor-ge/mBLIP",
        "filepath": "data/pretrain/generate_match_train.py",
        "commit_date": "2023-09-22T09:15:00Z",
        "message": "Updated for version 2 on arxiv"
    },
    {
        "repo_url": "github.com/VQAssessment/BVQI",
        "filepath": "prompt_tuning.py",
        "commit_date": "2023-05-20T08:23:42Z",
        "message": "extension"
    },
    {
        "repo_url": "github.com/VQAssessment/BVQI",
        "filepath": "load_features.py",
        "commit_date": "2023-05-20T08:23:42Z",
        "message": "extension"
    },
    {
        "repo_url": "github.com/VQAssessment/BVQI",
        "filepath": "semantic_affinity.py",
        "commit_date": "2023-03-19T11:36:25Z",
        "message": "Update, Reproduce, and ICME"
    },
    {
        "repo_url": "github.com/VQAssessment/BVQI",
        "filepath": "semantic_affinity.py",
        "commit_date": "2023-01-16T05:20:44Z",
        "message": "renew code"
    },
    {
        "repo_url": "github.com/VQAssessment/BVQI",
        "filepath": "semantic_affinity.py",
        "commit_date": "2022-12-19T09:16:58Z",
        "message": "fix"
    },
    {
        "repo_url": "github.com/VQAssessment/BVQI",
        "filepath": "semantic_affinity.py",
        "commit_date": "2022-12-19T09:06:47Z",
        "message": "initial"
    },
    {
        "repo_url": "github.com/zhang-tao-whu/DVIS_Plus",
        "filepath": "ov_dvis/backbones/clip.py",
        "commit_date": "2023-12-22T03:02:11Z",
        "message": "init"
    },
    {
        "repo_url": "github.com/waterhorse1/ChessGPT",
        "filepath": "eval/eval_clip/eval_multi_choice.py",
        "commit_date": "2023-06-24T15:03:14Z",
        "message": "all"
    },
    {
        "repo_url": "github.com/waterhorse1/ChessGPT",
        "filepath": "eval/eval_clip/eval_multi_choice.py",
        "commit_date": "2023-06-13T04:56:08Z",
        "message": "add chessclip evaluation"
    },
    {
        "repo_url": "github.com/waterhorse1/ChessGPT",
        "filepath": "eval/eval_clip/eval_clip_checkmate_in_one.py",
        "commit_date": "2023-06-24T15:03:14Z",
        "message": "all"
    },
    {
        "repo_url": "github.com/waterhorse1/ChessGPT",
        "filepath": "eval/eval_clip/eval_clip_checkmate_in_one.py",
        "commit_date": "2023-06-13T04:56:08Z",
        "message": "add chessclip evaluation"
    },
    {
        "repo_url": "github.com/waterhorse1/ChessGPT",
        "filepath": "chessclip/tests/util_test.py",
        "commit_date": "2023-06-13T02:00:33Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/waterhorse1/ChessGPT",
        "filepath": "chessclip/tests/test_inference_simple.py",
        "commit_date": "2023-06-13T02:00:33Z",
        "message": "first commit"
    },
    {
        "repo_url": "github.com/Vinayak-VG/GSN",
        "filepath": "tasks/segment_2d_text.py",
        "commit_date": "2023-12-15T07:50:21Z",
        "message": "gsn"
    },
    {
        "repo_url": "github.com/Vinayak-VG/GSN",
        "filepath": "feature_extractor/langfeat_extract_dtu.py",
        "commit_date": "2023-12-15T07:50:21Z",
        "message": "gsn"
    },
    {
        "repo_url": "github.com/Vinayak-VG/GSN",
        "filepath": "feature_extractor/langfeat_extract_llff.py",
        "commit_date": "2023-12-15T07:50:21Z",
        "message": "gsn"
    },
    {
        "repo_url": "github.com/OPPO-Mente-Lab/PEA-Diffusion",
        "filepath": "train_sd_zh.py",
        "commit_date": "2023-11-30T01:13:46Z",
        "message": "Add files via upload"
    },
    {
        "repo_url": "github.com/OPPO-Mente-Lab/PEA-Diffusion",
        "filepath": "train_sdxl_zh.py",
        "commit_date": "2023-11-30T01:13:46Z",
        "message": "Add files via upload"
    },
    {
        "repo_url": "github.com/OPPO-Mente-Lab/PEA-Diffusion",
        "filepath": "utils/custom_dataset.py",
        "commit_date": "2023-11-30T01:13:46Z",
        "message": "Add files via upload"
    },
    {
        "repo_url": "github.com/OPPO-Mente-Lab/PEA-Diffusion",
        "filepath": "utils/custom_dataset_sdxl.py",
        "commit_date": "2023-11-30T01:13:46Z",
        "message": "Add files via upload"
    },
    {
        "repo_url": "github.com/OPPO-Mente-Lab/PEA-Diffusion",
        "filepath": "tests/test_sd_zh.py",
        "commit_date": "2023-11-30T01:13:46Z",
        "message": "Add files via upload"
    },
    {
        "repo_url": "github.com/OPPO-Mente-Lab/PEA-Diffusion",
        "filepath": "tests/test_sdxl_zh.py",
        "commit_date": "2023-11-30T01:13:46Z",
        "message": "Add files via upload"
    },
    {
        "repo_url": "github.com/OPPO-Mente-Lab/PEA-Diffusion",
        "filepath": "tests/test_sdxl_zh_lcm.py",
        "commit_date": "2023-11-30T01:13:46Z",
        "message": "Add files via upload"
    },
    {
        "repo_url": "github.com/OPPO-Mente-Lab/PEA-Diffusion",
        "filepath": "tests/test_sdxl_zh_controlnet.py",
        "commit_date": "2023-11-30T01:13:46Z",
        "message": "Add files via upload"
    }
]