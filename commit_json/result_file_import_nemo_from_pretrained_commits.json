[
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2024-02-06T00:26:43Z",
        "message": "Support uploading NeMo models to HF via `push_to_hf_hub()` (#8263)\n\n* Initial support for saving unpacked nemo file directly and support for uploading NeMo models to Huggingface Hub\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add support to restore nemo models from HF in unpacked format\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Correct input types for model card\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update License Section to template\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add unit test to restore via unpacked checkpoint\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix typo\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Address comments\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Address comments\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add docs and address comments\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2024-01-24T18:25:22Z",
        "message": "Add support in Neural Typecheck to disable semantic checks (#8212)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2022-12-12T19:27:42Z",
        "message": "AIStore for ASR datasets (#5462)\n\nAIStore for ASR datasets\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2022-11-10T19:43:34Z",
        "message": "Fix Python type hints according to Python Docs (#5370)\n\n* Remove duplicated type annotations\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Fix tuple annotations in function return types\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Add necessary imports\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Add necessary imports\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Fix types in obvious places\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Fix types in obvious places\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Fix unused import (avoid quotes in type annotations)\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Revert \"Fix unused import (avoid quotes in type annotations)\"\n\nThis reverts commit ea433efcd9916abf8944879e791484a0a1437f83.\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Remove problematic import\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Fix list_available_models method type\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Revert some changes\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Revert quotes in list_available_models\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2022-10-24T20:22:44Z",
        "message": "[TTS] remove LinVocoder and apply Vocoder as parent class. (#5206)\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2022-10-21T16:17:23Z",
        "message": "[TTS] remove the avoidance of circular imports (#5214)\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2022-10-11T20:22:39Z",
        "message": "Fixes for docs/typos + remove max_utts parameter from tarred datasets as it causes hang in training (#5118)\n\n* Remove ; from jupyter notebook cells\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Fix typos in documentation/code\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Fix output message to have 'or equal'\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Link formatting fixes\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Add error if max_utts is used in tarred datasets\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Remove max_utts parameter from tarred datasets\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Fix max_utts removal in tests\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Fix typo if -> is\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2022-07-27T22:12:53Z",
        "message": "Support listing Hugging Face model info (#4619)\n\n* Support listing Hugging Face model info\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Add documentation about usage\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Add documentation about usage\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Update name of method, support list of model filters\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Improve docstring\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2022-06-01T21:28:56Z",
        "message": "Update common.py (#4304)\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2022-04-28T16:50:07Z",
        "message": "Add docs for `@typecheck()` (#4079)\n\n* Add docs for `@typecheck()``\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add more fixes to core docs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2022-04-25T19:21:58Z",
        "message": "Cherry pick HF integration and bug fixes from 1.8.1 (#4052)\n\n* Patch commons.py (#4039)\n\n* revert export.py changes\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert hack\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Add support for Huggingface Hub to NeMo `from_pretrained()` (#4030)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fixing pretrained name (#4022)\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\n\n* Add back Citrinet zh (#4040)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\n\n* cherry pick\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Boris Fomitchev <borisfom@users.noreply.github.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Subhankar Ghosh <subhankar2321@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2022-04-20T22:46:30Z",
        "message": "Merge r1.8.0 main (#4036)\n\n* update version\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Stateless timer fix for PTL 1.6 (#3925)\n\n* Stateless timer fix for PTL 1.6\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Stateless timer PTL test\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix year\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove unused imports\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* GPU test\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* clean import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: ericharper <complex451@gmail.com>\n\n* Fix issues with librosa deprecations (#3950)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix notebook bugs for branch r1.8.0 (#3948)\n\n* load the model from ngc\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix all biomegatron notebook\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix the typos\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* remove output\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix isort\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix merge error\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* change ntpath for isort workaround\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix unit test\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix ci\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix ci bert pretraining\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* make it compatible with main\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* add the teste for biomegatron ner\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix argument\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix usablity issue\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* work around\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Yi Dong <doyend@gmail.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix global batch fit loop (#3936)\n\n* add lightning module hooks for global batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean scripts\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* DP=1 fix\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* set num dataset workers to 2\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update validation_loop with GlobalDataFetcher\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add test global data fetcher\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Drop last for test ds\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix test epoch end\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix eval\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix reconfigure microbatch in the complete method\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add comments\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Set init consumed samples\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* fix shuffle\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add save_restore_connector arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix padding for labels and loss mask\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* GLUE/XNLI CI tests\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* limit val batches in hydra fix\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Restart CI\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix unittest\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Exports 22.03 war (#3957)\n\n* Fixed fastpitch for 22.03\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* cleanup\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Restored mask expansion; added WAR for test container images\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* style\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Refactor restorefrom (#3927)\n\n* update package info (#3926)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Refactor restore_from\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Move export related python files to scripts/export/\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Return state dict after modification function\n\n* Remove Megatron legacy parameter in common.py restore_from function\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* ability to set log_predictions to false (#3929)\n\n* Bumping Python version\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fixing style\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* load the model from ngc\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix all biomegatron notebook\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix the typos\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* remove output\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix isort\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix merge error\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* change ntpath for isort workaround\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix unit test\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix ci\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix ci bert pretraining\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* Rearrage export files; Style fix; Extend legacy MegatronBert conversion to NLP models nemo version updation\n\n* Glu activation variants (#3951)\n\n* Temp\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Add reglu and swiglu activations\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style on unrelated file\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* CI changes to test activations\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix unused import\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fix beacuse of merge from main\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* make it compatible with main\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* add the teste for biomegatron ner\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix argument\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix usablity issue\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* FastPitch FT notebook - Improving Speech Quality clarifications (#3954)\n\n* FastPitch FT notebook - Improving Speech Quality clarifications\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Add pynini dependency install to FastPitch FT notebook\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Pin pynini install for FastPitch FT tutorial\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* work around\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\nCo-authored-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\nCo-authored-by: Dima Rekesh <bmwshop@gmail.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nCo-authored-by: Yi Dong <doyend@gmail.com>\nCo-authored-by: Yi Dong <43824965+yidong72@users.noreply.github.com>\nCo-authored-by: Boris Fomitchev <borisfom@users.noreply.github.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Jocelyn <jocelynh@nvidia.com>\n\n* Bump TTS deprecation version to 1.9 (#3955)\n\n* bump deprecation version\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update talknet depre\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* added conformer for zh. (#3970)\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* Add pinned pynini and scipy installs to TTS training tutorial (#3967)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Fix variable name and move models to CPU in Change partition (#3972)\n\n* fixes\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* add CI\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\n\n* fix misconfiguration (#3975)\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Yi Dong <doyend@gmail.com>\n\n* Fix NMT variable passing bug (#3985)\n\n* fix\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* stylefix\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* Compatability override to load_state_dict for old TTS checkpoints (#3978)\n\n* Compatability override to load_state_dict for old TTS checkpoints\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Tacotron2 training notebook fix - add GPU argument\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Add hann window override warning for old model loading\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Notebook Bug Fixes for r1.8.0 (#3989)\n\n* Made config related bug fixes\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Fixed cfg.get syntax\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Fix compat override for TalkNet Aligner (#3993)\n\n* Fix compatibility override for TalkNet Aligner\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Remove extraneous logging import\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* docs fixes (#3987)\n\n* docs fixes\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* rename files in docs\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* docs improvement\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* arg renamed\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* Fix nemo megatron restore with artifacts (#3997)\n\n* update config_path in register_artifact\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix register_artifact calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix register_artifact calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update log messages to include merges file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add default prompts to config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fixes val_check_interval, skip loading train data during eval (#3968)\n\n* Change stage check\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix bugs in megatron t5 glue eval scripts\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Fix reconfigure\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Change check\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix hasattr\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix typo in cfg structure\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Update megatron t5 glue eval config file\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Reconfigure to avoid drop last\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix for train step reconfigure as well\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Update megatron t5 glue eval config file drop_last to False\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* limit test batches\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: Yu Yao <54727607+yaoyu-33@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* LogProb calculation performance fix (#3984)\n\n* performance fix for logprob computation\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix redandant assign\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix bug to add gather from TP workers\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Yi Dong <doyend@gmail.com>\n\n* Fix link issues in export example notebook and fix pretrained model info for MegatronBert (#4004)\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\nCo-authored-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Fix single GPU training issue + change deprecated Lightning args (#4010)\n\n* change vars\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* style fix\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* Fix P-Tune T5 model (#4001)\n\n* fix ptune t5\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix ci test\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix the ci fail because of the order problem\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Yi Dong <doyend@gmail.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Megatron work-arounds (#3998)\n\n* WAR around Apex issue, and making sure output is FP32\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixing merge issues; moving dummy Trainer; adding float() casts\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixing ColumnParallelLinear call\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Cleanup\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Cleanup#2\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* fix the broadcast shape mismatch (#4017)\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Yi Dong <doyend@gmail.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* add known issues (#4024)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update readme with conda env setup instructions\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert apex guard removal\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert --language to --lang\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix apex guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove set_trace\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix apex guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unreachable statement\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove duplicate lines\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove duplicate lines\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Yi Dong <43824965+yidong72@users.noreply.github.com>\nCo-authored-by: Yi Dong <doyend@gmail.com>\nCo-authored-by: Boris Fomitchev <borisfom@users.noreply.github.com>\nCo-authored-by: Ramanathan Arunachalam <ramanathan.arun@rutgers.edu>\nCo-authored-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\nCo-authored-by: Dima Rekesh <bmwshop@gmail.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nCo-authored-by: Jocelyn <jocelynh@nvidia.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Vahid Noroozi <VahidooX@users.noreply.github.com>\nCo-authored-by: Abhinav Khattar <aklife97@gmail.com>\nCo-authored-by: Virginia Adams <78445382+vadam5@users.noreply.github.com>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\nCo-authored-by: Yu Yao <54727607+yaoyu-33@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2022-04-14T15:56:58Z",
        "message": "[Core] Fix type checking to be compatible with named tuples (#3986)\n\n* Fix type checking for outputs to be compatible with named tuples\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Fix output names in tests\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2022-04-04T19:12:30Z",
        "message": "Megatron legacy conversion support (#3919)\n\n* Fix merge from main\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Rollback scripts/export.py changes and create a new file for converting legacy MegatronBert NLP models to current version\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Cleanup legacy conversion code\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Move state dict mapping of legacy Megatron to NLPSaveRestoreConnector; Do transpose op in Self attention if it's a legacy checkpoint; Add a example notebook for exporting NLP Bert models\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Style fix\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\nCo-authored-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2022-02-07T18:09:41Z",
        "message": "Fixed EH and error reporting in restore_from (#3583)\n\n* Fixed EH and error reporting in restore_from\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* --amend\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed merge issue\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2022-02-04T18:30:37Z",
        "message": "[TTS] remove CheckInstall (#3577)\n\n* remove CheckInstall\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* remove torch_tts install\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* move torch_tts tests to elsewhere in Jenkins\n\nSigned-off-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2022-01-31T22:20:29Z",
        "message": "Final merge r1.6.0 main (#3570)\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix the tutorial notebooks bug (#3465)\n\n* fix checkpoint loading and model config file\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix style\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* Fix checkpoint converter in O2 style (#3486)\n\n* Fix checkpoint converter in O2 style\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Fix style\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\nCo-authored-by: Yu Yao <yuya@nvidia.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Remove pickled features from tarred dataset (#3491)\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\nCo-authored-by: ekmb <ebakhturina@nvidia.com>\n\n* adding missing init files (#3505)\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* typos (#3504)\n\n* typos\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* link fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* update titanet conf (#3507)\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* Fix link to NGC page for ASR (#3512)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* vad typo fix (#3490)\n\n* remove always broken ptl link\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* fix typo\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* Add verification helper function and update docs (#3514)\n\n* Add verification helper function and update docs\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* typo fixes\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* fixed the num_classes bug of conv decoder. (#3525)\n\n* fixed the num_classes bug.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added logging info.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* Enforce utf-8 on all file r/w (#3520)\n\n* Update paths to subtask\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Enforce utf-8 on all file r/w\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fixed section typo (#3522)\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Pushing updated WFST Tutorial to r1.6.0 (#3521)\n\nSigned-off-by: tbartley94 <tbartley@nvidia.com>\n\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\n\n* Fixed duplicate cell bug (#3518)\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* WFST tutorial update (#3531)\n\n* Pushing updated WFST Tutorial to r1.6.0\n\nSigned-off-by: tbartley94 <tbartley@nvidia.com>\n\n* Hopefully final corrections to WFST tutorials.\n\nSigned-off-by: tbartley94 <tbartley@nvidia.com>\n\n* [TTS] Fix bug in inference tts notebook (#3532)\n\n* fix bug in inference tts notebook\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* Update Inference_ModelSelect.ipynb\n\n* fix space\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* remove space\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* Prompt tuning documentation (#3541)\n\n* Started prompt tuning doc\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Update prompt_tuning.rst\n\n* Update models.rst\n\n* Update models.rst\n\n* Update and rename megatron_finetuning.rst to megatron_downstream_tasks.rst\n\n* Update intro.rst\n\n* Update intro.rst\n\n* Update and rename megatron_downstream_tasks.rst to megatron_finetuning.rst\n\n* Update megatron_finetuning.rst\n\n* Delete prompt_tuning.rst\n\n* Update README.rst\n\n* Update docs/source/nlp/megatron_finetuning.rst\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix nmt resume (#3539)\n\n* check for model attr\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* TN bug fix (#3538)\n\n* ve and cel fixes\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* ve and cel fixes\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add w to single digit roman and cardinal single digit graph (non det)\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* isn't fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* fix bug in tutorial (#3546)\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* Update nvidia container check (#3535)\n\n* update nvidia container check\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update minor version\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add check to T5\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update bert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* forgot import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix an issue with wandb not displaying updated config changes (#3552)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* remove extra instance (#3551)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Yi Dong <43824965+yidong72@users.noreply.github.com>\nCo-authored-by: yaoyu-33 <54727607+yaoyu-33@users.noreply.github.com>\nCo-authored-by: Yu Yao <yuya@nvidia.com>\nCo-authored-by: PeganovAnton <peganoff2@mail.ru>\nCo-authored-by: ekmb <ebakhturina@nvidia.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: Vahid Noroozi <VahidooX@users.noreply.github.com>\nCo-authored-by: Virginia Adams <78445382+vadam5@users.noreply.github.com>\nCo-authored-by: tbartley94 <90423858+tbartley94@users.noreply.github.com>\nCo-authored-by: Oktai Tatanov <oktai.tatanov@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2021-11-22T22:41:34Z",
        "message": "CTC Conformer fixes for ONNX/TS export  (#3072)"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2021-11-18T18:33:58Z",
        "message": "Add support to modify nemo cache directory (#3208)\n\n* Add support to modify nemo cache directory\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct cache dir resolution with absolute path\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2021-11-10T08:37:19Z",
        "message": "Adding parallel transcribe for ASR models -  suppports multi-gpu/multi-node (#3017)\n\n* added transcribe_speech_parallel.py.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed style.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* removed comments.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed bug.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed bug.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added comments inside the script.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed speed_collate_fn for TTS.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed speed_collate_fn for TTS.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed speed_collate_fn for TTS.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed speed_collate_fn for TTS.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added return_sample_id.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added return_sample_id.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* merged dataset configs.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* merged dataset configs.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* dropped sample_ids from train and validation.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* dropped sample_ids from train and validation.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* reverted tts patches.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* reverted tts patches.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed the default values in the dataset's config\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed the default values in the dataset's config\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* Fixed the bug for optional outputs.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* Fixed the bug for optional outputs.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* addressed some comments.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* disabled dali support for return_sample_id.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* disabled dali support for return_sample_id.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* converted the config to omegaconf.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* converted the config to omegaconf.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* converted the config to omegaconf.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* moved wer/cer calculation to the end.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* moved wer/cer calculation to the end.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* moved wer/cer calculation to the end.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* moved wer/cer calculation to the end.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* moved wer/cer calculation to the end.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* calculates global wer instead of per sample.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* calculates global wer instead of per sample.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* calculates global wer instead of per sample.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2021-10-21T03:06:37Z",
        "message": "[BigNLP] Merge Megatron GPT to main (#2975)\n\n* fix gpu init after removing debug print in mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_adam\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check ds is not none before logging len\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set fp16 arg to true and fix enum conflict\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make fp16 arg configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add grad clip from megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Linear warmup with cosine annealing and constant holding (#2846)\n\n* Testing cosine schedule\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* More fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* update config for constant steps in schedule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* temporarily import enum from megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add grad clip for fp32\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update check for _del_model_without_trainer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating restore for model parallel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add predict script\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update test iters\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add barrier\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* return if clip_val is 0 or None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* when using amp clip grads after they are unscaled\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make native amp scaler hyperparams configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* (1) nvfuser, (2) amp-casting decoration (#2894)\n\n* (1) nvfuser, (2) amp-casting decoration\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* support bf16\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add set device to constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [BigNLP] Remove megatron-lm dependency. (#2910)\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update megatron_init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update process batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron clip_grad\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* trying to resolve circular import error\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove non-gpt models and datasets from __init__ files\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update MegatronDataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename fp16 and bf16 flags to fused_softmax_input_in_fp16/bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename to fused_fp16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_fp16 arg to LayerNorm calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Adding complete method to MegatronGPTModel (#2935)\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* make ffn_hidden_size mandatory\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Manually migrating timing of step into branch (#2937)\n\n* 1. Manually migrating timing of step into branch.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated file name and content.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated to latest code.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check fused_fp16 and fused_bf16 are not both True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update predict script for model parallel .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* NVfuser (#2943)\n\n* activation checkpoint recompute\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* selective nvfuser setup\n\n* Megatron gpt bfloat support (#2926)\n\n* Save/restore fix\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Another merge\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Bf16 args in init\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Set precision\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove debug stuff\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add bf16 casting decorator\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* Bfloat layernorm propagation\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* activation checkpoint recompute\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* selective nvfuser setup\n\n* More arg removal\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove BERTDataset\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* update to latest apex and patch transformer autocast\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: ericharper <complex451@gmail.com>\n\n* don't set jit for bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* replace apex.mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix grad clip\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* NVFuser fixes (#2951)\n\n* Fuser fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove dummy handler\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove PTL plugin based logic for fusion\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* remove duplicated file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo (#2960)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [BigNLP] Script to convert GPT checkpoint to .nemo (#2958)\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update megatron_init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update process batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron clip_grad\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* trying to resolve circular import error\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove non-gpt models and datasets from __init__ files\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update MegatronDataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename fp16 and bf16 flags to fused_softmax_input_in_fp16/bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename to fused_fp16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_fp16 arg to LayerNorm calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Adding complete method to MegatronGPTModel (#2935)\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* make ffn_hidden_size mandatory\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Manually migrating timing of step into branch (#2937)\n\n* 1. Manually migrating timing of step into branch.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated file name and content.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated to latest code.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check fused_fp16 and fused_bf16 are not both True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update predict script for model parallel .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add script to convert .ckpt to .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* convert mp checkpoints to nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update help\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add safeguard for model parallel save_to\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adjust NLPModel save_to to be safer for model parallel\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* [BigNLP] Update GPT evaluation to work with tensor model parallel  (#2959)\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add request dataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* tokenize request\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* able to run\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* reduce logits\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* capture response\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* squeeze and unsqueeze\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* handle non model parallel case\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* convert logits to log_probs\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* rename logits to log_probs\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* add megatron gpt pretraining\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron gpt pretraining\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron gpt pretraining\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating to work with latest megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating to work with latest megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update _del_model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding gpt model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding gpt model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding gpt model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* instantiate GPTmodel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding build dataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* build megatron dataset in .setup\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* setup dataloader\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add vocab_file and merge_file to megatron init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add forward\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add train loss\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add optimizer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add exp_manager\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* multi-gpu is working\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding val loop\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding val loop\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix ranks\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix model parallel checkpoint saving\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix _del_model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* added megatron batch sampler\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* try to fix num steps\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add wandb to config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* log lr\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add warmup ratio to config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update configs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update configs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add cpu init to args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Initial megatron dataset port\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix merge conflicts\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* License fixes and megatron model porting\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* More fixes to import from nemo rather than megatron\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix circular imports\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Revert config file\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Restructure further to avoid circular imports\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add Makefile\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Add megatron modules\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add license\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Port from latest megatron\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* update cfg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add _del_model_without_trainer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add data preprocessing script\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use apex mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* replace print_rank_0 with nemo utils logging\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use apex mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use apex mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add use_cpu_initialization\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fixing autoresume in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* properly removing last checkpoint\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* log consumed samples\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix mp autoresume\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add NLPSaveRestoreConnector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Megatron GPT training with NeMo tokenizers (#2818)\n\n* Update files from megatron repo\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove non NLP data related files from megatron\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Merge megatron and nemo tokenizers\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove get_tokenizer() calls from gpt model\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Update tokenizer yaml config\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add todo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make init_method_std configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make gpu init work by setting random seed earlier\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix gpu init after removing debug print in mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_adam\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check ds is not none before logging len\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set fp16 arg to true and fix enum conflict\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make fp16 arg configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add grad clip from megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Linear warmup with cosine annealing and constant holding (#2846)\n\n* Testing cosine schedule\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* More fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* update config for constant steps in schedule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* temporarily import enum from megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add grad clip for fp32\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update check for _del_model_without_trainer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating restore for model parallel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add predict script\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update test iters\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add barrier\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* return if clip_val is 0 or None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* when using amp clip grads after they are unscaled\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make native amp scaler hyperparams configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* (1) nvfuser, (2) amp-casting decoration (#2894)\n\n* (1) nvfuser, (2) amp-casting decoration\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* support bf16\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add set device to constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [BigNLP] Remove megatron-lm dependency. (#2910)\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update megatron_init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update process batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron clip_grad\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* trying to resolve circular import error\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove non-gpt models and datasets from __init__ files\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update MegatronDataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename fp16 and bf16 flags to fused_softmax_input_in_fp16/bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename to fused_fp16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_fp16 arg to LayerNorm calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Adding complete method to MegatronGPTModel (#2935)\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* make ffn_hidden_size mandatory\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Manually migrating timing of step into branch (#2937)\n\n* 1. Manually migrating timing of step into branch.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated file name and content.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated to latest code.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check fused_fp16 and fused_bf16 are not both True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update predict script for model parallel .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* NVfuser (#2943)\n\n* activation checkpoint recompute\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* selective nvfuser setup\n\n* Megatron gpt bfloat support (#2926)\n\n* Save/restore fix\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Another merge\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Bf16 args in init\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Set precision\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove debug stuff\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add bf16 casting decorator\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* Bfloat layernorm propagation\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* activation checkpoint recompute\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* selective nvfuser setup\n\n* More arg removal\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove BERTDataset\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* update to latest apex and patch transformer autocast\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: ericharper <complex451@gmail.com>\n\n* don't set jit for bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* replace apex.mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix grad clip\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* NVFuser fixes (#2951)\n\n* Fuser fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove dummy handler\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove PTL plugin based logic for fusion\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* remove duplicated file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo (#2960)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [BigNLP] Script to convert GPT checkpoint to .nemo (#2958)\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update megatron_init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update process batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron clip_grad\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* trying to resolve circular import error\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove non-gpt models and datasets from __init__ files\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update MegatronDataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename fp16 and bf16 flags to fused_softmax_input_in_fp16/bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename to fused_fp16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_fp16 arg to LayerNorm calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Adding complete method to MegatronGPTModel (#2935)\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* make ffn_hidden_size mandatory\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Manually migrating timing of step into branch (#2937)\n\n* 1. Manually migrating timing of step into branch.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated file name and content.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated to latest code.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check fused_fp16 and fused_bf16 are not both True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update predict script for model parallel .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add script to convert .ckpt to .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* convert mp checkpoints to nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update help\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add safeguard for model parallel save_to\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adjust NLPModel save_to to be safer for model parallel\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* [BigNLP] Update GPT evaluation to work with tensor model parallel  (#2959)\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add request dataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* tokenize request\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* able to run\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* reduce logits\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* capture response\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* squeeze and unsqueeze\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* handle non model parallel case\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* convert logits to log_probs\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* rename logits to log_probs\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix copyright headers\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix copyright headers\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove old TimingCallback\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins to use latest apex and sandeep's fork\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* try 2109 container\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* try cuda container\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use internal container\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update checkpoint tests\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix scheduler args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update eval\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins to use ptl 1.5 rc\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add import guard to jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add import guard to jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove deterministic\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* install numba .53\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* allow for more variance\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update trainer config dataclass\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* test_get_optimizer on gpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* change trainer config default to 32\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [BigNLP] Remove fused kernel code instead use Apex (#2984)\n\n* remove fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove fused layer norm and fused softmax and use apex instead\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use apex enums\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use apex enums\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add tab\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Timer with sliding window (#3002)\n\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\n\n* revert tab\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check for rank zero\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check for rank zero\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* try explicit log dir\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add +\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* don't rm\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make dir if it doesn't exist\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* create mp nemo file in temp directory\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* simplify mp save_to\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* handle mp 1 case\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style fix\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove files\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix consumed_samples when resuming\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix reinstall.sh\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update req\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add more detailed log for dataloaders\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check if cuda is available before using fused_adam\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update eval script to use model.freeze\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* log train loss averaged over gradient accumulation steps\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check copyright earlier\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* todo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* override SaveRestoreConnector in NLPModel init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move to scripts\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove star import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comments\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused dataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* removed barrier\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check cfg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove logging\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* freeze, unfreeze\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* return None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add TODO\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typecheck\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* todo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add common native plugin\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* restore with trainer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* deprecate megatron-lm bert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* deprecate megatron-lm bert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* compile helpers ont he fly\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove amp_level\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove amp_level from configs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add missing import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove amp_level\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use fast huggingface tokenizers by default\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* deal with huggingface tokenizer positional args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* deal with huggingface tokenizer positional args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* deal with huggingface tokenizer positional args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert use_fast default to False\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* return super training_epoch_end\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove optimizer_idx arg from training_step\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused arg from on_train_epoch_end\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add restore_from_path to nemo config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* override connector if not subclassing NLPSaveRestoreConnector for model parallel save\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update test optimizer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make data_prefix mandatory in config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update installation instructions on readme\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update dockerfile\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add todo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* raise error if trying to use always_save_nemo with model parallel model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2021-08-30T18:53:05Z",
        "message": "make restore errors more useful (#2750)\n\nSigned-off-by: Ryan Leary <rleary@nvidia.com>\n\nCo-authored-by: Ryan Leary <rleary@nvidia.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2021-08-17T14:55:43Z",
        "message": "Refactor and Minimize Dependencies (#2643)\n\n* squash\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add comments\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* style and cleanup\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* cleanup\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add new test file\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* syntax\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* style\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* typo\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* try again\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* wip\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* style; ci should fail\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* final\n\nSigned-off-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2021-08-06T00:45:57Z",
        "message": "Add save restore connector to ModelPT (#2592)\n\n* add save restore connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add save restore connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add save restore connector property\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add _default_save_to\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* moving globals to app_state\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* moving globals to app_state\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add model attribute to connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add model attribute to connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix tabs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix tabs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove ModelPT import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add default restore\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add default restore\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove eff globals\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix tabs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update globals, remove save restore property\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add setter\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add setter\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix app_state restore flag\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update paths\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add connector arg to from_pretrained\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update save restore connector after instantiating\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* get class from config in .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add TODO\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move extract_state_dict to connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add methods for toch save and torch load\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update mock model conf\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move mock model to common collection\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update NLPModel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update test to use connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move artifacts to save restore connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add save_restore_connector arg to register_artifact\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* default save_restore_connector arg to None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* default save_restore_connector arg to None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean commented line\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* default save_restore_connector arg to None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move MockModel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix docstrings, remove underscores, default from connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update docstring\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update docstring\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* change name to is_model_being_restored\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move constants from AppState to SaveRestoreConnector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* encapsulate logic for model parallel checkpoint\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update mock config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add init_subclass, remove connector arg from register_artifact, move MockModel to tests\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove old import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Add tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Finalize tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Finalize tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* fixing lgtm\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix lgtm\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update NLPModel.restore_from\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix classpath resolution\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2021-06-07T13:09:37Z",
        "message": "Update FastPitch (#2249)\n\n* wip\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* c1\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* bug fixes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* bug fixes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* v2\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* changes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add types, old model working\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* pitch\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* let it work\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fixes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add oktai comments\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* debug\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* scale\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* wip\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix test for v1\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* merge train and val\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* back to par bin att, add correct encoder settings\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* try\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* undo\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* lgtm:\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* style\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* default to ljs\n\nSigned-off-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2021-05-17T23:16:29Z",
        "message": "Set strict=True everywhere by default. (#2225)\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2021-05-01T00:31:23Z",
        "message": "Removing graphsurgeon optional dependency, improving import error rep\u2026 (#2144)\n\n* Removing graphsurgeon optional dependency, improving import error reporting\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixing scope error\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2021-04-20T18:30:30Z",
        "message": "add simple alias to from_pretrained (#2056)\n\nSigned-off-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2021-04-05T21:12:03Z",
        "message": "Add support for subclass overriding \"target\" in Serialization (#2021)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2021-03-30T02:51:15Z",
        "message": "Support target classpath resolution for all ModelPT subclasses (#1982)\n\n* Support target classpath resolution for all ModelPT subclasses\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Support target classpath resolution for all ModelPT subclasses\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2021-03-15T16:58:23Z",
        "message": "Properly construct set of pretrained models (#1910)\n\n* Properly construct set of pretrained models\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Style fix\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Double test equality\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2021-02-25T20:18:37Z",
        "message": "Add Transcription script for all ASR models  (#1786)\n\n* Add CTC transcription scripts\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add speech transcription script\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add speech transcription script\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Revert old changes\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Revert old changes\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add jenkins test to run transcribe_speech.py\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add missing apostrophe\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct duplicate stage name\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update jenkins\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update jenkins\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update jenkins\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update jenkins\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update jenkins\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update jenkins\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update jenkins\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update jenkins\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update jenkins\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* temp remove gpu unittests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Give up on Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2021-02-11T13:52:40Z",
        "message": "Add container support to `typecheck` (#1743)\n\n* Add tests for input container support\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Support input container typecheking\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* remove redundant info\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add more tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add support for containers in output type attachment\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Start adding docstrings\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add docstrings\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update RNNT typechecking\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove dangling `data`\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update neural types for waveglow.py\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update neural types for waveglowloss.py\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update neural types for stftlosses.py and squeezewave.py\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update neural types for squeezewave.py\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2021-01-29T18:42:14Z",
        "message": "add new quantization nodes in QuartzNet (#1678)\n\n* add new quantization nodes in QuartzNet\n\nSigned-off-by: Vincent Huang <vincenth@nvidia.com>\n\n* Refactor quantization support to be optional and localized\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Guard last few self.quantize\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update docstring for override_config_path\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix conf assignment\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct amp via flag\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add missing self.quantize\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-12-03T22:36:50Z",
        "message": "Update model config automatically inside ModelPT (#1511)\n\n* Add ModelPT level config update to remove `params`\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update docstring\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update imports\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Refactor model cfg initialization\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Code foratting\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Code formatting\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add compat with RNNT BPE models\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct optimizer and schedulers for new configs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct return value\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correctly support new configs for ASR\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update every ASR config\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add comment tASR BPE models\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Reduce batch size from 64 to 32\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update name of methods\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-11-13T22:55:22Z",
        "message": "Dataset creation tool based on CTC-segmentation (#1450)\n\nDataset creation tool based on CTC-segmentation\nSigned-off-by: ekmb <ebakhturina@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-11-11T06:43:34Z",
        "message": "Update NeMo core for melgan (#1437)\n\n* update nemo core\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* Update modelPT.py\n\nRemove Optional from setup_validation_data\nSigned-off-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-10-19T17:36:12Z",
        "message": "Upgrade PTL to 1.0.2 (#1278)\n\n* update ptl version\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* not working yet\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* not working\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fixed bug\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* safe divide\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* couldn't pickle\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fixed bug\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style fix\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updated to Metric\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updated\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updated\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rebase\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* more updates\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updated\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo (#1286)\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* updates\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updates\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updates\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updated\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updates\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* remove flag\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updates\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updates\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updates\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style fix\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updates\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updated\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style fix\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updates\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updated\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update speech top k models\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update megatron metric & lgtm\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* distributed_backend -> accelerator\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* updated\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* ptl 1.0.2\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updated\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updates\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* lower batch size\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* batch_size 1\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* testing gpu 1 on ci\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* testing gpu 1 on ci\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* testing gpu 1 on ci\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* removing model parallel from jenkins until after upgrade\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* disable pretrained nlp tests for now\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update classification report in intent and punc models\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update jenkinsfile\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update to new log method\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update to new log method\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* updated\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding test back to try ptl fix\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove trainer.check_val_every_n_epoch during tests\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* temporarily removing NER from_pretrained test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove pretrained test for now\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* disabled correct tests\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add strict, reenable tests\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix final tests\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add strict to punctationmodel\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* MegaBERT tests use GPU 1\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix bracket\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert compute_topk functional\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert compute_topk functional\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style fix\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert compute_topk functional\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert compute_topk functional\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fixed classification report\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fixed classification report\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* multiply precision by 100\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* nlp logging update\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* nlp logging update\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* nlp logging update\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* nlp logging update\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* nlp logging update\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* nlp logging update\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update docstring\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove commented line\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove commented lines\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove commented lines\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove commented lines\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-09-28T23:06:48Z",
        "message": "Fixed typos, improved notebooks (#1221)\n\n* Removed dataset info logging from transcribe method\n\nSigned-off-by: Vitaly Lavrukhin <vlavrukhin@nvidia.com>\n\n* Minor fixes to NeMo Primer notebook\n\nSigned-off-by: Vitaly Lavrukhin <vlavrukhin@nvidia.com>\n\n* Fixed a docstring\n\nSigned-off-by: Vitaly Lavrukhin <vlavrukhin@nvidia.com>\n\n* Fixed typos in NeMo_voice_swap_app notebook\n\nSigned-off-by: Vitaly Lavrukhin <vlavrukhin@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-09-22T06:20:07Z",
        "message": "hashcache (#1200)\n\n* hashcache\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* more descripting path\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-09-17T21:25:08Z",
        "message": "Enable loading a model on device + broken link fix (#1183)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-09-11T21:45:33Z",
        "message": "Add Pretrained TTS test script; Extend from_pretrained() Functionality (#1142)\n\n* add test script; extend from_pretrained() functionality\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* isort\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* batch inputs to waveglow\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* isort\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update list_available_models\n\nSigned-off-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-09-11T17:53:03Z",
        "message": "Fix SQuAD tutorial for QA (#1150)\n\n* add import\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* add option for config file in Model.from_pretrained()\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* add section about loading pretrained model to notebook\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-09-07T04:54:52Z",
        "message": "Improve usability of NeuralModule + Typing (#1129)\n\n* Make FileIO concrete with empty implementations\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add __eq__ for NeuralType\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct return type for result\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct _target_ setup\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-09-01T14:21:53Z",
        "message": "Update TTS, Add Notebook (#1047)\n\n* add conf\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* merge; trim\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add sigma\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add sigma\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add very WIP notebook\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update config\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update conf\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* gitignore\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update logger creation\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* make resume_from_checkpoint a str\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* make resume_from_checkpoint a str\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update exp_manager\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fixes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* copy -> move\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fixes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add sigma\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* clear notebook\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* rm\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* current WIP\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* working v1\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* style\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* WIP on glowtts\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* finalize glow tts and gl\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* move\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fixes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update glow tts\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* bugfix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* stop creating classes during forward\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update notebook\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* use from_pretrained\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* style\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update params logic\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* remove experimental import\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* bugfix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-08-31T17:14:00Z",
        "message": "Support overriding the config path when restoring model (#1088)\n\n* Add restore from override option and test\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct strict signature\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add support for extracting state dict from nemo files\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* correct signature of abstract FileIO method\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-08-21T19:44:20Z",
        "message": "Update Input Validation (#1051)\n\n* update input validation\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update wording\n\nSigned-off-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-08-11T17:42:51Z",
        "message": "TTS update (#1016)\n\n* remove from_config_dict\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* remove todo\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* typo\n\nSigned-off-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-08-10T21:07:29Z",
        "message": "Add experimental models + updates to configs for MatchboxNet (#1009)\n\n* Add cn 192 8x pool model\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Prepare contextnet 8x pooling model\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add config files and resolve configs prior to serialization and de-serialization\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update configs for ASR\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update docstring of BPE models\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add docstrings for processing scripts\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add docstring for MatchboxNet\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct config name\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Style fix\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Revert *args and **kwargs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix TTS loading of dataset\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-08-03T17:59:57Z",
        "message": "Logging Cleanup (#971)\n\n* cleanup\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* isort\n\nSigned-off-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-07-31T06:28:37Z",
        "message": "Adding TS export format and trying script (#958)\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-07-30T17:46:16Z",
        "message": "TTS Collection (#874)\n\n* add structure\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add files\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add init\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix init\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update taco\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* format\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* typo\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* val change\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add header\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add waveglow\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* waveglow fix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* waveglow fix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* waveglow fix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add O1\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add todo\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* change batch sizes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* move\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* move\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* V1\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* V1\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* structure\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* clean up\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix tacotron2\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add files\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update yamls\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix waveglow 1/2\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix waveglow 2/3\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix waveglow 3/?\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* merge asr and tts\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update waveglow\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* isort\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update configs\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update waveglow's dataloader\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update and refactor\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update t2 and waveglow\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* enforce dictconfig; style\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add fastdevruns\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* name\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* import\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update tests\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* yaml\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* use hydra rnner\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* style\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* move callback to common\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fixed tacotron 2; add typing to all neuralmodules\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* flatten\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* Style\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* patch jenkins\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* change typeheck logic\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix t2\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix wg\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* style\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update configs\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add num_workers\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update config\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update gitignore\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* config\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* enable fp16 on t2\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* enable fp16 on t2\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* enable fp16 on t2\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix t2\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fixes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add typing to models; use nemo loss class\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* make wg work\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* make t2 work\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* style\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix wg\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add better debug info to shape check\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* lgtm import error\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* lower batch size for testing\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* address comments\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* address comments and remove experimental\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* standardize\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* mark back as experimental\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* style\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* experimental\n\nSigned-off-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-07-28T21:32:39Z",
        "message": "Add automatic name assignments in case names are not resolved (#936)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-07-28T17:16:43Z",
        "message": "Support type definition override at function level (@typecheck()) (#908)\n\n* Support type override at function level\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update docstring\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove type preservation inside instance (not required)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Resolve defaults for _validate_*\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add dim assertions to typecheck\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Check for none in type axis\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Rebase\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-07-28T16:51:08Z",
        "message": "Nemo file updates (#903)\n\n* add target if not present. restore using torch\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* put test back\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* save/restore weights just using torch state_dict\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* full class name and s2t infer draft for testing\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fix style\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* adding artifacts to .nemo file\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* update config path\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* bugfix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* bugfix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* add register_artifact method\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* minor adjustments to speech_to_text_infer.py\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* download from cloud\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fix CPU\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* prettyfy inference, add Jenkins test\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* bugfix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* prettyfy\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* prettyfy inference script. Add jenkins test\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fixing jenkins file\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* tmp fix jenkins file\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* style and jenkins update\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* bugfix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* remove unnecessary CI test\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* script header update\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* addressing some review feedback\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-07-27T21:05:14Z",
        "message": "Add ability to globally disable @typecheck (#925)\n\n* Add ability to globally disable type checks\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add method to init\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Convert to staticmethod instead\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-07-24T16:55:54Z",
        "message": "Patch @typecheck() to support containers as outputs (#901)\n\n* Patch @typecheck() to support container and optionally test and attach types\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Style fixes\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Patch support for optional dims in input\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Patch ner typecheck\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Patch punctuation_capitalization_model.py\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* LGTM fix\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add recursive testing of input types and docstring\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Code formatting\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add typecheck tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-07-22T21:52:29Z",
        "message": "Add MatchboxNet + ASR Classification model support (#889)\n\n* Start work on matchboxnet_3x1x64.yaml\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Begin matchboxnet support\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add MatchboxNet to candidate\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Style fixes\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update docstring\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Address reviewer comments\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* LGTM fixes\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update docstring on how to properly evaluate topk accuracy\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile to run speech commands on small dataset\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct formatting and update Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove usage of MFCC\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct config on Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct config on Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct config on Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct config on Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Parallel asr Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Jenkinsfile to use seperate dirs for speech training\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-07-21T03:52:48Z",
        "message": "fix speech to text and revert serialization to original state\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-07-20T23:49:18Z",
        "message": " 'safer' deserialization\n\nSigned-off-by: Tomasz Kornuta <tkornuta@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-07-20T21:48:51Z",
        "message": "removed comment, fixed format\n\nSigned-off-by: Tomasz Kornuta <tkornuta@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-07-20T21:23:48Z",
        "message": "tests fixed\n\nSigned-off-by: Tomasz Kornuta <tkornuta@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-07-17T05:05:41Z",
        "message": "address some feedback, add more tests\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-07-16T20:52:14Z",
        "message": "save/restore to nemo file implementation\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-07-01T06:01:19Z",
        "message": "adjusting loss to NeMo convention\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-07-01T00:25:25Z",
        "message": "Style fix\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-07-01T00:02:42Z",
        "message": "Add new dataset schema as well as new typechecking for dataset items\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-06-30T01:35:50Z",
        "message": "Refactor @typecheck() decorator to defer checked actions to Typing abstract interface. Add docstring for usage\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-06-30T00:13:35Z",
        "message": "adjust datasets\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-06-27T00:07:45Z",
        "message": "Fully support typecheck() decorator for training\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-06-27T00:07:45Z",
        "message": "Add typecheck decorator\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-06-26T06:23:03Z",
        "message": "renaming plus loss change\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-06-25T22:01:16Z",
        "message": "removed NeMo prefix unless necessary\n\nSigned-off-by: ericharper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-06-25T21:50:47Z",
        "message": "removed NeMo prefix unless necessary\n\nSigned-off-by: ericharper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-06-25T21:40:29Z",
        "message": "naming suggestions\n\nSigned-off-by: ericharper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-06-25T00:13:40Z",
        "message": "Many changes:\n\n* update licenses everywhere\n* update class structure and names\n* fill in blocks and pieces for ASR model\n* NON-FUNCTIONAL YET\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-06-22T18:05:15Z",
        "message": "changes\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2020-06-20T05:26:00Z",
        "message": "clean-plate commit\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2024-03-01T17:13:09Z",
        "message": "Doc String fix for documentation update (#8554)\n\n* Fix SpeakerDecoder doc string\n\nSigned-off-by: Dong Hyuk Chang <donghyukc@nvidia.com>\n\n* Fix asr RNNT doc strings\n\nSigned-off-by: Dong Hyuk Chang <donghyukc@nvidia.com>\n\n* Fix ctc decoding doc strings\n\nSigned-off-by: Dong Hyuk Chang <donghyukc@nvidia.com>\n\n* More doc string fixes\n\nSigned-off-by: Dong Hyuk Chang <donghyukc@nvidia.com>\n\n* RNNTDecoding doc strings fix\n\nSigned-off-by: Dong Hyuk Chang <donghyukc@nvidia.com>\n\n* More doc string fixes\n\nSigned-off-by: Dong Hyuk Chang <donghyukc@nvidia.com>\n\n* modelPT, dataset doc string fixes\n\nSigned-off-by: Dong Hyuk Chang <donghyukc@nvidia.com>\n\n* Fix generate, encode, decode docstrings\n\nSigned-off-by: Dong Hyuk Chang <donghyukc@nvidia.com>\n\n* Update generate function docstring\n\nSigned-off-by: Dong Hyuk Chang <donghyukc@nvidia.com>\n\n* More generate function docstring update\n\nSigned-off-by: Dong Hyuk Chang <donghyukc@nvidia.com>\n\n---------\n\nSigned-off-by: Dong Hyuk Chang <donghyukc@nvidia.com>\nCo-authored-by: Dong Hyuk Chang <donghyukc@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2024-02-28T21:52:51Z",
        "message": "Fix AccessMixin (#8536)\n\n* fix AccessMixin\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* remove caching propagate_model_guid\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n---------\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2024-02-03T05:35:28Z",
        "message": " Attention encoder-decoder models for multiple speech-to-text tasks  (#8242)\n\n* Rebasing canary changes at current main\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Move the changes from asr transformer to nlp transformer as originally intended\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* update eval to strip spaces before punctuations\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* update pc strip\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* [canary] Refactor: `PromptedAudioToTextLhotseDataset` and `EncDecMultiTaskModel` (#8247)\n\n* Create a separate CanaryDataset and use it inside `transformer_bpe_models.py`. Ditches `token_sequence_format`.\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* [canary] Refactor: move changes in transformer_bpe_models.py to Canar\u2026 (#8252)\n\n* [canary] Refactor: move changes in transformer_bpe_models.py to CanaryModel\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Rename `CanaryModel` to `EncDecMultiTaskModel` and remove inheritance from `EncDecTransfModelBPE`; add a separate config for this model\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n---------\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Rename `CanaryDataset` to `PromptedAudioToTextLhotseDataset`; add `prompt_format_fn` argument; clean-up the `_canary_prompt_format` function a bit\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Move tokenization into `prompt_format_fn`, fix usage, add docs\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Backward-compatible utterance validation\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Improve type annotations\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* config and prompt_fn registration changes from review\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n---------\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* fix transcribe config\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* Refactor Canary to follow schema of remaining ASR models (#8260)\n\n* Initial draft of multi task beam decoding strategy\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Stabilize inference\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update AED Multi Task model to mostly conform to Archetype-Type format. Update config\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add change decoding strategy\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove redundant imports\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Cleanup\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Cleanup\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* remove asr transformer dependency on nlp\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* clean up\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* copy token_classifier from nlp to asr\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* Address comments\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add typing to beam decoding\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Make prompt format configurable\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* drop asr dependency on nlp\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nSigned-off-by: stevehuang52 <heh@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: stevehuang52 <heh@nvidia.com>\n\n* fix transcribe, update asr evaluator\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* Extend the docs for the canary prompt_fn\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Incorporate changes from Nithin's code review\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* training bug fix and adding launch script for speech_multitask (#8270)\n\n* bug fix and adding launch script for speech_multitask\n\nSigned-off-by: Krishna Puvvada <kpuvvada@nvidia.com>\n\n* update launch script example in speech_to_text_aed.py\n\nSigned-off-by: Krishna Puvvada <kpuvvada@nvidia.com>\n\n---------\n\nSigned-off-by: Krishna Puvvada <kpuvvada@nvidia.com>\nCo-authored-by: Krishna Puvvada <kpuvvada@nvidia.com>\n\n* Fix: drop_last must be true in validation/test otherwise the training will hang\n\nSigned-off-by: Piotr \u017belasko <pzelasko@nvidia.com>\n\n* revert to current transcribe API\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* revert changes to NLP, update docs\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* update eval utils\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* update docs\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* Remove DALI; rename compute_audio_loss to compute_loss\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* set default use_model_transcribe=False\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* change os.path.dirname to pathlib\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* [canary] Test for CanaryTokenizer + refactoring (#8285)\n\n* Test for CanaryTokenizer\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Attempt at refactor...\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n---------\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Update config for AED models (#8294)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* set default calculate_wer=False in transcribe_speech.py\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* Attention encoder-decoder models for multiple speech-to-text tasks\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Apply suggestions from code review, part 1\n\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Apply suggestions from code review, part 2\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Document compute_loss\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* update transcribe_speech.py\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* add docstring\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* Attention encoder-decoder models for multiple speech-to-text tasks\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n---------\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\nSigned-off-by: stevehuang52 <heh@nvidia.com>\nSigned-off-by: smajumdar <titu1994@gmail.com>\nSigned-off-by: Krishna Puvvada <kpuvvada@nvidia.com>\nSigned-off-by: Piotr \u017belasko <pzelasko@nvidia.com>\nCo-authored-by: stevehuang52 <heh@nvidia.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Krishna Puvvada <93558329+krishnacpuvvada@users.noreply.github.com>\nCo-authored-by: Krishna Puvvada <kpuvvada@nvidia.com>\nCo-authored-by: He Huang (Steve) <105218074+stevehuang52@users.noreply.github.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2024-01-18T17:50:42Z",
        "message": "Fix learning rate schedule in Megatron models when `max_steps` is not set (#7518)\n\n* Fix learning rate schedule in Megatron models when `max_steps` is not set\n\nSigned-off-by: Olivier Delalleau <507137+odelalleau@users.noreply.github.com>\n\n* Rename `_get_optim_config_copy()` -> `_optim_config_copy()`\n\nSigned-off-by: Olivier Delalleau <507137+odelalleau@users.noreply.github.com>\n\n* Relax some assumptions to avoid crashing in `setup_optimization()`\n\nSigned-off-by: Olivier Delalleau <507137+odelalleau@users.noreply.github.com>\n\n* Remove a useless assert, and add a more relevant one\n\n`trainer.max_steps` can never be `None` since it is always an integer\n(with -1 being used for \"not set\"), and PTL would have crashed earlier\nif someone had tried to use `None`.\n\nSigned-off-by: Olivier Delalleau <507137+odelalleau@users.noreply.github.com>\n\n* Do not instantiate scheduler when we cannot compute `max_steps`\n\nSigned-off-by: Olivier Delalleau <507137+odelalleau@users.noreply.github.com>\n\n* Raise exception when scheduler can't be instantiated\n\nSigned-off-by: Olivier Delalleau <507137+odelalleau@users.noreply.github.com>\n\n---------\n\nSigned-off-by: Olivier Delalleau <507137+odelalleau@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2023-12-18T20:18:25Z",
        "message": "SFT patch: (1) enable sequence parallelism and (2) enable profile (#7963)\n\n* SFT profile start and end step fix\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* Removed sequence parallelism assertion check\n\nSigned-off-by: Selvaraj Anandaraj <selvaraja@login-eos01.eos.clusters.nvidia.com>\n\n---------\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\nSigned-off-by: Selvaraj Anandaraj <selvaraja@login-eos01.eos.clusters.nvidia.com>\nCo-authored-by: Selvaraj Anandaraj <selvaraja@login-eos01.eos.clusters.nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2023-11-03T22:46:25Z",
        "message": "Multimodal merge (#7728)\n\n* ControlNet TRT export\n\n* Final MR before release\n\n* SD2 update\n\n* Fixed export issue\n\n* Fix for instruct p2p and reformat\n\n* Fix SD export issue\n\n* Add nemo clip export for DB\n\n* Fix ins pix2pix\n\n* fix sd2 config\n\n* [Mingyuan Ma] BF16 and SD conversion script\n\n* [Imagen] NHWC Feature\n\n* Fix .nemo loading issue for NeMo CLIP in SD\n\n* NeMo r1.20.0 Multimodal Merge\n\n* fix the inductor issue in inference\n\n* Fix inductor loading .nemo issue\n\n* Add Neva Model Support\n\n* Imagen Optimizations\n\n* Neva inference code\n\n* NeMo TOT 1.21 to Internal/main\n\n* Update neva_inference.yaml\n\n* REBASING  for latest code changes\n\n* Update internal/main to main tot\n\n* Parallel DDIM implementation\n\n* 1. Fixing indentation bug. (#7352)\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* NeMo MCore llama2 support + MCore PEFT adapters (#7299)\n\n* start adding gpt from megatron core path\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set model parallel config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use model parallel config object\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* set vp size to none if it is 1\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set vp size to none if it is 1\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add TransformerConfig\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* start updating to TransformerConfig\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add todo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert to model parallel config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add hidden_size to model_parallel_config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* remove imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* small clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update hidden size in peft base model, add mcore commit to jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update module args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add config obj to flash attention tests\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* remove sequence parallel arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add config to self\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add config to test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* get hidden_size from config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add try except\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use default\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config with hidden size\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* comment out jenkins test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* build transformer config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add model to provider func\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update forward and float16 wrapper\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* instantiate model parallel config after init model parallel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set virtual rank\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add GQA config to megatron gpt model (#7096)\n\n* Add GQA config in gpt config file\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* Verify mcore is enabled when using GQA\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n---------\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* revert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* mcore llama2 ckpt conversion & small fix\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* Add inference & sft config by Hongbin\n\nCo-authored-by: Hongbin Liu <hongbinl@nvidia.com>\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* fix config\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* add inference param. update TP/PP script to support mcore gpt\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* p-tuning\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* modify ckpt conversion script (adding model cast)\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* ckpt conversion use relative path for config\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* start adding gpt from megatron core path\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set model parallel config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use model parallel config object\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* set vp size to none if it is 1\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set vp size to none if it is 1\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add TransformerConfig\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* start updating to TransformerConfig\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add todo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert to model parallel config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add hidden_size to model_parallel_config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* remove import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* small clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update hidden size in peft base model, add mcore commit to jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update module args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add config obj to flash attention tests\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* remove sequence parallel arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add config to self\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add config to test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* get hidden_size from config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add try except\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use default\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config with hidden size\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* comment out jenkins test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove optimizer_idx\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* prefetch num microbatches\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* start adding gpt from megatron core path\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set model parallel config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use model parallel config object\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix for p-tuning sequence parallel\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* support SFT/distOpt mcore (#7207)\n\n* add inference param. update TP/PP script to support mcore gpt\n\n* p-tuning\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* change layer names for SFT\n\nSigned-off-by: Hongbin Liu <hongbinl@nvidia.com>\n\n* fix bug in SFT\n\nSigned-off-by: Hongbin Liu <hongbinl@nvidia.com>\n\n---------\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\nSigned-off-by: Hongbin Liu <hongbinl@nvidia.com>\nCo-authored-by: Hongbin Liu <hongbinl@nvidia.com>\nCo-authored-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* start updating to TransformerConfig\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert to model parallel config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add hidden_size to model_parallel_config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update module args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add config to self\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* build transformer config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add model to provider func\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update forward and float16 wrapper\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* instantiate model parallel config after init model parallel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set virtual rank\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add GQA config to megatron gpt model (#7096)\n\n* Add GQA config in gpt config file\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* Verify mcore is enabled when using GQA\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n---------\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* revert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove import\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* rollback model cast for p-tuning\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* update for dist adam\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* use get_gpt_module_list\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update ckpt conversion script\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* ptl2.0 patch for llama config\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* add plugins to trainer in scripts\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* fix activation checkpointing mcore\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* fix variable names\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* overwrite normalization type for mcore/te\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* Update megatron_llama_sft.yaml\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* add PEFT adapter support for mcore gpt path (#7276)\n\n* implementation for mcore adapter/mxins\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* small fix for lora and ptuning\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* support layerwise peft\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* support multiple target layers\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* support lora GQA\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* support amp O2\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* revert & more O2 fix\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* lora inject to attention\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* support lora weight tying\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* add copyright header\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* rollback ptuning name change. full string match mcore target\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* remove comment\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n---------\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* clean up config\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* Sync llama branch (#7297)\n\n* add inference param. update TP/PP script to support mcore gpt\n\n* p-tuning\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* change layer names for SFT\n\nSigned-off-by: Hongbin Liu <hongbinl@nvidia.com>\n\n* fix bug in SFT\n\nSigned-off-by: Hongbin Liu <hongbinl@nvidia.com>\n\n* fix bug: cpu initialization is not really enabled\n\nSigned-off-by: Hongbin Liu <hongbinl@nvidia.com>\n\n* add use_cpu_initialization to TransformerConfig\n\nSigned-off-by: Hongbin Liu <hongbinl@nvidia.com>\n\n* fix bug: wrong config path when using relative cjpt path\n\nSigned-off-by: Hongbin Liu <hongbinl@nvidia.com>\n\n* revert mcore config change\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n---------\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\nSigned-off-by: Hongbin Liu <hongbinl@nvidia.com>\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\nCo-authored-by: Hongbin Liu <hongbinl@nvidia.com>\n\n* clean up ckpt conversion script\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* rollback git merge errors\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* update mcore, add check for mcore+te\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* formatting\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* make sft test dataset optional. fix indentation in config\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* one more fix for optional test set\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* support merging lora weights in mcore\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* update mcore for cpu init\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update ckpt conversion for code llama\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add seq_len_interpolation_factor support for long-context llama ckpts (#7312)\n\n* add inference param. update TP/PP script to support mcore gpt\n\n* p-tuning\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* add seq_len_interpolation_factor\n\nSigned-off-by: Hongbin Liu <hongbinl@nvidia.com>\n\n---------\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\nSigned-off-by: Hongbin Liu <hongbinl@nvidia.com>\nCo-authored-by: jasonwan <jasonwan@nvidia.com>\nCo-authored-by: Hongbin Liu <hongbinl@nvidia.com>\n\n* fix old ptuning model, update mcore to support seq_len_interpolation_factor\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* support fused layernorm linear, fix ptuning O2\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* drop loss mask for mcore for now\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* disable dist ckpt in peft\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix loading non dist ckpt\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* add ckpt conversion to CI\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* update CI\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* mcore_mixin docstring\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* minor change in mcore peft error message\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* fix amp o2 in lora weight tying\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* correct mcore fp8 config\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* add TE installation\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* support mcore adapter tuning\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* comment out new CI test. rollback docker image\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* ignore FA tests, try new CI on 23.08\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* mark new CI as L2, put to beginning to test\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* minor fix for prompt learning\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* rollback to 23.06. comment out CI\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* minor fix ckpt conversion script\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* minor rollback gpt model change\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n---------\n\nSigned-off-by: ericharper <complex451@gmail.com>\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\nSigned-off-by: eharper <eharper@nvidia.com>\nSigned-off-by: Hongbin Liu <hongbinl@nvidia.com>\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\nCo-authored-by: ericharper <complex451@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: eharper <eharper@nvidia.com>\nCo-authored-by: Hongbin Liu <hongbinl@nvidia.com>\nCo-authored-by: Kelvin Liu <lhb8125@users.noreply.github.com>\n\n* Hiddens modules documentation (#7303)\n\n* 1. Changed hiddens transformations module from `transformations` to `hiddens`.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* 1. Debugging. Signed-off-by: Micha Livne <mlivne@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* 1. Finished doc.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging. Signed-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging. Signed-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging. Signed-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging. Signed-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging. Signed-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging. Signed-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging. Signed-off-by: Micha Livne <mlivne@nvidia.com>\n\n---------\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Support for flash attention 2.0 (#7063)\n\n* Add flash attn 2\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add FA2 feature\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Remove debugging\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nSigned-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\nCo-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* lora merge fix for O2 names (#7325)\n\n* wip\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* adjust key names based on O2\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* minor\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n---------\n\nSigned-off-by: arendu <adithyare@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* multiple fields can form a context (#7147)\n\n* list of context fields and flexible prompt template\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* list of fields for context\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Add multiple truncation fields and middle truncation\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Compatible to old ckpt\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix tokenize detokenize issue\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Remove detokenization, add truncation augmentation\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Resolve comments\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Remove unused import\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* revert eos\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Add tokenizer space_sensitive attribute\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix error\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Fix erorr and use re\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Change assert logic\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Follow adi suggestion\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Remove merge function\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add example and comment\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Remove context_key and add comment\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Remove random truncation\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix template none\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n---------\n\nSigned-off-by: arendu <adithya.r@gmail.com>\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nSigned-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\n\n* Load buffers in checkpoint (#7357)\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* Add migration guide for lightning 2.0 upgrade (#7360)\n\n* Add lightning 2.0 migration guide in NeMo docs\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add remaining guide for lightning 2.0 upgrade\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Remove line spill over and continue in next line\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add missing dataloader_iter in the guide\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Fix minor typo\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* adding bias_dropout_add_fusion option for BERT (#7332)\n\nSigned-off-by: Alexander Jipa <azzhipa@amazon.com>\nCo-authored-by: Alexander Jipa <azzhipa@amazon.com>\n\n* [TTS] Change audio codec token type to TokenIndex (#7356)\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* enable selective unfreeze (#7326)\n\n* wip\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* wip\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* avoid PTL method conflicts\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: arendu <adithyare@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Fix typos (#7361)\n\n* fix typos\n\nSigned-off-by: omahs <73983677+omahs@users.noreply.github.com>\n\n* fix typo\n\nSigned-off-by: omahs <73983677+omahs@users.noreply.github.com>\n\n* fix typos\n\nSigned-off-by: omahs <73983677+omahs@users.noreply.github.com>\n\n* fix typos\n\nSigned-off-by: omahs <73983677+omahs@users.noreply.github.com>\n\n* fix typo\n\nSigned-off-by: omahs <73983677+omahs@users.noreply.github.com>\n\n* fix typos\n\nSigned-off-by: omahs <73983677+omahs@users.noreply.github.com>\n\n* fix typo\n\nSigned-off-by: omahs <73983677+omahs@users.noreply.github.com>\n\n* fix typo\n\nSigned-off-by: omahs <73983677+omahs@users.noreply.github.com>\n\n* fix typo\n\nSigned-off-by: omahs <73983677+omahs@users.noreply.github.com>\n\n---------\n\nSigned-off-by: omahs <73983677+omahs@users.noreply.github.com>\n\n* pin numba=0.57.1 to fix reinstall.sh error (#7366)\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Update new conversion script for converting safetensors.\n\n* Upgrade pytorch container to 23.08 (#7353)\n\n* upgrade pytorch container\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* use mcore\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* revert test change\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* pleasefixme\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* check for ampere\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* comment test temporarily\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n---------\n\nSigned-off-by: eharper <eharper@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* enable fp32 optimizer for output_layer in mcore (#7355)\n\nSigned-off-by: lhb8125 <lhb8125@gmail.com>\n\n* revert comment (#7368)\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* Update to core 23.08 branch ToT (#7371)\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* upper bounding ptl (#7370)\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* fix pipeline parallel inference (#7367)\n\n* fix pp inference\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* fix for peft tied weights (#7372)\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* fixed trainer.strategy=auto from None. (#7369)\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* add O2 option in gpt eval (#7358)\n\n* add O2 option in eval\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add doc for O2 config\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* add to llama inference config\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n---------\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Move model precision copy (#7336)\n\n* move cfg precision set to megatron base model\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* remove copy from other models\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* modify attribute not arg\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* fix gpt model test for ptl 2.0\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* rename function and add docstring\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* replace precision to dtype conditionals with func call\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* unnecessary function and cfg reset\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* set default value\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* fix precision lookup in a few more places\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* rename mapping function\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* ununsed import\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* save torch datatype to model\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* set weights precision wrt amp o2\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* Revert \"set weights precision wrt amp o2\"\n\nThis reverts commit 313a4bfe5eb69d771a6d2433898c0685836aef5c.\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* revert half precision at inference attempt\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* move autocast dtype to base model\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* move params dtype to base model, enable fp16 O2 inf\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* unused imports\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n---------\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* Fix PEFT checkpoint loading (#7388)\n\n* Fix PEFT checkpoint loading\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Use distributed optimizer support for multiple dtypes (#7359)\n\n* Update distopt wrapper with multiple dtype support\n\nRemove manual handling of separate FP32 optimizer.\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Use distopt support for contiguous buffers with multiple dtypes\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Fix typo\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Separate distopt buckets for first GPT layer and non-overlapped params\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Add distopt logic for int dtypes\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Update Apex commit\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Remove unused variables\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Update Apex commit in README and Jenkensfile\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Debug Dockerfile and Jenkinsfile\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n---------\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* minor fix for llama ckpt conversion script (#7387)\n\n* minor fix for llama ckpt conversion script\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* remove fast_swiglu configuration\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n---------\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix wrong calling of librosa.get_duration() in notebook (#7376)\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\n\n* [PATCH] PEFT import mcore (#7393)\n\n* [PATCH] PEFT import mcore\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* [TTS] Added a callback for logging initial data (#7384)\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>\n\n* Update Core Commit (#7402)\n\n* Update Core Commit\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* update commit\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n---------\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* Use cfg attribute in bert (#7394)\n\n* use cfg attribute instead of arg\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* use torch_dtype in place of cfg.precision\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* move precision copy before super constructor\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* use trainer arg\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n---------\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* Add support for bias conversion in Swiglu models (#7386)\n\n* Add support for bias conversion in Swiglu models\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add support for auto extracting tokenizer model\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add support for auto extracting tokenizer model\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix issue with missing tokenizer\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Refactor\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Refactor\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Update save_to and restore_from for dist checkpointing (#7343)\n\n* add dist ckpt to save to, in progress\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* move dist ckpt\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* clean up\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update restore from, need to figure out how to initialize distributed\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* launch distrib if needed when restoring dist ckpt\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* when using mcore we can change tp pp on the fly\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* add load_from_checkpoint support for dist ckpt\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update llama convert script to save dist .nemo\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* fix load dist ckpt\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* setup TE TP groups if needed\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* setup te tp groups if needed\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* remove import\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n---------\n\nSigned-off-by: eharper <eharper@nvidia.com>\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: jasonwan <jasonwan@nvidia.com>\n\n* fix forward for with mcore=false (#7403)\n\nSigned-off-by: Jimmy Zhang <jiemingz@nvidia.com>\nCo-authored-by: Jimmy Zhang <jiemingz@nvidia.com>\n\n* Fix logging to remove 's/it' from progress bar in Megatron models and add train_step_timing (#7374)\n\n* Add CustomProgressBar class to exp_manager and trainer callbacks\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix the progress bar to reflect total microbatch cnt\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Modify CustomProgressBar class\n\n1) Modify CustomProgressBar class to update progress bar per global_step instead of per microbatch\n2) Add the callback to other megatron training/finetuning files that are not using MegatronTrainerBuilder\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add CustomProgressBar callback to tuning files\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Set Activation Checkpointing Defaults (#7404)\n\n* Set Activation Checkpointing Defaults\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* check for None\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* make loss mask default to false (#7407)\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* Add dummy userbuffer config files (#7408)\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* add missing ubconf files (#7412)\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* New tutorial on Speech Data Explorer (#7405)\n\n* Added Google Colab based tutorial on Speech Data Explorer \n\nSigned-off-by: George Zelenfroynd <gzelenfroind@nvidia.com>\n\n* Update ptl training ckpt conversion script to work with dist ckpt (#7416)\n\n* update ptl convert script\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* don't break legacy\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: eharper <eharper@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Allow disabling sanity checking when num_sanity_val_steps=0 (#7413)\n\n* Allow disabling sanity checking when num_sanity_val_steps=0\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Update num_sanity_val_steps to be a multiple of num_microbatches\n\nSigned-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nSigned-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Add comprehensive error messages (#7261)\n\nSigned-off-by: Anton Peganov <apeganov@nvidia.com>\n\n* check NEMO_PATH (#7418)\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* layer selection for ia3 (#7417)\n\n* layer selection for ia3\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: arendu <adithyare@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Fix missing pip package 'einops' (#7397)\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Fix failure of pyaudio in Google Colab (#7396)\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Update README.md: output_path --> output_manifest_filepath (#7442)\n\nSigned-off-by: Samuele Cornell <cornellsamuele@gmail.com>\n\n* Updating FlashAttention API to match FlashAttentionV2\n\n* Multiple fixes for mm\n\n* Fix CI inductor issue and update to torch compile\n\n* Remove suppress error\n\n* Fix when conversion config uses fp16 and it complains about precision plugin\n\n* Fixing FAv2 API usage\n\n* Initial release of content filtering model\n\n* Added synthetic dataloader for precached and online mode\n\n* Mingyuanm/dreambooth opt\n\n* Add llama2 support in neva training\n\n* Fix sampler length\n\n* Fix all precision issues in nemo multimodal\n\n* Add rope dynamic linear scaling (#7437)\n\n* Add dynamic linear scaling\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n---------\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\n\n* Fix None dataloader issue in PTL2.0 (#7455)\n\n* Fix None dataloader issue in PTL2.0\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* updating values of self._validation_dl and self._test_dl as well\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* updating values of self._validation_dl and self._test_dl as well\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* [ASR] Confidence measure -> method renames (#7434)\n\n* measure -> method\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Add steps for document of getting dataset 'SF Bilingual Speech' (#7378)\n\n* Add steps for document of getting dataset 'SF Bilingual Speech'\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Update datasets.rst\n\nadded a link from a tutorial demonstrating detailed data prep steps.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* RNN-T confidence and alignment bugfix (#7381)\n\n* new frame_confidence and alignments lists are now always created after the while loop\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n* tests added\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n---------\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n* Fix resume from checkpoint in exp_manager (#7424) (#7426)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix checking of cuda/cpu device for inputs of Decoder (#7444)\n\n* Fix checking of cuda/cpu device for inputs of Decoder\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Update tacotron2.py\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\n\n* Fix failure of ljspeech's get_data.py (#7430)\n\n* Fix failure of ljspeech's get_data.py\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* [TTS] Fix audio codec type checks (#7373)\n\n* [TTS] Fix audio codec type checks\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Fix audio codec tests\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n---------\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Add dataset to path of logged artifacts (#7462)\n\n* [TTS] Add dataset to path of logged artifacts\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Revert axis name back to Audio Frames\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n---------\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* Fix sft dataset truncation (#7464)\n\n* Add fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n---------\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Automatic Lip Reading Recognition (ALR) - ASR/CV (Visual ASR) (#7330)\n\n* striding_conv1d_k5 and dw_striding_conv1d_k5 subsampling\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* transpose conv1d inputs\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* Update subsampling.py\n\nchange striding_conv1d_k5 to striding_conv1d\n\nSigned-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>\n\n* cv branch\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* video manifest\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* add collection classes\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add test_step_outputs\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* correct manifest bug when having only audio or only videos\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* correct manifest bug when having only audio or only videos\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* clean references\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* freeze unfreeze transcribe cv models\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* correct manifest get_full_path bug\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* update for PR\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* guard torchvision\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Update nemo/collections/cv/data/video_to_text_dataset.py\n\nCo-authored-by: Igor Gitman <igor.a.gitman@gmail.com>\nSigned-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>\n\n* _video_speech_collate_fn in cv/data/video_to_text.py\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* add self.out = None to asr subsampling\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* Update nemo/collections/cv/data/video_to_text_dataset.py\n\nCo-authored-by: Igor Gitman <igor.a.gitman@gmail.com>\nSigned-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>\n\n* cv -> multimodal/speech_cv branch\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\nSigned-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Igor Gitman <igor.a.gitman@gmail.com>\n\n* HF StarCoder to NeMo conversion script (#7421)\n\n* Script to convert HF StarCoder checkpoint to NeMo\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* StarCoder conversion test\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Fix test\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Catch up with save_to changes\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Don't abbreviate args for clarity\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Configurable precision: BF16 vs FP32\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* fix bug when loading dist ckpt in peft (#7452)\n\nSigned-off-by: Hongbin Liu <hongbinl@nvidia.com>\nCo-authored-by: Hongbin Liu <hongbinl@nvidia.com>\n\n* Fix adding positional embeddings in-place in transformer module (#7440)\n\nSigned-off-by: Tamerlan Tabolov <tktabolov@gmail.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\n\n* Fix (#7478)\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* add sleep (#7498) (#7499)\n\n* add sleep\n\n\n\n* add sleep onto config instead\n\n\n\n* add comment\n\n\n\n---------\n\nSigned-off-by: Gerald Shen <geshen@nvidia.com>\nCo-authored-by: Gerald Shen <119401249+gshennvm@users.noreply.github.com>\n\n* Fix exp manager check for sleep (#7503) (#7504)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\n\n* bugfix: trainer.accelerator=auto from None. (#7492) (#7493)\n\nSigned-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nCo-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\n\n* [doc] fix broken link (#7481)\n\nSigned-off-by: Stas Bekman <stas00@users.noreply.github.com>\n\n* [TTS] Read audio as int32 to avoid flac read errors (#7477)\n\n* [TTS] Read audio as int32 to avoid flac read errors\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Add comment about read failures\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n---------\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS (#7409)\n\n* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS\n* Train 'AISHELL-3' dataset with multi-speakers\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Update get_data.py\n\nupdate copyright header\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Update get_data.py\n\nadded a disclaimer\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add new configuration file for AISHELL3 with multispeaker of fastpitch\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* dllogger - log on rank 0 only (#7513)\n\nSigned-off-by: Stas Bekman <stas00@users.noreply.github.com>\n\n* Fix TTS FastPitch tutorial (#7494) (#7516)\n\n* Fix\n\n---------\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\n\n* Fix get_dist() tensor dimension (#7506) (#7515)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\nCo-authored-by: Jocelyn <jocelynh@nvidia.com>\n\n* bugfix: specify trainer.strategy=auto when devices=1 (#7509) (#7512)\n\nSigned-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\n\n* fix (#7511)\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* [TTS] Fix FastPitch data prep tutorial (#7524)\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* add italian tokenization (#7486)\n\n* add italian tokenization\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add more ipa lexicon it\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix error deletion\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* add test\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Replace None strategy with auto in tutorial notebooks (#7521) (#7527)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\n\n* unpin setuptools (#7534) (#7535)\n\nSigned-off-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\n\n* remove auto generated examples (#7510)\n\n* explicitly remove autogenerated examples for data parallel evaluation\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* mark autogenrated and remove it for test\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: arendu <adithyare@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Add the `strategy` argument to `MegatronGPTModel.generate()` (#7264)\n\nIt is passed as an explicit argument rather than through\n`**strategy_args` so as to ensure someone cannot accidentally pass other\narguments that would end up being ignored.\n\nIt is a keyword-only argument to ensure that if in the future we want to\nupdate the signature to `**strategy_args`, we can do it without breaking\ncode.\n\nSigned-off-by: Olivier Delalleau <507137+odelalleau@users.noreply.github.com>\n\n* Fix PTL2.0 related ASR bugs in r1.21.0: Val metrics logging, None dataloader issue (#7531) (#7533)\n\n* fix none dataloader issue ptl2\n\n\n\n* ptl2.0 logging fixes for rnnt_models\n\n\n\n---------\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\nCo-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\n\n* gpus -> devices (#7542) (#7545)\n\nSigned-off-by: Nithin Rao Koluguri <nithinraok>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\n\n* Update FFMPEG version to fix issue with torchaudio (#7551) (#7553)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\n\n* PEFT GPT & T5 Refactor (#7308)\n\n* initial implementation of add_adapters API\n\n* correct type hint\n\n* Add config in add_adapters for save and load (@author bobchen)\n\n* Remove AdapterConfig to avoid import error\n\n* Add AdaterConfig back and move adaptermixin to sft model\n\n* Add NLPSaveRestoreConnector as default in NLPModel.restore_from\n\n* Add restore_from_nemo_with_adapter and test script\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* rename t5 file and classes to be consistent with GPT\n\n* add t5 sft dataset\n\n* add support for single-file format with T5SFTDataset\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Various small changes to make T5 SFT work like GPT SFT\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add adapter evaluation test script\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add MultiAdaterConfig for ia3 and fix builder issue\n\n* Make ptuning for T5SFTModel work using mixin\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add IA3_Adapter for AdapterName\n\n* Add adapter name for ptuning and attention adapter\n\n* Make test script GPT/T5 agnostic\n\n* Add layer selection feature\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Integrate adapter name and config\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update gpt peft tuning script to new API\n\n* add t5 peft tuning script with new API\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix IA3 layer selection issue\n\n* Override state_dict on SFT model instead of mixin\n\n* Add load adapter by adapter config\n\n* move peft config map away from example script\n\n* auto get config from nemo adapter\n\n* Move PEFTConfig to new file\n\n* fix ckpt save/load for t5\n\n* name change: add_adapters -> add_adapter\n\n* variable name change\n\n* update t5 script\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix t5 issues\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add weight tying\n\n* update gpt tuning script\n\n* PEFT-API proposal\n\n* Fix according to comments\n\n* update tuning scripts\n\n* move merge_cfg_with to mixin class since it applies to both gpt and t5 and requires the model class for restore\n\n* Add mcore_gpt support for NLPAdapterMixin\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix typo\n\n* variable name change to distinguish \"peft\" and \"adapter\"\n\n* override `load_adapters` to support `add_adapter` name change\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update tuning and eval script for adapter save/load\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add Ptuning on first stage only\n\n* add lora tutorial for review\n\n* Fix layer selection for mcore\n\n* add landing page\n\n* fix resume training\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add mcore condition in sharded_state_dict to make sft work\n\n* Update lora_tutorial.md\n\nFirst edit of this file for PEFT documentation for NeMO\n\nSigned-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>\n\n* rename Adapter to AttentionAdapter to avoid confusion in doc\n\n* Change load_adapters to load .nemo\n\n* add quick start guide\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add load_adapters with .ckpt\n\n* Remove setup_complete changes in load_adapters\n\n* update landing page\n\n* remove typo\n\n* Updated quick_start.md per Chen Cui\n\nSigned-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>\n\n* Add inference config merger and tutorial\n\n* Add doc string for NLPAdapterModelMixin and deprecated warning on MegatronGPTPEFTModel\n\n* add suppor\u2026"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2023-09-29T18:12:43Z",
        "message": "fix validation_step_outputs initialization for multi-dataloader (#7546) (#7572)\n\n* added correct validation_step_outputs initialization for mutli-dataloader\n\n\n\n* changed kernel for display\n\n\n\n* Update logic for validation and test step outputs\n\n\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* revert multidataloader changes in multilang ASR notebook\n\n\n\n---------\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2023-09-19T00:48:37Z",
        "message": "Fix None dataloader issue in PTL2.0 (#7455)\n\n* Fix None dataloader issue in PTL2.0\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* updating values of self._validation_dl and self._test_dl as well\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* updating values of self._validation_dl and self._test_dl as well\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2023-08-05T22:40:17Z",
        "message": "Upgrade to pytorch lightning 2.0 (#6433)\n\n* Upgrade pytorch lightning version in requirements\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Initial fixes for PTL2.0\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add further fixes to support lightning 2.0\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add replacements for replace_sampler_ddp, resume_from_checkpoint_fit_path and few occurances of validation_epoch_end\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Replace all occurances of validation_epoch_end to on_validation_epoch_end\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Replace training_epoch_end, test_epoch_end with on_train_epoch_end and on_test_epoch_end respectively\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Change logger=None to logger=False in Trainer object\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Remove PTL2.0 deprecated Trainer args from TrainerConfig dataclass\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Modify trainer.precision check and other small edits\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Replace logger=None with logger=False in test_ptl_stateless_timer.py Trainer\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add default values for args to fix Attribute Error\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add the following modifications\n\n1) Remove outputs arg from on_validation_epoch_end, on_test_epoch_end and make it an arg of the class\n2) Replace resume_from_checkpoint with ckpt_path as needed\n3) Explicitly add accelerator as 'CPU' in UTs being run on CPU\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Remove outputs arg from on_validation_epoch_end, on_test_epoch_end\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Remove outputs arg in on_validation_epoch_end in MultiBinaryAccuracy docstrings\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add val, test outputs as instance vars in PunctuationCapitalizationModel and TokenClassificationModel\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Replace trainer.fit_loop.max_steps with trainer.fit_loop.epoch_loop.max_steps in test_optimizers_schedulers.py\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Revert an extra space that was mistakenly added\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Use self.validation_step_outputs and self.test_step_outputs in test_ema.py for uniformity\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Use self.validation_step_outputs and self.test_step_outputs in test_ptl_stateless_timer.py and check_for_ranks.py for uniformity\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add self.validation_step_outputs.clear() and self.test_step_outputs.clear() wherever missing\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Remove outputs arg from on_train_epoch_end\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Remove outputs from on_validation_epoch_end in multi_binary_acc.py\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Remove output args from on_validation_epoch_end in the docstrings of some ASR files\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Remove output args from on_validation_epoch_end and clear memory from validation_step_outputs\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add on_validation_epoch_end and remove outputs args for nlp models\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Append output of validation_step to validation_step_outputs in EncDecClassificationModel\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add the following changes\n\n1) Index self.validation_step_outputs and self.test_step.outputs with dataloader_idx wherever needed\n2) Initialize self.validation_step_outputs and self.test_step.outputs as empty lists and add support for multi dataloaders if they exist\n3) Remove self.pre_configure_ddp from NLPDDPStrategy class as its removed in PTL 2.0\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add default value dataloader_idx=0 for on_validation_batch_end() in megatron_base_model.py\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* TypeCast precision to str in attention.py and utils_funcs.py to avoid TypeError\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add if condition check for multiple dataloaders when appending to validation outputs\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Separate validation pass to be used with both validation_step and test_step\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add if condition check for multiple dataloader while appending to test_step_outputs in punctuation_capitalization_model.py\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add condition check for multiple dataloaders based on type of trainer.val/test_dataloaders or self._validation/test_dl instead of len\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Comment Megatron T5 IA3 PP=2 in CI pipeline due to dataloader_iter issue with PTL 2.0\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Modify precision checks to account for 16-mixed and bf16-mixed\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Append output of validation/test_step to self.validation/test_step_outputs in CTCG2PModel\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Modify find_unused_parameters=True in g2p_heteronym model\n\n1) Add find_unused_parameters=True for DDP strategy in g2p_heteronym_classification_train_and_evaluate.py\n2) Remove args output in validation/test_step and add instance variables instead for heteronym_classification.py\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Remove outputs from on_test_epoch_end in DialogueGPTClassificationModel\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add validation/test outputs in sgdqa_model and modify dialogue_config.yaml\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add split arg self.test_step_outputs to TextClassificationModel\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add test_step_outputs to dialogue and text classification models\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Change condition check for multiple dataloaders:\n\n1) Replace ds_item as list in dialogue_config.yaml\n2) Check for len of val/test_dataloaders or validation/test_dl along with type check of list in sgdqa_model.py while appending outputs of validation/test_step\n3) Check for len of _validation/test_dl for creating self.validation/test_step_outputs in ModelPT and punctuation_cpitalization_model.py\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add additional condition for multi dataloaders\n\nCheck len(self.trainer.val/test_dataloaders) > 1 along with type(self.trainer.val/test_dataloaders) == list for multi dataloaders in validation/test_step\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add val step outputs and default val for dataloader_idx\n\n1) Append validation_step outout to self.validation_step_outputs in MultiLabelIntentSlotClassificationMode\n2) Add default val for dataloader_idx for on_test_batch_start/end in TimingCallback\n3) Add self.validation/test_step_outputs in BERTQAModel and remove outputs arg\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add val/test_step_outputs to S2SQAModel and GPTQAModel\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Edit JenkinsFile for bert_pretrainig.py\n\nEdit Jenkinsfile for this test to disable validation as a workaround for trainer.val_dataloader None error\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Modify precision to support 16-mixed, bf16-mixed in megatron_gpt_pretraining.py\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add ddp_find_unused_parameters_true and remove output args\n\n1) Add ddp_find_unused_parameters_true fro trainer.strategy in self_alignment_pretraining.py as it has unused parameters\n2) Remove output args and add self.validation/test_step_outputs to validation/test_step in mt_enc_dec_model.py\n3) Comment tests in JenkinsFile that need to be fixed\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Precision fix in megatron_nmt_training.py for 16-mixed, bf16-mixed\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Precision fix for megatron_bert_pretraining.py and megatron_bert_model.py\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Precision fix and validation/test_step_outputs\n\n1) Add fix to account for 16-mixed and bf16-mixed in megatron_retro_mutransfer_pretrain.py, megatron_retro_pretraining.py\n2) Reset ckpt_path for test in enc_dec_nmt.py\n3) Remove outputs args and add validation/test_step_outputs in megatron_retrieval_model.py\n4) Comment Megatron Bert Pretraining and Resume Training with Pipeline Paralleism and add back NMT Training Post-LN\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Precision fix and skip few failing tests\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add missing comment lines in JenkinsFile\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Comment jenkin tests and super().on_validation_epoch_end() in megatron_gpt_sft_model.py\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Minor edit JenkinsFile\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Minor edit in jenkins file\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Edit in Jenkins file\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Comment missed lines in Jenkins file\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Fix precision and validation/test outputs\n\n1) Add precision fix to account for 16-mixed and bf16-mixed in megatron_t5_pretraining.py\n2) Remove outputs args and add append loss to self.validation/test_step_outputs in megatron_lm_encoder_decoder_model.py\n3) Add back resume_from_checkpoint in the megatron_t5_config.yaml\n4) Comment out certain tests in Jenkins file\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Fix precision and validation/test/predict errors in megatron_t5_prompt_learning.py\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Precision fix and edit precision typo in all files\n\n1) Account for 16-mixed and bf16-mixed in megatron_bart_pretraining.py and megatron_t5_seq2seq_finetune.py\n2) Fix precision typo in all files\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Fix all CI TTS tests and comment few Jenkins tests\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Combine xx_epoch_end and on_xx_epoch_end\n\nAdd on_inference_epoch_end to inference_epoch_end function and have a single on_validation/test_epoch_end in megatron_finetune_model.py and megatron_gpt_sft_model.py\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add a missing comment in JenkinsFile\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add try except StopIteration in validation_step for models with dataloader_iter\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Remove pyyaml from requirements\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add try except for inference_step in megatron_finetune_model.py\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Remove limit_val_batches for mockGPTDataset test\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add new self.validation_step_outputs for MegatronGPTSFTModel\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Minor edit Jenkinsfile\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Initialize self.validation/test_step_outputs in megatron_gpt_sft_model.py\n\nInitialize self.validation/test_step_outputs in setup of MegatronGPTSFTModel to take care of cases when datalaoders are not setup in ModelPT for example while restoring the model.\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Remove resume_from_checkpoint if trainer arg in conf yaml files\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Remove resume_from_checkpoint as trainer arg in GPT, T5 configs\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Remove resume_from_checkpoint in duplex_tn_config.yaml\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Fix typos, unused imports and refactor code to remove redundant funcs\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Remove commented code in megatron_nmt_model.py\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Fix overriden functions to match parent class functions\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Prefetch dataloader_iter to prevent hang for PP>1\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Override setup() in NLPDDPStrategy to avoid hang during predict with PP>1\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Uncomment tests in JenkinsFile\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add '16' to precision checks and other minor fixes\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Clear validation/test_step_outputs with dataloader_idx for multi dataloaders\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Minor edits\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Modify precision checks to avoid indexing\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Remove self.validation_step_outputs_sft and add dataloader_idx to clear outputs\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Reference checkpoint with trainer.ckpt_path\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add _prefetch to NLPModel and minor fixes\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add limit_val_batches in JenkinsFile for NMT\n\n1) Add trainer.limit_val_batches in Megatron NMT Training TP=2\n2) Remove unused import in ModelPT\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2023-05-15T20:05:16Z",
        "message": "Confidence ensembles implementation (#6614)\n\n* Working version to train conf model + save ensemble class\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Working version\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Remove copy of transcribe_speech.py\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Move models parameter to config\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Add explicit parameters to transcribe\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Small cleanups\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Add temperature and integration tests\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Add more tests\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Add pc removal config\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Cleanup\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Fix typo\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Address review comments\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n---------\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2023-03-10T00:28:26Z",
        "message": "Save model parallel .nemo in ExpManager (#6115)\n\n* patch to allow using tokenizers without additional_special_tokens_ids attribute\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* save tp pp > 1 .nemo in exp manager\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* Better rank checking for model parallel > 1 .nemo saving\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Safety check\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* check for nlp model\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* custom on save checkpoint for NLPModel\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* minor update\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* minor updates\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* reverting custom save logic\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* reverting custom save logic\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* reverting custom save logic\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* reverting custom save logic\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* reverting custom save logic\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* reverting custom save logic\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* added pleasefixme\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* updated\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: arendu <adithya.r@gmail.com>\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2023-02-06T18:21:37Z",
        "message": "Dynamic freezing in Nemo (#5879)\n\n* Initial commit for dynamic freezing logic\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Updated logic to handle lists and updated docs\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Transferred dynamic freezing logic to core from asr\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Revert asr config to original\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* Fixed tab indent in core.rst\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* Updated modelPT for latest from master\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fixed indents in docs\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n---------\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\nCo-authored-by: Daniel Egert <degert@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2023-01-23T19:04:09Z",
        "message": "Support nested NeMo models (#5671)\n\nNested NeMo models support\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Sean Naren <sean.narenthiran@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2023-01-23T08:39:08Z",
        "message": "[TTS][DE] Augment tokenization/G2P to preserve capitalization of words and mix phonemes with word-level graphemes for an input text. (#5805)\n\n* unify german and any locale text processing func.\n* add comments and instructions for grapheme_prefix.\n* add comments to nomralize_unicode_text func.\n* relax the g2p dictionary lookup for mixed cases and added unit tests to verify.\n* fix special cases for English.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-12-12T18:23:45Z",
        "message": "Fix: setup_multiple validation/test data (#5585)\n\nFix: setup_multiple validation/test data (#5585)\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-12-09T21:14:12Z",
        "message": "Add an option to defer data setup from ``__init__`` to ``setup`` (#5569)\n\n* Add an option to defer dataloader setup from __init__ to setup\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>\n\n* Updated doc\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-10-13T22:39:16Z",
        "message": "refactor TTS documentation organization and add new contents. (#5137)\n\n* refactor TTS documentation organization and add new contents.\n* fix asr api bug.\n* fix broken links.\n* fix unexpected indentation errors.\n* fixed unexpected indentation.\n* fixed broken paper reference.\n* fixed cross-reference and typos.\n* fixed toctree errors.\n* revert to 'Augmentors'\n* reordered TTS tutorial list in starthere.\n* ordered api classes alphabetically for each Section.\n* fixed underscore typo for fastpitch checkpoint.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* upcase 'Tuning'\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* fixed typo for RAD-TTS Aligner\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* reorder aligner section after mel-gen and vocoders in models.rst.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* clarify Mixer-TTS-X and reorder model descriptions alphabetically.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* fixed some typos and formats.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* removed old megatron.rst.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* fixed block quote ends without a blank line warnings.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* remove duplicate reference; fixed missing key nlp-megatron-shoeybi2019megatron\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Revert \"removed old megatron.rst.\"\n\nThis reverts commit c5ea1dc3f23272eecfe8040e3abfa54fa122cf73.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* removed Russian, a hyphen, and add a note about G2P in tts/config.rst\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* added pynini installation in wfst_text_normalization.rst\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* added description of manifest key/value pairs.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* add toctree in tts/intro\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* replace main branch to stable.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* add 'upcoming' for e2e systems.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* replaced main branch to stable.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-10-11T20:22:39Z",
        "message": "Fixes for docs/typos + remove max_utts parameter from tarred datasets as it causes hang in training (#5118)\n\n* Remove ; from jupyter notebook cells\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Fix typos in documentation/code\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Fix output message to have 'or equal'\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Link formatting fixes\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Add error if max_utts is used in tarred datasets\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Remove max_utts parameter from tarred datasets\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Fix max_utts removal in tests\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\n* Fix typo if -> is\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-09-13T00:24:36Z",
        "message": "merge r1.11 to main (#4920)\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info and dockerfile\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [TTS] bugfix for missing configs. (#4725)\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Fix pynini install in TTS tutorials (#4729)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* [TTS] updated config with a German IPA phoneme tokenizer (#4756)\n\n* [TTS] added a German IPA phoneme tokenizer\n* [TTS][ASR] enabled customized arguments for trimming the leading and trailing silence.\n* [TTS] disabled spline interpolation for beta-binomial distribution. Let it generate align prior and save to disks. Use a new phoneme tokenizer.\n* [TTS] use consistent spline interpolation with fastpitch checkpoint when generating mel-spectrograms for hifigan finetune.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Update r1.11 to new heteronyms list (#4745)\n\n* Update configs to new heteronyms list\n* Remove old heteronyms list, add alt 'merchandise' pron to CMUdict\n* Update remaining references to old heteronyms list\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Fix tutorial formatting (#4778)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* update branch and typos (#4788)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Adding support for models trained with full context for cache-aware streaming. (#4687)\n\n* added support for models trained with full context.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed style.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* dropped seq_range\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed indexing in caching methods.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed code style.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed code style.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* updated docs.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* addressed comments.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed code style.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed code style.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed code style.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* change frame-wise to cache-aware.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* change frame-wise to cache-aware.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* change frame-wise to cache-aware.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed code style.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* Update megatron encoder decoder model to support py37 for colab (#4791)\n\n* [ASR] Add pretrained ASR models for Croatian (#4682)\n\n* [ASR] Add pretrained ASR models for Croatian\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>\n\n* Fix style for import\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>\nCo-authored-by: Ante Jukic\u0301 <ajukic@nvidia.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\n\n* added/fixed export for Megatron models (#4712)\n\n* added/fixed export for Megatron models\n\nSigned-off-by: David Mosallanezhad <dmosallanezh@nvidia.com>\n\n* fixed style\n\nSigned-off-by: David Mosallanezhad <dmosallanezh@nvidia.com>\n\n* fixed FusedScaleMaskSoftmax in BioMegatron\n\nSigned-off-by: David Mosallanezhad <dmosallanezh@nvidia.com>\n\n* included comments\n\nSigned-off-by: David Mosallanezhad <dmosallanezh@nvidia.com>\n\nSigned-off-by: David Mosallanezhad <dmosallanezh@nvidia.com>\nCo-authored-by: David Mosallanezhad <dmosallanezh@nvidia.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* update branch for qa notebook\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix initializing weights from ptl ckpt with exclude (#4807)\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* Fix index error from addition of voiced_mask and p_voiced (#4811)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* T5 prompt learning fixes (#4771)\n\n* RPE, hidden size and config fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Update to reflect new config names\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Sentencepiece fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix finetuning\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Add encoder seq len to gpt\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Add finetune eval script\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix name\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Update Jenkinsfile\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Update config\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix CI test\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Update check\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Backward compat\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Update CI test\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Split rank for Enc-Dec models\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Address comments\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Virginia Adams <78445382+vadam5@users.noreply.github.com>\n\n* G2P docs (#4841)\n\n* g2p docs added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix references\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* address review feedback\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* Fix providing glue in seq2seq eval (#4843)\n\n* Fix providing glue in seq2seq eval\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Updated inference code and squad scripts (#4835)\n\n* Updated inference code and squad scripts\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Reverted GPT & T5 inference files back to use NLPDDPlugin\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Overwrite frozen LM to use fused adam\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Added padded vocab size\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Fixed val check interval value\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Python format fix\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Make t5 prompt learning preds write to file\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Added back dp=1 check\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\n\n* Set the number of workers to 0 for validation and test sets in all enc-dec models (#4790)\n\n* Set workers to 0 for validation and test\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Revert pin memory\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Sean Naren <sean.narenthiran@gmail.com>\n\n* Fix Megatron NMT consumed samples and ckpt_to_nemo split rank (#4884)\n\n* Fix nmt and ckpt_to_nemo\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* added utf8 encoding (#4892)\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* update readme with apex commit\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Add support for Apex distributed Adam optimizer with GPT-3 (#4487)\n\n* Add support for Apex distributed Adam optimizer with GPT-3\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Fix bug in grad clipping with dist Adam\n\nGrad norm was computed over all params, not respecting model parallelism.\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Fix bug with DDP initialization\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Make distopt dependent on megatron_amp_o2\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Fix code formatting\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Handle dist Adam in optimizer unit tests\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* update readme\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update readme\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fixed styles\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* removed unsued import.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* removed duplicated func defintion.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* replace 'r1.11.0' with 'main' in Jenkinsfile and all tutorials.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* fix: PRE_RELEASE = 'rc0'\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* replace branch name to main for asr_with_adapters.ipynb.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* fix Fastpitch mixertts tutorial format to align with main to distingshuish diff\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* fix: correct path for tokenizers.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\nSigned-off-by: ericharper <complex451@gmail.com>\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>\nSigned-off-by: David Mosallanezhad <dmosallanezh@nvidia.com>\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\nCo-authored-by: ericharper <complex451@gmail.com>\nCo-authored-by: Jocelyn <jocelynh@nvidia.com>\nCo-authored-by: Vahid Noroozi <VahidooX@users.noreply.github.com>\nCo-authored-by: Zhilin Wang <wangzhilin12061996@hotmail.com>\nCo-authored-by: anteju <108555623+anteju@users.noreply.github.com>\nCo-authored-by: Ante Jukic\u0301 <ajukic@nvidia.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: David <amosalla@asu.edu>\nCo-authored-by: David Mosallanezhad <dmosallanezh@nvidia.com>\nCo-authored-by: Samuel Kriman <samuelkriman@gmail.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Virginia Adams <78445382+vadam5@users.noreply.github.com>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\nCo-authored-by: Sean Naren <sean.narenthiran@gmail.com>\nCo-authored-by: Tim Moon <4406448+timmoon10@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-08-15T23:37:31Z",
        "message": "Add support for Apex distributed Adam optimizer with GPT-3 (#4487)\n\n* Add support for Apex distributed Adam optimizer with GPT-3\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Fix bug in grad clipping with dist Adam\n\nGrad norm was computed over all params, not respecting model parallelism.\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Fix bug with DDP initialization\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Make distopt dependent on megatron_amp_o2\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Fix code formatting\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Handle dist Adam in optimizer unit tests\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-08-11T15:20:29Z",
        "message": "upgrade to PTL 1.7 (#4672)\n\n* upgrade to PTL 1.7\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* min version\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* replace progressbar_refresh_rate with enable progressbar, this is callback now\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* progressbar\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* replace removed PTL 1.7 args, fix cpu tests, remove p-tune older script\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* revert ssl test fixes\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* override trainer property and fix numba grad check\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* NLPDDPlugin -> NLPDDPStrategy\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* style fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* set max_steps default as -1\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* fix maxsteps in notebooks\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* update trainer config\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* fix speech2label jenkins\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* fix speech2text jenkins\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* DDPPlugin -> DDPStrategy\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* remove provided strategy keys from trainer config nlp\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* check other examples\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* override LightningModule .cuda call to maintain pytorch default behavior\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert gpt eval jenkins test\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* overwrite cuda class to PTL\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* review feedback\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* remove checkpoint callback from main config\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* patch fix for intentslot classification test\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* style fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\nSigned-off-by: ericharper <complex451@gmail.com>\nCo-authored-by: ericharper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-07-15T22:42:31Z",
        "message": "Removed NLPDDPPlugin Import check (#4555)\n\n* Removed NLPDDPPlugin Import check\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Python formatting fix\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* changed app to app_state\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* moved num workers check back to bottom\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Python code reformat\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-07-13T20:48:41Z",
        "message": "Add nsys profiling (#4539)\n\n* add nsys profiling\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* only access omegaconf in setup\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use robust get_rank function\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* simplify\n\nSigned-off-by: ericharper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-07-09T02:11:13Z",
        "message": "Update finetune label models (#4504)\n\n* initial_script\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* move old script\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* remove finetune func from label models\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* style clean\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* updated config\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* update tutorial\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* lgtm fixes\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* updated based on comments\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* update doc\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-07-08T13:12:58Z",
        "message": "[Add] Support for Different LRs with Param Groups (#4508)\n\n* add support for param groups\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* make config more general\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-06-30T22:37:24Z",
        "message": "[TTS] created the finetuning Hifigan 44100Hz recipe on HUI-Audio-Corpus-German. (#4478)\n\n* implemented a script of generating mel-spectrograms for finetuning Hifigan using multiprocessing.\n* fixed some typos.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-06-28T02:33:34Z",
        "message": "Add O2 support for RETRO model (#4411)\n\n* make sure post-ln works with new coeff\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* add some comments\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* second v\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix headscale\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* works both for pre-ln and post-ln\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix unittest\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* stop gradient\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* stop gradient\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* use half rotary embedding\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* use default grad clip\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* turn off rotary embedding\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* added o2 support\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix style\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* add debugging\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* make cyclic lr work\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* o2 works with cyclic lr\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* remove deepnet\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix merge error\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* update the comments\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* added output scaling for stable training\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* improve the debug code\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix comment\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* move debug hook above\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* move optimizer config to base class\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* address comments\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-05-26T04:50:43Z",
        "message": "BigNLP perf regression fix (#4267)\n\n* Temp\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove line that caused perf regression\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-05-17T18:59:54Z",
        "message": "Add Module-level Adapters, Save-Restore and tests (#4114)\n\n* First draft of model level tests and support for multiple types adapters in same model\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add save restore tests for adapters\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add save restore tests for adapters\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add adapter only save and restore\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update base adapter config\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix collection of get enabled adapters, limiting to each module's scope\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update docs and add support for resolution of module adapter names\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update ASR adapters to only support module adapters\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add state dict match test\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix name resolution for set_enabled_adapters\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct case where name is none for set adapter\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct case where there are no adapters to save\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update config for training\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Force update to internal config upon get or set\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add spec augment update support to adapters\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct config update\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add dropout support to linear adapters\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add type to config\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add stochastic depth regularization to adapter merge strategy and related tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add support for dynamic strategy change\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add support for dynamic strategy change\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add more tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add more tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove logging of adapter name\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update changes for reviews\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Refactor the utility methods\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Refactor the utility methods\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Fixed configs for optim and spec augment\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Fixed configs for optim and spec augment\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Rename method to subclassable private\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Add support for adapter module names to be pre-specified in config\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Fix imports\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Fix typos\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-04-29T19:40:38Z",
        "message": "NeMo Adapters Support + ASR Adapters (#3942)\n\n* Initial impl of adapters\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Stabilize Adapter core api\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix tests for freezing\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Initial subclass impl\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add encoder adapters support to Model level\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Improve code stability\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix as_frozen()\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix as_frozen()\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Localize config for stability and delegate updates\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update name of method\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Stabilize codebase\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Style fixes\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add download test\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update test\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add docstrings to base adapter mixin\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add docstrings to base adapter mixin\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add docstrings to ASR adapter mixin\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add docs for mixins and adapter modules\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Revamp Jasper support for adapters to be dynamic in output dim, add data class support for adapter mixins, add linear adapter dataclass, refactor tests and add more asr tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Style fixes\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update conformer encoder adapter docs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct indent\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [INCORRECT] COMMIT\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [INCORRECT] COMMIT\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [INCORRECT] COMMIT\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add asr adapter scripts\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct initialization of adapters, fix rnnt debug logging and fix modelpt issue with optimizer param groups\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update recommendations for asr adaptation\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix trailing \\\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix missing adapter value for config\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add export test for adapter asr module\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Test only on gpu\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix trailing \\\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix trailing \\\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix configs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Refactor out asr adapter mixin into AdapterModelPTMixin\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add Jenkinsfile test\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add Jenkinsfile test\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct feature dim for small Conformers\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix adapters test position\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Temp\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add support for top level config in adapters\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add support for global_cfg for adapter\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add support for adapter global_cfg support, make ASR adapter mixin optionally build encoder adapters\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update script to train adapters\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Refactor out LinearAdapter to commons\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix inits\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* patch model.summarize() deprecation notice\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add adapter registry support\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove extra import\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove extra import\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Address review comments\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix paths to config\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add execution flow diagrams\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-04-28T00:39:51Z",
        "message": "[Core] Support pre-extracted nemo checkpoint for restoration (#4061)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-04-26T18:09:15Z",
        "message": "Update num worker calculation due to PTL flag changes (#4056)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-04-20T22:46:30Z",
        "message": "Merge r1.8.0 main (#4036)\n\n* update version\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Stateless timer fix for PTL 1.6 (#3925)\n\n* Stateless timer fix for PTL 1.6\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Stateless timer PTL test\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix year\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove unused imports\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* GPU test\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* clean import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: ericharper <complex451@gmail.com>\n\n* Fix issues with librosa deprecations (#3950)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix notebook bugs for branch r1.8.0 (#3948)\n\n* load the model from ngc\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix all biomegatron notebook\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix the typos\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* remove output\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix isort\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix merge error\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* change ntpath for isort workaround\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix unit test\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix ci\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix ci bert pretraining\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* make it compatible with main\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* add the teste for biomegatron ner\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix argument\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix usablity issue\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* work around\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Yi Dong <doyend@gmail.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix global batch fit loop (#3936)\n\n* add lightning module hooks for global batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean scripts\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* DP=1 fix\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* set num dataset workers to 2\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update validation_loop with GlobalDataFetcher\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add test global data fetcher\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Drop last for test ds\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix test epoch end\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix eval\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix reconfigure microbatch in the complete method\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add comments\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Set init consumed samples\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* fix shuffle\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add save_restore_connector arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix padding for labels and loss mask\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* GLUE/XNLI CI tests\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* limit val batches in hydra fix\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Restart CI\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix unittest\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Exports 22.03 war (#3957)\n\n* Fixed fastpitch for 22.03\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* cleanup\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Restored mask expansion; added WAR for test container images\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* style\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Refactor restorefrom (#3927)\n\n* update package info (#3926)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Refactor restore_from\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Move export related python files to scripts/export/\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Return state dict after modification function\n\n* Remove Megatron legacy parameter in common.py restore_from function\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* ability to set log_predictions to false (#3929)\n\n* Bumping Python version\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fixing style\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* load the model from ngc\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix all biomegatron notebook\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix the typos\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* remove output\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix isort\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix merge error\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* change ntpath for isort workaround\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix unit test\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix ci\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix ci bert pretraining\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* Rearrage export files; Style fix; Extend legacy MegatronBert conversion to NLP models nemo version updation\n\n* Glu activation variants (#3951)\n\n* Temp\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Add reglu and swiglu activations\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style on unrelated file\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* CI changes to test activations\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix unused import\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fix beacuse of merge from main\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* make it compatible with main\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* add the teste for biomegatron ner\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix argument\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix usablity issue\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* FastPitch FT notebook - Improving Speech Quality clarifications (#3954)\n\n* FastPitch FT notebook - Improving Speech Quality clarifications\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Add pynini dependency install to FastPitch FT notebook\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Pin pynini install for FastPitch FT tutorial\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* work around\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\nCo-authored-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\nCo-authored-by: Dima Rekesh <bmwshop@gmail.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nCo-authored-by: Yi Dong <doyend@gmail.com>\nCo-authored-by: Yi Dong <43824965+yidong72@users.noreply.github.com>\nCo-authored-by: Boris Fomitchev <borisfom@users.noreply.github.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Jocelyn <jocelynh@nvidia.com>\n\n* Bump TTS deprecation version to 1.9 (#3955)\n\n* bump deprecation version\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update talknet depre\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* added conformer for zh. (#3970)\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* Add pinned pynini and scipy installs to TTS training tutorial (#3967)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Fix variable name and move models to CPU in Change partition (#3972)\n\n* fixes\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* add CI\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\n\n* fix misconfiguration (#3975)\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Yi Dong <doyend@gmail.com>\n\n* Fix NMT variable passing bug (#3985)\n\n* fix\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* stylefix\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* Compatability override to load_state_dict for old TTS checkpoints (#3978)\n\n* Compatability override to load_state_dict for old TTS checkpoints\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Tacotron2 training notebook fix - add GPU argument\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Add hann window override warning for old model loading\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Notebook Bug Fixes for r1.8.0 (#3989)\n\n* Made config related bug fixes\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Fixed cfg.get syntax\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Fix compat override for TalkNet Aligner (#3993)\n\n* Fix compatibility override for TalkNet Aligner\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Remove extraneous logging import\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* docs fixes (#3987)\n\n* docs fixes\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* rename files in docs\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* docs improvement\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* arg renamed\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* Fix nemo megatron restore with artifacts (#3997)\n\n* update config_path in register_artifact\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix register_artifact calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix register_artifact calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update log messages to include merges file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add default prompts to config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fixes val_check_interval, skip loading train data during eval (#3968)\n\n* Change stage check\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix bugs in megatron t5 glue eval scripts\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Fix reconfigure\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Change check\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix hasattr\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix typo in cfg structure\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Update megatron t5 glue eval config file\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Reconfigure to avoid drop last\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix for train step reconfigure as well\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Update megatron t5 glue eval config file drop_last to False\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* limit test batches\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: Yu Yao <54727607+yaoyu-33@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* LogProb calculation performance fix (#3984)\n\n* performance fix for logprob computation\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix redandant assign\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix bug to add gather from TP workers\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Yi Dong <doyend@gmail.com>\n\n* Fix link issues in export example notebook and fix pretrained model info for MegatronBert (#4004)\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\nCo-authored-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Fix single GPU training issue + change deprecated Lightning args (#4010)\n\n* change vars\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* style fix\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* Fix P-Tune T5 model (#4001)\n\n* fix ptune t5\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix ci test\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix the ci fail because of the order problem\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Yi Dong <doyend@gmail.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Megatron work-arounds (#3998)\n\n* WAR around Apex issue, and making sure output is FP32\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixing merge issues; moving dummy Trainer; adding float() casts\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixing ColumnParallelLinear call\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Cleanup\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Cleanup#2\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* fix the broadcast shape mismatch (#4017)\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Yi Dong <doyend@gmail.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* add known issues (#4024)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update readme with conda env setup instructions\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert apex guard removal\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert --language to --lang\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix apex guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove set_trace\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix apex guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unreachable statement\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove duplicate lines\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove duplicate lines\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Yi Dong <43824965+yidong72@users.noreply.github.com>\nCo-authored-by: Yi Dong <doyend@gmail.com>\nCo-authored-by: Boris Fomitchev <borisfom@users.noreply.github.com>\nCo-authored-by: Ramanathan Arunachalam <ramanathan.arun@rutgers.edu>\nCo-authored-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\nCo-authored-by: Dima Rekesh <bmwshop@gmail.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nCo-authored-by: Jocelyn <jocelynh@nvidia.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Vahid Noroozi <VahidooX@users.noreply.github.com>\nCo-authored-by: Abhinav Khattar <aklife97@gmail.com>\nCo-authored-by: Virginia Adams <78445382+vadam5@users.noreply.github.com>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\nCo-authored-by: Yu Yao <54727607+yaoyu-33@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-04-01T06:27:27Z",
        "message": "Upgrade to PTL 1.6.0 (#3890)\n\n* upgrade\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* upgrade\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update logger_connector attribute\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update checkpoint_connector attribute\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update trainer dataclass\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use pypi ptl\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update requirements\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* wandb offline for unit test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove self.training_step_end calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* create new ddpplugin object\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add storage_options arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update val_check_interval and max_steps\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update checkpointing\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip validation epoch end if no outputs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* pin setuptools\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check for global zero\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* if not outputs return in validation epoch end\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update checkpoint_connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update checkpoint_connector\n\nSigned-off-by: ericharper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-03-30T01:20:18Z",
        "message": "Megatron support (#3893)\n\n* Add MegatronBert training support for more NLP models; Replace check for nemo_file existence to decide if it's megatron training or not; Add support for finetuning a downstream NLP task model on a different downstream dataset using MegatronBert; Add skelton support for ONNX export of MegatronBert\n\n* Remove duplicate lm_checkpoint key in config\n\n* Adding new Apex classes for export replacement and default trainer support\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixing order of exported inputs in NLP models\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed typo\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed ORT check\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Refactor of NLP models initialization\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed style\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed runtime check\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Code style fixes\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Code style fixes\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Code style fixes\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Check for existence of downstream key before setting it\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Fix Huggingface download unit tests based on get_lm_model refactor\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Add register artifact for MegatronBert models; Remove unused import\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Fixed style\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed duplex decoder init\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* moved set_world_size up\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixing _trainer initialization\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed GPT tokenizer init\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fix Token classification and Q&A forward flag checks for MegatronBert\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Fix world_size init\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Skip GPT eval test\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Fix get_lm_model function calls based on recent refactoring\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Check for presence of keys in the Dict before trying to access them in BERTLMModel\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Check if tokenizer is present before accesing it in lm_utils\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Check for presence of keys in the Dict before trying to register them as artifacts\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Bypass NLP init statements pertaining to MegatronBert when using Ptune downstream task\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Revert NLPModel modification\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Skip the Jenkins Test Megatron P-Tuning GPT LM\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Merge branch 'main' into megatron_support\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\nCo-authored-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\nCo-authored-by: Boris Fomitchev <bfomitchev@nvidia.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nCo-authored-by: Boris Fomitchev <borisfom@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-02-23T21:40:46Z",
        "message": "upgrade PTL trainer flags (#3589)\n\n* upgrade PTL trainer flags\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* remove nlp override changes\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* fix test and update gpus -> devices\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* setting devices=1 for cpu case\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* update jenkins for gpus -> devices\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* single quote to double quote jenkins fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* single quote to double quote jenkins fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* devices in docs\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* update devices in tutorials :sigh:\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* checkpointing_callback -> enable_checkpointing\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* text normalization decoder trainer name fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* enable checkpoint callback name fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* NLPDDPPlugin overrides strategy ddp\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* more strategy cleaning for NLPDDPPlugin\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* now DDPPlugin for strategy removal\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* typo fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* NLPDDPPlugin more fixes\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* devices require accelerator as mandatory argument\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* moving megatron accelerator from gpu to cpu\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* accelerator null to strategy null fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* distrib_type taken from training_type_plugin\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* check for distributed type is removed\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* revert training type\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* revert transcribe_speech\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* style fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* typo fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* revert distributed backend type\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* remove flush_logs_every_n_steps trainer flag\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* rebase main\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* style fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* SGD gen update\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* NLPDDPPlugin change\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* remove strategy from dialogue conf\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* reverting find unused params\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* update jenkins\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* more nlp fixes\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* num_nodes removal from NLPDDPPlugin\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-02-14T17:05:44Z",
        "message": "[NeMoMegatron] Pipeline parallelism for GPT (#3388)\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix File Load Error (#3069)\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* update (#3113)\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* added to avail models (#3044)\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* Notebook bugfixes (#3165)\n\n* zero shot intent slot notebook bug fix\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Added megatronBERT not support in this release message to notebook\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* added apex backend to config\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Removed apex from entity linking and added 1.4.0 nemo info to warning\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* update app_state.local_rank\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* interpolate precision and sequence length in config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove trainer.precision interpolation\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove nemo_experiments after prallel stage\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove rm call\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use apex safe_divide\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update model parallel size to tensor model parallel size\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update model parallel size to tensor model parallel size\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add pipeline model paralllel size to config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* uncommment pipeline parallel offset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fake model parallel ranks\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update compute tensor model parallel rank in train script\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add logging for model parallel groups\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add logging for model parallel groups\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* model parallel rank is from index of group\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* model parallel rank is from index of group\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add build_model from apex\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add model_parallel_size\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add _optimizer_param_groups to ModelPT\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typos\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check that fake mp ranks match after mp init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove list of modules for now\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update model_parallel_size\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress of updating training_step and validation_step with fwd/bwd funcs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* added initialize word embeddings and updated validation for pipeline\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update training step for pipeline\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress of adding training step\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* training_step in progress. need to figure out logging and grad scaling for pipeline parallel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove barriers\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add pipeline to checkpointing\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add get_parameters\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* override zero_grad\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add comments for modifying training_step\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add global batch size to config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add global batch fetching and process batch for apex fwd/bwd\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* average losses across micro batches\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update validation_epoch_end\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update training_step to use global batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update training_step to use global batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove automatic grad sync and add manual grad all reduce\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* repeat attention_mask for apex fwd/bwd functions\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fwd/bwd no pipeline\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make apex transformer log level configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add comment explaining batch in train/val steps\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add comments\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix bug with initialize word embeddings\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update set_input_tensor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* refactor dtype for comm\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add dtype for pipeline comm\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rebase after prompt tuning\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add pipeline plugin to disable ptl autocast\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use torch.float instead of None for autocast_dtype\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rebase after O2 recipe was added\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* don't autocast forward when using o2\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* import inject model parallel rank\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* import inject model parallel rank\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* uninject mp rank for resume checkpoint\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* replace MasterOptimizer with MainParamsOptimizer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update fwd/bwd for fp16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress allreduce embeddings for O2\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* allreduce first last stage embeddings for O2\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add comments\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progres updating save restore and ckpt conversion\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* pass correct number of gpus to trainer in convert script\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update save_to\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update restore and eval\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding pipeline for complete method\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* pass microbatch to gpu in pipeline\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert complete method changes\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update no pipeline calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove duplicate imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add persist layer norm arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rebase\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move inject/uninject model parallel rank to prevent circular import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix check for mp_rank or tp_rank\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* specify param_groups as list\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update configs and exp_manager for model_parallel_size\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add resolver for omegaconf interpolation\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update resume checkpoint in example scripts\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* destroy model parallel groups\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* get precision from trainer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update gpt prompt tuning dataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* temporarily disable prompt tuning\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip prompt unit tests\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add default\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check if pipeline size is none\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update app_state after cpu restore\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert jenkins change\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert jenkins change\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert jenkins change\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert diff\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert diff\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* trainer grad acc must be 1\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set O2 recipe options automatically\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move require backward grad sync under conditional\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add comment, fix typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set find unused to false in bert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* find unused false\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* cleanup\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove config check\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add pipeline parallel jenkins test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins tests\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add torch.distributed init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update grad_scaler arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: vadam5 <78445382+vadam5@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-02-08T03:22:47Z",
        "message": "Add NeMo version to all new .nemo files (#3605)\n\n* Add NeMo version to all new .nemo files\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add escape clause for data classes\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-01-31T22:20:29Z",
        "message": "Final merge r1.6.0 main (#3570)\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix the tutorial notebooks bug (#3465)\n\n* fix checkpoint loading and model config file\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix style\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* Fix checkpoint converter in O2 style (#3486)\n\n* Fix checkpoint converter in O2 style\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Fix style\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\nCo-authored-by: Yu Yao <yuya@nvidia.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Remove pickled features from tarred dataset (#3491)\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\nCo-authored-by: ekmb <ebakhturina@nvidia.com>\n\n* adding missing init files (#3505)\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* typos (#3504)\n\n* typos\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* link fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* update titanet conf (#3507)\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* Fix link to NGC page for ASR (#3512)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* vad typo fix (#3490)\n\n* remove always broken ptl link\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* fix typo\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* Add verification helper function and update docs (#3514)\n\n* Add verification helper function and update docs\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* typo fixes\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* fixed the num_classes bug of conv decoder. (#3525)\n\n* fixed the num_classes bug.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added logging info.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* Enforce utf-8 on all file r/w (#3520)\n\n* Update paths to subtask\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Enforce utf-8 on all file r/w\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fixed section typo (#3522)\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Pushing updated WFST Tutorial to r1.6.0 (#3521)\n\nSigned-off-by: tbartley94 <tbartley@nvidia.com>\n\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\n\n* Fixed duplicate cell bug (#3518)\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* WFST tutorial update (#3531)\n\n* Pushing updated WFST Tutorial to r1.6.0\n\nSigned-off-by: tbartley94 <tbartley@nvidia.com>\n\n* Hopefully final corrections to WFST tutorials.\n\nSigned-off-by: tbartley94 <tbartley@nvidia.com>\n\n* [TTS] Fix bug in inference tts notebook (#3532)\n\n* fix bug in inference tts notebook\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* Update Inference_ModelSelect.ipynb\n\n* fix space\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* remove space\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* Prompt tuning documentation (#3541)\n\n* Started prompt tuning doc\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Update prompt_tuning.rst\n\n* Update models.rst\n\n* Update models.rst\n\n* Update and rename megatron_finetuning.rst to megatron_downstream_tasks.rst\n\n* Update intro.rst\n\n* Update intro.rst\n\n* Update and rename megatron_downstream_tasks.rst to megatron_finetuning.rst\n\n* Update megatron_finetuning.rst\n\n* Delete prompt_tuning.rst\n\n* Update README.rst\n\n* Update docs/source/nlp/megatron_finetuning.rst\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix nmt resume (#3539)\n\n* check for model attr\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* TN bug fix (#3538)\n\n* ve and cel fixes\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* ve and cel fixes\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add w to single digit roman and cardinal single digit graph (non det)\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* isn't fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* fix bug in tutorial (#3546)\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* Update nvidia container check (#3535)\n\n* update nvidia container check\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update minor version\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add check to T5\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update bert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* forgot import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix an issue with wandb not displaying updated config changes (#3552)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* remove extra instance (#3551)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Yi Dong <43824965+yidong72@users.noreply.github.com>\nCo-authored-by: yaoyu-33 <54727607+yaoyu-33@users.noreply.github.com>\nCo-authored-by: Yu Yao <yuya@nvidia.com>\nCo-authored-by: PeganovAnton <peganoff2@mail.ru>\nCo-authored-by: ekmb <ebakhturina@nvidia.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: Vahid Noroozi <VahidooX@users.noreply.github.com>\nCo-authored-by: Virginia Adams <78445382+vadam5@users.noreply.github.com>\nCo-authored-by: tbartley94 <90423858+tbartley94@users.noreply.github.com>\nCo-authored-by: Oktai Tatanov <oktai.tatanov@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-01-27T20:23:50Z",
        "message": "Fix bug in multi-checkpoint loading (#3536)\n\n* fix\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* check for both\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-01-27T18:47:49Z",
        "message": "Added P-Tuning method  (#3488)\n\n* init checking of p-tune method\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* training is working\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* refactor to seperate prediction and loss computation\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* updated the notebook\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* match the original hyper parameters\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fixed the loss bug\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* better scheduler\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* notebook runs\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* added neural types\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* updated the doc\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fixed the notebook\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* updated expected result\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* added accuracy\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* style fix\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix reassgin\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* log accuracy\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* load the best checkpoint\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* address PR comments\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* added ci test\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fixed max_step calculation error due to wrong number of workers\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* add import guard for nlp plugin\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fixed the metric report issue when using tensor parallel\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-01-26T17:44:33Z",
        "message": "Self-supervised tutorial & update (#3344)\n\n* update\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* update\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* version test\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* version test\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* image for tutorial\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* enc_final in model_defaults\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* enc_final in model_defaults\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* self-supervised tutorial\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* fix\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* fix\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* contextnet ssl config\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* remove test_ds from config\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* update recon decoder\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* don't save -last if val_loss is nan\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* check if val_loss is there\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* keep entries from same file together when tarring\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* keep entries from same file together when tarring\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* print num of files in shard\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* update\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* style\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* moving configs, add docstrings\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* tutorial updates\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* update test\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* update loading\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* update loading\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* update loading\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* update loading\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* fix\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* fix\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* citrinet configs\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* citrinet configs update\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* update\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* default include all\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* comments\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* docstring hydra example\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-01-19T20:41:47Z",
        "message": "fix/machine translation/minor bug in passing variables (#2954)\n\n* Fix minor bug\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix minor bug\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\nCo-authored-by: Aleksey Grinchuk (Oleksii Hrinchuk) <grinchuk.alexey@gmail.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2022-01-07T20:27:12Z",
        "message": "TalkNet Fix (#3092)\n\n* Fix 'model' key and object collisionn.\n\nSigned-off-by: Stanislav Beliaev <stasbelyaev96@gmail.com>\n\n* Rename model config node to encoder.\n\nSigned-off-by: Stanislav Beliaev <stasbelyaev96@gmail.com>\n\n* Remove line adding.\n\nSigned-off-by: Stanislav Beliaev <stasbelyaev96@gmail.com>\n\n* Return TalkNet to README.\n\nSigned-off-by: Stanislav Beliaev <stasbelyaev96@gmail.com>\n\n* Add model.model test and remove some stuff.\n\nSigned-off-by: Stanislav Beliaev <stasbelyaev96@gmail.com>\n\n* Add moAdd typing to TalkNet.\n\nSigned-off-by: Stanislav Beliaev <stasbelyaev96@gmail.com>\n\n* TalkNet Training notebook fixed.\n\nSigned-off-by: Stanislav Beliaev <stasbelyaev96@gmail.com>\n\nCo-authored-by: Oktai Tatanov <oktai.tatanov@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-11-19T23:56:05Z",
        "message": "patch comegaconf for cfg (#3224)\n\nSigned-off-by: fayejf <fayejf07@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-11-12T06:25:47Z",
        "message": "Merge r1.5.0 bugfixes to main (#3173)\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Always save last checkpoint on train end even if folder does not exist (#2976)\n\n* add fix for no checkpoint folder when training ends\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix test\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fixes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* typo\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* change check\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* [NLP] Add Apex import guard (#3041)\n\n* add apex import guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add apex import guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add apex import guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove from init add logging to constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove from init add logging to constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove import from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert encoder logic from NLPModel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Update reinstall and cherry-pick bignlp commits (#3065)\n\n* add ptl install to reinstall and update jenkins install\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Add a stateless timer to specify max_time per run instead of global m\u2026 (#3056)\n\n* Add a stateless timer to specify max_time per run instead of global max_time across runs\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* (1) reduce the validation loss within a epoch, (2) convert global-batch-based iteartion counts to micro-batch-based (#3055)\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\n\n* Timer class monitors total time (train + validation + testing) to monitor when to end training (#3061)\n\n* Check total time in train/validation to exit\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\n\n* Add PUBLICATIONS.md (#3051)\n\n* Add PUBLICATIONS.md\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add NLP\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update PUBLICATIONS.md\n\n* Update PUBLICATIONS.md\n\n* Fix links\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* fix uninstall\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\n\n* fix File Load Error (#3069)\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Exp manager small refactor (#3067)\n\n* Exp manager small refactor\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* move super() call earlier in the function\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\n\n* update (#3113)\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* Upgrade to PTL 1.5.0 (#3127)\n\n* update for ptl 1.5.0\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update trainer config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* limit cuda visible devices to the first two gpus on check for ranks CI test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comments\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make datasets larger for test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make datasets larger for test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update compute_max_steps\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update compute_max_steps\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Update a few packages' version (#3134)\n\n* update torchaudio lower bound in tutorials\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update torchtext version in tutorials\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* Revert \"update torchtext version in tutorials\"\n\nThis reverts commit 9f7f660f3b0926d3b7d6cdbb92751e0d881d65f3.\n\n* update torchtext in tutorials\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update packages version in this notebook\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update numba version in tutorial\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update requirements\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update package version in Dockerfile\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* Revert \"update torchtext version in tutorials\"\n\nThis reverts commit 9f7f660f3b0926d3b7d6cdbb92751e0d881d65f3.\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* added to avail models (#3044)\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* 1. Fixed warmup batches when no timing is measured. (#3140)\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\n\n* Cannot unset both `source_processor` and `target_processor` for NMT model inference. (#3136)\n\n* Fix processor setting for nmt inference\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add ignore option description to argparse\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix typo\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\n\n* config link fixes (#3148)\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* fix nemo checkpoint converter (#3149)\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\nCo-authored-by: Yu Yao <yuya@nvidia.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* link fix (#3153)\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* remove (#3154)\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* [BigNLP] Add CI Tests for Megatron GPT (#3124)\n\n* add pretrain CI test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add .cpp and Makefile to python package_data\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check for local_rank and barrier when compiling helper\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check for local_rank and barrier when compiling helper\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add device, have jenkins test use fp16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add device, have jenkins test use fp16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update app_state.local_rank\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add configure gradient clipping hook\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add configure gradient clipping hook\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add resume test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add eval\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add eval\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* (1) update auto-casting api, (2) simplifiy precision arguments and remove redundancy (#3142)\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* only set jit fusion options if we are in 21.10 container\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update nemo file for eval test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move tests down in the jenkinsfile\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* removed fused arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* interpolate precision and sequence length in config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove trainer.precision interpolation\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove nemo_experiments after prallel stage\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove rm call\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\n\n* Fix the asr bucketing parsing the manifest. (#3089)\n\n* Patch LR max_step computation check (#3152)\n\n* Patch LR max_step computation check\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Perform < 0 check only\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* FastPitch Notebook Bugfix (#3161)\n\n* update notebook\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update test\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* [BugFix] Fix check for model parallel size in TP 1 case (#3162)\n\n* check model parallel size is greater than one before injection\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check model parallel size > 1\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check model parallel size is greater than one before injection\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check model parallel size is greater than one before injection\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* tp 1 ckpt conv\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Notebook bugfixes (#3165)\n\n* zero shot intent slot notebook bug fix\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Added megatronBERT not support in this release message to notebook\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* added apex backend to config\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Removed apex from entity linking and added 1.4.0 nemo info to warning\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* add note that megatron bert is supported in r1.5.0 (#3169)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Text2sparql fix 1.5.0 (#3166)\n\n* Model neural type changes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Neural types fix\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix typo\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove ipdb\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix cfg issue for r1.5.0 (#3170)\n\n* fix cfg due to ptl updated\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* style fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove cfg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\nCo-authored-by: PeganovAnton <peganoff2@mail.ru>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: yaoyu-33 <54727607+yaoyu-33@users.noreply.github.com>\nCo-authored-by: Yu Yao <yuya@nvidia.com>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\nCo-authored-by: Vahid Noroozi <VahidooX@users.noreply.github.com>\nCo-authored-by: vadam5 <78445382+vadam5@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-11-10T23:33:11Z",
        "message": "Self-supervised pre-training for speech models (#3139)\n\n* self-supervised training\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* test\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* remove imports\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* fix\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* sort imports\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* fix audio_to_text\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* manifest handle no text\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* loss init\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* style\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* remove tokenizer from config\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* config changes\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* remove hydra import\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* always spec augment\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* fixes\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* copyright\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* fix cosine sim\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* fix cosine sim\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* fix cosine sim\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* changes based on comments\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* changes based on comments\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* configs\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* name fix\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* ci config changes\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* renamed to num_negatives\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* minor changes\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* name changes, type annotations\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-11-04T16:26:58Z",
        "message": "Merge r1.5.0 bugfixes and doc updates to main (#3133)\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Always save last checkpoint on train end even if folder does not exist (#2976)\n\n* add fix for no checkpoint folder when training ends\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix test\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fixes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* typo\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* change check\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* [NLP] Add Apex import guard (#3041)\n\n* add apex import guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add apex import guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add apex import guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove from init add logging to constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove from init add logging to constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove import from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert encoder logic from NLPModel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Exp manager small refactor (#3067)\n\n* Exp manager small refactor\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* move super() call earlier in the function\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\n\n* Change container (#3087)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Training of machine translation model fails if config parameter `trainer.max_epochs` is used instead of `trainer.max_steps`. (#3112)\n\n* fix: replace distributed_backend for accelarator\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add debug script\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove debug script\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* update (#3113)\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* Fix: punctuation capitalization inference on short queries (#3111)\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Multiple ASR Fixes to SPE tokenization (#3119)\n\n* Reduce num workers for transcribe\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix SPE tokenizer vocabulary construction\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update tokenizer building script\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove logs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Megatron GPT training in BCP (#3095)\n\n* BCP megatron training\n\nSigned-off-by: madhukar <madhukar@penguin>\n\n* Add quotes\n\nSigned-off-by: madhukar <madhukar@penguin>\n\n* Style fix\n\nSigned-off-by: madhukar <madhukar@penguin>\n\nCo-authored-by: madhukar <madhukar@penguin>\n\n* Upgrade to PTL 1.5.0 (#3127)\n\n* update for ptl 1.5.0\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update trainer config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* limit cuda visible devices to the first two gpus on check for ranks CI test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comments\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make datasets larger for test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make datasets larger for test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update compute_max_steps\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update compute_max_steps\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove duplicate code\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: PeganovAnton <peganoff2@mail.ru>\nCo-authored-by: Madhukar K <26607911+madhukarkm@users.noreply.github.com>\nCo-authored-by: madhukar <madhukar@penguin>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-10-30T02:15:37Z",
        "message": "Merge r1.5.0 bugfixes and doc updates to main (#3093)\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix quantization bug in Asr (#3062)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update reinstall and cherry-pick bignlp commits (#3065)\n\n* add ptl install to reinstall and update jenkins install\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Add a stateless timer to specify max_time per run instead of global m\u2026 (#3056)\n\n* Add a stateless timer to specify max_time per run instead of global max_time across runs\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* (1) reduce the validation loss within a epoch, (2) convert global-batch-based iteartion counts to micro-batch-based (#3055)\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\n\n* Timer class monitors total time (train + validation + testing) to monitor when to end training (#3061)\n\n* Check total time in train/validation to exit\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\n\n* Add PUBLICATIONS.md (#3051)\n\n* Add PUBLICATIONS.md\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add NLP\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update PUBLICATIONS.md\n\n* Update PUBLICATIONS.md\n\n* Fix links\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* fix uninstall\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\n\n* fix File Load Error (#3069)\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Update hyper parameter saving (#3058)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Exp manager small refactor (#3067)\n\n* Exp manager small refactor\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* move super() call earlier in the function\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\n\n* Fix FastPitch Pitch Duration Notebook (#3068)\n\n* bugfix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* bugfix2\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* better check\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* confusionmatrix (#3085)\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* typo and fix link (#3086)\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* inf cross-checking across tensor-parallel ranks (#3088)\n\n* inf cross-checking across tensor-parallel ranks\n\n* sylte\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix save top k (#3075)\n\n* inject mp_rank for checkpoint paths in NLPDDPPlugin\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* == instead of i\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* when checking previous run account for mp\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* uninject mp ranks when needed\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-10-27T18:13:29Z",
        "message": "Merge r1.5.0 bugfixes and doc updates to main (#3048)\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Always save last checkpoint on train end even if folder does not exist (#2976)\n\n* add fix for no checkpoint folder when training ends\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix test\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fixes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* typo\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* change check\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* [NLP] Add Apex import guard (#3041)\n\n* add apex import guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add apex import guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add apex import guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove from init add logging to constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove from init add logging to constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove import from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert encoder logic from NLPModel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-10-21T03:06:37Z",
        "message": "[BigNLP] Merge Megatron GPT to main (#2975)\n\n* fix gpu init after removing debug print in mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_adam\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check ds is not none before logging len\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set fp16 arg to true and fix enum conflict\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make fp16 arg configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add grad clip from megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Linear warmup with cosine annealing and constant holding (#2846)\n\n* Testing cosine schedule\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* More fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* update config for constant steps in schedule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* temporarily import enum from megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add grad clip for fp32\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update check for _del_model_without_trainer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating restore for model parallel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add predict script\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update test iters\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add barrier\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* return if clip_val is 0 or None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* when using amp clip grads after they are unscaled\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make native amp scaler hyperparams configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* (1) nvfuser, (2) amp-casting decoration (#2894)\n\n* (1) nvfuser, (2) amp-casting decoration\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* support bf16\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add set device to constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [BigNLP] Remove megatron-lm dependency. (#2910)\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update megatron_init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update process batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron clip_grad\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* trying to resolve circular import error\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove non-gpt models and datasets from __init__ files\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update MegatronDataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename fp16 and bf16 flags to fused_softmax_input_in_fp16/bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename to fused_fp16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_fp16 arg to LayerNorm calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Adding complete method to MegatronGPTModel (#2935)\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* make ffn_hidden_size mandatory\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Manually migrating timing of step into branch (#2937)\n\n* 1. Manually migrating timing of step into branch.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated file name and content.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated to latest code.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check fused_fp16 and fused_bf16 are not both True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update predict script for model parallel .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* NVfuser (#2943)\n\n* activation checkpoint recompute\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* selective nvfuser setup\n\n* Megatron gpt bfloat support (#2926)\n\n* Save/restore fix\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Another merge\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Bf16 args in init\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Set precision\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove debug stuff\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add bf16 casting decorator\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* Bfloat layernorm propagation\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* activation checkpoint recompute\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* selective nvfuser setup\n\n* More arg removal\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove BERTDataset\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* update to latest apex and patch transformer autocast\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: ericharper <complex451@gmail.com>\n\n* don't set jit for bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* replace apex.mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix grad clip\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* NVFuser fixes (#2951)\n\n* Fuser fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove dummy handler\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove PTL plugin based logic for fusion\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* remove duplicated file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo (#2960)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [BigNLP] Script to convert GPT checkpoint to .nemo (#2958)\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update megatron_init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update process batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron clip_grad\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* trying to resolve circular import error\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove non-gpt models and datasets from __init__ files\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update MegatronDataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename fp16 and bf16 flags to fused_softmax_input_in_fp16/bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename to fused_fp16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_fp16 arg to LayerNorm calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Adding complete method to MegatronGPTModel (#2935)\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* make ffn_hidden_size mandatory\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Manually migrating timing of step into branch (#2937)\n\n* 1. Manually migrating timing of step into branch.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated file name and content.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated to latest code.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check fused_fp16 and fused_bf16 are not both True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update predict script for model parallel .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add script to convert .ckpt to .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* convert mp checkpoints to nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update help\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add safeguard for model parallel save_to\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adjust NLPModel save_to to be safer for model parallel\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* [BigNLP] Update GPT evaluation to work with tensor model parallel  (#2959)\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add request dataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* tokenize request\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* able to run\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* reduce logits\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* capture response\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* squeeze and unsqueeze\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* handle non model parallel case\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* convert logits to log_probs\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* rename logits to log_probs\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* add megatron gpt pretraining\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron gpt pretraining\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron gpt pretraining\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating to work with latest megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating to work with latest megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update _del_model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding gpt model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding gpt model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding gpt model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* instantiate GPTmodel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding build dataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* build megatron dataset in .setup\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* setup dataloader\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add vocab_file and merge_file to megatron init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add forward\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add train loss\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add optimizer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add exp_manager\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* multi-gpu is working\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding val loop\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding val loop\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix ranks\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix model parallel checkpoint saving\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix _del_model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* added megatron batch sampler\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* try to fix num steps\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add wandb to config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* log lr\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add warmup ratio to config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update configs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update configs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add cpu init to args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Initial megatron dataset port\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix merge conflicts\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* License fixes and megatron model porting\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* More fixes to import from nemo rather than megatron\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix circular imports\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Revert config file\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Restructure further to avoid circular imports\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add Makefile\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Add megatron modules\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add license\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Port from latest megatron\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* update cfg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add _del_model_without_trainer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add data preprocessing script\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use apex mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* replace print_rank_0 with nemo utils logging\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use apex mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use apex mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add use_cpu_initialization\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fixing autoresume in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* properly removing last checkpoint\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* log consumed samples\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix mp autoresume\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add NLPSaveRestoreConnector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Megatron GPT training with NeMo tokenizers (#2818)\n\n* Update files from megatron repo\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove non NLP data related files from megatron\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Merge megatron and nemo tokenizers\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove get_tokenizer() calls from gpt model\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Update tokenizer yaml config\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add todo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make init_method_std configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make gpu init work by setting random seed earlier\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix gpu init after removing debug print in mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_adam\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check ds is not none before logging len\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set fp16 arg to true and fix enum conflict\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make fp16 arg configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add grad clip from megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Linear warmup with cosine annealing and constant holding (#2846)\n\n* Testing cosine schedule\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* More fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* update config for constant steps in schedule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* temporarily import enum from megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add grad clip for fp32\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update check for _del_model_without_trainer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating restore for model parallel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add predict script\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update test iters\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add barrier\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* return if clip_val is 0 or None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* when using amp clip grads after they are unscaled\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make native amp scaler hyperparams configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* (1) nvfuser, (2) amp-casting decoration (#2894)\n\n* (1) nvfuser, (2) amp-casting decoration\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* support bf16\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add set device to constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [BigNLP] Remove megatron-lm dependency. (#2910)\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update megatron_init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update process batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron clip_grad\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* trying to resolve circular import error\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove non-gpt models and datasets from __init__ files\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update MegatronDataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename fp16 and bf16 flags to fused_softmax_input_in_fp16/bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename to fused_fp16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_fp16 arg to LayerNorm calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Adding complete method to MegatronGPTModel (#2935)\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* make ffn_hidden_size mandatory\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Manually migrating timing of step into branch (#2937)\n\n* 1. Manually migrating timing of step into branch.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated file name and content.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated to latest code.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check fused_fp16 and fused_bf16 are not both True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update predict script for model parallel .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* NVfuser (#2943)\n\n* activation checkpoint recompute\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* selective nvfuser setup\n\n* Megatron gpt bfloat support (#2926)\n\n* Save/restore fix\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Another merge\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Bf16 args in init\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Set precision\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove debug stuff\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add bf16 casting decorator\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* Bfloat layernorm propagation\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* activation checkpoint recompute\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* selective nvfuser setup\n\n* More arg removal\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove BERTDataset\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* update to latest apex and patch transformer autocast\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: ericharper <complex451@gmail.com>\n\n* don't set jit for bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* replace apex.mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix grad clip\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* NVFuser fixes (#2951)\n\n* Fuser fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove dummy handler\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove PTL plugin based logic for fusion\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* remove duplicated file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo (#2960)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [BigNLP] Script to convert GPT checkpoint to .nemo (#2958)\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update megatron_init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update process batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron clip_grad\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* trying to resolve circular import error\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove non-gpt models and datasets from __init__ files\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update MegatronDataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename fp16 and bf16 flags to fused_softmax_input_in_fp16/bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename to fused_fp16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_fp16 arg to LayerNorm calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Adding complete method to MegatronGPTModel (#2935)\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* make ffn_hidden_size mandatory\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Manually migrating timing of step into branch (#2937)\n\n* 1. Manually migrating timing of step into branch.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated file name and content.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated to latest code.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check fused_fp16 and fused_bf16 are not both True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update predict script for model parallel .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add script to convert .ckpt to .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* convert mp checkpoints to nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update help\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add safeguard for model parallel save_to\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adjust NLPModel save_to to be safer for model parallel\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* [BigNLP] Update GPT evaluation to work with tensor model parallel  (#2959)\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add request dataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* tokenize request\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* able to run\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* reduce logits\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* capture response\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* squeeze and unsqueeze\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* handle non model parallel case\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* convert logits to log_probs\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* rename logits to log_probs\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix copyright headers\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix copyright headers\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove old TimingCallback\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins to use latest apex and sandeep's fork\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* try 2109 container\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* try cuda container\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use internal container\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update checkpoint tests\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix scheduler args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update eval\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins to use ptl 1.5 rc\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add import guard to jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add import guard to jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove deterministic\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* install numba .53\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* allow for more variance\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update trainer config dataclass\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* test_get_optimizer on gpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* change trainer config default to 32\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [BigNLP] Remove fused kernel code instead use Apex (#2984)\n\n* remove fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove fused layer norm and fused softmax and use apex instead\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use apex enums\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use apex enums\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add tab\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Timer with sliding window (#3002)\n\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\n\n* revert tab\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check for rank zero\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check for rank zero\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* try explicit log dir\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add +\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* don't rm\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make dir if it doesn't exist\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* create mp nemo file in temp directory\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* simplify mp save_to\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* handle mp 1 case\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style fix\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove files\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix consumed_samples when resuming\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix reinstall.sh\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update req\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add more detailed log for dataloaders\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check if cuda is available before using fused_adam\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update eval script to use model.freeze\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* log train loss averaged over gradient accumulation steps\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check copyright earlier\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* todo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* override SaveRestoreConnector in NLPModel init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move to scripts\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove star import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comments\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused dataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* removed barrier\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check cfg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove logging\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* freeze, unfreeze\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* return None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add TODO\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typecheck\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* todo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add common native plugin\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* restore with trainer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* deprecate megatron-lm bert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* deprecate megatron-lm bert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* compile helpers ont he fly\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove amp_level\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove amp_level from configs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add missing import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove amp_level\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use fast huggingface tokenizers by default\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* deal with huggingface tokenizer positional args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* deal with huggingface tokenizer positional args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* deal with huggingface tokenizer positional args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert use_fast default to False\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* return super training_epoch_end\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove optimizer_idx arg from training_step\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused arg from on_train_epoch_end\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add restore_from_path to nemo config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* override connector if not subclassing NLPSaveRestoreConnector for model parallel save\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update test optimizer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make data_prefix mandatory in config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update installation instructions on readme\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update dockerfile\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add todo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* raise error if trying to use always_save_nemo with model parallel model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-08-17T14:55:43Z",
        "message": "Refactor and Minimize Dependencies (#2643)\n\n* squash\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add comments\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* style and cleanup\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* cleanup\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add new test file\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* syntax\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* style\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* typo\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* try again\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* wip\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* style; ci should fail\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* final\n\nSigned-off-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-08-10T19:50:22Z",
        "message": "Remove PTL 1.4 upper bound (#2600)\n\n* update exp_manager\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update ptl trainer dataclass\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update check for ranks\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove returned from val epoch end\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Try to fix multi validation logging\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Try to fix multi validation logging\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Try to fix multi validation logging\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* update for glue with PTL1.4 (#2634)\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add rank_zero_only to self.log\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-08-06T22:28:24Z",
        "message": "Fix return config path for new SaveRestoreConnector (#2626)\n\n* Fix return config path for new SaveRestore connector\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix return config path for new SaveRestore connector\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-08-06T00:45:57Z",
        "message": "Add save restore connector to ModelPT (#2592)\n\n* add save restore connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add save restore connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add save restore connector property\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add _default_save_to\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* moving globals to app_state\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* moving globals to app_state\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add model attribute to connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add model attribute to connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix tabs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix tabs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove ModelPT import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add default restore\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add default restore\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove eff globals\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix tabs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update globals, remove save restore property\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add setter\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add setter\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix app_state restore flag\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update paths\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add connector arg to from_pretrained\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update save restore connector after instantiating\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* get class from config in .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add TODO\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move extract_state_dict to connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add methods for toch save and torch load\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update mock model conf\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move mock model to common collection\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update NLPModel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update test to use connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move artifacts to save restore connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add save_restore_connector arg to register_artifact\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* default save_restore_connector arg to None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* default save_restore_connector arg to None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean commented line\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* default save_restore_connector arg to None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move MockModel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix docstrings, remove underscores, default from connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update docstring\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update docstring\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* change name to is_model_being_restored\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move constants from AppState to SaveRestoreConnector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* encapsulate logic for model parallel checkpoint\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update mock config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add init_subclass, remove connector arg from register_artifact, move MockModel to tests\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove old import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Add tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Finalize tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Finalize tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* fixing lgtm\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix lgtm\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update NLPModel.restore_from\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix classpath resolution\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-07-14T21:19:06Z",
        "message": "fix squad for chinese (#2484)\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-06-12T02:28:32Z",
        "message": "Update ranges for omegaconf and hydra (#2336)\n\n* Update ranges\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Updates for Hydra and OmegaConf updates\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Style fixes\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct tests and revert patch for model utils\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct docstring\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Revert unnecessary change\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Revert unnecessary change\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Guard scheduler for None\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* default to 0.0 if bpe_dropout is None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Correctly log class that was restored\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Root patch *bpe_dropout\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: ericharper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-06-08T17:40:35Z",
        "message": "[BUGFIX] OmegaConf forward compatibility (#2319)\n\n* Update OmegaConf compatibility\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Correct OmegaConf.pretty()\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* upper bound omegaconf\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add if,else back\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-06-03T22:49:50Z",
        "message": "Merge tag 'v1.0.0' into main\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-06-02T20:02:40Z",
        "message": "ASR improvements (#2293)\n\n* Update numba messages and citrinet configs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove support for weight init scale and hidden hidden bias scale for layer normalized lstm\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add support for multiple filetypes in tarred datasets, correct rnn LN-lstm inputs, fix OmegaConf compat issue\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-06-02T00:02:13Z",
        "message": "Adjust warning messages (#2294)\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-06-01T23:39:00Z",
        "message": "Revert \"Adjust warning messages\"\n\nThis reverts commit df046ec55754d0136a2a28451435068f32409f30."
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-06-01T23:37:20Z",
        "message": "Adjust warning messages\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-05-26T22:07:02Z",
        "message": "ASR Refactoring (#2240)\n\n* Refactor out the preprocessing from ASR into common\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct nltk issue with vocabs.py for clusters\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add typing information to SpecAugment and SpecCutout\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Reorganize parts directory\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Refactor parts submodules, add __init__ to few important parts\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update docs for new path to parts\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Cherry pick PR https://github.com/NVIDIA/NeMo/pull/2219\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add header for preprocessing commons\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix style of tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add forced update of configs for train-val-test ds to new labels tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update path to FilterbankFeatures for TTS\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add an alias file for backward compatibility\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add an alias file for backward compatibility\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update training scripts of ASR to support finetuning\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update Finetuning step to be ModelPT level\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update docs for finetuning for ASR\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix style\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update docs and scripts with fine-tuning info\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update docs and scripts with fine-tuning info\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix style\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update scripts\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add comment for weight initialization\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-05-26T06:32:31Z",
        "message": "Support multiple models being instantiated in same execution scope (#2245)\n\n* Support multiple models being instantiated in same execution scope\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add locks to methods in appstate\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Perform locks only on write operations\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct deadlock issue\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add more tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add test for multi save and remove patch to change save type\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update app state to preserve gidx of previous token\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct restoration logic for tarfiles\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-05-25T16:44:20Z",
        "message": "Merge branch 'v1.0.0' into main"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-05-21T23:16:33Z",
        "message": "[BUGFIX] Only process tarfile artifacts when model was restored from tarfile (#2250)\n\n* process tarfile artifacts only if model is being restored\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* process tarfile artifacts only if model was restored from a tarfile\n\nSigned-off-by: ericharper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-05-17T23:30:01Z",
        "message": "Merge branch 'v1.0.0' into main\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-05-17T23:16:29Z",
        "message": "Set strict=True everywhere by default. (#2225)\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-05-14T06:55:42Z",
        "message": "ASR patches for v1.0.0 (#2207)\n\n* Multiple updates to RNNT add initialization\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct name of initilization\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update dockerignore\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix RNNT WER calculation\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Address comments\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-05-10T17:47:17Z",
        "message": "Merge branch 'v1.0.0' into main\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-05-10T17:37:26Z",
        "message": "Update ptl to 1.3 on main branch (#2178)\n\n* Update PTL\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Begin update to Pytorch Lightning 1.3.x\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Formatting\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Formatting\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* minor fix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* minor fix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* get testing attribute from trainer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update init_ddp_connection override\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update attribute\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add barrier after load checkpoint in megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove barrier\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update last naming\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\nCo-authored-by: ericharper <complex451@gmail.com>\nCo-authored-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-05-07T17:45:12Z",
        "message": "Fix to always_save_nemo (#2174)\n\n* Initial attempt at always_save_nemo fix\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* updated path before saving in exp manager, fixed bug when handling tarfile artifacts\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Add test with always_save_nemo to exp_manager\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* update jenkins branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check for nemo:\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check for nemo:\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check for nemo:\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: ericharper <complex451@gmail.com>\nCo-authored-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-05-04T20:55:35Z",
        "message": "Update how artifacts work (#2138)\n\n* Update how artifacts work\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fixing some tests\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fix more tests\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* add __init__ to tests to make them discoverable\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* empty src support\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* updates plust unittest\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* add copyright check\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* copyright header\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fix style\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* handle hashed megatron checkpoint version in nlp restore_from\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add _MODEL_RESTORE_PATH to AppState\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* get rid of global folder caching\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* double register - warning instead of exception\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Add asr spe tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Pop out asr wpe pre-registered value\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct ASR tests and paths\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct tokenizer saving\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct ASR tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct ASR bpe mixin\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Patch up backward compatibility\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* update register_bert_model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update all get_lm_model calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* return None if src not found\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* handle case with no tokenizer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* do not add another hash is using tarfile_artifacts\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add return_none flag, update doc string\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update default behavior of register_artifact for NLPModel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* change kwarg name to verify_src_exists\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use cfg instead of _cfg\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* some cleanups\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: ericharper <complex451@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-04-21T19:26:40Z",
        "message": "[NLP] Updating model parallel  (#2015)\n\n* create nlp ddp plugin\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* call NLPDDPPlugin from example script\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* training is working but autoresume is not\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* training working again\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* autoresume working again\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* bug fix\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* automatically use nlp ddp\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* automatically use nlp ddp\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* automatically use nlp ddp\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* automatically use nlp ddp\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* automatically use nlp ddp\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* automatically use nlp ddp\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* automatically use nlp ddp\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* upgrade container version\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* convert config to dict\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* convert config to dict\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* save nemo model for each mp rank\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* restore from mp .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* refactoring model parallel to nlpddpplugin\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* training working again\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* only finish mpu init when not using model parallel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* cleanup and add trainer to restore_from\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* testing working\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* register megatron checkpoint version\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* convert to one .nemo file in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* combine .nemo files after saving on each mp rank, in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* combine .nemo files after saving on each mp rank, in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* combine .nemo files after saving on each mp rank\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* combine .nemo files after saving on each mp rank\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* .nemo restore working\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* get pl random seed default to 1234\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* change check\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* super restore_from\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* super restore_from\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert config change\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move override after checking for mp\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add jenkins training test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix bug when training from .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add jenkins test for train from .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* added jenkins test for evaluation from .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add model_restore_path to AppState\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update cfg if using vocab file in .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* detect if model parallel already known from .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update header\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check for mp_rank in directory\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move NLPDDPPLUgin\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move NLPCheckpointConnector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* document PTL hooks\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove todo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update docstring for nlp\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update path\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check if checkpoint version already set\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add autoresume test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* super static methods\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* detect model parallel without unpacking tarfile\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Update nemo/collections/nlp/models/nlp_model.py\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* raise exception if trainer.local_rank is None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-04-20T22:56:53Z",
        "message": "Update container to 21.04 (#2079)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-04-06T18:09:51Z",
        "message": "Talknet bug fix & TalkNet Training tutorial  (#2008)\n\n* has_audio to speech_collate\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* log warning to setup_optimization, fix bugs in talknet\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix formatting\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix import order\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* add talknet training tutorial\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-03-25T23:48:11Z",
        "message": "Merge branch 'r1.0.0rc1' into main"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-03-25T05:05:48Z",
        "message": "Correct hyper parameter saving for correct logging (#1965)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-03-11T22:53:30Z",
        "message": "NMT export, _prepare_for_export refactor (#1866)\n\n* Added citrinet export test\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* NMT export\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* More realistic citrinet test\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* DIsabling tril() mask for inference\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Removing experimental TRTorch code\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Moved export test into proper separate methods\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Format fix\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Removing unused Exportale APIs from NMT model\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Skipping jit.trace before ONNX export, splitting TS and ONNX tests\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* re-enabling Megatron export test\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed style\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-03-05T20:49:28Z",
        "message": "Cleanup save/restore (#1851)\n\n* Cleanup save/restore\n\n* Remove EFF save/restore routes\n* Once we can take EFF dependency we will use EFF.Archive directly\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fix copyright headers\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-02-10T00:39:06Z",
        "message": "Merge branch 'r1.0.0b4' into main\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-02-09T03:18:51Z",
        "message": "Patch for NMT accuracy regression from PTL 1.1.3 to PTL 1.1.4+ (#1669)\n\n* set find_unused_parameters to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert requirements\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* lifting ddp override to ModelPT\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove from ModelPT\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove from ModelPT\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove from nlp model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* limit ptl to 1.1.5\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* limit ptl to 1.1.5\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comments\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add config for find_unused_parameters\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove neuralmodule subclassing from beam search\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* testing beam search\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* beam search to constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert change from merge\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert change from merge\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert change from merge\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add as_frozen to embedding and decoder\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* freeze unfreeze manually\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up comments\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* default find_unused_parameters to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add context manager to beam search\n\nSigned-off-by: ericharper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-02-06T00:23:15Z",
        "message": "Update NeMo model filepath (#1687)\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-02-03T02:21:22Z",
        "message": "Update ASR RTD Documentation (r1.4) (#1695)\n\n* Cleanup warnings\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update ModelPT docs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update ASR Docs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update ASR Docs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add regex based updation of requirements\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct indentation\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* catch torch.hub import for nlp docs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix nlp docs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* force torch_home to be a string\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding sacremoses to nlp_requirements\n\nSigned-off-by: ericharper <complex451@gmail.com>\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Begin adding benchmarks\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update scores\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update scores\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update benchmarks\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update language benchmarks\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add placeholder for spanish model\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix formatting issues\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add Speech datasets docs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: ericharper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-01-29T18:42:14Z",
        "message": "add new quantization nodes in QuartzNet (#1678)\n\n* add new quantization nodes in QuartzNet\n\nSigned-off-by: Vincent Huang <vincenth@nvidia.com>\n\n* Refactor quantization support to be optional and localized\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Guard last few self.quantize\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update docstring for override_config_path\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix conf assignment\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct amp via flag\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add missing self.quantize\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2021-01-25T22:07:47Z",
        "message": "Nmt Model (#1574)\n\n* Machine translation modules ported from release 0.10.1_p_c (#1275)\n\n* Fix parameter name\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* remove vocab parameter from encoder constructor call\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix model params\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Test connection to github\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove excess parameter from decoder constructor call\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* remove foo\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove excess parameter from beam search constructor\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix parameter names in beam search constructor call\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix parameter name in function call\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Change gpu settings\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix forward function of mt model\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* backup\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Return to logits type\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* backup\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* backup\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add pl callback\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix docstring\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Replace logger.info with print\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* backou\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove debug prints and fix several bugs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Detach beam results earlier\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove debug prints and fix several bugs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* merge\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add ngc config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add NeMo to PYTHONPATH in ngc command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve the way nemo path is set\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add debug print to ngc command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce batch size in ngc model\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce validation batch size\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Set result path and reduce batch size\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update hp\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update hp\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce batch size in ngc command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Rename job\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* add de en config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Move logging to model, improve config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Disable progress bar\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove mt callback from trainer\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update 2 gpu config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix test dataset in ngc command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* backup\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update configs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update ngc debug commands\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add model converting to float\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Separate train and test\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add de->en config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce seq len\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce batch size\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix bash syntax error and reduce batch\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix Error  in config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Increase num steps\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Migrate to pl 1.0.2\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix bash syntax error\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update OmegaConf & Hydra (#1303)\n\n* update req\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update jenkins\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* remove print\n\nSigned-off-by: Jason <jasoli@nvidia.com>\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix file name\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add debug print into ngc command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Replace exp dir with best ckpt path\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* disable test (#1310)\n\nSigned-off-by: Jason <jasoli@nvidia.com>\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix checkpoint path saving\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* TTS Collection Cleanup (#1304)\n\n* update yamls\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* OperationMode change\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* drop experimental and unneeded functions, fix dataclass\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update notebook\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update docs; ipython notebook; fixes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* unused import\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* style\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update pad_value\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* style\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix Preprocessor dataclass\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update tacotron2 labels\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* move labels\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* typo\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* typos\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update taco2\n\nSigned-off-by: Jason <jasoli@nvidia.com>\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* backup\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* backup\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix yaml configs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* minor changes to PTL 1.0 support (#1312)\n\n* PTL 1.0 support\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* ipdb removal\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* fix to unequal length of correct counts\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* fixed test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: ericharper <complex451@gmail.com>\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Close opened file to prevent IOError (#1308)\n\n* Close opened file to prevent IOError\n\nClose an opened text file when done, in order to prevent reaching the number of opened files.\n\nSigned-off-by: Mpho Mphego <mpho112@gmail.com>\n\n* style\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\nCo-authored-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* moved all tensorboard logs to self.log (#1317)\n\n* moved all tensorboard logs to self.log\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* PTL upgrade change for classification models\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Patch QA training_step (#1316)\n\n* fix training_step\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* limit jenkins run with train_ds.num_samples rather than trainer.max_steps\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* limit jenkins run with train_ds.num_samples rather than trainer.max_steps\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* limit jenkins run with train_ds.num_samples rather than trainer.max_steps\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* limit jenkins run with train_ds.num_samples rather than trainer.max_steps\n\nSigned-off-by: ericharper <complex451@gmail.com>\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix config names\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* upgrade to PTL 1.0.2 (#1318)\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix config names\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix bug in squeezing excess dimension\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix num tokens in batch\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix num steps\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix Licence section\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove unused import\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove unused local variables\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* init\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove vim swp files\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* back up draft of nmt model\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add tokenizer model\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Expand user in tokenizer model paths\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Expand user in tokenizer model paths\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix typo\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add paths to data to config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Expand user\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Expand user\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update gitignore\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove excess newlines\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Replace distributed sampler with random sampler\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Make mt train on test\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Make mt train on test\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Make mt train on test\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix shuffle param\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix batch size parameter\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix typo\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix retrieving params from config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix parameter name\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove embedding dropout from encoder parameters\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix parameter name\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* remove vocab parameter from encoder constructor call\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix model params\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Test connection to github\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove excess parameter from decoder constructor call\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* remove foo\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove excess parameter from beam search constructor\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix parameter names in beam search constructor call\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix parameter name in function call\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Change gpu settings\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix forward function of mt model\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* backup\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Return to logits type\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* backup\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* backup\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add pl callback\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix docstring\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Replace logger.info with print\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* backou\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove debug prints and fix several bugs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Detach beam results earlier\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove debug prints and fix several bugs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* merge\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add ngc config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add NeMo to PYTHONPATH in ngc command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve the way nemo path is set\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add debug print to ngc command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce batch size in ngc model\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce validation batch size\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Set result path and reduce batch size\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update hp\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update hp\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce batch size in ngc command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Rename job\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* add de en config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Move logging to model, improve config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Disable progress bar\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove mt callback from trainer\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update 2 gpu config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix test dataset in ngc command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* backup\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update configs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update ngc debug commands\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add model converting to float\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Separate train and test\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add de->en config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce seq len\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce batch size\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix bash syntax error and reduce batch\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix Error  in config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Increase num steps\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Replace logger.info with print\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove debug prints and fix several bugs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* init\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove vim swp files\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix typo\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add paths to data to config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update gitignore\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove excess newlines\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Make mt train on test\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Make mt train on test\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix batch size parameter\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix typo\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Test connection to github\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* remove foo\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Change gpu settings\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* backou\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove debug prints and fix several bugs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Detach beam results earlier\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove debug prints and fix several bugs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* merge\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add ngc config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add NeMo to PYTHONPATH in ngc command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve the way nemo path is set\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add debug print to ngc command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce batch size in ngc model\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce validation batch size\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Set result path and reduce batch size\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update hp\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update hp\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce batch size in ngc command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Rename job\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* add de en config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Move logging to model, improve config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Disable progress bar\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update 2 gpu config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix test dataset in ngc command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce seq len\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix Error  in config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Increase num steps\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix bug in squeezing excess dimension\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix num steps\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix Licence section\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove unused local variables\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix problems after rebase\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add configs with large batch size\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix rebase consequences\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Rebalance emb and W, rm excess conf, inc vocab sz\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix en de vocab size\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Replace py scalar with tensor, add fp32 confs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Adjust parameters\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Make minor fixes\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix jobs names\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix bug in beam search len penalty\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce test and validation batch size\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix PEP 8\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Try to bypass illegal mem access error\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce eval batch size\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Replace byte with bool and fix indents\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Refactor future mask computation\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove dev code\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add debug print\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add debug print\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce batch size\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce init range\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce init range\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix init range\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce init range\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Move embeddings factor to initialization\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add params stats collection script\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix bugs in stats collection\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add step logging when collecting stats\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Adjust initialization according to paper\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Restore typecheck command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix arg name\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix arg name\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix init range\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update docker image\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix argument passing\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove weights logging\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix init range\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce batch size\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Replace init scaling with multiplication\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add draft of circe command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update circe command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce batch size\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\nCo-authored-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: ericharper <complex451@gmail.com>\nCo-authored-by: Mpho Mphego <mmphego@ska.ac.za>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Aleksey Grinchuk (Oleksii Hrinchuk) <grinchuk.alexey@gmail.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* undo ASR example\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* clean up some unnecessary changes\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Fix default config names\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* updates\n\nSigned-off-by: Oleksii Kuchaiev <kuchaev@gmail.com>\n\n* style fix\n\nSigned-off-by: Oleksii Kuchaiev <kuchaev@gmail.com>\n\n* Change inheritance to NeMo\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add Facebook copyright to fairseq tokenizer\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Switch to sacrebleu lib, remove callback\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Pring examples in debug config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Migrate to sacrebleu package\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove ngc and circe commands\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove eda\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix minor bug and create ckpt to best model\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add configs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* working copy and train-on-test examples\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* minor fixes\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fix dataloader param reading\n\nSigned-off-by: Oleksii Kuchaiev <kuchaev@gmail.com>\n\n* add 4 gpu example\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Add perplexity to transformer mt model\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Minor fix\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove non existent tokens from beam results\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix best ckpt link creation\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix bugs in id filtering\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove non existent tokens from beam results\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix bleu logging\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Adding nmt_transformer_infer.py script\nFixing bugs in .translate method\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Comment out scaling in translate method\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update configs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix device placement bug\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove hacky hack\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* initial service commit\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* updates\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* disable grads in beam search\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* undo hack\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* style fix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Update logging procedure\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Optimize beam search\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* magin memory fix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* delete quant reqs\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Add fast inference instruments\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Change logging message a little\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Encoder-Decoder NMT Refactor (#1471)\n\n* add EncDecNLPModel and refactor nmt\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* was refactoring the wrong model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add encoder-decoder nlp base model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding enc dec tokenizers\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding enc dec tokenizers\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add vocab_divisible_by_eight config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add enc_dec_nmt example script\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* addded enc dec example\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding embeddings\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* can instantiate embedding layers\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* can instantiate embedding layers\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding transformer encoder\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding transformer encoder and decoder\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* instaniate encoder and decoder\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* instantiate head\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* instantiate beam search\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* instantiate loss\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* setup optimizer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* delete unnec comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add datasets\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add datasets\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add cache_ids argument to translation dataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* cache dataset ids per node\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add caching per node argument\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* cache dataset ids per node\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* cache dataset ids per node\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* bug\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style fixes so that CI can proceed\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fixing optim\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add Optional where needed in dataclasses\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move dataclass\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* training is working\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* refactor from structured config to hybrid config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* transformers version upper bound\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove num_samples from config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add exp_manager\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* lower default max_generation_delta\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* change val_check_interval default\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress refactor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress refactor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* refactor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fixes\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add yaml\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add jenkins test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add jenkins test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove old megabert test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add jenkins test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove vocab size setter\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove vocab size setter\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove vocab size setter\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove vocab size setter\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move dataclass to config.py\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update docstring\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove vocab divis by 8 cfg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unnec comments\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Bug fixes to EncDec MT model (#1525)\n\n* bugfixes\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* update jenkins test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* small fixes\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* config fixes\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* remove pplx\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: ericharper <complex451@gmail.com>\n\n* minor fixes\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Properly register tokenizers inside EncDecNLPModel\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* add pre_ln option\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* cleanups\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* batch size change\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Add entire dataset caching via a preproc script, bpe dropout and deto\u2026 (#1601)\n\n* Add entire dataset caching via a preproc script, bpe dropout and detokenization\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Removed unused code and allow reverse lang direction in dataset\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix unused imports\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* fix style\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* bugfix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* bugfix to bugfix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* get rid of ModelPTConfig\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fixing a test fail\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* unittest fix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* set logger as False by default in TrainerConfig\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* exp manager logger fix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* address some review feedback, bugfixes\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* add tensorboard logger back\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* NMT combine embedding plus encoder/decoder into one neural module. (#1611)\n\n* adding transformer encoder and ecoder neural modules\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* encoder decoder neural modules\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update configs and forward\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* forgot subclass\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* change comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* interpolate hidden size and add todo comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove instantiate\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add EncoderModule and DecoderModule to typing\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* cleaning configs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* using named arguments\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* using named arguments\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* bug fix\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* bug fix\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* bug fix\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* schema not allowing +\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* merge configs with update_model_config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* small fixes to Transformer neural modules\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* small fixes to Transformer neural modules\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add abstract properties to encoder and decoder nms\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* small bugfix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* check if bert_model is there\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Add load cached dataset and reverse lang direction to translation data config class\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Add source lang tokenization and punct normalization to model translate function\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* nmt webservice\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* style fix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fix bug in configs\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* updates to nmt service\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* add index.html\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* some webapp ui improvements\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* try-catch in webservice\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Set beam size and len pen during inference\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* average eval loss\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix mnist test\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* sgdqa fix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* sgdqa fix attempt 2\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fixing sgdqa\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* jenkinstest to main\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add types to args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add types to args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add todo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comments\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove docstring for forward\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add typecheck\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove kwargs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use ptl defaults\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* upper bound ptl to 1.13\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix jenkins test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix jenkins test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert typecheck\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding enable_pl_optimizer to trainer config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: PeganovAnton <peganoff2@mail.ru>\nCo-authored-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: ericharper <complex451@gmail.com>\nCo-authored-by: Mpho Mphego <mmphego@ska.ac.za>\nCo-authored-by: Aleksey Grinchuk (Oleksii Hrinchuk) <grinchuk.alexey@gmail.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2020-12-17T22:14:59Z",
        "message": "Correct ASR issues + Patch for Pytorch 1.8 (#1565)\n\n* Trim silence default to False\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update stft and torch.fft.ifft for Pytorch 1.8\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Style fixes\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Clear up old code\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2020-12-16T21:59:14Z",
        "message": "Adding the feature of variational noise to the RNNT-based models (#1563)"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2020-12-06T18:01:43Z",
        "message": "fix for modelpt config.optim (#1524)\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2020-12-04T06:33:51Z",
        "message": "Update every ASR config to new Hydra format (#1516)\n\n* Update every ASR config to new format\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update notebook tutorials\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Reorder cfg\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2020-12-03T22:36:50Z",
        "message": "Update model config automatically inside ModelPT (#1511)\n\n* Add ModelPT level config update to remove `params`\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update docstring\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update imports\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Refactor model cfg initialization\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Code foratting\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Code formatting\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add compat with RNNT BPE models\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct optimizer and schedulers for new configs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct return value\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correctly support new configs for ASR\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update every ASR config\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add comment tASR BPE models\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Reduce batch size from 64 to 32\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update name of methods\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2020-12-01T23:04:51Z",
        "message": "Preserve absolute path of model restore file (#1509)\n\n* Preserve absolute path of model restore file\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correctly expand ~\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2020-11-24T21:34:31Z",
        "message": "Update ModelPT level save and restore (#1491)\n\n* Update ModelPT level save and restore\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove logging\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* polish style a little\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Correct model restoration from .nemo vs .pt checkpoint\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct model restoration from .nemo vs .pt checkpoint\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2020-11-24T01:13:18Z",
        "message": "Fixes to IntentSlots init logic making all TLT scripts operational (#1477)\n\n* Vlads fix to intent test dataloader setup\n\nSigned-off-by: Tomasz Kornuta <tkornuta@nvidia.com>\n\n* intent model conditional initialization - depending whether user passes data_dir\n\nSigned-off-by: Tomasz Kornuta <tkornuta@nvidia.com>\n\n* intent: train and inference working\n\nSigned-off-by: Tomasz Kornuta <tkornuta@nvidia.com>\n\n* basic training operational\n\nSigned-off-by: Tomasz Kornuta <tkornuta@nvidia.com>\n\n* micro polish of update_data_dir_for_training\n\nSigned-off-by: Tomasz Kornuta <tkornuta@nvidia.com>\n\n* Intent: all TLT scripts operational, spec files with desired structure\n\nSigned-off-by: Tomasz Kornuta <tkornuta@nvidia.com>\n\n* Polishing the logic of Intent&Slots model, fix to the way paths are handled in ModelPT artifacts\n\nSigned-off-by: Tomasz Kornuta <tkornuta@nvidia.com>\n\n* skipping IntentModel exportable test to see other results\n\nSigned-off-by: Tomasz Kornuta <tkornuta@nvidia.com>\n\n* skipping IntentModel exportable test to see other results\n\nSigned-off-by: Tomasz Kornuta <tkornuta@nvidia.com>\n\n* fixes: moved tokenizer back before model init (as used in setup_*_), additional condition to cfg.data_desc\n\nSigned-off-by: Tomasz Kornuta <tkornuta@nvidia.com>\n\n* reverted test skip\n\nSigned-off-by: Tomasz Kornuta <tkornuta@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2020-11-24T00:13:00Z",
        "message": "Add support for model level dataclass/config class (#1328)\n\n* Add support for model level dataclass\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove unnecessary code\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Reviewer comments, cleanup etc\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update support for configs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add examples under structured dir\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Rebase\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add docstring\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update failing test\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Revert update_model_dataclass\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* reorganize configs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Move /structured under /experimental/structured and move out dataset config from ModelPT dataset config\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove hardcoded paths to datasets\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Make all 3 datasets optional by default\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove unnecessary imports\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Reduce formatting lines\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Formatng\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add note about parameter injection not working with data classes\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2020-11-17T22:27:05Z",
        "message": "[Bug] Ensure lr scheduler uses limit_train_batches when working out max steps (#1464)\n\n* Ensure lr scheduler uses limit_train_batches when working out max steps\n\nSigned-off-by: SeanNaren <sean@grid.ai>\n\n* Fix leftover debugging error\n\nSigned-off-by: SeanNaren <sean@grid.ai>\n\n* Reformat\n\nSigned-off-by: SeanNaren <sean@grid.ai>\n\n* Add random option to use float in test\n\nSigned-off-by: SeanNaren <sean@grid.ai>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2020-11-17T00:44:47Z",
        "message": "Merge branch 'v1.0.0b2' into main\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2020-11-13T00:35:16Z",
        "message": "minor fix (#1447)\n\nSigned-off-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/classes/modelPT.py",
        "commit_date": "2020-11-12T21:42:43Z",
        "message": "refactored EFF save/restore - NeMoCookbook (#1438)\n\nSigned-off-by: Tomasz Kornuta <tkornuta@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tools/nmt_webapp/nmt_service.py",
        "commit_date": "2021-08-09T22:31:41Z",
        "message": "Add basic grpc MT server (#1807)\n\n* Add basic grpc MT server\n\nAdd readme, server updates\n\nSigned-off-by: Ryan Leary <rleary@nvidia.com>\n\n* style fix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fixing license headers\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Add punctuation model into NMT service\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix merge conflicts\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* style fixes to unblock CI\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Add a Jarvis ASR + NeMo NMT client\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Refactor gRPC service\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Update license headers\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Update one more license header\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Whitepsace in header\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix grpc requirement\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Update license headers\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Add option to specify src/tgt lang and import fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix unused imports\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Renaming variables\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: Ryan Leary <rleary@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nCo-authored-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/tts/models/mixer_tts.py",
        "commit_date": "2023-05-30T18:14:09Z",
        "message": "[TTS] corrected misleading deprecation warnings. (#6702)\n\n* [TTS] corrected misleading deprecation warnings.\n* deprecation warning is only triggered when old models applied old g2p.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n---------\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/tts/models/mixer_tts.py",
        "commit_date": "2023-05-16T16:48:01Z",
        "message": "Merge r1.18.0 bugfixes and doc updates to main (#6655)\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Remove from jenkins (#6641)\n\n* add megatron_core to requirements\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove from jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n---------\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove dup\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [TTS] reformat NeMo versions in the tts logging messages to avoid batch process them when upgrading NeMo versions.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n---------\n\nSigned-off-by: ericharper <complex451@gmail.com>\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/tts/models/mixer_tts.py",
        "commit_date": "2023-02-24T21:20:48Z",
        "message": "[TTS][refactor] Part 2 - nemo.colletions.tts.parts (#6105)\n\n* [TTS][refactor] Part 2 - nemo.colletions.tts.parts\n* aggregate imports\n* added __init__.py\n---------\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/tts/models/mixer_tts.py",
        "commit_date": "2023-02-15T22:22:50Z",
        "message": "[TTS/TN/G2P] Remove Text Processing from NeMo, move G2P to TTS (#5982)\n\n* remove TN\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix imports\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix import\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add missing init\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix import\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* rename unit test\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix import\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix modules test\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix imports\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* remove whitelist from config\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* delete wordid file\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* remove pynini_install from tutorials\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* update requirements\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add support warning\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* review\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n---------\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/tts/models/mixer_tts.py",
        "commit_date": "2022-10-27T21:18:31Z",
        "message": "[TTS] Fastpitch energy condition and refactoring (#5218)\n\n* Incorporating Energy conditioning in FastPitch\n\nSigned-off-by: subhankar-ghosh <subhankar2321@gmail.com>\n\n* Minor fixes in Energy conditioning in FastPitch\n\nSigned-off-by: subhankar-ghosh <subhankar2321@gmail.com>\n\n* Add Energy conditioning in FastPitch to infer method\n\nSigned-off-by: subhankar-ghosh <subhankar2321@gmail.com>\n\n* adding fn to function names\n\nSigned-off-by: subhankar-ghosh <subhankar2321@gmail.com>\n\n* Incorporating Energy conditioning in FastPitch\n\nSigned-off-by: subhankar-ghosh <subhankar2321@gmail.com>\n\n* Minor fixes in Energy conditioning in FastPitch\n\nSigned-off-by: subhankar-ghosh <subhankar2321@gmail.com>\n\n* Add Energy conditioning in FastPitch to infer method\n\nSigned-off-by: subhankar-ghosh <subhankar2321@gmail.com>\n\n* adding fn to function names\n\nSigned-off-by: subhankar-ghosh <subhankar2321@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* remove ifelse from batching, minor refactoring changes in energy code\n\nSigned-off-by: subhankar-ghosh <subhankar2321@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Refactor based on PR comments.\n\nSigned-off-by: subhankar-ghosh <subhankar2321@gmail.com>\n\n* Added support for not learning alignment in energy\n\nSigned-off-by: subhankar-ghosh <subhankar2321@gmail.com>\n\n* Fix typo in assert statemetn\n\nSigned-off-by: subhankar-ghosh <subhankar2321@gmail.com>\n\n* Renaming average_pitch to average_features\n\nSigned-off-by: subhankar-ghosh <subhankar2321@gmail.com>\n\n* Renaming len variable name as it is a keyword\n\nSigned-off-by: subhankar-ghosh <subhankar2321@gmail.com>\n\n* Renaming len variable name as it is a keyword\n\nSigned-off-by: subhankar-ghosh <subhankar2321@gmail.com>\n\nSigned-off-by: subhankar-ghosh <subhankar2321@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/tts/models/mixer_tts.py",
        "commit_date": "2022-08-23T19:56:07Z",
        "message": "TTS tokenizers moved to collections.common.tokenizers (#4690)\n\n* fixed branch in IR tutorial\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\n* ddp translate GPU allocation fix\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\n* map_location instead of set_device\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\n* tts tokenizers moved to collections.common.tokenizers\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\n* imports and style fixes\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\n* copyright fix\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\n* two last paths refactor\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\n* ugly backward compatibility fix\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\n* codestyle fix\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\n* g2ps moved to nemo_text_processing\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\n* nemo_text_processing import path fix\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\n* nemo_text_processing import path fix\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\n* style fix\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\n* style fix\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/tts/models/mixer_tts.py",
        "commit_date": "2022-08-04T17:03:39Z",
        "message": "Pynini dependency fix (#4674)\n\n* nlp guard, logging removed\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* pynini conda install for mac, add import guard to TN tests\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* tts pynini dependency\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add try/except block to tts models\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add missing file\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/tts/models/mixer_tts.py",
        "commit_date": "2022-03-01T00:43:59Z",
        "message": "Merge r1.7.0 main (#3773)\n\n* Tn bug 1.7.0 (#3730)\n\n* fix es and fr bug\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* add file\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* [TTS] Fix bugs in E2E TTS, Mixer-TTS and FastPitch (#3740)\n\n* fix bugs\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix bug in e2e tts and mixer tts\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* Mirror AN4 data while servers are down (#3743)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Bugfix for GPT eval  (#3744)\n\n* use tokens_cut not tokens\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove precision conversion and comment jit for bias gelu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert comment update mbs in config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* calculate micro_batch_size during complete and compute_logprobs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* ASR SSL update (#3746)\n\n* ssl update\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* tutorial update\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* Fix SSL configs for 1.7 (#3748)\n\n* ssl update\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* tutorial update\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* revert configs\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* revert configs\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* punct process bug fix (#3747)\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\n\n* updated conformer models. (#3741)\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\n\n* Yuya/megatron t5 glue eval (#3751)\n\n* Add megatron t5 glue eval-only script\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Update megatron t5 glue eval default configs\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Update megatron t5 glue eval configs\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Update config comments\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\nCo-authored-by: Yu Yao <yuya@nvidia.com>\n\n* Specify gpus in SSL notebook (#3753)\n\n* ssl update\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* tutorial update\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* revert configs\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* revert configs\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* specify gpus\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* Duplex model inference fix, money encoder fix (#3754)\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* Update docs for RNNT and overriding fused batch size (#3755)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* fix consumed samples calculation + PTune Model bugs (#3738)\n\n* fix the way computing consumed samples\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fixed ptune model\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* make sure notebook is working\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* added try-catch\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* fix directories in ssl notebook (#3758)\n\n* ssl update\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* tutorial update\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* revert configs\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* revert configs\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* specify gpus\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* update dirs\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* TN docs update (#3735)\n\n* TN docs update: audio based docs added, quick start, ref fixed, etc\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add deployment script dir and Sp TN\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\n\n* Update Tacotron2_Training.ipynb (#3769)\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update requirements and package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: Oktai Tatanov <oktai.tatanov@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Samuel Kriman <samuelkriman@gmail.com>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\nCo-authored-by: Vahid Noroozi <VahidooX@users.noreply.github.com>\nCo-authored-by: yaoyu-33 <54727607+yaoyu-33@users.noreply.github.com>\nCo-authored-by: Yu Yao <yuya@nvidia.com>\nCo-authored-by: Yi Dong <43824965+yidong72@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/tts/models/mixer_tts.py",
        "commit_date": "2022-02-11T22:26:51Z",
        "message": "[TTS] Add Mixed Representation Training (#3473)\n\n* Update CMUdict with ADLR version pronunciations\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* minor updates for finetuning\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update conf\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* merge\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* bug fixes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update config\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* bf16 support\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* bf16 support\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* bugfix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* finalize changes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* undo notebook 1.6.0 pins\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* more 1.6.0 undos\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* wip\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update num_workers\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update hypers\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* revert to main _align yamls\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update yamls\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* cleanup\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* remove unnecessary line\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* address comments\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update vocoder mel uploading; add contextmanager to mixed g2p\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update comments; make prob required argument\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* added val check\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update message\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* revert num workers\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\nCo-authored-by: Jocelyn Huang <jocelynh@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/tts/models/mixer_tts.py",
        "commit_date": "2022-02-02T17:22:50Z",
        "message": "[TTS] Update UnivNet, HiFi-GAN and WaveGlow, small fixes in Mixer-TTS, FastPitch and Exportable (#3585)\n\n* update hifigan and mixer tts\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* remove unused import\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix bug with sched_config\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix bug with set_struct\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update hifigan and univnet\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update univnet\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update waveglow\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix bug\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix bug\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* remove unnecessary header from configs\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix comments\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/tts/models/mixer_tts.py",
        "commit_date": "2022-02-02T07:18:45Z",
        "message": "[TTS] Fix bugs in HiFi-GAN (scheduler, optimizers) and add input_example() in Mixer-TTS/Mixer-TTS-X (#3564)\n\n* update hifigan and mixer tts\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* remove unused import\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix bug with sched_config\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix bug with set_struct\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\nCo-authored-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/tts/models/mixer_tts.py",
        "commit_date": "2022-01-11T16:34:16Z",
        "message": "Update Mixer-TTS, FastPitch and TTSDataset (#3366)\n\n* update tts dataset, fastpitch and mixer tts\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix style and notebooks\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update notebooks\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update mixer-tts, mixer-tts-x and fastpitch configs\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update notebooks and configs\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update configs\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* add links, update README, fix tutorials\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix style\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* remove unnecessary code from fastpitch model\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update jenkinsfile and fastpitch typo fix\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix configs\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* revert jenkinsfile\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/tts/models/mixer_tts.py",
        "commit_date": "2021-12-15T09:38:06Z",
        "message": "Fix MixerTTS types and dimensions (#3330)\n\n* Fix MixerTTS types and dimensions\n\nSigned-off-by: Markus Toman <m.toman@neuratec.com>\n\n* fix style\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\nCo-authored-by: Markus Toman <m.toman@neuratec.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/tts/models/mixer_tts.py",
        "commit_date": "2021-12-02T15:10:12Z",
        "message": "Normalizer to TTS models, TTS tokenizer updates, AxisKind updates (#3271)\n\n* update tts tokenizer, mixer tts and add normalizer to some models\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix bugs in mixer tts, update types to aligner loss\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix bugs, update fastpitch types\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix style\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update german dataset, update fastpitch\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update types, fix comments\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* add cmudict and heteronyms paths\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/tts/models/mixer_tts.py",
        "commit_date": "2021-11-01T15:56:14Z",
        "message": "add export methods for mixer-tts (#3082)\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\nCo-authored-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/tts/models/mixer_tts.py",
        "commit_date": "2021-10-25T14:50:48Z",
        "message": "MixerTTS, MixerTTSDataset and small updates in tts tokenizers  (#2859)\n\n* new vocabs and g2ps for tts\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix style\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update tts torch data\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update g2p modules, data and add example for tts vocabs\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix style\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update tts dataset\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* add tokens field to tts dataset\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update tts dataset\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* add TTSDataset and docs for all of them\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix paths in yaml\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update test for tts dataset\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* add heteronyms-030921 file to scripts folder\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* change requirements_torch_tts.txt\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* add tts_data_types.py\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix style tts_data_types.py\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update yaml and comments\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* add mixer tts dataset\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* add example.py to tts torch\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update helpers.py\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* add mixer tts model and ds\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update mixer tts dataset\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update tokenizers\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update tts tokenizer\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update tts dataset and mixer tts model\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update tts_dataset.yaml\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* add copyright header to mixer_tts file\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update import in tts/torch/data.py\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* add fastpitch in mixer tts code\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* add raw version of benchmark\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* remove without matching mode\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* remove unnecessary flags in model\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* refactor mixer tts\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* remove unnecessary blocks in mixer tts model\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* update tts_tokenizers.py\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* add mixer tts x config and run script\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* fix elif and unnecessary file\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* add types for mixer tts methods\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\nCo-authored-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/core/config/templates/model_card.py",
        "commit_date": "2024-02-06T00:26:43Z",
        "message": "Support uploading NeMo models to HF via `push_to_hf_hub()` (#8263)\n\n* Initial support for saving unpacked nemo file directly and support for uploading NeMo models to Huggingface Hub\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add support to restore nemo models from HF in unpacked format\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Correct input types for model card\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update License Section to template\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add unit test to restore via unpacked checkpoint\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix typo\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Address comments\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Address comments\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add docs and address comments\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2023-01-28T14:45:44Z",
        "message": "RETRO model finetuning (#5800)\n\n* add save and load dynmaic index\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* add chunk stride feature\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* add chunk stride feature\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* add no pq index\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* added megatron lm compatible mode\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* addd config\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix position embedding\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* added index factory\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* share neighbors and weights amoung strategies\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix bug\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* added metric tto faiss index\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* set default to inner product\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* added qa fine tuen dataset\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* added fine tuning code\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* trim it\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix data issue\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix style\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* added version\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix key error\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* make sure to overwrite the cfg\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* make multiple sentence bert available\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix the document\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix the table\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix transformer\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* make sure to turn off the rope in chunked cross attention layer\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix the security issue\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* style fix\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix codeql issues\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* use -1\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix empty index\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* clean up\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix the lower bound for repetition penalty\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* add retro qa inference strategy\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* added new inference logic\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* working inference\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix TP inference\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* revert requirement\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* added file inference\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* use string to prevent collison\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* use NQ test\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix prompt\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix inference\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* set good defaults for demo\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* replicate adlr\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* make sure to turn off attention reset for megatron lm compatible model\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* style fix\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix typo\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix inference error\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix logging\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* address comments\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n---------\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2023-01-06T04:47:58Z",
        "message": "Support non-standard padding token id (#5543)\n\n* Support non-standard padding token id\n\nRead the id of the padding token from the tokenizer when creating the\nembedding, rather than always defaulting to 0. This allows use of\n(admittedly bizarre) non-standard tokenizer models that don't give the\npadding token <PAD> the id 0.\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nCo-authored-by: Numeri <kaden.uhlig@lilt.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2022-09-08T20:41:11Z",
        "message": "removed unused imports for all domains. (#4901)\n\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2022-04-09T04:46:15Z",
        "message": "Merge r1.8 main (#3959)\n\n* update version\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Stateless timer fix for PTL 1.6 (#3925)\n\n* Stateless timer fix for PTL 1.6\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Stateless timer PTL test\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix year\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove unused imports\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* GPU test\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* clean import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: ericharper <complex451@gmail.com>\n\n* fix save_best missing chpt bug, update for setup_tokenizer() changes (#3932)\n\n* fix save_best missing chpt bug, update for setup_tokenizer() changes\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* style fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* Fix divide by world size (#3941)\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* remove old doc (#3946)\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* Fix issues with librosa deprecations (#3950)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix issue with Segfault in ASR models (#3956)\n\n* Fix issue with Segfault in ASR models\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add docstring\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix notebook bugs for branch r1.8.0 (#3948)\n\n* load the model from ngc\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix all biomegatron notebook\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix the typos\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* remove output\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix isort\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix merge error\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* change ntpath for isort workaround\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix unit test\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix ci\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix ci bert pretraining\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* make it compatible with main\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* add the teste for biomegatron ner\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix argument\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix usablity issue\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* work around\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Yi Dong <doyend@gmail.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix global batch fit loop (#3936)\n\n* add lightning module hooks for global batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean scripts\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* DP=1 fix\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* set num dataset workers to 2\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update validation_loop with GlobalDataFetcher\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add test global data fetcher\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Drop last for test ds\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix test epoch end\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix eval\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix reconfigure microbatch in the complete method\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add comments\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Set init consumed samples\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* fix shuffle\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add save_restore_connector arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix padding for labels and loss mask\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* GLUE/XNLI CI tests\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* limit val batches in hydra fix\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Restart CI\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix unittest\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Update max_epochs on megatron configs (#3958)\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update version\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Yi Dong <43824965+yidong72@users.noreply.github.com>\nCo-authored-by: Yi Dong <doyend@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2022-04-04T19:12:30Z",
        "message": "Megatron legacy conversion support (#3919)\n\n* Fix merge from main\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Rollback scripts/export.py changes and create a new file for converting legacy MegatronBert NLP models to current version\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Cleanup legacy conversion code\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Move state dict mapping of legacy Megatron to NLPSaveRestoreConnector; Do transpose op in Self attention if it's a legacy checkpoint; Add a example notebook for exporting NLP Bert models\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Style fix\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\nCo-authored-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2022-03-30T01:20:18Z",
        "message": "Megatron support (#3893)\n\n* Add MegatronBert training support for more NLP models; Replace check for nemo_file existence to decide if it's megatron training or not; Add support for finetuning a downstream NLP task model on a different downstream dataset using MegatronBert; Add skelton support for ONNX export of MegatronBert\n\n* Remove duplicate lm_checkpoint key in config\n\n* Adding new Apex classes for export replacement and default trainer support\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixing order of exported inputs in NLP models\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed typo\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed ORT check\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Refactor of NLP models initialization\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed style\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed runtime check\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Code style fixes\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Code style fixes\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Code style fixes\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Check for existence of downstream key before setting it\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Fix Huggingface download unit tests based on get_lm_model refactor\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Add register artifact for MegatronBert models; Remove unused import\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Fixed style\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed duplex decoder init\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* moved set_world_size up\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixing _trainer initialization\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed GPT tokenizer init\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fix Token classification and Q&A forward flag checks for MegatronBert\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Fix world_size init\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Skip GPT eval test\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Fix get_lm_model function calls based on recent refactoring\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Check for presence of keys in the Dict before trying to access them in BERTLMModel\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Check if tokenizer is present before accesing it in lm_utils\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Check for presence of keys in the Dict before trying to register them as artifacts\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Bypass NLP init statements pertaining to MegatronBert when using Ptune downstream task\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Revert NLPModel modification\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Skip the Jenkins Test Megatron P-Tuning GPT LM\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Merge branch 'main' into megatron_support\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\nCo-authored-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\nCo-authored-by: Boris Fomitchev <bfomitchev@nvidia.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nCo-authored-by: Boris Fomitchev <borisfom@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2022-01-28T19:48:04Z",
        "message": "More fixes to SentencePiece for T5 (#3515)\n\n* More fixes to spm for T5\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2022-01-15T03:09:00Z",
        "message": "BioMegatron token classification tutorial fix to be compatible with current Megatron BERT (#3435)\n\n* fixed the tokenizer\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* training is working\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fixed text\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fixed text\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* working notebook\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* style fix\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fixed text\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* handles the different megatron-lm checkpoint versions\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fixed the text classification notebook\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fixed key error\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* more key error\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* replace the old notebooks\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* register vocab to nemo file\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* added the missing notebook\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2021-10-27T18:13:29Z",
        "message": "Merge r1.5.0 bugfixes and doc updates to main (#3048)\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Always save last checkpoint on train end even if folder does not exist (#2976)\n\n* add fix for no checkpoint folder when training ends\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix test\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fixes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* typo\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* change check\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* [NLP] Add Apex import guard (#3041)\n\n* add apex import guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add apex import guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add apex import guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove from init add logging to constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove from init add logging to constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove import from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert encoder logic from NLPModel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove megatron bert from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2021-10-21T03:06:37Z",
        "message": "[BigNLP] Merge Megatron GPT to main (#2975)\n\n* fix gpu init after removing debug print in mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_adam\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check ds is not none before logging len\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set fp16 arg to true and fix enum conflict\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make fp16 arg configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add grad clip from megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Linear warmup with cosine annealing and constant holding (#2846)\n\n* Testing cosine schedule\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* More fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* update config for constant steps in schedule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* temporarily import enum from megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add grad clip for fp32\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update check for _del_model_without_trainer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating restore for model parallel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add predict script\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update test iters\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add barrier\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* return if clip_val is 0 or None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* when using amp clip grads after they are unscaled\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make native amp scaler hyperparams configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* (1) nvfuser, (2) amp-casting decoration (#2894)\n\n* (1) nvfuser, (2) amp-casting decoration\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* support bf16\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add set device to constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [BigNLP] Remove megatron-lm dependency. (#2910)\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update megatron_init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update process batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron clip_grad\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* trying to resolve circular import error\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove non-gpt models and datasets from __init__ files\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update MegatronDataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename fp16 and bf16 flags to fused_softmax_input_in_fp16/bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename to fused_fp16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_fp16 arg to LayerNorm calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Adding complete method to MegatronGPTModel (#2935)\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* make ffn_hidden_size mandatory\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Manually migrating timing of step into branch (#2937)\n\n* 1. Manually migrating timing of step into branch.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated file name and content.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated to latest code.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check fused_fp16 and fused_bf16 are not both True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update predict script for model parallel .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* NVfuser (#2943)\n\n* activation checkpoint recompute\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* selective nvfuser setup\n\n* Megatron gpt bfloat support (#2926)\n\n* Save/restore fix\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Another merge\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Bf16 args in init\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Set precision\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove debug stuff\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add bf16 casting decorator\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* Bfloat layernorm propagation\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* activation checkpoint recompute\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* selective nvfuser setup\n\n* More arg removal\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove BERTDataset\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* update to latest apex and patch transformer autocast\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: ericharper <complex451@gmail.com>\n\n* don't set jit for bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* replace apex.mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix grad clip\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* NVFuser fixes (#2951)\n\n* Fuser fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove dummy handler\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove PTL plugin based logic for fusion\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* remove duplicated file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo (#2960)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [BigNLP] Script to convert GPT checkpoint to .nemo (#2958)\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update megatron_init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update process batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron clip_grad\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* trying to resolve circular import error\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove non-gpt models and datasets from __init__ files\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update MegatronDataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename fp16 and bf16 flags to fused_softmax_input_in_fp16/bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename to fused_fp16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_fp16 arg to LayerNorm calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Adding complete method to MegatronGPTModel (#2935)\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* make ffn_hidden_size mandatory\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Manually migrating timing of step into branch (#2937)\n\n* 1. Manually migrating timing of step into branch.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated file name and content.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated to latest code.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check fused_fp16 and fused_bf16 are not both True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update predict script for model parallel .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add script to convert .ckpt to .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* convert mp checkpoints to nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update help\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add safeguard for model parallel save_to\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adjust NLPModel save_to to be safer for model parallel\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* [BigNLP] Update GPT evaluation to work with tensor model parallel  (#2959)\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add request dataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* tokenize request\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* able to run\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* reduce logits\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* capture response\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* squeeze and unsqueeze\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* handle non model parallel case\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* convert logits to log_probs\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* rename logits to log_probs\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* add megatron gpt pretraining\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron gpt pretraining\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron gpt pretraining\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating to work with latest megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating to work with latest megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update _del_model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding gpt model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding gpt model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding gpt model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* instantiate GPTmodel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding build dataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* build megatron dataset in .setup\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* setup dataloader\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add vocab_file and merge_file to megatron init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add forward\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add train loss\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add optimizer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add exp_manager\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* multi-gpu is working\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding val loop\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adding val loop\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix ranks\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix model parallel checkpoint saving\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix _del_model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* added megatron batch sampler\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* try to fix num steps\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add wandb to config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* log lr\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add warmup ratio to config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update configs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update configs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add cpu init to args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Initial megatron dataset port\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix merge conflicts\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* License fixes and megatron model porting\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* More fixes to import from nemo rather than megatron\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix circular imports\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Revert config file\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Restructure further to avoid circular imports\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add Makefile\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Add megatron modules\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add license\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Port from latest megatron\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* update cfg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add _del_model_without_trainer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add data preprocessing script\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use apex mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* replace print_rank_0 with nemo utils logging\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use apex mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use apex mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add use_cpu_initialization\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fixing autoresume in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* properly removing last checkpoint\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* log consumed samples\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix mp autoresume\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add NLPSaveRestoreConnector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Megatron GPT training with NeMo tokenizers (#2818)\n\n* Update files from megatron repo\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove non NLP data related files from megatron\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Merge megatron and nemo tokenizers\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove get_tokenizer() calls from gpt model\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Update tokenizer yaml config\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add todo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make init_method_std configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make gpu init work by setting random seed earlier\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix gpu init after removing debug print in mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_adam\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check ds is not none before logging len\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set fp16 arg to true and fix enum conflict\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make fp16 arg configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add grad clip from megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Linear warmup with cosine annealing and constant holding (#2846)\n\n* Testing cosine schedule\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* More fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* update config for constant steps in schedule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* temporarily import enum from megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add grad clip for fp32\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update check for _del_model_without_trainer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating restore for model parallel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add predict script\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update test iters\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add barrier\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* return if clip_val is 0 or None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* when using amp clip grads after they are unscaled\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make native amp scaler hyperparams configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* (1) nvfuser, (2) amp-casting decoration (#2894)\n\n* (1) nvfuser, (2) amp-casting decoration\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* support bf16\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add set device to constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [BigNLP] Remove megatron-lm dependency. (#2910)\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update megatron_init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update process batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron clip_grad\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* trying to resolve circular import error\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove non-gpt models and datasets from __init__ files\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update MegatronDataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename fp16 and bf16 flags to fused_softmax_input_in_fp16/bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename to fused_fp16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_fp16 arg to LayerNorm calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Adding complete method to MegatronGPTModel (#2935)\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* make ffn_hidden_size mandatory\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Manually migrating timing of step into branch (#2937)\n\n* 1. Manually migrating timing of step into branch.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated file name and content.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated to latest code.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check fused_fp16 and fused_bf16 are not both True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update predict script for model parallel .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* NVfuser (#2943)\n\n* activation checkpoint recompute\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* selective nvfuser setup\n\n* Megatron gpt bfloat support (#2926)\n\n* Save/restore fix\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Another merge\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Bf16 args in init\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Set precision\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove debug stuff\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add bf16 casting decorator\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* Bfloat layernorm propagation\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* activation checkpoint recompute\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\n\n* selective nvfuser setup\n\n* More arg removal\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove BERTDataset\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* update to latest apex and patch transformer autocast\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: ericharper <complex451@gmail.com>\n\n* don't set jit for bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* replace apex.mpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix grad clip\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* NVFuser fixes (#2951)\n\n* Fuser fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove dummy handler\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove PTL plugin based logic for fusion\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* remove duplicated file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo (#2960)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [BigNLP] Script to convert GPT checkpoint to .nemo (#2958)\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove args in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add load_fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update megatron_init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update process batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove erroneous import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron clip_grad\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* trying to resolve circular import error\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove non-gpt models and datasets from __init__ files\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set device in constructorfor gpu init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* set_device in constructor\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update MegatronDataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up MegatronModule\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename fp16 and bf16 flags to fused_softmax_input_in_fp16/bf16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* rename to fused_fp16\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add fused_fp16 arg to LayerNorm calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix arg name\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* skip warmup default to True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Adding complete method to MegatronGPTModel (#2935)\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* make ffn_hidden_size mandatory\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Manually migrating timing of step into branch (#2937)\n\n* 1. Manually migrating timing of step into branch.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated file name and content.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Updated to latest code.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check fused_fp16 and fused_bf16 are not both True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update predict script for model parallel .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add script to convert .ckpt to .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* convert mp checkpoints to nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update help\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add safeguard for model parallel save_to\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* adjust NLPModel save_to to be safer for model parallel\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* [BigNLP] Update GPT evaluation to work with tensor model parallel  (#2959)\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add request dataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* tokenize request\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* able to run\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* reduce logits\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* capture response\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* squeeze and unsqueeze\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* handle non model parallel case\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* convert logits to log_probs\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* rename logits to log_probs\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix copyright headers\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix copyright headers\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove old TimingCallback\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins to use latest apex and sandeep's fork\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* try 2109 container\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* try cuda container\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use internal container\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update checkpoint tests\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix scheduler args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update eval\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins to use ptl 1.5 rc\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add import guard to jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add import guard to jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove deterministic\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* install numba .53\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* allow for more variance\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update trainer config dataclass\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* test_get_optimizer on gpu\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* change trainer config default to 32\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [BigNLP] Remove fused kernel code instead use Apex (#2984)\n\n* remove fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove fused_kernels\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove fused layer norm and fused softmax and use apex instead\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use apex enums\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use apex enums\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add tab\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Timer with sliding window (#3002)\n\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\n\n* revert tab\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check for rank zero\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check for rank zero\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* try explicit log dir\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add +\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* don't rm\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make dir if it doesn't exist\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* create mp nemo file in temp directory\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* simplify mp save_to\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* handle mp 1 case\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style fix\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove files\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix consumed_samples when resuming\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix reinstall.sh\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update req\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add more detailed log for dataloaders\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check if cuda is available before using fused_adam\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update eval script to use model.freeze\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* log train loss averaged over gradient accumulation steps\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check copyright earlier\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* todo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* override SaveRestoreConnector in NLPModel init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move to scripts\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove star import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comments\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused dataset\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* removed barrier\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check cfg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove logging\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* freeze, unfreeze\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* return None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add TODO\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typecheck\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* todo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add common native plugin\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* restore with trainer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* deprecate megatron-lm bert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* deprecate megatron-lm bert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* compile helpers ont he fly\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove amp_level\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove amp_level from configs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add missing import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove amp_level\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use fast huggingface tokenizers by default\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* deal with huggingface tokenizer positional args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* deal with huggingface tokenizer positional args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* deal with huggingface tokenizer positional args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert use_fast default to False\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* return super training_epoch_end\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove optimizer_idx arg from training_step\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused arg from on_train_epoch_end\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add restore_from_path to nemo config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* override connector if not subclassing NLPSaveRestoreConnector for model parallel save\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update test optimizer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make data_prefix mandatory in config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update installation instructions on readme\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update dockerfile\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add todo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* raise error if trying to use always_save_nemo with model parallel model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove comment\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2021-08-24T22:21:59Z",
        "message": "Merge 1.3 bugfixes into main (#2715)\n\n* update jenkins branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update notebooks branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update readme\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update nemo version for Dockerfile\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update notebook branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Update colab links to Transducer notebooks (#2654)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix nmt grpc server, concatdataset for raw text files (#2656)\n\n* Fix nmt grpc server and concatdataset for raw text files\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Check if lang direction is provided correctly\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add missing init (#2662)\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix qa inference for single example (#2668)\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* Fix max symbol per step updating for RNNT (#2672)\n\n* Fix max symbol per step updating for RNNT\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix notebooks\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Replaced unfold() with split_view() (#2671)\n\n* Replaced unfold() with split_view()\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* fixed typo\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\n\n* Correct voice app demo (#2682)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Import guard (#2692)\n\n* add asr and pynini import guard\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* remove asrmodel type\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* remove asrmodel type\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fixing branch (#2695)\n\nSigned-off-by: Ghasem Pasandi <gpasandi@nvidia.com>\n\nCo-authored-by: Ghasem Pasandi <gpasandi@nvidia.com>\n\n* fix for emojis (#2675)\n\n* fix for emojis\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* remove redundant line\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* raise error\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* use app_state\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix issues with ASR notebooks (#2698)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Allow non divisible split_size (#2699)\n\n* bugfix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* bugfix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* TN fix for corner cases (#2689)\n\n* serial added, weights to common defaults, decimal bug fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* one failing\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* all tests pass\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* remove redundant file\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix telephone, add test cases\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* money fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* clean format\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix edge case of greedy decoding for greedy_batch mode (#2701)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove time macro (#2703)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Minor FastPitch Fixes (#2697)\n\n* fixes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update CI\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* refix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* Fix ddp error. (#2678)\n\nTo avoid \"MisconfigurationException: Selected distributed backend ddp is not compatible with an interactive environment.\" error.\n\nCo-authored-by: ekmb <ebakhturina@nvidia.com>\n\n* update jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update notebooks\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add split_view back\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: Boris Fomitchev <borisfom@users.noreply.github.com>\nCo-authored-by: Ghasem <35242805+pasandi20@users.noreply.github.com>\nCo-authored-by: Ghasem Pasandi <gpasandi@nvidia.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\nCo-authored-by: khcs <khcs@users.noreply.github.com>\nCo-authored-by: ekmb <ebakhturina@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2021-06-17T02:32:33Z",
        "message": "[NMT] Model Parallel Megatron Encoders (#2238)\n\n* add megatron encoder\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* added megatron to get_nmt_tokenizer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add vocab_size and hidden_size to megatron bert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron encoder module\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fixed horrible typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix typo and add default\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating nlp overrides for mp nmt\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move some logic back to nlpmodel from overrides\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add checkpoint_file property\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix property\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* num_tokentypes=0\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* find_unused_parameters=True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* get instead of pop\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove token type ids from megatron input example\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* pop vocab_size\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix checkpointing for model parallel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix bug in non model parallel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* convert cfg.trainer to dict\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make num_tokentypes configurable for nmt\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update checkpoint_file when using named megatron model in nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make vocab_file configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* dataclass can't have mutable default\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert input example\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check that checkpoint version is not None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add mp jenkins test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update docstring\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add docs for pretrained encoders with nemo nmt\n\nSigned-off-by: ericharper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2021-05-18T17:07:23Z",
        "message": "Transformer final norm preln (#2197)\n\n* fix pre_ln final norm\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* style fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* bug fixed\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* bugfix post_ln\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update and add pre_ln_final_norm\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* style fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* fix for unit test\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* rename final_norm to final_layer_norm\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* bug fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* tiny fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* fix and improve\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* tiny fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* Patch for NMT to allow loading old modlels trained with pre-LN\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2021-03-12T00:29:33Z",
        "message": "NMT adding pretrained HF encoders (#1871)\n\n* add get_transformer and get_nemo_transformer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add get_transformer and get_nemo_transformer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating get_nemo_transformer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating get_nemo_transformer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* aayn base working with get_transformer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add get_nmt_tokenizer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* in progress of adding HF encoder\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating yaml and args\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fixing typos and bugs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fixing typos and bugs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fixing typos and bugs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add huggingface encoder neural module\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add hf encoder decoder neural module files\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update weight init for pretrained encoder and decoder\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add huggingface config file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add todo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add docstring and dataclass for get_transformer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* refactoring encoder configs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* refactoring encoder configs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* refactoring encoder configs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* refactor decoder config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert arg name change\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* refactor encoder/decoder configs again\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* refactor encoder/decoder configs again\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* previous configs working\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* refactor config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean up config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check for attribute\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use detach\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use detach\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* if using pretrained, check config_dict is empty\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* change pretrained default to false in hf config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add jenkins tests\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix jenkins test for custom hf\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* change jenkins to bert-base-cased\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix header and add doc string\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused neural type\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add exception if tokenizer not supported\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add typecheck to huggingface encoder\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add typecheck to nemo decoder\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add typecheck to nemo encoder\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert change from merge\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert change from merge\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2021-02-25T23:46:56Z",
        "message": "Fix megatron vocab file (#1803)\n\n* use user specified vocab_file with megatron\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating all examples\n\nSigned-off-by: ericharper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2020-09-23T23:20:55Z",
        "message": "Aws2ngc (#1212)\n\n* change AWS links with NGC links\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* remove some experimental\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* bugfix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* bugfix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* bugfixes\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fix test\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* attempted bugfix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* bugfixes\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* stylefix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* file rename\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* download test refactor\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2020-09-09T02:04:18Z",
        "message": "Support for automodel hf (#1132)\n\n* biomegatron added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* expose get_megatron_models_list method\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* nlp LM notebook added, nlp notebooks renamed to follow asr naming schema\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* adding renamed notebooks\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* revert notebooks renaming\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* docstring fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* branch name changed, get_lm_model added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* autoencoder added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins tests added for HF models withou a wrapper class + mismatched name\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* revert changes in the notebooks\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* clean up\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* clean up\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* get_huggingface_pretrained_lm_models_list doent include all HF supported automodels\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* ooo  fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* update auto tokenizer to preserve default special tokens\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* check added, review feedback\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* tests renamed\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* glue tests changed from bert to albert and roberta, fix in tokenizer_type\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix squad test\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2020-09-05T02:10:33Z",
        "message": "Tokenizer and get_lm refactoring (#1114)\n\n* Tokenizer refactoring\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2024-02-09T03:44:47Z",
        "message": "Add longform infer for MultitaskAED models (#8355)\n\n* add multitaskAED longform infer\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* refactor and changed default beam=1 and len_pen=0\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* revert default len_pen=1.0\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* refactor\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* refactor\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* update doc\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* fix autocast\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* fix typo in docstring\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n---------\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2024-02-03T05:35:28Z",
        "message": " Attention encoder-decoder models for multiple speech-to-text tasks  (#8242)\n\n* Rebasing canary changes at current main\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Move the changes from asr transformer to nlp transformer as originally intended\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* update eval to strip spaces before punctuations\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* update pc strip\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* [canary] Refactor: `PromptedAudioToTextLhotseDataset` and `EncDecMultiTaskModel` (#8247)\n\n* Create a separate CanaryDataset and use it inside `transformer_bpe_models.py`. Ditches `token_sequence_format`.\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* [canary] Refactor: move changes in transformer_bpe_models.py to Canar\u2026 (#8252)\n\n* [canary] Refactor: move changes in transformer_bpe_models.py to CanaryModel\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Rename `CanaryModel` to `EncDecMultiTaskModel` and remove inheritance from `EncDecTransfModelBPE`; add a separate config for this model\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n---------\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Rename `CanaryDataset` to `PromptedAudioToTextLhotseDataset`; add `prompt_format_fn` argument; clean-up the `_canary_prompt_format` function a bit\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Move tokenization into `prompt_format_fn`, fix usage, add docs\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Backward-compatible utterance validation\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Improve type annotations\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* config and prompt_fn registration changes from review\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n---------\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* fix transcribe config\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* Refactor Canary to follow schema of remaining ASR models (#8260)\n\n* Initial draft of multi task beam decoding strategy\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Stabilize inference\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update AED Multi Task model to mostly conform to Archetype-Type format. Update config\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add change decoding strategy\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove redundant imports\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Cleanup\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Cleanup\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* remove asr transformer dependency on nlp\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* clean up\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* copy token_classifier from nlp to asr\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* Address comments\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add typing to beam decoding\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Make prompt format configurable\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* drop asr dependency on nlp\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nSigned-off-by: stevehuang52 <heh@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: stevehuang52 <heh@nvidia.com>\n\n* fix transcribe, update asr evaluator\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* Extend the docs for the canary prompt_fn\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Incorporate changes from Nithin's code review\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* training bug fix and adding launch script for speech_multitask (#8270)\n\n* bug fix and adding launch script for speech_multitask\n\nSigned-off-by: Krishna Puvvada <kpuvvada@nvidia.com>\n\n* update launch script example in speech_to_text_aed.py\n\nSigned-off-by: Krishna Puvvada <kpuvvada@nvidia.com>\n\n---------\n\nSigned-off-by: Krishna Puvvada <kpuvvada@nvidia.com>\nCo-authored-by: Krishna Puvvada <kpuvvada@nvidia.com>\n\n* Fix: drop_last must be true in validation/test otherwise the training will hang\n\nSigned-off-by: Piotr \u017belasko <pzelasko@nvidia.com>\n\n* revert to current transcribe API\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* revert changes to NLP, update docs\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* update eval utils\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* update docs\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* Remove DALI; rename compute_audio_loss to compute_loss\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* set default use_model_transcribe=False\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* change os.path.dirname to pathlib\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* [canary] Test for CanaryTokenizer + refactoring (#8285)\n\n* Test for CanaryTokenizer\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Attempt at refactor...\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n---------\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Update config for AED models (#8294)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* set default calculate_wer=False in transcribe_speech.py\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* Attention encoder-decoder models for multiple speech-to-text tasks\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Apply suggestions from code review, part 1\n\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Apply suggestions from code review, part 2\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* Document compute_loss\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n* update transcribe_speech.py\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* add docstring\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* Attention encoder-decoder models for multiple speech-to-text tasks\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\n\n---------\n\nSigned-off-by: Piotr \u017belasko <petezor@gmail.com>\nSigned-off-by: stevehuang52 <heh@nvidia.com>\nSigned-off-by: smajumdar <titu1994@gmail.com>\nSigned-off-by: Krishna Puvvada <kpuvvada@nvidia.com>\nSigned-off-by: Piotr \u017belasko <pzelasko@nvidia.com>\nCo-authored-by: stevehuang52 <heh@nvidia.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Krishna Puvvada <93558329+krishnacpuvvada@users.noreply.github.com>\nCo-authored-by: Krishna Puvvada <kpuvvada@nvidia.com>\nCo-authored-by: He Huang (Steve) <105218074+stevehuang52@users.noreply.github.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-12-29T15:34:44Z",
        "message": "Add text metrics to asr eval (#8087)\n\n* add text metrics to asr eval\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* temporary fix for EncDecTransfModelBPE\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n---------\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-10-07T01:51:11Z",
        "message": "Create per.py (#7538)\n\n* Move model precision copy (#7336)\n\n* move cfg precision set to megatron base model\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* remove copy from other models\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* modify attribute not arg\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* fix gpt model test for ptl 2.0\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* rename function and add docstring\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* replace precision to dtype conditionals with func call\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* unnecessary function and cfg reset\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* set default value\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* fix precision lookup in a few more places\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* rename mapping function\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* ununsed import\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* save torch datatype to model\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* set weights precision wrt amp o2\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* Revert \"set weights precision wrt amp o2\"\n\nThis reverts commit 313a4bfe5eb69d771a6d2433898c0685836aef5c.\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* revert half precision at inference attempt\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* move autocast dtype to base model\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* move params dtype to base model, enable fp16 O2 inf\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* unused imports\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n---------\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix PEFT checkpoint loading (#7388)\n\n* Fix PEFT checkpoint loading\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Use distributed optimizer support for multiple dtypes (#7359)\n\n* Update distopt wrapper with multiple dtype support\n\nRemove manual handling of separate FP32 optimizer.\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Use distopt support for contiguous buffers with multiple dtypes\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Fix typo\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Separate distopt buckets for first GPT layer and non-overlapped params\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Add distopt logic for int dtypes\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Update Apex commit\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Remove unused variables\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Update Apex commit in README and Jenkensfile\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Debug Dockerfile and Jenkinsfile\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n---------\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* minor fix for llama ckpt conversion script (#7387)\n\n* minor fix for llama ckpt conversion script\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* remove fast_swiglu configuration\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n---------\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix wrong calling of librosa.get_duration() in notebook (#7376)\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [PATCH] PEFT import mcore (#7393)\n\n* [PATCH] PEFT import mcore\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Create per.py\n\nScript for calculation Punctuation Error Rate and related rates (correct rate, deletions rate, etc.)\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [TTS] Added a callback for logging initial data (#7384)\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Update Core Commit (#7402)\n\n* Update Core Commit\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* update commit\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n---------\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Use cfg attribute in bert (#7394)\n\n* use cfg attribute instead of arg\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* use torch_dtype in place of cfg.precision\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* move precision copy before super constructor\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* use trainer arg\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n---------\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add support for bias conversion in Swiglu models (#7386)\n\n* Add support for bias conversion in Swiglu models\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add support for auto extracting tokenizer model\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add support for auto extracting tokenizer model\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix issue with missing tokenizer\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Refactor\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Refactor\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Update save_to and restore_from for dist checkpointing (#7343)\n\n* add dist ckpt to save to, in progress\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* move dist ckpt\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* clean up\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update restore from, need to figure out how to initialize distributed\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* launch distrib if needed when restoring dist ckpt\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* when using mcore we can change tp pp on the fly\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* add load_from_checkpoint support for dist ckpt\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update llama convert script to save dist .nemo\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* fix load dist ckpt\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* setup TE TP groups if needed\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* setup te tp groups if needed\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* remove import\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n---------\n\nSigned-off-by: eharper <eharper@nvidia.com>\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: jasonwan <jasonwan@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* fix forward for with mcore=false (#7403)\n\nSigned-off-by: Jimmy Zhang <jiemingz@nvidia.com>\nCo-authored-by: Jimmy Zhang <jiemingz@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix logging to remove 's/it' from progress bar in Megatron models and add train_step_timing (#7374)\n\n* Add CustomProgressBar class to exp_manager and trainer callbacks\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix the progress bar to reflect total microbatch cnt\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Modify CustomProgressBar class\n\n1) Modify CustomProgressBar class to update progress bar per global_step instead of per microbatch\n2) Add the callback to other megatron training/finetuning files that are not using MegatronTrainerBuilder\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add CustomProgressBar callback to tuning files\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Set Activation Checkpointing Defaults (#7404)\n\n* Set Activation Checkpointing Defaults\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* check for None\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* make loss mask default to false (#7407)\n\nSigned-off-by: eharper <eharper@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add dummy userbuffer config files (#7408)\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* add missing ubconf files (#7412)\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* New tutorial on Speech Data Explorer (#7405)\n\n* Added Google Colab based tutorial on Speech Data Explorer\n\nSigned-off-by: George Zelenfroynd <gzelenfroind@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Update ptl training ckpt conversion script to work with dist ckpt (#7416)\n\n* update ptl convert script\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* don't break legacy\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: eharper <eharper@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Allow disabling sanity checking when num_sanity_val_steps=0 (#7413)\n\n* Allow disabling sanity checking when num_sanity_val_steps=0\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Update num_sanity_val_steps to be a multiple of num_microbatches\n\nSigned-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nSigned-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add comprehensive error messages (#7261)\n\nSigned-off-by: Anton Peganov <apeganov@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* check NEMO_PATH (#7418)\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* layer selection for ia3 (#7417)\n\n* layer selection for ia3\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: arendu <adithyare@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix missing pip package 'einops' (#7397)\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix failure of pyaudio in Google Colab (#7396)\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Update README.md: output_path --> output_manifest_filepath (#7442)\n\nSigned-off-by: Samuele Cornell <cornellsamuele@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add rope dynamic linear scaling (#7437)\n\n* Add dynamic linear scaling\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n---------\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix None dataloader issue in PTL2.0 (#7455)\n\n* Fix None dataloader issue in PTL2.0\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* updating values of self._validation_dl and self._test_dl as well\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* updating values of self._validation_dl and self._test_dl as well\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [ASR] Confidence measure -> method renames (#7434)\n\n* measure -> method\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add steps for document of getting dataset 'SF Bilingual Speech' (#7378)\n\n* Add steps for document of getting dataset 'SF Bilingual Speech'\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Update datasets.rst\n\nadded a link from a tutorial demonstrating detailed data prep steps.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* RNN-T confidence and alignment bugfix (#7381)\n\n* new frame_confidence and alignments lists are now always created after the while loop\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n* tests added\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n---------\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix resume from checkpoint in exp_manager (#7424) (#7426)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix checking of cuda/cpu device for inputs of Decoder (#7444)\n\n* Fix checking of cuda/cpu device for inputs of Decoder\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Update tacotron2.py\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix failure of ljspeech's get_data.py (#7430)\n\n* Fix failure of ljspeech's get_data.py\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [TTS] Fix audio codec type checks (#7373)\n\n* [TTS] Fix audio codec type checks\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Fix audio codec tests\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n---------\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [TTS] Add dataset to path of logged artifacts (#7462)\n\n* [TTS] Add dataset to path of logged artifacts\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Revert axis name back to Audio Frames\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n---------\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix sft dataset truncation (#7464)\n\n* Add fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n---------\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Automatic Lip Reading Recognition (ALR) - ASR/CV (Visual ASR) (#7330)\n\n* striding_conv1d_k5 and dw_striding_conv1d_k5 subsampling\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* transpose conv1d inputs\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* Update subsampling.py\n\nchange striding_conv1d_k5 to striding_conv1d\n\nSigned-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>\n\n* cv branch\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* video manifest\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* add collection classes\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add test_step_outputs\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* correct manifest bug when having only audio or only videos\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* correct manifest bug when having only audio or only videos\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* clean references\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* freeze unfreeze transcribe cv models\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* correct manifest get_full_path bug\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* update for PR\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* guard torchvision\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Update nemo/collections/cv/data/video_to_text_dataset.py\n\nCo-authored-by: Igor Gitman <igor.a.gitman@gmail.com>\nSigned-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>\n\n* _video_speech_collate_fn in cv/data/video_to_text.py\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* add self.out = None to asr subsampling\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* Update nemo/collections/cv/data/video_to_text_dataset.py\n\nCo-authored-by: Igor Gitman <igor.a.gitman@gmail.com>\nSigned-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>\n\n* cv -> multimodal/speech_cv branch\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\nSigned-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Igor Gitman <igor.a.gitman@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* HF StarCoder to NeMo conversion script (#7421)\n\n* Script to convert HF StarCoder checkpoint to NeMo\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* StarCoder conversion test\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Fix test\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Catch up with save_to changes\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Don't abbreviate args for clarity\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Configurable precision: BF16 vs FP32\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* fix bug when loading dist ckpt in peft (#7452)\n\nSigned-off-by: Hongbin Liu <hongbinl@nvidia.com>\nCo-authored-by: Hongbin Liu <hongbinl@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix adding positional embeddings in-place in transformer module (#7440)\n\nSigned-off-by: Tamerlan Tabolov <tktabolov@gmail.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix (#7478)\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* add sleep (#7498) (#7499)\n\n* add sleep\n\n* add sleep onto config instead\n\n* add comment\n\n---------\n\nSigned-off-by: Gerald Shen <geshen@nvidia.com>\nCo-authored-by: Gerald Shen <119401249+gshennvm@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix exp manager check for sleep (#7503) (#7504)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* bugfix: trainer.accelerator=auto from None. (#7492) (#7493)\n\nSigned-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nCo-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [doc] fix broken link (#7481)\n\nSigned-off-by: Stas Bekman <stas00@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [TTS] Read audio as int32 to avoid flac read errors (#7477)\n\n* [TTS] Read audio as int32 to avoid flac read errors\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Add comment about read failures\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n---------\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS (#7409)\n\n* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS\n* Train 'AISHELL-3' dataset with multi-speakers\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Update get_data.py\n\nupdate copyright header\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Update get_data.py\n\nadded a disclaimer\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add new configuration file for AISHELL3 with multispeaker of fastpitch\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* dllogger - log on rank 0 only (#7513)\n\nSigned-off-by: Stas Bekman <stas00@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix TTS FastPitch tutorial (#7494) (#7516)\n\n* Fix\n\n---------\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix get_dist() tensor dimension (#7506) (#7515)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\nCo-authored-by: Jocelyn <jocelynh@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* bugfix: specify trainer.strategy=auto when devices=1 (#7509) (#7512)\n\nSigned-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* fix (#7511)\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [TTS] Fix FastPitch data prep tutorial (#7524)\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* add italian tokenization (#7486)\n\n* add italian tokenization\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add more ipa lexicon it\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix error deletion\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* add test\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Replace None strategy with auto in tutorial notebooks (#7521) (#7527)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* unpin setuptools (#7534) (#7535)\n\nSigned-off-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Update per.py\n\n- if __name__ == \"__main__\" removed (now metric can be imported);\n- removed excessive classes (like \"Sample\" and \"Statistics\");\n- transition from pandas df to dict of dicts;\n- removed unnecessary \"return\";\n- notation fixing;\n- reduced calculation time\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Create punctuation_rates.py\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Format fixing\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* added nemo.logging, header, docstrings, how to use\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Added asserions to rate_punctuation.py\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* fix typo\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* added function for import and call, docstrings\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* remove auto generated examples (#7510)\n\n* explicitly remove autogenerated examples for data parallel evaluation\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* mark autogenrated and remove it for test\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: arendu <adithyare@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add the `strategy` argument to `MegatronGPTModel.generate()` (#7264)\n\nIt is passed as an explicit argument rather than through\n`**strategy_args` so as to ensure someone cannot accidentally pass other\narguments that would end up being ignored.\n\nIt is a keyword-only argument to ensure that if in the future we want to\nupdate the signature to `**strategy_args`, we can do it without breaking\ncode.\n\nSigned-off-by: Olivier Delalleau <507137+odelalleau@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix PTL2.0 related ASR bugs in r1.21.0: Val metrics logging, None dataloader issue (#7531) (#7533)\n\n* fix none dataloader issue ptl2\n\n* ptl2.0 logging fixes for rnnt_models\n\n---------\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\nCo-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* gpus -> devices (#7542) (#7545)\n\nSigned-off-by: Nithin Rao Koluguri <nithinraok>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Update FFMPEG version to fix issue with torchaudio (#7551) (#7553)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* PEFT GPT & T5 Refactor (#7308)\n\n* initial implementation of add_adapters API\n\n* correct type hint\n\n* Add config in add_adapters for save and load (@author bobchen)\n\n* Remove AdapterConfig to avoid import error\n\n* Add AdaterConfig back and move adaptermixin to sft model\n\n* Add NLPSaveRestoreConnector as default in NLPModel.restore_from\n\n* Add restore_from_nemo_with_adapter and test script\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* rename t5 file and classes to be consistent with GPT\n\n* add t5 sft dataset\n\n* add support for single-file format with T5SFTDataset\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Various small changes to make T5 SFT work like GPT SFT\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add adapter evaluation test script\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add MultiAdaterConfig for ia3 and fix builder issue\n\n* Make ptuning for T5SFTModel work using mixin\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add IA3_Adapter for AdapterName\n\n* Add adapter name for ptuning and attention adapter\n\n* Make test script GPT/T5 agnostic\n\n* Add layer selection feature\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Integrate adapter name and config\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update gpt peft tuning script to new API\n\n* add t5 peft tuning script with new API\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix IA3 layer selection issue\n\n* Override state_dict on SFT model instead of mixin\n\n* Add load adapter by adapter config\n\n* move peft config map away from example script\n\n* auto get config from nemo adapter\n\n* Move PEFTConfig to new file\n\n* fix ckpt save/load for t5\n\n* name change: add_adapters -> add_adapter\n\n* variable name change\n\n* update t5 script\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix t5 issues\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add weight tying\n\n* update gpt tuning script\n\n* PEFT-API proposal\n\n* Fix according to comments\n\n* update tuning scripts\n\n* move merge_cfg_with to mixin class since it applies to both gpt and t5 and requires the model class for restore\n\n* Add mcore_gpt support for NLPAdapterMixin\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix typo\n\n* variable name change to distinguish \"peft\" and \"adapter\"\n\n* override `load_adapters` to support `add_adapter` name change\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update tuning and eval script for adapter save/load\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add Ptuning on first stage only\n\n* add lora tutorial for review\n\n* Fix layer selection for mcore\n\n* add landing page\n\n* fix resume training\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add mcore condition in sharded_state_dict to make sft work\n\n* Update lora_tutorial.md\n\nFirst edit of this file for PEFT documentation for NeMO\n\nSigned-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>\n\n* rename Adapter to AttentionAdapter to avoid confusion in doc\n\n* Change load_adapters to load .nemo\n\n* add quick start guide\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add load_adapters with .ckpt\n\n* Remove setup_complete changes in load_adapters\n\n* update landing page\n\n* remove typo\n\n* Updated quick_start.md per Chen Cui\n\nSigned-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>\n\n* Add inference config merger and tutorial\n\n* Add doc string for NLPAdapterModelMixin and deprecated warning on MegatronGPTPEFTModel\n\n* add supported_methods.md and update other documentations\n\n* Update supported_methods.md\n\nminor updates.\n\nSigned-off-by: Adi Renduchintala <adithyare@nvidia.com>\n\n* Update landing_page.md\n\nminor update.\n\nSigned-off-by: Adi Renduchintala <adithyare@nvidia.com>\n\n* Modify doc string for NLPAdapterModelMixin\n\n* Add doc string add_adapters in NLPAdapterModelMixin\n\n* rename canonical adapters\n\n* remove mcore hard dependency\n\n* [PATCH] move microbatch calculator to nemo from apex\n\n* remove apex dependency in gpt and t5 sft models\n\n* remove apex dependency in gpt model\n\n* render doc strings\n\n* fix\n\n* Add missing virtual_tokens on ptuning\n\n* fix docstrings\n\n* update gpt-style model coverage in docs\n\n* update docstring\n\n* Remove pdb\n\n* add lightning_fabric to make docstring rendering work\n\n* Add Ptuning missing key\n\n* try docstring rendering\n\n* Fix ptuning issue\n\n* update gpt t5 peft tuning and eval scripts\n\n* typos\n\n* update eval config\n\n* fix bug relating to apex dependency removal\n\n* typo\n\n* make predict step behave the same as test step\n\n* make lora tutorial work in notebook\n\n* cosmetics\n\n* update yaml scripts\n\n* mcore_gpt attribute optional\n\n* typo\n\n* update eval scripts and fix T5 eval bugs\n\n* add NLPDDPStrategyNotebook and trainer builder logic to use it\n\n* update lora notebook to use new trainer builder\n\n* fix microbatch calculator bug for inference after training\n\n* Convert markdown files to RST and incorporate with doc\n\n* typo\n\n* revise language\n\n* remove extra cell\n\n* remove unnecessary inheritance\n\n* remove old tests\n\n* move layer selection default so logging messages make sense\n\n* remove `save_adapters` as adapter weights are saved automatically during training\n\n* initialize weights from a checkpoint instead of randomly\n\n* multiple fields can form a context (#7147)\n\n* list of context fields and flexible prompt template\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* list of fields for context\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Add multiple truncation fields and middle truncation\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Compatible to old ckpt\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix tokenize detokenize issue\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Remove detokenization, add truncation augmentation\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Resolve comments\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Remove unused import\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* revert eos\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Add tokenizer space_sensitive attribute\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix error\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Fix erorr and use re\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Change assert logic\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Follow adi suggestion\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Remove merge function\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add example and comment\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Remove context_key and add comment\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Remove random truncation\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix template none\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n---------\n\nSigned-off-by: arendu <adithya.r@gmail.com>\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nSigned-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\n\n* revert config changes\n\n* remove accidental breakpoint\n\n* support TP>1 loading\n\n* infer adapter type from checkpoint in during eval\n\n* breakup add adapter\n\n* enable interpolation of train_ds and validation_ds\n\n* update metric calc script to conform to single-file eval format\n\n* remove extraneous print\n\n* update lora notebook for updated merge_inference_cfg\n\n* Update nlp_adapter_mixins.py\n\nvariable name change\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* turn off grad scaler for PP to match old scripts\n\n* remove PEFTSaveRestoreConnector since functionality all covered by the new mixin class\n\n* remove resume_from_checkpoint check since covered in #7335\n\n* revert changes made in eval config interpolation\n\n* more interpolation\n\n* typo\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* remove dup line\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* code style warnings\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix config mistake\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* add copyright header\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* fix code check warnings\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* revert changes to remove apex dependency (mixed apex+nemo microbatch calculator broke some CI tests)\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add more deprecation notices\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* update deprecation notices\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* update deprecation notices\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* consolidate peft and sft scripts\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* update CI tests\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* notebook branch points to main to prepare for merge\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* fix gpt and t5 validation with any metric other than loss\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* support pre-extracted checkpoints\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n---------\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\nSigned-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>\nSigned-off-by: Adi Renduchintala <adithyare@nvidia.com>\nSigned-off-by: arendu <adithya.r@gmail.com>\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nSigned-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\nSigned-off-by: Chen Cui <chcui@nvidia.com>\nCo-authored-by: Chen Cui <chcui@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Marc Romeyn <marcromeyn@gmail.com>\nCo-authored-by: jasonwan <jasonwan@nvidia.com>\nCo-authored-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>\nCo-authored-by: Adi Renduchintala <adithyare@nvidia.com>\nCo-authored-by: Yuanzhe Dong <yudong@nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* fix a typo (#7496)\n\nSigned-off-by: BestJuly <chntaoli@163.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [TTS] remove curly braces from ${BRANCH} in jupyer notebook cell. (#7554) (#7560)\n\n* remove curly braces.\n* remove installation of pynini.\n---------\n\nSigned-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* add youtube embed url (#7570)\n\nSigned-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nCo-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Remap speakers to continuous range of speaker_id for dataset AISHELL3 (#7536)\n\n* Remap speakers to continuous range of speaker_id for dataset AISHELL3\n* Add new key/value pair to record raw speaker for AISHELL3 dataset\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* fix validation_step_outputs initialization for multi-dataloader (#7546) (#7572)\n\n* added correct validation_step_outputs initialization for mutli-dataloader\n\n* changed kernel for display\n\n* Update logic for validation and test step outputs\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* revert multidataloader changes in multilang ASR notebook\n\n---------\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Append output of val step to self.validation_step_outputs (#7530) (#7532)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [TTS] fixed trainer's accelerator and strategy. (#7569) (#7574)\n\nSigned-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Append val/test output to instance variable in EncDecSpeakerLabelModel (#7562) (#7573)\n\n* Append val/test output to the instance variable in EncDecSpeakerLabelModel\n\n* Handle test case in evaluation_step\n\n* Replace type with isinstance\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix CustomProgressBar for resume (#7427) (#7522)\n\n* Fix CustomProgress Bar for resume and multiple epochs\n\n* Edit num_training_batches\n\n* Use max_steps as total for progress bar for resume\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* fix typos in nfa and speech enhancement tutorials (#7580) (#7583)\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\nCo-authored-by: Elena Rastorgueva <80532067+erastorgueva-nv@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add strategy as ddp_find_unused_parameters_true for glue_benchmark.py (#7454) (#7461)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* update strategy (#7577) (#7578)\n\nSigned-off-by: Nithin Rao Koluguri <nithinraok>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix typos (#7581)\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Change hifigan finetune strategy to ddp_find_unused_parameters_true (#7579) (#7584)\n\n* Change strategy to auto\n\n---------\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [BugFix] Add missing quotes for auto strategy in tutorial notebooks (#7541) (#7548)\n\n* Add missing quotes for auto strategy\n\n* Revert trainer.gpus to trainer.devices in Self_Supervised_Pre_Training.ipynb\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nSigned-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* added per tests\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [PATCH] PEFT import mcore (#7393)\n\n* [PATCH] PEFT import mcore\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* add build os key (#7596) (#7599)\n\n* add build os key\n\n* add tools\n\n* update to stable version\n\n---------\n\nSigned-off-by: Nithin Rao Koluguri <nithinraok>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* StarCoder SFT test + bump PyT NGC image to 23.09 (#7540)\n\n* Add SFT StarCoder test\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Remove _modify_config call as it is covered in load_from_nemo just below\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Test with pyt:23.09 container\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n---------\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* defaults changed (#7600)\n\n* defaults changed\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* typo\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* update\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n---------\n\nSigned-off-by: arendu <adithyare@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* add ItalianPhonemesTokenizer (#7587)\n\n* add ItalianPhonemesTokenizer\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix Italian phonemes\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add test\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n---------\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* best ckpt fix (#7564) (#7588)\n\nSigned-off-by: dimapihtar <dpihtar@gmail.com>\nCo-authored-by: Dmytro Pykhtar <37850217+dimapihtar@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* rate_punctuation.py\n\nFixed output manifest saving\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix tests\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add files via upload (#7598)\n\nspecifies the branch\n\nSigned-off-by: George <37293288+Jorjeous@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix validation in G2PModel and ThutmoseTaggerModel (#7597) (#7606)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain (#7576) (#7586)\n\n* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Safeguard nemo_text_processing installation on ARM (#7485)\n\n* safeguard nemo_text_processing installing\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update check\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n---------\n\nSigned-off-by: Jason <jasoli@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Function name fixing\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Moving PER to speech_to_text_eval.py\n\nAdded:\n- \"use_per\": PER metric computing;\n- \"scores_per_sample\": metrics computation sample by sample for wer/cer/punctuation rates;\n- \"output_with_scores_filename\": saving manifest with metrics\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Update test_metrics.py\n\nUpdated \"punctuation_error_rate\" function name\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Added use_per description\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* guard extra dependencies\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Write metrics to \"output_filename\" if \"scores_per_sample=True\"\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* scores_per_sample description\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix import guards\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Stats printing when HAVE_TABLUATE_AND_PANDAS=False\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Bound transformers version in requirements (#7620)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* fix llama2 70b lora tuning bug (#7622)\n\n* fix llama2 70b lora tuning bug\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* Update peft_config.py\n\nbrackets\n\nSigned-off-by: Adi Renduchintala <adithyare@nvidia.com>\n\n---------\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\nSigned-off-by: Adi Renduchintala <adithyare@nvidia.com>\nCo-authored-by: Adi Renduchintala <adithyare@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix import error no module name model_utils (#7629)\n\nSigned-off-by: Mehadi Hasan Menon <mehadihasan80@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Delete examples/asr/rate_punctuation.py\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Added use_per description\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* metric and variables name fixing\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add else samples = None\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* add fc large ls models (#7641)\n\nSigned-off-by: Nithin Rao Koluguri <nithinraok>\nCo-authored-by: Nithin Rao Koluguri <nithinraok>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* bugfix: trainer.gpus, trainer.strategy, trainer.accelerator (#7621) (#7642)\n\n* [TTS] bugfix for Tacotron2 tutorial due to PTL 2.0\n* trainer.gpus -> trainer.devices\n* fixed related tutorial bugs\n---------\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* fix ssl models ptl monitor val through logging (#7608) (#7614)\n\nSigned-off-by: Nithin Rao Koluguri <nithinraok>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix metrics for SE tutorial (#7604) (#7612)\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>\nCo-authored-by: anteju <108555623+anteju@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add ddp_find_unused_parameters=True and change accelerator to auto (#7623) (#7644)\n\n* Add ddp_find_unused_parameters=True and change acclerator to auto\n\n* Add ddp_find_unused_parameters True for normalization_as_tagging_train.py\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix py3.11 dataclasses issue  (#7616)\n\n* Fix py3.11 dataclasses issue  (#7582)\n\n* Update ASR configs to support Python 3.11\n\nSigne\u2026"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-08-22T18:38:37Z",
        "message": "fix partial transcribe (#7284)\n\n* fix partial transcribe\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* refactor\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\n\n---------\n\nSigned-off-by: stevehuang52 <heh@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-08-17T19:31:33Z",
        "message": "[ASR] Fix GPU memory leak in transcribe_speech.py (#7249)\n\nSigned-off-by: Ryan <rlangman@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-06-26T16:23:58Z",
        "message": "Move model change out of if-branch (#6908)\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-06-21T21:41:31Z",
        "message": "Fix transcribe_utils.py for hybrid models in partial transcribe mode (#6899)\n\n* Fix transcribe_utils.py for hybrid models in partial transcribe mode\n\nSigned-off-by: He Huang (Steve) <105218074+stevehuang52@users.noreply.github.com>\n\n* Update transcribe_utils.py\n\nSigned-off-by: He Huang (Steve) <105218074+stevehuang52@users.noreply.github.com>\n\n---------\n\nSigned-off-by: He Huang (Steve) <105218074+stevehuang52@users.noreply.github.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-06-15T05:57:56Z",
        "message": "Update transcribe_utils.py (#6865)\n\nfix ctc decoding for hybrid model in partial transcribe\n\nSigned-off-by: He Huang (Steve) <105218074+stevehuang52@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-05-16T22:42:08Z",
        "message": "Add support for RNNT/hybrid models to partial transcribe (#6609)\n\n* Add support for RNNT/hybrid models to partial transcribe\n\nSigned-off-by: He Huang (Steve) <105218074+stevehuang52@users.noreply.github.com>\n\n* Update transcribe_utils.py\n\nSigned-off-by: He Huang (Steve) <105218074+stevehuang52@users.noreply.github.com>\n\n* Update transcribe_speech.py\n\nSigned-off-by: He Huang (Steve) <105218074+stevehuang52@users.noreply.github.com>\n\n* Update transcribe_utils.py\n\nSigned-off-by: He Huang (Steve) <105218074+stevehuang52@users.noreply.github.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: He Huang (Steve) <105218074+stevehuang52@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-05-11T01:31:03Z",
        "message": "Offline and streaming inference support for hybrid model (#6570)\n\n* streaming buffered for hybrid + ctc\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* change default model_stride in eval.yaml\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* add fc model_stride\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* small fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* check whether model and decoding match\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* small fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* streaming buffered for hybrid + rnnt\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* style fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* fix yaml\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* reflect comment wip\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* refactor and verified\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* add get_full_path to buffered\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* small fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* add RNNTDecodingConfig\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* model name & instruction of changing decoding\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n---------\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\nSigned-off-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-05-10T15:14:38Z",
        "message": "Cherry pick commits in #6601 to main (#6611)\n\n* fix write\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* decoding ctc\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* temp set rnnt decoding return_best_hypothesis to true\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* add wer cal back to transcribe_speech as requested\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* add wer cal back to speech_to_text_buffered_infer_rnnt  as requested\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* add wer cal back to speech_to_text_buffered_infer_ctc as requested\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* style fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* reflect change in asr_evaluator\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* reflect som and vahid comment\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* remove return_best_hy=true in transcribe_speech\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* no text skip\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* revert partial\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n---------\n\nSigned-off-by: fayejf <fayejf07@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-05-09T19:04:46Z",
        "message": "Bug/typo fixes (#6599)\n\nSigned-off-by: Igor Gitman <igitman@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-05-05T18:17:02Z",
        "message": "whitespace (#6574)\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-05-04T16:57:47Z",
        "message": "Make KenLM with PC for AggregateTokenizer and merge it (#6081)\n\n* do_lowercase, rm_punctuation\n\nSigned-off-by: Nikolay Karpov <nkarpov@nvidia.com>\n\n* support beam_strategy = beam\n\nSigned-off-by: Nikolay Karpov <nkarpov@nvidia.com>\n\n* black\n\nSigned-off-by: Nikolay Karpov <nkarpov@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix config and^Cunctuation capitalization\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* rm math\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* update kenlm\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* black\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add opengrm\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* mv install_beamsearch_decoders\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* punctuation_to_preserve\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Only tikenizer opion\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* Black\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* DEFAULT_TOKEN_OFFSET\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* aggregate_tokenizer\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* install kenlm with more than 5gram\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* install_beamsearch_decoders\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* ngram_bin_path kenlm_bin_path\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* black\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* fix greedy PC bug\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* move global params\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* fix description and perplexity\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* fix description\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* NEMO_PATH\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* nemo:23.01\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* License\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* description\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* isinstance\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* refactor kenlm stdin\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* black\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* add cmd arg\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* use new iter_files\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* EncDecHybridRNNTCTCModel\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* punctuation\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* train_kenlm args\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* add docstrings\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add ngram_merge docs\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* ngram_prune\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rename to ngram_merge\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rename to ngram\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* add comments\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* Ngram\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* nemo_model_file\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* install_opengrm_ngram\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* install opengrm\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rename to install_opengrm.sh\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rm extra import\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* train_paths\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* text_processing\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* fix ngram_bin_path\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* DECODERS_PATH\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* farcompile\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rm text processing\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* text_processing\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* AggregateTokenizer.DummyTokenizer\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* comments\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* TextProcessingConfig\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* typo\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* doc\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* types\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* nemo_model_file\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rm assert\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* import kenlm_utils\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* return None\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* Copyright\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* 2022\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* 2023\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n---------\n\nSigned-off-by: Nikolay Karpov <nkarpov@nvidia.com>\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\nCo-authored-by: Nikolay Karpov <nkarpov@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-05-04T09:36:27Z",
        "message": "Patch transcribe and support offline transcribe for hybrid model (#6550) (#6559)\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-03-20T19:12:10Z",
        "message": "[ASR] Support audio_filepath as a list of single-channel files (#6132)\n\n* Support audio_filepath as a list of single-channel files\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>\n\n---------\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-03-01T18:12:26Z",
        "message": "Ngram (#6063)\n\n* do_lowercase, rm_punctuation\n\nSigned-off-by: Nikolay Karpov <nkarpov@nvidia.com>\n\n* support beam_strategy = beam\n\nSigned-off-by: Nikolay Karpov <nkarpov@nvidia.com>\n\n* black\n\nSigned-off-by: Nikolay Karpov <nkarpov@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix config and^Cunctuation capitalization\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* rm math\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* else TypeError\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n---------\n\nSigned-off-by: Nikolay Karpov <nkarpov@nvidia.com>\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\nCo-authored-by: Nikolay Karpov <nkarpov@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-01-14T01:35:05Z",
        "message": "Flashlight Decoder for Nemo (#5790)\n\n* Added initial flashlight decoding files\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* Fixed some minor bugs\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* Added fixes from auto style thingamajig\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* Ran pre-commit and fixed script file formatting\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* Minor fixes brought up during PR review\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* Added Windows-compatible code to eval_beamsearch_ngram.py\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* Added initial flashlight decoding files\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* Fixed some minor bugs\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* Added fixes from auto style thingamajig\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* Ran pre-commit and fixed script file formatting\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* Minor fixes brought up during PR review\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* Added Windows-compatible code to eval_beamsearch_ngram.py\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\nCo-authored-by: Daniel Egert <degert@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-01-11T16:57:25Z",
        "message": "ASR evaluator (#5728)\n\n* backbone\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* engineer and analyzer\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* offline_by_chunked\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* test_ds wip\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* temp remove inference\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* mandarin yaml\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* augmentor and a few updates\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* address alerts and revert unnecessary changes\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* Add readme\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* rename\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* typo fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* small fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* add missing header\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* rename augmentor_config to augmentor\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* raname inference_mode to inference\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* move utils.py\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update temp file\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* make wer cer clear\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* seed_everything\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* fix missing rn augmentor_config in rnnt\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* fix rnnt transcribe\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* add more docstring and style fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* address codeQL\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* reflect comments\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update readme\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* clearer\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\nSigned-off-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: He Huang (Steve) <105218074+stevehuang52@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2022-12-15T11:16:03Z",
        "message": "Conformer local attention (#5525)\n\n* local attn and merge\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* optional\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* override\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* incorporate comments\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* update\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* fix\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* comment\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* changes, test\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* changes\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* check att context\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* readme link\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* utils\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\n* update\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\n\nSigned-off-by: sam1373 <samuelkriman@gmail.com>\nSigned-off-by: Samuel Kriman <samuelkriman@gmail.com>\nCo-authored-by: Vahid Noroozi <VahidooX@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2022-12-07T19:16:48Z",
        "message": "Finalize (#5568)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: Vahid Noroozi <VahidooX@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2022-11-23T10:22:41Z",
        "message": "Add missing import (#5487)\n\nSigned-off-by: Jonghwan Hyeon <hyeon0145@gmail.com>\n\nSigned-off-by: Jonghwan Hyeon <hyeon0145@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2022-11-22T22:13:31Z",
        "message": "Transcribe for multi-channel signals (#5479)\n\nTranscribe for multi-channel signals (#5479)\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2022-11-19T00:19:57Z",
        "message": "Refactor/unify ASR offline and buffered inference (#5440)\n\n* refactor/unify offline and buffered\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* docstring and type\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* style fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* audio_dir for buffered\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* reflect comments\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* revert setup_gpu\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2022-11-10T19:43:34Z",
        "message": "Fix Python type hints according to Python Docs (#5370)\n\n* Remove duplicated type annotations\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Fix tuple annotations in function return types\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Add necessary imports\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Add necessary imports\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Fix types in obvious places\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Fix types in obvious places\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Fix unused import (avoid quotes in type annotations)\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Revert \"Fix unused import (avoid quotes in type annotations)\"\n\nThis reverts commit ea433efcd9916abf8944879e791484a0a1437f83.\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Remove problematic import\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Fix list_available_models method type\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Revert some changes\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\n* Revert quotes in list_available_models\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2022-11-04T22:03:05Z",
        "message": "small bugfix for r1.13.0 (#5310) (#5325)\n\n* typo fix\n* udpate transcribe\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2022-08-24T20:18:02Z",
        "message": "Merge r1.11.0 main (#4787)\n\n* NeMo Megatron doc updates\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info and dockerfile\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix fastpitch export (#4676)\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* [TTS] fixed wrong pronunciations for r1.11. (#4677)\n\n* [TTS] fixed wrong pronunciations.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* incremented the version number to 22.08 as @blisc suggested.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* correct cmudict versions in world-wide places.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Fix for incorrect batch size issue while decoding (#4675)\n\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* [TTS] incremented the version number to 22.08 in tutorials. (#4684)\n\n* [TTS] incremented the version number to 22.08 in tutorials.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Megatron encode function with RPE fix (#4692)\n\n* Fix for RPE\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* fix to fetch config file (#4699)\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* Fix notebook for buffered inference (#4703)\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Prompt Learning Notebook Bug Fix (#4689)\n\n* Added back dataset class list of dict input for generation in tutorial notebook\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* updated argument name for build dataset\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* add psutils to mock imports (#4728)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Update Aligner model and tutorial to add NGC checkpoint loading (#4714)\n\n* Update Aligner model and tutorial to add NGC checkpoint loading\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Fix pynini install for Aligner notebook, minor formatting fix for model\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Aligner notebook formatting consistency\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* [TTS] bugfix for missing configs. (#4725)\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* docs typo fix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Fix pynini install in TTS tutorials (#4729)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Fix ASR notebooks (#4738)\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Multilingual VAD model (#4734)\n\n* add ngc link\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* add tuned VAD config on ASR data\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* yaml note\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update vad asr notebook with mVAD\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update vad infer config comment\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* mvad sd config for ch109\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update sd readme\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* add new mVAD model to doc\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* style fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update sd tutorial with mVAD\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* typo fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* publish pretrained itn t5 model for English (#4748)\n\nSigned-off-by: Alexandra Antonova <aleksandraa@nvidia.com>\n\nSigned-off-by: Alexandra Antonova <aleksandraa@nvidia.com>\nCo-authored-by: Alexandra Antonova <aleksandraa@nvidia.com>\n\n* Updated docs and doc paths (#4754)\n\n* Updated docs and doc paths\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Update Multitask_Prompt_and_PTuning.ipynb\n\n* Update README.rst\n\n* Changed branch name to use single quotes\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* fix bug relating to ddp strategy in joint intent slot classification tutorial (#4762)\n\n* [TTS] updated config with a German IPA phoneme tokenizer (#4756)\n\n* [TTS] added a German IPA phoneme tokenizer\n* [TTS][ASR] enabled customized arguments for trimming the leading and trailing silence.\n* [TTS] disabled spline interpolation for beta-binomial distribution. Let it generate align prior and save to disks. Use a new phoneme tokenizer.\n* [TTS] use consistent spline interpolation with fastpitch checkpoint when generating mel-spectrograms for hifigan finetune.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Update r1.11 to new heteronyms list (#4745)\n\n* Update configs to new heteronyms list\n* Remove old heteronyms list, add alt 'merchandise' pron to CMUdict\n* Update remaining references to old heteronyms list\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* [TTS] Add multi-speaker German FastPitch and HiFiGAN NGC checkpoints (#4763)\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* [TTS] Add single male speaker German FastPitch and HiFiGAN NGC checkpoints (#4770)\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Update CMUdict with more recent 0.7b entries (#4768)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Install pynini in docker container (#4733)\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix tutorial formatting (#4778)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* [TTS] deprecated old scripts for ljspeech. (#4780)\n\n* deprecated old scripts for ljspeech.\n* removed relevent function calls in TTS docs.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info and requirements\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update container\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Update stragglers to new cmudict and heteronyms paths\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nSigned-off-by: ericharper <complex451@gmail.com>\nSigned-off-by: Jason <jasoli@nvidia.com>\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\nSigned-off-by: fayejf <fayejf07@gmail.com>\nSigned-off-by: Alexandra Antonova <aleksandraa@nvidia.com>\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Rajesh Ilango <rilango@gmail.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Virginia Adams <78445382+vadam5@users.noreply.github.com>\nCo-authored-by: Jocelyn <jocelynh@nvidia.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: bene-ges <61418381+bene-ges@users.noreply.github.com>\nCo-authored-by: Alexandra Antonova <aleksandraa@nvidia.com>\nCo-authored-by: Zhilin Wang <wangzhilin12061996@hotmail.com>\nCo-authored-by: Vladimir Bataev <vbataev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2022-06-22T02:52:18Z",
        "message": "Fixing bugs in calling method ctc_decoder_predictions_tensor. (#4414)\n\n* updated ctc decoding calls.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed the ones for timestamp_utils.py\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed the ones for timestamp_utils.py\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed the ones for timestamp_utils.py\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2022-03-17T01:43:26Z",
        "message": "Offline VAD+ASR tutorial (#3828)\n\n* merge updated part in vad_utils\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* path librosa and add int\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* manifest input for transcribe\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* stitch support\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* Offline_VAD_ASR tutorial\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* full manifest warning\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* style fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* handle the pure noise edge case\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* merge vad_util in other branch\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* revert parts that will be convered in https://github.com/NVIDIA/NeMo/pull/3463\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* remove comment\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* style fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* add readme and doc\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* typo and fix lgtm\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* revert due to abstraction level\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update per request\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* remove num_files\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update for feedback\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* add missing files\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* rename notebook\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update for feedback and modify for colab\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update per request\n\nSigned-off-by: fayejf <fayejf07@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/multimodal/data/neva/neva_dataset.py",
        "commit_date": "2024-02-21T22:56:21Z",
        "message": "Add Neva Template for NV-DPO Models  (#8358)\n\n* add/rename from nvgpt to nv_steerlm, add nv_dpo template\n\nSigned-off-by: HuiyingLi <willwin.lee@gmail.com>\n\n* add nv_dpo conversation to accomendate empty system message\n\nSigned-off-by: HuiyingLi <willwin.lee@gmail.com>\n\n* handle nv_dpo template text generation\n\nSigned-off-by: HuiyingLi <willwin.lee@gmail.com>\n\n* add prompt string to nvgpt\n\nSigned-off-by: HuiyingLi <willwin.lee@gmail.com>\n\n* bugfix for inference prompt template\n\nSigned-off-by: HuiyingLi <willwin.lee@gmail.com>\n\n* bug fix for grabbing clean text\n\nSigned-off-by: Huiying Li <willwin.lee@gmail.com>\n\n* fix code format\n\nSigned-off-by: Huiying Li <willwin.lee@gmail.com>\n\n---------\n\nSigned-off-by: HuiyingLi <willwin.lee@gmail.com>\nSigned-off-by: Huiying Li <willwin.lee@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/multimodal/data/neva/neva_dataset.py",
        "commit_date": "2024-02-16T17:16:16Z",
        "message": "Multimodal r1.23.0 bug fix  (#8315) (#8339)\n\n* Rename quick-gelu\n\n\n\n* ddpm config guard\n\n\n\n* Fix ddpm edit api\n\n\n\n* Fix insert_image_token cfg issue\n\n\n\n* neva updates\n\n\n\n* reformat\n\n\n\n* Add back jenkins\n\n\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix jenkins\n\n\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bugs\n\n\n\n* Update default neva template\n\n\n\n---------\n\nSigned-off-by: yaoyu-33 <yaoyu.094@gmail.com>\nCo-authored-by: yaoyu-33 <54727607+yaoyu-33@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/multimodal/data/neva/neva_dataset.py",
        "commit_date": "2024-01-20T01:59:23Z",
        "message": "Final multimodal PR with our recent developments on MM side (#8127)\n\n* Hotfix (#7501) (#7568)\n\nSigned-off-by: Jan Baczek <jbaczek@nvidia.com>\nCo-authored-by: jbaczek <45043825+jbaczek@users.noreply.github.com>\n\n* Avoid duplicated checkpoint save (#7555) (#7566)\n\nSigned-off-by: Miko\u0142aj B\u0142a\u017c <mblaz@nvidia.com>\nCo-authored-by: mikolajblaz <mikolajblaz@users.noreply.github.com>\n\n* Cache FP8 weight and transpose only at the first micro-batch in each validation and test routine (#7470) (#7483)\n\n* Cache weight and transpose only in the first batch in all training, val, and test runs\n\n\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Add an option to disable manual GC in validation (#7467) (#7476)\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\n\n* Remove PUBLICATIONS.md, point to github.io NeMo page instead (#7694) (#7695)\n\n* update publications section to point to blog website page\n\n\n\n* add hyphen\n\n\n\n* use double backquotes for code formatting\n\n\n\n---------\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\nSigned-off-by: Elena Rastorgueva <80532067+erastorgueva-nv@users.noreply.github.com>\nCo-authored-by: Elena Rastorgueva <80532067+erastorgueva-nv@users.noreply.github.com>\n\n* Fix multi rank finetune for ASR (#7684) (#7699)\n\n* Fix multi rank finetune for ASR\n\n\n\n* Actually add time\n\n\n\n* Actually add time\n\n\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\n\n* Update docs: readme, getting started, ASR intro (#7679)\n\n* [TTS] Add dataset to path of logged artifacts (#7462)\n\n* [TTS] Add dataset to path of logged artifacts\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Revert axis name back to Audio Frames\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n---------\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* move install info to INSTALLATION.md\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* tidy up links\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Fix sft dataset truncation (#7464)\n\n* Add fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n---------\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Automatic Lip Reading Recognition (ALR) - ASR/CV (Visual ASR) (#7330)\n\n* striding_conv1d_k5 and dw_striding_conv1d_k5 subsampling\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* transpose conv1d inputs\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* Update subsampling.py\n\nchange striding_conv1d_k5 to striding_conv1d\n\nSigned-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>\n\n* cv branch\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* video manifest\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* add collection classes\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add test_step_outputs\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* correct manifest bug when having only audio or only videos\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* correct manifest bug when having only audio or only videos\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* clean references\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* freeze unfreeze transcribe cv models\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* correct manifest get_full_path bug\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* update for PR\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* guard torchvision\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Update nemo/collections/cv/data/video_to_text_dataset.py\n\nCo-authored-by: Igor Gitman <igor.a.gitman@gmail.com>\nSigned-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>\n\n* _video_speech_collate_fn in cv/data/video_to_text.py\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* add self.out = None to asr subsampling\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* Update nemo/collections/cv/data/video_to_text_dataset.py\n\nCo-authored-by: Igor Gitman <igor.a.gitman@gmail.com>\nSigned-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>\n\n* cv -> multimodal/speech_cv branch\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\nSigned-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Igor Gitman <igor.a.gitman@gmail.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* HF StarCoder to NeMo conversion script (#7421)\n\n* Script to convert HF StarCoder checkpoint to NeMo\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* StarCoder conversion test\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Fix test\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Catch up with save_to changes\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Don't abbreviate args for clarity\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Configurable precision: BF16 vs FP32\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* fix bug when loading dist ckpt in peft (#7452)\n\nSigned-off-by: Hongbin Liu <hongbinl@nvidia.com>\nCo-authored-by: Hongbin Liu <hongbinl@nvidia.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Fix adding positional embeddings in-place in transformer module (#7440)\n\nSigned-off-by: Tamerlan Tabolov <tktabolov@gmail.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Fix (#7478)\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* add sleep (#7498) (#7499)\n\n* add sleep\n\n\n\n* add sleep onto config instead\n\n\n\n* add comment\n\n\n\n---------\n\nSigned-off-by: Gerald Shen <geshen@nvidia.com>\nCo-authored-by: Gerald Shen <119401249+gshennvm@users.noreply.github.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Fix exp manager check for sleep (#7503) (#7504)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* bugfix: trainer.accelerator=auto from None. (#7492) (#7493)\n\nSigned-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nCo-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* [doc] fix broken link (#7481)\n\nSigned-off-by: Stas Bekman <stas00@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* [TTS] Read audio as int32 to avoid flac read errors (#7477)\n\n* [TTS] Read audio as int32 to avoid flac read errors\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Add comment about read failures\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n---------\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS (#7409)\n\n* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS\n* Train 'AISHELL-3' dataset with multi-speakers\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Update get_data.py\n\nupdate copyright header\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Update get_data.py\n\nadded a disclaimer\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add new configuration file for AISHELL3 with multispeaker of fastpitch\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* dllogger - log on rank 0 only (#7513)\n\nSigned-off-by: Stas Bekman <stas00@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Fix TTS FastPitch tutorial (#7494) (#7516)\n\n* Fix\n\n---------\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Fix get_dist() tensor dimension (#7506) (#7515)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\nCo-authored-by: Jocelyn <jocelynh@nvidia.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* bugfix: specify trainer.strategy=auto when devices=1 (#7509) (#7512)\n\nSigned-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* fix (#7511)\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* [TTS] Fix FastPitch data prep tutorial (#7524)\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* add italian tokenization (#7486)\n\n* add italian tokenization\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add more ipa lexicon it\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix error deletion\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* add test\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Replace None strategy with auto in tutorial notebooks (#7521) (#7527)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* unpin setuptools (#7534) (#7535)\n\nSigned-off-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* remove auto generated examples (#7510)\n\n* explicitly remove autogenerated examples for data parallel evaluation\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* mark autogenrated and remove it for test\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: arendu <adithyare@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Add the `strategy` argument to `MegatronGPTModel.generate()` (#7264)\n\nIt is passed as an explicit argument rather than through\n`**strategy_args` so as to ensure someone cannot accidentally pass other\narguments that would end up being ignored.\n\nIt is a keyword-only argument to ensure that if in the future we want to\nupdate the signature to `**strategy_args`, we can do it without breaking\ncode.\n\nSigned-off-by: Olivier Delalleau <507137+odelalleau@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Fix PTL2.0 related ASR bugs in r1.21.0: Val metrics logging, None dataloader issue (#7531) (#7533)\n\n* fix none dataloader issue ptl2\n\n\n\n* ptl2.0 logging fixes for rnnt_models\n\n\n\n---------\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\nCo-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* gpus -> devices (#7542) (#7545)\n\nSigned-off-by: Nithin Rao Koluguri <nithinraok>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Update FFMPEG version to fix issue with torchaudio (#7551) (#7553)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* PEFT GPT & T5 Refactor (#7308)\n\n* initial implementation of add_adapters API\n\n* correct type hint\n\n* Add config in add_adapters for save and load (@author bobchen)\n\n* Remove AdapterConfig to avoid import error\n\n* Add AdaterConfig back and move adaptermixin to sft model\n\n* Add NLPSaveRestoreConnector as default in NLPModel.restore_from\n\n* Add restore_from_nemo_with_adapter and test script\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* rename t5 file and classes to be consistent with GPT\n\n* add t5 sft dataset\n\n* add support for single-file format with T5SFTDataset\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Various small changes to make T5 SFT work like GPT SFT\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add adapter evaluation test script\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add MultiAdaterConfig for ia3 and fix builder issue\n\n* Make ptuning for T5SFTModel work using mixin\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add IA3_Adapter for AdapterName\n\n* Add adapter name for ptuning and attention adapter\n\n* Make test script GPT/T5 agnostic\n\n* Add layer selection feature\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Integrate adapter name and config\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update gpt peft tuning script to new API\n\n* add t5 peft tuning script with new API\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix IA3 layer selection issue\n\n* Override state_dict on SFT model instead of mixin\n\n* Add load adapter by adapter config\n\n* move peft config map away from example script\n\n* auto get config from nemo adapter\n\n* Move PEFTConfig to new file\n\n* fix ckpt save/load for t5\n\n* name change: add_adapters -> add_adapter\n\n* variable name change\n\n* update t5 script\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix t5 issues\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add weight tying\n\n* update gpt tuning script\n\n* PEFT-API proposal\n\n* Fix according to comments\n\n* update tuning scripts\n\n* move merge_cfg_with to mixin class since it applies to both gpt and t5 and requires the model class for restore\n\n* Add mcore_gpt support for NLPAdapterMixin\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix typo\n\n* variable name change to distinguish \"peft\" and \"adapter\"\n\n* override `load_adapters` to support `add_adapter` name change\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update tuning and eval script for adapter save/load\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add Ptuning on first stage only\n\n* add lora tutorial for review\n\n* Fix layer selection for mcore\n\n* add landing page\n\n* fix resume training\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add mcore condition in sharded_state_dict to make sft work\n\n* Update lora_tutorial.md\n\nFirst edit of this file for PEFT documentation for NeMO\n\nSigned-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>\n\n* rename Adapter to AttentionAdapter to avoid confusion in doc\n\n* Change load_adapters to load .nemo\n\n* add quick start guide\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add load_adapters with .ckpt\n\n* Remove setup_complete changes in load_adapters\n\n* update landing page\n\n* remove typo\n\n* Updated quick_start.md per Chen Cui\n\nSigned-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>\n\n* Add inference config merger and tutorial\n\n* Add doc string for NLPAdapterModelMixin and deprecated warning on MegatronGPTPEFTModel\n\n* add supported_methods.md and update other documentations\n\n* Update supported_methods.md\n\nminor updates.\n\nSigned-off-by: Adi Renduchintala <adithyare@nvidia.com>\n\n* Update landing_page.md\n\nminor update.\n\nSigned-off-by: Adi Renduchintala <adithyare@nvidia.com>\n\n* Modify doc string for NLPAdapterModelMixin\n\n* Add doc string add_adapters in NLPAdapterModelMixin\n\n* rename canonical adapters\n\n* remove mcore hard dependency\n\n* [PATCH] move microbatch calculator to nemo from apex\n\n* remove apex dependency in gpt and t5 sft models\n\n* remove apex dependency in gpt model\n\n* render doc strings\n\n* fix\n\n* Add missing virtual_tokens on ptuning\n\n* fix docstrings\n\n* update gpt-style model coverage in docs\n\n* update docstring\n\n* Remove pdb\n\n* add lightning_fabric to make docstring rendering work\n\n* Add Ptuning missing key\n\n* try docstring rendering\n\n* Fix ptuning issue\n\n* update gpt t5 peft tuning and eval scripts\n\n* typos\n\n* update eval config\n\n* fix bug relating to apex dependency removal\n\n* typo\n\n* make predict step behave the same as test step\n\n* make lora tutorial work in notebook\n\n* cosmetics\n\n* update yaml scripts\n\n* mcore_gpt attribute optional\n\n* typo\n\n* update eval scripts and fix T5 eval bugs\n\n* add NLPDDPStrategyNotebook and trainer builder logic to use it\n\n* update lora notebook to use new trainer builder\n\n* fix microbatch calculator bug for inference after training\n\n* Convert markdown files to RST and incorporate with doc\n\n* typo\n\n* revise language\n\n* remove extra cell\n\n* remove unnecessary inheritance\n\n* remove old tests\n\n* move layer selection default so logging messages make sense\n\n* remove `save_adapters` as adapter weights are saved automatically during training\n\n* initialize weights from a checkpoint instead of randomly\n\n* multiple fields can form a context (#7147)\n\n* list of context fields and flexible prompt template\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* list of fields for context\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Add multiple truncation fields and middle truncation\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Compatible to old ckpt\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix tokenize detokenize issue\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Remove detokenization, add truncation augmentation\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Resolve comments\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Remove unused import\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* revert eos\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Add tokenizer space_sensitive attribute\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix error\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Fix erorr and use re\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Change assert logic\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Follow adi suggestion\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Remove merge function\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add example and comment\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Remove context_key and add comment\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Remove random truncation\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix template none\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n---------\n\nSigned-off-by: arendu <adithya.r@gmail.com>\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nSigned-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\n\n* revert config changes\n\n* remove accidental breakpoint\n\n* support TP>1 loading\n\n* infer adapter type from checkpoint in during eval\n\n* breakup add adapter\n\n* enable interpolation of train_ds and validation_ds\n\n* update metric calc script to conform to single-file eval format\n\n* remove extraneous print\n\n* update lora notebook for updated merge_inference_cfg\n\n* Update nlp_adapter_mixins.py\n\nvariable name change\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* turn off grad scaler for PP to match old scripts\n\n* remove PEFTSaveRestoreConnector since functionality all covered by the new mixin class\n\n* remove resume_from_checkpoint check since covered in #7335\n\n* revert changes made in eval config interpolation\n\n* more interpolation\n\n* typo\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* remove dup line\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* code style warnings\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix config mistake\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* add copyright header\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* fix code check warnings\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* revert changes to remove apex dependency (mixed apex+nemo microbatch calculator broke some CI tests)\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add more deprecation notices\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* update deprecation notices\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* update deprecation notices\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* consolidate peft and sft scripts\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* update CI tests\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* notebook branch points to main to prepare for merge\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* fix gpt and t5 validation with any metric other than loss\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* support pre-extracted checkpoints\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n---------\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\nSigned-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>\nSigned-off-by: Adi Renduchintala <adithyare@nvidia.com>\nSigned-off-by: arendu <adithya.r@gmail.com>\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nSigned-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\nSigned-off-by: Chen Cui <chcui@nvidia.com>\nCo-authored-by: Chen Cui <chcui@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Marc Romeyn <marcromeyn@gmail.com>\nCo-authored-by: jasonwan <jasonwan@nvidia.com>\nCo-authored-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>\nCo-authored-by: Adi Renduchintala <adithyare@nvidia.com>\nCo-authored-by: Yuanzhe Dong <yudong@nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* fix a typo (#7496)\n\nSigned-off-by: BestJuly <chntaoli@163.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* [TTS] remove curly braces from ${BRANCH} in jupyer notebook cell. (#7554) (#7560)\n\n* remove curly braces.\n* remove installation of pynini.\n---------\n\nSigned-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* add youtube embed url (#7570)\n\nSigned-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nCo-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Remap speakers to continuous range of speaker_id for dataset AISHELL3 (#7536)\n\n* Remap speakers to continuous range of speaker_id for dataset AISHELL3\n* Add new key/value pair to record raw speaker for AISHELL3 dataset\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* fix validation_step_outputs initialization for multi-dataloader (#7546) (#7572)\n\n* added correct validation_step_outputs initialization for mutli-dataloader\n\n\n\n* changed kernel for display\n\n\n\n* Update logic for validation and test step outputs\n\n\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* revert multidataloader changes in multilang ASR notebook\n\n\n\n---------\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Append output of val step to self.validation_step_outputs (#7530) (#7532)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* [TTS] fixed trainer's accelerator and strategy. (#7569) (#7574)\n\nSigned-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Append val/test output to instance variable in EncDecSpeakerLabelModel (#7562) (#7573)\n\n* Append val/test output to the instance variable in EncDecSpeakerLabelModel\n\n\n\n* Handle test case in evaluation_step\n\n\n\n* Replace type with isinstance\n\n\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Fix CustomProgressBar for resume (#7427) (#7522)\n\n* Fix CustomProgress Bar for resume and multiple epochs\n\n\n\n* Edit num_training_batches\n\n\n\n* Use max_steps as total for progress bar for resume\n\n\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* fix typos in nfa and speech enhancement tutorials (#7580) (#7583)\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\nCo-authored-by: Elena Rastorgueva <80532067+erastorgueva-nv@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Add strategy as ddp_find_unused_parameters_true for glue_benchmark.py (#7454) (#7461)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* update strategy (#7577) (#7578)\n\nSigned-off-by: Nithin Rao Koluguri <nithinraok>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Fix typos (#7581)\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Change hifigan finetune strategy to ddp_find_unused_parameters_true (#7579) (#7584)\n\n* Change strategy to auto\n\n\n\n---------\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* [BugFix] Add missing quotes for auto strategy in tutorial notebooks (#7541) (#7548)\n\n* Add missing quotes for auto strategy\n\n\n\n* Revert trainer.gpus to trainer.devices in Self_Supervised_Pre_Training.ipynb\n\n\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nSigned-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* add build os key (#7596) (#7599)\n\n* add build os key\n\n\n\n* add tools\n\n\n\n* update to stable version\n\n\n\n---------\n\nSigned-off-by: Nithin Rao Koluguri <nithinraok>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* StarCoder SFT test + bump PyT NGC image to 23.09 (#7540)\n\n* Add SFT StarCoder test\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Remove _modify_config call as it is covered in load_from_nemo just below\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Test with pyt:23.09 container\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n---------\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* defaults changed (#7600)\n\n* defaults changed\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* typo\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* update\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n---------\n\nSigned-off-by: arendu <adithyare@nvidia.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* add ItalianPhonemesTokenizer (#7587)\n\n* add ItalianPhonemesTokenizer\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix Italian phonemes\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add test\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n---------\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* best ckpt fix (#7564) (#7588)\n\nSigned-off-by: dimapihtar <dpihtar@gmail.com>\nCo-authored-by: Dmytro Pykhtar <37850217+dimapihtar@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Add files via upload (#7598)\n\nspecifies the branch\n\nSigned-off-by: George <37293288+Jorjeous@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Fix validation in G2PModel and ThutmoseTaggerModel (#7597) (#7606)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain (#7576) (#7586)\n\n* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Safeguard nemo_text_processing installation on ARM (#7485)\n\n* safeguard nemo_text_processing installing\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update check\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n---------\n\nSigned-off-by: Jason <jasoli@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Bound transformers version in requirements (#7620)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* fix llama2 70b lora tuning bug (#7622)\n\n* fix llama2 70b lora tuning bug\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* Update peft_config.py\n\nbrackets\n\nSigned-off-by: Adi Renduchintala <adithyare@nvidia.com>\n\n---------\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\nSigned-off-by: Adi Renduchintala <adithyare@nvidia.com>\nCo-authored-by: Adi Renduchintala <adithyare@nvidia.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Fix import error no module name model_utils (#7629)\n\nSigned-off-by: Mehadi Hasan Menon <mehadihasan80@gmail.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* add fc large ls models (#7641)\n\nSigned-off-by: Nithin Rao Koluguri <nithinraok>\nCo-authored-by: Nithin Rao Koluguri <nithinraok>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* bugfix: trainer.gpus, trainer.strategy, trainer.accelerator (#7621) (#7642)\n\n* [TTS] bugfix for Tacotron2 tutorial due to PTL 2.0\n* trainer.gpus -> trainer.devices\n* fixed related tutorial bugs\n---------\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* fix ssl models ptl monitor val through logging (#7608) (#7614)\n\nSigned-off-by: Nithin Rao Koluguri <nithinraok>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Fix metrics for SE tutorial (#7604) (#7612)\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>\nCo-authored-by: anteju <108555623+anteju@users.noreply.github.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Add ddp_find_unused_parameters=True and change accelerator to auto (#7623) (#7644)\n\n* Add ddp_find_unused_parameters=True and change acclerator to auto\n\n\n\n* Add ddp_find_unused_parameters True for normalization_as_tagging_train.py\n\n\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Fix py3.11 dataclasses issue  (#7616)\n\n* Fix py3.11 dataclasses issue  (#7582)\n\n* Update ASR configs to support Python 3.11\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update TTS configs to support Python 3.11\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Guard MeCab and Ipadic\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix remaining ASR dataclasses\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix remaining ASR dataclasses\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix scripts\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Update name to ConfidenceMethodConfig\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain (#7576) (#7586)\n\n* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Safeguard nemo_text_processing installation on ARM (#7485)\n\n* safeguard nemo_text_processing installing\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update check\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n---------\n\nSigned-off-by: Jason <jasoli@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Fix changes to confidence measure\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\nSigned-off-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: github-actions[bot] <41898282+github-actions[bot]@users.noreply.github.com>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Fix issues with Dockerfile (#7650) (#7652)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* [ASR] RNN-T greedy decoding max_frames fix for alignment and confidence (#7635)\n\n* decoding and test fix\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* [ASR] Fix type error in jasper (#7636) (#7653)\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\nCo-authored-by: Ryan Langman <rlangman@nvidia.com>\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* [TTS] Add STFT and SI-SDR loss to audio codec recipe (#7468)\n\n* [TTS] Add STFT and SI-SDR loss to audio codec recipe\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Fix STFT resolution\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Fix training metric logging\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Add docstring to mel and stft losses\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* add outline of asr quickstart info to asr/intro.rst\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* add CLI, LM and real-time transcription sections\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\n\n* Create per.py (#7538)\n\n* Move model precision copy (#7336)\n\n* move cfg precision set to megatron base model\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* remove copy from other models\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* modify attribute not arg\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* fix gpt model test for ptl 2.0\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* rename function and add docstring\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* replace precision to dtype conditionals with func call\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* unnecessary function and cfg reset\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* set default value\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* fix precision lookup in a few more places\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* rename mapping function\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* ununsed import\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* save torch datatype to model\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* set weights precision wrt amp o2\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* Revert \"set weights precision wrt amp o2\"\n\nThis reverts commit 313a4bfe5eb69d771a6d2433898c0685836aef5c.\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* revert half precision at inference attempt\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* move autocast dtype to base model\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* move params dtype to base model, enable fp16 O2 inf\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* unused imports\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n---------\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix PEFT checkpoint loading (#7388)\n\n* Fix PEFT checkpoint loading\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Use distributed optimizer support for multiple dtypes (#7359)\n\n* Update distopt wrapper with multiple dtype support\n\nRemove manual handling of separate FP32 optimizer.\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Use distopt support for contiguous buffers with multiple dtypes\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Fix typo\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Separate distopt buckets for first GPT layer and non-overlapped params\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Add distopt logic for int dtypes\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Update Apex commit\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Remove unused variables\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Update Apex commit in README and Jenkensfile\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Debug Dockerfile and Jenkinsfile\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n---------\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* minor fix for llama ckpt conversion script (#7387)\n\n* minor fix for llama ckpt conversion script\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* remove fast_swiglu configuration\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n---------\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix wrong calling of librosa.get_duration() in notebook (#7376)\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [PATCH] PEFT import mcore (#7393)\n\n* [PATCH] PEFT import mcore\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Create per.py\n\nScript for calculation Punctuation Error Rate and related rates (correct rate, deletions rate, etc.)\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [TTS] Added a callback for logging initial data (#7384)\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Update Core Commit (#7402)\n\n* Update Core Commit\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* update commit\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n---------\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Use cfg attribute in bert (#7394)\n\n* use cfg attribute instead of arg\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* use torch_dtype in place of cfg.precision\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* move precision copy before super constructor\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* use trainer arg\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n---------\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add support for bias conversion in Swiglu models (#7386)\n\n* Add support for bias conversion in Swiglu models\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add support for auto extracting tokenizer model\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add support for auto extracting tokenizer model\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix issue with missing tokenizer\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Refactor\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Refactor\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Update save_to and restore_from for dist checkpointing (#7343)\n\n* add dist ckpt to save to, in progress\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* move dist ckpt\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* clean up\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update restore from, need to figure out how to initialize distributed\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* launch distrib if needed when restoring dist ckpt\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* when using mcore we can change tp pp on the fly\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* add load_from_checkpoint support for dist ckpt\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update llama convert script to save dist .nemo\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* fix load dist ckpt\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* setup TE TP groups if needed\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* setup te tp groups if needed\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* remove import\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n---------\n\nSigned-off-by: eharper <eharper@nvidia.com>\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: jasonwan <jasonwan@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* fix forward for with mcore=false (#7403)\n\nSigned-off-by: Jimmy Zhang <jiemingz@nvidia.com>\nCo-authored-by: Jimmy Zhang <jiemingz@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix logging to remove 's/it' from progress bar in Megatron models and add train_step_timing (#7374)\n\n* Add CustomProgressBar class to exp_manager and trainer callbacks\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix the progress bar to reflect total microbatch cnt\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Modify CustomProgressBar class\n\n1) Modify CustomProgressBar class to update progress bar per global_step instead of per microbatch\n2) Add the callback to other megatron training/finetuning files that are not using MegatronTrainerBuilder\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add CustomProgressBar callback to tuning files\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Set Activation Checkpointing Defaults (#7404)\n\n* Set Activation Checkpointing Defaults\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* check for None\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* make loss mask default to false (#7407)\n\nSigned-off-by: eharper <eharper@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add dummy userbuffer config files (#7408)\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* add missing ubconf files (#7412)\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* New tutorial on Speech Data Explorer (#7405)\n\n* Added Google Colab based tutorial on Speech Data Explorer\n\nSigned-off-by: George Zelenfroynd <gzelenfroind@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Update ptl training ckpt conversion script to work with dist ckpt (#7416)\n\n* update ptl convert script\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* don't break legacy\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: eharper <eharper@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Allow disabling sanity checking when num_sanity_val_steps=0 (#7413)\n\n* Allow disabling sanity checking when num_sanity_val_steps=0\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Update num_sanity_val_steps to be a multiple of num_microbatches\n\nSigned-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nSigned-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add comprehensive error messages (#7261)\n\nSigned-off-by: Anton Peganov <apeganov@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* check NEMO_PATH (#7418)\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* layer selection for ia3 (#7417)\n\n* layer selection for ia3\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: arendu <adithyare@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix missing pip package 'einops' (#7397)\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix failure of pyaudio in Google Colab (#7396)\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Update README.md: output_path --> output_manifest_filepath (#7442)\n\nSigned-off-by: Samuele Cornell <cornellsamuele@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add rope dynamic linear scaling (#7437)\n\n* Add dynamic linear scaling\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n---------\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix None dataloader issue in PTL2.0 (#7455)\n\n* Fix None dataloader issue in PTL2.0\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* updating values of self._validation_dl and self._test_dl as well\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* updating values of self._validation_dl and self._test_dl as well\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [ASR] Confidence measure -> method renames (#7434)\n\n* measure -> method\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add steps for document of getting dataset 'SF Bilingual Speech' (#7378)\n\n* Add steps for document of getting dataset 'SF Bilingual Speech'\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Update datasets.rst\n\nadded a link from a tutorial demonstrating detailed data prep steps.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* RNN-T confidence and alignment bugfix (#7381)\n\n* new frame_confidence and alignments lists are now always created after the while loop\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n* tests added\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n---------\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix resume from checkpoint in exp_manager (#7424) (#7426)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix checking of cuda/cpu device for inputs of Decoder (#7444)\n\n* Fix checking of cuda/cpu device for inputs of Decoder\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Update tacotron2.py\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix failure of ljspeech's get_data.py (#7430)\n\n* Fix failure of ljspeech's get_data.py\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [TTS] Fix audio codec type checks (#7373)\n\n* [TTS] Fix audio codec type checks\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Fix audio codec tests\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n---------\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [\u2026"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/multimodal/data/neva/neva_dataset.py",
        "commit_date": "2024-01-19T16:11:01Z",
        "message": "Multimodal required NLP base model changes (#8188)\n\n* Base model changes\n\n* Revert \"Base model changes\"\n\nThis reverts commit 8d7fd0e86b73e2cc706d46c128896c4443f63fae.\n\n* Base model changes\n\n* Update nvgpt template\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/multimodal/data/neva/neva_dataset.py",
        "commit_date": "2023-12-13T02:12:55Z",
        "message": "Add All Multimodal Source Code (#7791)\n\n* Add comprehensive error messages (#7261)\n\nSigned-off-by: Anton Peganov <apeganov@nvidia.com>\n\n* check NEMO_PATH (#7418)\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* layer selection for ia3 (#7417)\n\n* layer selection for ia3\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: arendu <adithyare@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Fix missing pip package 'einops' (#7397)\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Fix failure of pyaudio in Google Colab (#7396)\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Update README.md: output_path --> output_manifest_filepath (#7442)\n\nSigned-off-by: Samuele Cornell <cornellsamuele@gmail.com>\n\n* Updating FlashAttention API to match FlashAttentionV2\n\n* Multiple fixes for mm\n\n* Fix CI inductor issue and update to torch compile\n\n* Remove suppress error\n\n* Fix when conversion config uses fp16 and it complains about precision plugin\n\n* Fixing FAv2 API usage\n\n* Initial release of content filtering model\n\n* Added synthetic dataloader for precached and online mode\n\n* Mingyuanm/dreambooth opt\n\n* Add llama2 support in neva training\n\n* Fix sampler length\n\n* Fix all precision issues in nemo multimodal\n\n* Add rope dynamic linear scaling (#7437)\n\n* Add dynamic linear scaling\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n---------\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\n\n* Fix None dataloader issue in PTL2.0 (#7455)\n\n* Fix None dataloader issue in PTL2.0\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* updating values of self._validation_dl and self._test_dl as well\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* updating values of self._validation_dl and self._test_dl as well\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* [ASR] Confidence measure -> method renames (#7434)\n\n* measure -> method\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Add steps for document of getting dataset 'SF Bilingual Speech' (#7378)\n\n* Add steps for document of getting dataset 'SF Bilingual Speech'\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Update datasets.rst\n\nadded a link from a tutorial demonstrating detailed data prep steps.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* RNN-T confidence and alignment bugfix (#7381)\n\n* new frame_confidence and alignments lists are now always created after the while loop\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n* tests added\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n---------\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n* Fix resume from checkpoint in exp_manager (#7424) (#7426)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix checking of cuda/cpu device for inputs of Decoder (#7444)\n\n* Fix checking of cuda/cpu device for inputs of Decoder\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Update tacotron2.py\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\n\n* Fix failure of ljspeech's get_data.py (#7430)\n\n* Fix failure of ljspeech's get_data.py\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* [TTS] Fix audio codec type checks (#7373)\n\n* [TTS] Fix audio codec type checks\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Fix audio codec tests\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n---------\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Add dataset to path of logged artifacts (#7462)\n\n* [TTS] Add dataset to path of logged artifacts\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Revert axis name back to Audio Frames\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n---------\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* Fix sft dataset truncation (#7464)\n\n* Add fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n---------\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Automatic Lip Reading Recognition (ALR) - ASR/CV (Visual ASR) (#7330)\n\n* striding_conv1d_k5 and dw_striding_conv1d_k5 subsampling\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* transpose conv1d inputs\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* Update subsampling.py\n\nchange striding_conv1d_k5 to striding_conv1d\n\nSigned-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>\n\n* cv branch\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* video manifest\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* add collection classes\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add test_step_outputs\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* correct manifest bug when having only audio or only videos\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* correct manifest bug when having only audio or only videos\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* clean references\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* freeze unfreeze transcribe cv models\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* correct manifest get_full_path bug\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* update for PR\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* guard torchvision\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Update nemo/collections/cv/data/video_to_text_dataset.py\n\nCo-authored-by: Igor Gitman <igor.a.gitman@gmail.com>\nSigned-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>\n\n* _video_speech_collate_fn in cv/data/video_to_text.py\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* add self.out = None to asr subsampling\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* Update nemo/collections/cv/data/video_to_text_dataset.py\n\nCo-authored-by: Igor Gitman <igor.a.gitman@gmail.com>\nSigned-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>\n\n* cv -> multimodal/speech_cv branch\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: mburchi <maxime.burchi@gmail.com>\nSigned-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Igor Gitman <igor.a.gitman@gmail.com>\n\n* HF StarCoder to NeMo conversion script (#7421)\n\n* Script to convert HF StarCoder checkpoint to NeMo\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* StarCoder conversion test\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Fix test\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Catch up with save_to changes\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Don't abbreviate args for clarity\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Configurable precision: BF16 vs FP32\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* fix bug when loading dist ckpt in peft (#7452)\n\nSigned-off-by: Hongbin Liu <hongbinl@nvidia.com>\nCo-authored-by: Hongbin Liu <hongbinl@nvidia.com>\n\n* Fix adding positional embeddings in-place in transformer module (#7440)\n\nSigned-off-by: Tamerlan Tabolov <tktabolov@gmail.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\n\n* Fix (#7478)\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* add sleep (#7498) (#7499)\n\n* add sleep\n\n\n\n* add sleep onto config instead\n\n\n\n* add comment\n\n\n\n---------\n\nSigned-off-by: Gerald Shen <geshen@nvidia.com>\nCo-authored-by: Gerald Shen <119401249+gshennvm@users.noreply.github.com>\n\n* Fix exp manager check for sleep (#7503) (#7504)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\n\n* bugfix: trainer.accelerator=auto from None. (#7492) (#7493)\n\nSigned-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nCo-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\n\n* [doc] fix broken link (#7481)\n\nSigned-off-by: Stas Bekman <stas00@users.noreply.github.com>\n\n* [TTS] Read audio as int32 to avoid flac read errors (#7477)\n\n* [TTS] Read audio as int32 to avoid flac read errors\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Add comment about read failures\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n---------\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS (#7409)\n\n* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS\n* Train 'AISHELL-3' dataset with multi-speakers\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Update get_data.py\n\nupdate copyright header\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Update get_data.py\n\nadded a disclaimer\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add new configuration file for AISHELL3 with multispeaker of fastpitch\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* dllogger - log on rank 0 only (#7513)\n\nSigned-off-by: Stas Bekman <stas00@users.noreply.github.com>\n\n* Fix TTS FastPitch tutorial (#7494) (#7516)\n\n* Fix\n\n---------\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\n\n* Fix get_dist() tensor dimension (#7506) (#7515)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\nCo-authored-by: Jocelyn <jocelynh@nvidia.com>\n\n* bugfix: specify trainer.strategy=auto when devices=1 (#7509) (#7512)\n\nSigned-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\n\n* fix (#7511)\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* [TTS] Fix FastPitch data prep tutorial (#7524)\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* add italian tokenization (#7486)\n\n* add italian tokenization\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add more ipa lexicon it\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix error deletion\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* add test\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Replace None strategy with auto in tutorial notebooks (#7521) (#7527)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\n\n* unpin setuptools (#7534) (#7535)\n\nSigned-off-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\n\n* remove auto generated examples (#7510)\n\n* explicitly remove autogenerated examples for data parallel evaluation\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* mark autogenrated and remove it for test\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: arendu <adithyare@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Add the `strategy` argument to `MegatronGPTModel.generate()` (#7264)\n\nIt is passed as an explicit argument rather than through\n`**strategy_args` so as to ensure someone cannot accidentally pass other\narguments that would end up being ignored.\n\nIt is a keyword-only argument to ensure that if in the future we want to\nupdate the signature to `**strategy_args`, we can do it without breaking\ncode.\n\nSigned-off-by: Olivier Delalleau <507137+odelalleau@users.noreply.github.com>\n\n* Fix PTL2.0 related ASR bugs in r1.21.0: Val metrics logging, None dataloader issue (#7531) (#7533)\n\n* fix none dataloader issue ptl2\n\n\n\n* ptl2.0 logging fixes for rnnt_models\n\n\n\n---------\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\nCo-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\n\n* gpus -> devices (#7542) (#7545)\n\nSigned-off-by: Nithin Rao Koluguri <nithinraok>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\n\n* Update FFMPEG version to fix issue with torchaudio (#7551) (#7553)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\n\n* PEFT GPT & T5 Refactor (#7308)\n\n* initial implementation of add_adapters API\n\n* correct type hint\n\n* Add config in add_adapters for save and load (@author bobchen)\n\n* Remove AdapterConfig to avoid import error\n\n* Add AdaterConfig back and move adaptermixin to sft model\n\n* Add NLPSaveRestoreConnector as default in NLPModel.restore_from\n\n* Add restore_from_nemo_with_adapter and test script\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* rename t5 file and classes to be consistent with GPT\n\n* add t5 sft dataset\n\n* add support for single-file format with T5SFTDataset\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Various small changes to make T5 SFT work like GPT SFT\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add adapter evaluation test script\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add MultiAdaterConfig for ia3 and fix builder issue\n\n* Make ptuning for T5SFTModel work using mixin\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add IA3_Adapter for AdapterName\n\n* Add adapter name for ptuning and attention adapter\n\n* Make test script GPT/T5 agnostic\n\n* Add layer selection feature\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Integrate adapter name and config\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update gpt peft tuning script to new API\n\n* add t5 peft tuning script with new API\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix IA3 layer selection issue\n\n* Override state_dict on SFT model instead of mixin\n\n* Add load adapter by adapter config\n\n* move peft config map away from example script\n\n* auto get config from nemo adapter\n\n* Move PEFTConfig to new file\n\n* fix ckpt save/load for t5\n\n* name change: add_adapters -> add_adapter\n\n* variable name change\n\n* update t5 script\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix t5 issues\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add weight tying\n\n* update gpt tuning script\n\n* PEFT-API proposal\n\n* Fix according to comments\n\n* update tuning scripts\n\n* move merge_cfg_with to mixin class since it applies to both gpt and t5 and requires the model class for restore\n\n* Add mcore_gpt support for NLPAdapterMixin\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix typo\n\n* variable name change to distinguish \"peft\" and \"adapter\"\n\n* override `load_adapters` to support `add_adapter` name change\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update tuning and eval script for adapter save/load\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add Ptuning on first stage only\n\n* add lora tutorial for review\n\n* Fix layer selection for mcore\n\n* add landing page\n\n* fix resume training\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add mcore condition in sharded_state_dict to make sft work\n\n* Update lora_tutorial.md\n\nFirst edit of this file for PEFT documentation for NeMO\n\nSigned-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>\n\n* rename Adapter to AttentionAdapter to avoid confusion in doc\n\n* Change load_adapters to load .nemo\n\n* add quick start guide\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add load_adapters with .ckpt\n\n* Remove setup_complete changes in load_adapters\n\n* update landing page\n\n* remove typo\n\n* Updated quick_start.md per Chen Cui\n\nSigned-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>\n\n* Add inference config merger and tutorial\n\n* Add doc string for NLPAdapterModelMixin and deprecated warning on MegatronGPTPEFTModel\n\n* add supported_methods.md and update other documentations\n\n* Update supported_methods.md\n\nminor updates.\n\nSigned-off-by: Adi Renduchintala <adithyare@nvidia.com>\n\n* Update landing_page.md\n\nminor update.\n\nSigned-off-by: Adi Renduchintala <adithyare@nvidia.com>\n\n* Modify doc string for NLPAdapterModelMixin\n\n* Add doc string add_adapters in NLPAdapterModelMixin\n\n* rename canonical adapters\n\n* remove mcore hard dependency\n\n* [PATCH] move microbatch calculator to nemo from apex\n\n* remove apex dependency in gpt and t5 sft models\n\n* remove apex dependency in gpt model\n\n* render doc strings\n\n* fix\n\n* Add missing virtual_tokens on ptuning\n\n* fix docstrings\n\n* update gpt-style model coverage in docs\n\n* update docstring\n\n* Remove pdb\n\n* add lightning_fabric to make docstring rendering work\n\n* Add Ptuning missing key\n\n* try docstring rendering\n\n* Fix ptuning issue\n\n* update gpt t5 peft tuning and eval scripts\n\n* typos\n\n* update eval config\n\n* fix bug relating to apex dependency removal\n\n* typo\n\n* make predict step behave the same as test step\n\n* make lora tutorial work in notebook\n\n* cosmetics\n\n* update yaml scripts\n\n* mcore_gpt attribute optional\n\n* typo\n\n* update eval scripts and fix T5 eval bugs\n\n* add NLPDDPStrategyNotebook and trainer builder logic to use it\n\n* update lora notebook to use new trainer builder\n\n* fix microbatch calculator bug for inference after training\n\n* Convert markdown files to RST and incorporate with doc\n\n* typo\n\n* revise language\n\n* remove extra cell\n\n* remove unnecessary inheritance\n\n* remove old tests\n\n* move layer selection default so logging messages make sense\n\n* remove `save_adapters` as adapter weights are saved automatically during training\n\n* initialize weights from a checkpoint instead of randomly\n\n* multiple fields can form a context (#7147)\n\n* list of context fields and flexible prompt template\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* list of fields for context\n\nSigned-off-by: arendu <adithya.r@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Add multiple truncation fields and middle truncation\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Compatible to old ckpt\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix tokenize detokenize issue\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Remove detokenization, add truncation augmentation\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Resolve comments\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Remove unused import\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* revert eos\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Add tokenizer space_sensitive attribute\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix error\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Fix erorr and use re\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Change assert logic\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Follow adi suggestion\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Remove merge function\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add example and comment\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Remove context_key and add comment\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* Remove random truncation\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix template none\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n---------\n\nSigned-off-by: arendu <adithya.r@gmail.com>\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nSigned-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\n\n* revert config changes\n\n* remove accidental breakpoint\n\n* support TP>1 loading\n\n* infer adapter type from checkpoint in during eval\n\n* breakup add adapter\n\n* enable interpolation of train_ds and validation_ds\n\n* update metric calc script to conform to single-file eval format\n\n* remove extraneous print\n\n* update lora notebook for updated merge_inference_cfg\n\n* Update nlp_adapter_mixins.py\n\nvariable name change\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* turn off grad scaler for PP to match old scripts\n\n* remove PEFTSaveRestoreConnector since functionality all covered by the new mixin class\n\n* remove resume_from_checkpoint check since covered in #7335\n\n* revert changes made in eval config interpolation\n\n* more interpolation\n\n* typo\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* remove dup line\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* code style warnings\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix config mistake\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* add copyright header\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* fix code check warnings\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* revert changes to remove apex dependency (mixed apex+nemo microbatch calculator broke some CI tests)\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add more deprecation notices\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* update deprecation notices\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* update deprecation notices\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* consolidate peft and sft scripts\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* update CI tests\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* notebook branch points to main to prepare for merge\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* fix gpt and t5 validation with any metric other than loss\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* support pre-extracted checkpoints\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n---------\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\nSigned-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>\nSigned-off-by: Adi Renduchintala <adithyare@nvidia.com>\nSigned-off-by: arendu <adithya.r@gmail.com>\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nSigned-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\nSigned-off-by: Chen Cui <chcui@nvidia.com>\nCo-authored-by: Chen Cui <chcui@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Marc Romeyn <marcromeyn@gmail.com>\nCo-authored-by: jasonwan <jasonwan@nvidia.com>\nCo-authored-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>\nCo-authored-by: Adi Renduchintala <adithyare@nvidia.com>\nCo-authored-by: Yuanzhe Dong <yudong@nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\n\n* fix a typo (#7496)\n\nSigned-off-by: BestJuly <chntaoli@163.com>\n\n* [TTS] remove curly braces from ${BRANCH} in jupyer notebook cell. (#7554) (#7560)\n\n* remove curly braces.\n* remove installation of pynini.\n---------\n\nSigned-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\n\n* add youtube embed url (#7570)\n\nSigned-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nCo-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\n\n* Remap speakers to continuous range of speaker_id for dataset AISHELL3 (#7536)\n\n* Remap speakers to continuous range of speaker_id for dataset AISHELL3\n* Add new key/value pair to record raw speaker for AISHELL3 dataset\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* fix validation_step_outputs initialization for multi-dataloader (#7546) (#7572)\n\n* added correct validation_step_outputs initialization for mutli-dataloader\n\n\n\n* changed kernel for display\n\n\n\n* Update logic for validation and test step outputs\n\n\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* revert multidataloader changes in multilang ASR notebook\n\n\n\n---------\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Append output of val step to self.validation_step_outputs (#7530) (#7532)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\n\n* [TTS] fixed trainer's accelerator and strategy. (#7569) (#7574)\n\nSigned-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>\n\n* Append val/test output to instance variable in EncDecSpeakerLabelModel (#7562) (#7573)\n\n* Append val/test output to the instance variable in EncDecSpeakerLabelModel\n\n\n\n* Handle test case in evaluation_step\n\n\n\n* Replace type with isinstance\n\n\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\n\n* Fix CustomProgressBar for resume (#7427) (#7522)\n\n* Fix CustomProgress Bar for resume and multiple epochs\n\n\n\n* Edit num_training_batches\n\n\n\n* Use max_steps as total for progress bar for resume\n\n\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* fix typos in nfa and speech enhancement tutorials (#7580) (#7583)\n\nSigned-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>\nCo-authored-by: Elena Rastorgueva <80532067+erastorgueva-nv@users.noreply.github.com>\n\n* Add strategy as ddp_find_unused_parameters_true for glue_benchmark.py (#7454) (#7461)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\n\n* update strategy (#7577) (#7578)\n\nSigned-off-by: Nithin Rao Koluguri <nithinraok>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\n\n* Fix typos (#7581)\n\n* Change hifigan finetune strategy to ddp_find_unused_parameters_true (#7579) (#7584)\n\n* Change strategy to auto\n\n\n\n---------\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>\n\n* [BugFix] Add missing quotes for auto strategy in tutorial notebooks (#7541) (#7548)\n\n* Add missing quotes for auto strategy\n\n\n\n* Revert trainer.gpus to trainer.devices in Self_Supervised_Pre_Training.ipynb\n\n\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nSigned-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\n\n* add build os key (#7596) (#7599)\n\n* add build os key\n\n\n\n* add tools\n\n\n\n* update to stable version\n\n\n\n---------\n\nSigned-off-by: Nithin Rao Koluguri <nithinraok>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\n\n* StarCoder SFT test + bump PyT NGC image to 23.09 (#7540)\n\n* Add SFT StarCoder test\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Remove _modify_config call as it is covered in load_from_nemo just below\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* Test with pyt:23.09 container\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n---------\n\nSigned-off-by: Jan Lasek <janek.lasek@gmail.com>\n\n* defaults changed (#7600)\n\n* defaults changed\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* typo\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* update\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n---------\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* add ItalianPhonemesTokenizer (#7587)\n\n* add ItalianPhonemesTokenizer\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix Italian phonemes\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add test\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\n\n---------\n\nSigned-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* best ckpt fix (#7564) (#7588)\n\nSigned-off-by: dimapihtar <dpihtar@gmail.com>\nCo-authored-by: Dmytro Pykhtar <37850217+dimapihtar@users.noreply.github.com>\n\n* Add files via upload (#7598)\n\nspecifies the branch\n\nSigned-off-by: George <37293288+Jorjeous@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Fix validation in G2PModel and ThutmoseTaggerModel (#7597) (#7606)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\n\n* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain (#7576) (#7586)\n\n* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Safeguard nemo_text_processing installation on ARM (#7485)\n\n* safeguard nemo_text_processing installing\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update check\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n---------\n\nSigned-off-by: Jason <jasoli@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Bound transformers version in requirements (#7620)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* fix llama2 70b lora tuning bug (#7622)\n\n* fix llama2 70b lora tuning bug\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* Update peft_config.py\n\nbrackets\n\nSigned-off-by: Adi Renduchintala <adithyare@nvidia.com>\n\n---------\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\nSigned-off-by: Adi Renduchintala <adithyare@nvidia.com>\nCo-authored-by: Adi Renduchintala <adithyare@nvidia.com>\n\n* Fix import error no module name model_utils (#7629)\n\nSigned-off-by: Mehadi Hasan Menon <mehadihasan80@gmail.com>\n\n* add fc large ls models (#7641)\n\nSigned-off-by: Nithin Rao Koluguri <nithinraok>\nCo-authored-by: Nithin Rao Koluguri <nithinraok>\n\n* bugfix: trainer.gpus, trainer.strategy, trainer.accelerator (#7621) (#7642)\n\n* [TTS] bugfix for Tacotron2 tutorial due to PTL 2.0\n* trainer.gpus -> trainer.devices\n* fixed related tutorial bugs\n---------\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* fix ssl models ptl monitor val through logging (#7608) (#7614)\n\nSigned-off-by: Nithin Rao Koluguri <nithinraok>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Fix metrics for SE tutorial (#7604) (#7612)\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>\nCo-authored-by: anteju <108555623+anteju@users.noreply.github.com>\n\n* Add ddp_find_unused_parameters=True and change accelerator to auto (#7623) (#7644)\n\n* Add ddp_find_unused_parameters=True and change acclerator to auto\n\n\n\n* Add ddp_find_unused_parameters True for normalization_as_tagging_train.py\n\n\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\n\n* Fix py3.11 dataclasses issue  (#7616)\n\n* Fix py3.11 dataclasses issue  (#7582)\n\n* Update ASR configs to support Python 3.11\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update TTS configs to support Python 3.11\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Guard MeCab and Ipadic\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix remaining ASR dataclasses\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix remaining ASR dataclasses\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix scripts\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Update name to ConfidenceMethodConfig\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain (#7576) (#7586)\n\n* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Safeguard nemo_text_processing installation on ARM (#7485)\n\n* safeguard nemo_text_processing installing\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update check\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n---------\n\nSigned-off-by: Jason <jasoli@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Fix changes to confidence measure\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\nSigned-off-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: github-actions[bot] <41898282+github-actions[bot]@users.noreply.github.com>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\n\n* [Stable Diffusion/ControlNet] Enable O2 training for SD and Fix ControlNet CI failure\n\n* Mingyuanm/dreambooth fix\n\n* Fix NeMo CI Infer Issue\n\n* DreamFusion\n\n* Move neva export changes\n\n* Add Imagen Synthetic Dataloader\n\n* Add VITWrapper and export stuff to wrapper\n\n* Update neva with megatron-core support\n\n* Fix issues with Dockerfile (#7650) (#7652)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\n\n* [ASR] RNN-T greedy decoding max_frames fix for alignment and confidence (#7635)\n\n* decoding and test fix\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* [ASR] Fix type error in jasper (#7636) (#7653)\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\nCo-authored-by: Ryan Langman <rlangman@nvidia.com>\n\n* [TTS] Add STFT and SI-SDR loss to audio codec recipe (#7468)\n\n* [TTS] Add STFT and SI-SDR loss to audio codec recipe\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Fix STFT resolution\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Fix training metric logging\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Add docstring to mel and stft losses\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Create per.py (#7538)\n\n* Move model precision copy (#7336)\n\n* move cfg precision set to megatron base model\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* remove copy from other models\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* modify attribute not arg\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* fix gpt model test for ptl 2.0\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* rename function and add docstring\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* replace precision to dtype conditionals with func call\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* unnecessary function and cfg reset\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* set default value\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* fix precision lookup in a few more places\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* rename mapping function\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* ununsed import\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* save torch datatype to model\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* set weights precision wrt amp o2\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* Revert \"set weights precision wrt amp o2\"\n\nThis reverts commit 313a4bfe5eb69d771a6d2433898c0685836aef5c.\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* revert half precision at inference attempt\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* move autocast dtype to base model\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* move params dtype to base model, enable fp16 O2 inf\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* unused imports\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n---------\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix PEFT checkpoint loading (#7388)\n\n* Fix PEFT checkpoint loading\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Use distributed optimizer support for multiple dtypes (#7359)\n\n* Update distopt wrapper with multiple dtype support\n\nRemove manual handling of separate FP32 optimizer.\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Use distopt support for contiguous buffers with multiple dtypes\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Fix typo\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Separate distopt buckets for first GPT layer and non-overlapped params\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Add distopt logic for int dtypes\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Update Apex commit\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Remove unused variables\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Update Apex commit in README and Jenkensfile\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n* Debug Dockerfile and Jenkinsfile\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\n\n---------\n\nSigned-off-by: Tim Moon <tmoon@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* minor fix for llama ckpt conversion script (#7387)\n\n* minor fix for llama ckpt conversion script\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* Update Jenkinsfile\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* remove fast_swiglu configuration\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n---------\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix wrong calling of librosa.get_duration() in notebook (#7376)\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [PATCH] PEFT import mcore (#7393)\n\n* [PATCH] PEFT import mcore\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Jason Wang <jasonwan@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Create per.py\n\nScript for calculation Punctuation Error Rate and related rates (correct rate, deletions rate, etc.)\n\nSigned-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [TTS] Added a callback for logging initial data (#7384)\n\nSigned-off-by: Ante Jukic\u0301 <ajukic@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Update Core Commit (#7402)\n\n* Update Core Commit\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* update commit\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n---------\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Use cfg attribute in bert (#7394)\n\n* use cfg attribute instead of arg\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* use torch_dtype in place of cfg.precision\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* move precision copy before super constructor\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n* use trainer arg\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\n\n---------\n\nSigned-off-by: Maanu Grover <maanug@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add support for bias conversion in Swiglu models (#7386)\n\n* Add support for bias conversion in Swiglu models\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add support for auto extracting tokenizer model\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add support for auto extracting tokenizer model\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix issue with missing tokenizer\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Refactor\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Refactor\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Update save_to and restore_from for dist checkpointing (#7343)\n\n* add dist ckpt to save to, in progress\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* move dist ckpt\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* clean up\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update restore from, need to figure out how to initialize distributed\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* launch distrib if needed when restoring dist ckpt\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* when using mcore we can change tp pp on the fly\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* add load_from_checkpoint support for dist ckpt\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update llama convert script to save dist .nemo\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* fix load dist ckpt\n\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* setup TE TP groups if needed\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* setup te tp groups if needed\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* remove import\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n---------\n\nSigned-off-by: eharper <eharper@nvidia.com>\nSigned-off-by: jasonwan <jasonwan@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: jasonwan <jasonwan@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* fix forward for with mcore=false (#7403)\n\nSigned-off-by: Jimmy Zhang <jiemingz@nvidia.com>\nCo-authored-by: Jimmy Zhang <jiemingz@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix logging to remove 's/it' from progress bar in Megatron models and add train_step_timing (#7374)\n\n* Add CustomProgressBar class to exp_manager and trainer callbacks\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix the progress bar to reflect total microbatch cnt\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Modify CustomProgressBar class\n\n1) Modify CustomProgressBar class to update progress bar per global_step instead of per microbatch\n2) Add the callback to other megatron training/finetuning files that are not using MegatronTrainerBuilder\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Add CustomProgressBar callback to tuning files\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Set Activation Checkpointing Defaults (#7404)\n\n* Set Activation Checkpointing Defaults\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* check for None\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* make loss mask default to false (#7407)\n\nSigned-off-by: eharper <eharper@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add dummy userbuffer config files (#7408)\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* add missing ubconf files (#7412)\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* New tutorial on Speech Data Explorer (#7405)\n\n* Added Google Colab based tutorial on Speech Data Explorer\n\nSigned-off-by: George Zelenfroynd <gzelenfroind@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Update ptl training ckpt conversion script to work with dist ckpt (#7416)\n\n* update ptl convert script\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* don't break legacy\n\nSigned-off-by: eharper <eharper@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: eharper <eharper@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Allow disabling sanity checking when num_sanity_val_steps=0 (#7413)\n\n* Allow disabling sanity checking when num_sanity_val_steps=0\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\n\n* Update num_sanity_val_steps to be a multiple of num_microbatches\n\nSigned-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nSigned-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add comprehensive error messages (#7261)\n\nSigned-off-by: Anton Peganov <apeganov@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* check NEMO_PATH (#7418)\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* layer selection for ia3 (#7417)\n\n* layer selection for ia3\n\nSigned-off-by: arendu <adithyare@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: arendu <adithyare@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix missing pip package 'einops' (#7397)\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix failure of pyaudio in Google Colab (#7396)\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Update README.md: output_path --> output_manifest_filepath (#7442)\n\nSigned-off-by: Samuele Cornell <cornellsamuele@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add rope dynamic linear scaling (#7437)\n\n* Add dynamic linear scaling\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix bug\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\n\n---------\n\nSigned-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix None dataloader issue in PTL2.0 (#7455)\n\n* Fix None dataloader issue in PTL2.0\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* updating values of self._validation_dl and self._test_dl as well\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* updating values of self._validation_dl and self._test_dl as well\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: KunalDhawan <kunaldhawan97@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [ASR] Confidence measure -> method renames (#7434)\n\n* measure -> method\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Add steps for document of getting dataset 'SF Bilingual Speech' (#7378)\n\n* Add steps for document of getting dataset 'SF Bilingual Speech'\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Update datasets.rst\n\nadded a link from a tutorial demonstrating detailed data prep steps.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* RNN-T confidence and alignment bugfix (#7381)\n\n* new frame_confidence and alignments lists are now always created after the while loop\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n* tests added\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\n\n---------\n\nSigned-off-by: Aleksandr Laptev <alaptev@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix resume from checkpoint in exp_manager (#7424) (#7426)\n\nSigned-off-by: Abhishree <abhishreetm@gmail.com>\nCo-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix checking of cuda/cpu device for inputs of Decoder (#7444)\n\n* Fix checking of cuda/cpu device for inputs of Decoder\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* Update tacotron2.py\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nSigned-off-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* Fix failure of ljspeech's get_data.py (#7430)\n\n* Fix failure of ljspeech's get_data.py\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Robin Dong <robin.k.dong@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nSigned-off-by: Sasha Meister <sasha.meister.work@gmail.com>\n\n* [TTS] Fix audio codec type checks (#7373)\n\n* [TTS] Fix audio codec type checks\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n* [TTS] Fix audio codec tests\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\n\n---------\n\nSigned-off-by: Ryan <rlangman@nvidia.com>\nSigne\u2026"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "scripts/asr_language_modeling/ngram_lm/ngram_merge.py",
        "commit_date": "2023-07-14T09:24:14Z",
        "message": "rnnt and char utils (#6971)\n\n* rnnt_ngram_merge\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* char level bug\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "scripts/asr_language_modeling/ngram_lm/ngram_merge.py",
        "commit_date": "2023-05-04T16:57:47Z",
        "message": "Make KenLM with PC for AggregateTokenizer and merge it (#6081)\n\n* do_lowercase, rm_punctuation\n\nSigned-off-by: Nikolay Karpov <nkarpov@nvidia.com>\n\n* support beam_strategy = beam\n\nSigned-off-by: Nikolay Karpov <nkarpov@nvidia.com>\n\n* black\n\nSigned-off-by: Nikolay Karpov <nkarpov@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix config and^Cunctuation capitalization\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* rm math\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* update kenlm\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* black\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add opengrm\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* mv install_beamsearch_decoders\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* punctuation_to_preserve\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Only tikenizer opion\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* Black\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* DEFAULT_TOKEN_OFFSET\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* aggregate_tokenizer\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* install kenlm with more than 5gram\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* install_beamsearch_decoders\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* ngram_bin_path kenlm_bin_path\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* black\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* fix greedy PC bug\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* move global params\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* fix description and perplexity\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* fix description\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* NEMO_PATH\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* nemo:23.01\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* License\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* description\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* isinstance\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* refactor kenlm stdin\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* black\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* add cmd arg\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* use new iter_files\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* EncDecHybridRNNTCTCModel\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* punctuation\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* train_kenlm args\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* add docstrings\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add ngram_merge docs\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* ngram_prune\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rename to ngram_merge\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rename to ngram\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* add comments\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* Ngram\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* nemo_model_file\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* install_opengrm_ngram\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* install opengrm\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rename to install_opengrm.sh\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rm extra import\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* train_paths\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* text_processing\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* fix ngram_bin_path\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* DECODERS_PATH\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* farcompile\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rm text processing\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* text_processing\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* AggregateTokenizer.DummyTokenizer\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* comments\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* TextProcessingConfig\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* typo\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* doc\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* types\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* nemo_model_file\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rm assert\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* import kenlm_utils\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* return None\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* Copyright\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* 2022\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* 2023\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n---------\n\nSigned-off-by: Nikolay Karpov <nkarpov@nvidia.com>\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\nCo-authored-by: Nikolay Karpov <nkarpov@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "scripts/asr_language_modeling/ngram_lm/kenlm_utils.py",
        "commit_date": "2023-07-14T09:24:14Z",
        "message": "rnnt and char utils (#6971)\n\n* rnnt_ngram_merge\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* char level bug\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "scripts/asr_language_modeling/ngram_lm/kenlm_utils.py",
        "commit_date": "2023-05-04T16:57:47Z",
        "message": "Make KenLM with PC for AggregateTokenizer and merge it (#6081)\n\n* do_lowercase, rm_punctuation\n\nSigned-off-by: Nikolay Karpov <nkarpov@nvidia.com>\n\n* support beam_strategy = beam\n\nSigned-off-by: Nikolay Karpov <nkarpov@nvidia.com>\n\n* black\n\nSigned-off-by: Nikolay Karpov <nkarpov@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix config and^Cunctuation capitalization\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* rm math\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* update kenlm\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* black\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add opengrm\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* mv install_beamsearch_decoders\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* punctuation_to_preserve\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Only tikenizer opion\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* Black\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* DEFAULT_TOKEN_OFFSET\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* aggregate_tokenizer\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* install kenlm with more than 5gram\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* install_beamsearch_decoders\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* ngram_bin_path kenlm_bin_path\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* black\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* fix greedy PC bug\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* move global params\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* fix description and perplexity\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* fix description\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* NEMO_PATH\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* nemo:23.01\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* License\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* description\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* isinstance\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* refactor kenlm stdin\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* black\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* add cmd arg\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* use new iter_files\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* EncDecHybridRNNTCTCModel\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* punctuation\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* train_kenlm args\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* add docstrings\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add ngram_merge docs\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* ngram_prune\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rename to ngram_merge\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rename to ngram\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* add comments\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* Ngram\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* nemo_model_file\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* install_opengrm_ngram\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* install opengrm\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rename to install_opengrm.sh\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rm extra import\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* train_paths\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* text_processing\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* fix ngram_bin_path\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* DECODERS_PATH\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* farcompile\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rm text processing\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* text_processing\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* AggregateTokenizer.DummyTokenizer\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* comments\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* TextProcessingConfig\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* typo\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* doc\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* types\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* nemo_model_file\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* rm assert\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* import kenlm_utils\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* return None\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* Copyright\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* 2022\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n* 2023\n\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\n\n---------\n\nSigned-off-by: Nikolay Karpov <nkarpov@nvidia.com>\nSigned-off-by: Nikolay Karpov <karpnv@gmail.com>\nCo-authored-by: Nikolay Karpov <nkarpov@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "scripts/asr_language_modeling/ngram_lm/kenlm_utils.py",
        "commit_date": "2023-03-14T16:26:08Z",
        "message": "Ngram lm fusion for RNNT maes decoding (#6118)\n\n* add parameters for ngram_lm\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add parameters for ngram lm\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add RNNT model types for kenlm training\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add ngram lm fusion to maes decoding mode\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add a script for the rnnt beam search decoding with a ngram lm fusion for maes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* minor fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* minor fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix autocast\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* typing fix\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* minor fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add set_decoding_type function\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* remove tokens_type\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* remove tokens_type from config\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* import token_offset from train_kenlm\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add DEFAULT_TOKEN_OFFSET variable\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix applying token_offset for char models\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* fixe copyright year\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* leave DEFAULT_TOKEN_OFFSET only\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n---------\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "scripts/asr_language_modeling/ngram_lm/kenlm_utils.py",
        "commit_date": "2022-01-31T22:20:29Z",
        "message": "Final merge r1.6.0 main (#3570)\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix the tutorial notebooks bug (#3465)\n\n* fix checkpoint loading and model config file\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix style\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* Fix checkpoint converter in O2 style (#3486)\n\n* Fix checkpoint converter in O2 style\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Fix style\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\nCo-authored-by: Yu Yao <yuya@nvidia.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Remove pickled features from tarred dataset (#3491)\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\nCo-authored-by: ekmb <ebakhturina@nvidia.com>\n\n* adding missing init files (#3505)\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* typos (#3504)\n\n* typos\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* link fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* update titanet conf (#3507)\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* Fix link to NGC page for ASR (#3512)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* vad typo fix (#3490)\n\n* remove always broken ptl link\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* fix typo\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* Add verification helper function and update docs (#3514)\n\n* Add verification helper function and update docs\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* typo fixes\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* fixed the num_classes bug of conv decoder. (#3525)\n\n* fixed the num_classes bug.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added logging info.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* Enforce utf-8 on all file r/w (#3520)\n\n* Update paths to subtask\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Enforce utf-8 on all file r/w\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fixed section typo (#3522)\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Pushing updated WFST Tutorial to r1.6.0 (#3521)\n\nSigned-off-by: tbartley94 <tbartley@nvidia.com>\n\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\n\n* Fixed duplicate cell bug (#3518)\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* WFST tutorial update (#3531)\n\n* Pushing updated WFST Tutorial to r1.6.0\n\nSigned-off-by: tbartley94 <tbartley@nvidia.com>\n\n* Hopefully final corrections to WFST tutorials.\n\nSigned-off-by: tbartley94 <tbartley@nvidia.com>\n\n* [TTS] Fix bug in inference tts notebook (#3532)\n\n* fix bug in inference tts notebook\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* Update Inference_ModelSelect.ipynb\n\n* fix space\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* remove space\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* Prompt tuning documentation (#3541)\n\n* Started prompt tuning doc\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Update prompt_tuning.rst\n\n* Update models.rst\n\n* Update models.rst\n\n* Update and rename megatron_finetuning.rst to megatron_downstream_tasks.rst\n\n* Update intro.rst\n\n* Update intro.rst\n\n* Update and rename megatron_downstream_tasks.rst to megatron_finetuning.rst\n\n* Update megatron_finetuning.rst\n\n* Delete prompt_tuning.rst\n\n* Update README.rst\n\n* Update docs/source/nlp/megatron_finetuning.rst\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix nmt resume (#3539)\n\n* check for model attr\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* TN bug fix (#3538)\n\n* ve and cel fixes\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* ve and cel fixes\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add w to single digit roman and cardinal single digit graph (non det)\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* isn't fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* fix bug in tutorial (#3546)\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* Update nvidia container check (#3535)\n\n* update nvidia container check\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update minor version\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add check to T5\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update bert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* forgot import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix an issue with wandb not displaying updated config changes (#3552)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* remove extra instance (#3551)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Yi Dong <43824965+yidong72@users.noreply.github.com>\nCo-authored-by: yaoyu-33 <54727607+yaoyu-33@users.noreply.github.com>\nCo-authored-by: Yu Yao <yuya@nvidia.com>\nCo-authored-by: PeganovAnton <peganoff2@mail.ru>\nCo-authored-by: ekmb <ebakhturina@nvidia.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: Vahid Noroozi <VahidooX@users.noreply.github.com>\nCo-authored-by: Virginia Adams <78445382+vadam5@users.noreply.github.com>\nCo-authored-by: tbartley94 <90423858+tbartley94@users.noreply.github.com>\nCo-authored-by: Oktai Tatanov <oktai.tatanov@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "scripts/asr_language_modeling/ngram_lm/kenlm_utils.py",
        "commit_date": "2021-04-23T01:51:48Z",
        "message": "Fixing the docs of LM for ASR models. (#2096)\n\n* fixed the doc.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed the doc.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed the doc.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed the doc.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed the doc.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed the doc.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* changed modelling to modeling.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tools/ctc_segmentation/scripts/run_ctc_segmentation.py",
        "commit_date": "2024-02-06T21:12:13Z",
        "message": "ASR Transcription Refactor (#8167)\n\n* Temp commit\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Temp transcription api file\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Initial draft of transcribable API\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Udpate ASR nd Classiication model transcription functions\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Commit draft - works on CTC/RNNT/Hybrid/SpeechClassification\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Upate transcription tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix minor typos\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Update tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Try reverting numba fix\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Revert patch\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Formatting\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add full support for tensor input to model.transcribe()\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Make BS 2 for mixed tensor inference\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update return type signature and add return type tests. Fix decoder_timestamps_utils.py\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix cast to numpy\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update transcribe speech script\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix signature to transcribe()\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Address comments, fix issues with paths2audio_files\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix typo\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix logprobs signature for ctc segmentation\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Address comments\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Address comments and add docs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Remove old logprobs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix issues with regression model and add regression config. Remove `return_generator` arg\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add AED tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add support for Canary models\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Refactor prompt format for lhotse\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tools/ctc_segmentation/scripts/run_ctc_segmentation.py",
        "commit_date": "2022-09-30T20:06:11Z",
        "message": "Bug fixes for parallel mp3 to wav conversion, PC notebook, update Readme for TN requirements (#5047) (#5053)\n\n* bug fixes segmenation, pc\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* bug fixes segmenation, pc\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* install pynini\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add requirements install back\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* update sox requirements\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tools/ctc_segmentation/scripts/run_ctc_segmentation.py",
        "commit_date": "2022-01-06T21:03:39Z",
        "message": "CTC Segmentation-Citrinet support (#3279)\n\n* segmentation package update\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* update logs\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* tutorial\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* tutorial update\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* update tutorial\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* header\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* lgtm\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins reqs installed\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* review\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add num_workers to transcribe, fix oov pre-processing\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* num_workers default\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* docstrings\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* review\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* lgmt\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tools/ctc_segmentation/scripts/run_ctc_segmentation.py",
        "commit_date": "2021-04-22T21:55:01Z",
        "message": "Adding N-gram LM for ASR Models (#2066)"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tools/ctc_segmentation/scripts/run_ctc_segmentation.py",
        "commit_date": "2020-12-11T22:48:59Z",
        "message": "segmentation (#1529)\n\n* expanded normalization helpers\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* wip\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* wip\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* wip\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* wip\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* wip\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* additional split symbols exposed\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* split condition fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix in add split symbols\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins test added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* text update\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* notebook jupyter upgrade cmd added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* install requirements\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* test\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* ffmped install\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* rearrange steps\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* rearrange steps\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* test\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* test\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* test\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* restart ci\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* restart ci\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* restart ci\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* file name update\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* prefix=0\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* separator\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* refactor\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* notebook reqs\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* replace\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* restart ci\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tools/ctc_segmentation/scripts/run_ctc_segmentation.py",
        "commit_date": "2020-11-13T22:55:22Z",
        "message": "Dataset creation tool based on CTC-segmentation (#1450)\n\nDataset creation tool based on CTC-segmentation\nSigned-off-by: ekmb <ebakhturina@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/decoder_timestamps_utils.py",
        "commit_date": "2024-02-06T21:12:13Z",
        "message": "ASR Transcription Refactor (#8167)\n\n* Temp commit\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Temp transcription api file\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Initial draft of transcribable API\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Udpate ASR nd Classiication model transcription functions\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Commit draft - works on CTC/RNNT/Hybrid/SpeechClassification\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Upate transcription tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix minor typos\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Update tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Try reverting numba fix\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Revert patch\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Formatting\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Add full support for tensor input to model.transcribe()\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Make BS 2 for mixed tensor inference\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update return type signature and add return type tests. Fix decoder_timestamps_utils.py\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix cast to numpy\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update transcribe speech script\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix signature to transcribe()\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Address comments, fix issues with paths2audio_files\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix typo\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix logprobs signature for ctc segmentation\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Address comments\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Address comments and add docs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Remove old logprobs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix issues with regression model and add regression config. Remove `return_generator` arg\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add AED tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add support for Canary models\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Refactor prompt format for lhotse\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/decoder_timestamps_utils.py",
        "commit_date": "2024-01-05T23:45:52Z",
        "message": "Wer fix (#8047)\n\n* WER metric reformatting + AST transformer fix.\n\nSigned-off-by: Travis Bartley <tbartley@nvidia.com>\n\n* fixing tests for new WER\n\nSigned-off-by: Travis Bartley <tbartley@nvidia.com>\n\n* Adding getter and fixing tutorial formats\n\nSigned-off-by: Travis Bartley <tbartley@nvidia.com>\n\n* Adding in fold_consecutive flag for WER, also adding check for proper decoding types\n\nSigned-off-by: Travis Bartley <tbartley@nvidia.com>\n\n* Catching some jenkins bugs\n\nSigned-off-by: Travis Bartley <tbartley@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fixing ctc_decoding variable assignment\n\nSigned-off-by: Travis Bartley <tbartley@nvidia.com>\n\n* Broke a test, fixing\n\nSigned-off-by: Travis Bartley <tbartley@nvidia.com>\n\n* variable fix\n\nSigned-off-by: Travis Bartley <tbartley@nvidia.com>\n\n* Found missed ctc import for diarization_with_asr\n\nSigned-off-by: Travis Bartley <tbartley@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Got too excited, forgot to style check\n\nSigned-off-by: Travis Bartley <tbartley@nvidia.com>\n\n* I have found yet more references to old ctc_decoding\n\nSigned-off-by: Travis Bartley <tbartley@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Variable fixes for tutorials, tts, and speech_cv modules\n\nSigned-off-by: Travis Bartley <tbartley@nvidia.com>\n\n---------\n\nSigned-off-by: Travis Bartley <tbartley@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/decoder_timestamps_utils.py",
        "commit_date": "2023-04-28T16:39:24Z",
        "message": "[BugFix] Force _get_batch_preds() to keep logits in decoder timestamps generator (#6499)\n\n* [BugFix] _get_batch_preds() is forced to keep logits in  decoder timestamps generators\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Ingnore keep_logits boolean in FrameASRBatchLogits\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n---------\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\nCo-authored-by: Jagadeesh Balam <4916480+jbalam-nv@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/decoder_timestamps_utils.py",
        "commit_date": "2023-01-19T14:45:15Z",
        "message": "[BugFix] decoder timestamp count has a mismatch when <unk> is decoded (#5825)\n\n* [BugFix] decoder timestamp count has a mismatch when <unk> is decoded\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Style fix\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/decoder_timestamps_utils.py",
        "commit_date": "2022-11-29T04:24:23Z",
        "message": "[BugFix] Removing <unk> tokens from decoding timestamp (#5481)\n\n* Removing <unk> tokens from timestamp decoding\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fixed notebook bug\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/decoder_timestamps_utils.py",
        "commit_date": "2022-11-12T01:33:06Z",
        "message": "Add cpWER for evaluation of ASR with diarization (#5279)\n\n* Add cpWER calculation feature\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* added notebook\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* updated notebook and diarization_utils\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Minor update on tutorial notebook\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Style fix\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Update on missing docstrings\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fixed an unfinished docstring\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Removed unused variables\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fixed dict input to list input\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Style fix\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* fixed LGTM issues\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fixed error in cpWER cal\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* fixed docstrings\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* fixed docstrings\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fix some of the typing issues, lower case names\n\nSigned-off-by: SeanNaren <snarenthiran@nvidia.com>\n\n* Replaced bruteforce with LSA alg for cpWER\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Reflected PR comments\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Cleaned notebook\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* updated notebook\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fixed LGTM warnings\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* added test_diar_metrics.py\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fixed typos\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fixed wrong type annotations\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Added bruteforce mode and its unit-test\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* LGTM issues fixed\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* reolve LGTM issues\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* unified speaker key in trans_dict\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Removed unused variable and imports\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Update nemo/collections/asr/parts/utils/diarization_utils.py\n\nCo-authored-by: Sean Naren <snarenthiran@nvidia.com>\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Update nemo/collections/asr/parts/utils/diarization_utils.py\n\nCo-authored-by: Sean Naren <snarenthiran@nvidia.com>\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* moved all the diarization eval to der.py\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Update tests/collections/asr/test_diar_metrics.py\n\nCo-authored-by: Sean Naren <snarenthiran@nvidia.com>\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* der.py update on tests\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* unused imports and style fix\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* style fix\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* unused import\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* reflected review comments\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fixed an import bug in tutorial notebook\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\nSigned-off-by: SeanNaren <snarenthiran@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: SeanNaren <snarenthiran@nvidia.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/decoder_timestamps_utils.py",
        "commit_date": "2022-10-16T15:52:38Z",
        "message": "Fix get_samples function  (#5141)\n\n* Fixed get_samples in utils and tutorial\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* tutorial update\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* LGTM fix\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Reflected comments for PR. moved get_samples to audio_utils\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Style fix\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Updated get_samples function in tutorials\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/decoder_timestamps_utils.py",
        "commit_date": "2022-09-21T02:35:05Z",
        "message": "reorder model check (#4959) (#4967)\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/decoder_timestamps_utils.py",
        "commit_date": "2022-08-26T10:39:20Z",
        "message": "Bug fix for Issue #4059, word time stamps for single word cases (#4095)"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/decoder_timestamps_utils.py",
        "commit_date": "2022-06-14T17:26:26Z",
        "message": "Add ASR CTC Decoding module (#4342)\n\n* Initial commit\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Full support for decoding strategy\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Temp\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Fix labels of y_sequence\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Set support for sentencepiece subword merging\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Fix char and word based token merge alignment\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Revert incorrect change\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Update docstring\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Improve compatibility with greedy tokens and log probs\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Update scripts to use decoding strategy\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Add tests and docs\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Add tests and docs\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Fix speaker decoder timestamps\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Fix speaker decoder timestamps\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Fix decoding of ctc models\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Address reviewer comments\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Address reviewer comments\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/decoder_timestamps_utils.py",
        "commit_date": "2022-04-14T01:33:57Z",
        "message": "Torch conversion for VAD-Diarization pipeline (#3930)\n\n* Initial file update\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fixed torch jit related error\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Style fix update\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* revived torch.jit deco on NMESC class\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fixed sentence output error in diar utils\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fix code formatting error\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* encoding\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update and style fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* Switched npath import position for CI pass\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fixed conformer_ctc bug for diar_with_asr\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fix errors in docstrings\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* typo fix and reflect TJ's comment\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* style fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* reflect nithin's comment\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* Reflect review comments\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Minor fixes on docstrings\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Reduced unnecessary code lines\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* grammar\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* reflected comments\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Filled in the missing docsterings and random trials\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Reflected Jagadesh's comments\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* style fix\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Added docstrings to specClus\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\nCo-authored-by: fayejf <fayejf07@gmail.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/decoder_timestamps_utils.py",
        "commit_date": "2022-01-24T05:46:55Z",
        "message": "Merge r1.6.0 main (#3500)\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* minor updates for finetuning (#3455)\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* Fix hysterisis loading (#3460)\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix the tutorial notebooks bug (#3465)\n\n* fix checkpoint loading and model config file\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix style\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* Test only if the model was trained on single GPU for accurate results. (#3470)\n\n* Test only if the model was trained on single GPU for accurate results.\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Test only if the model was trained on single GPU for accurate results.\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix the errors/bugs in ASR with diarization tutorial (#3461)\n\n* Initial commit\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* fixed missing docstring\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fixed main to r1.6.0\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fixed pip install issues\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* NMT documentation for bottleneck architecture (#3464)\n\n* 1. Updated NMT doc to include bottleneck architecture.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\n\n* WFST Punct post fix + punct tutorial fixes (#3469)\n\n* punct tutorial and wfst_post_process firx\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* format\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: PeganovAnton <peganoff2@mail.ru>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\n\n* Process correctly label ids dataset parameter + standardize type of label ids model attribute + minor changes (error messages, typing) (#3471)\n\n* Fix label ids dictionary type\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix to_container method usage\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\nCo-authored-by: ekmb <ebakhturina@nvidia.com>\n\n* file name fix - Segmentation tutorial (#3474)\n\n* update file name\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* update file name\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* Patch fix for the multiple last checkpoints issue (#3468)\n\n* fix line\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* add TODO comment\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* upper bound ptl, lower bound numpy (#3466)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix bug with arguments for preprocessor (#3481)\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* Fix `punctuation_capitalization_train_evaluate.py` description (#3482)\n\n* fix run script documentation\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add missing parameters to examples in documentation\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Standardize format of paths and file names in docs examples\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove wordtokenizer example from NLP tokenizer notebook (#3477)\n\n* nb fix\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* keep token change for later\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* fix\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* Properly support -1 for labels in ctc char models (#3487)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Vahid Noroozi <VahidooX@users.noreply.github.com>\n\n* typo fix in diarization notebooks (#3480)\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* Add Apex import guard (#3467)\n\n* add apex guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add import guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove MegatronBertEncoder class\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update warning message when apex not found\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove import from init\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix checkpoint converter in O2 style (#3486)\n\n* Fix checkpoint converter in O2 style\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Fix style\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\nCo-authored-by: Yu Yao <yuya@nvidia.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Yi Dong <43824965+yidong72@users.noreply.github.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Taejin Park <tango4j@gmail.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\nCo-authored-by: PeganovAnton <peganoff2@mail.ru>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: ekmb <ebakhturina@nvidia.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: Oktai Tatanov <oktai.tatanov@gmail.com>\nCo-authored-by: Abhinav Khattar <aklife97@gmail.com>\nCo-authored-by: Vahid Noroozi <VahidooX@users.noreply.github.com>\nCo-authored-by: yaoyu-33 <54727607+yaoyu-33@users.noreply.github.com>\nCo-authored-by: Yu Yao <yuya@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/decoder_timestamps_utils.py",
        "commit_date": "2022-01-13T22:11:33Z",
        "message": "Update speaker diarization docs (#3419)\n\n* Initial commit\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fixed minor mistakes\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Some changes regarding diarization utils\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fixed minor typos\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Reflected PR comments\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Reflected PR comments\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Reflected addtional comments\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Changed pics and refined text\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Minor typos\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Minor change on dataset\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Minor change on dataset 2\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Changed manifest input to yaml format\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Capitalization of titles\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Last commit\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/asr/parts/utils/decoder_timestamps_utils.py",
        "commit_date": "2022-01-10T20:30:26Z",
        "message": "Updates on ASR with diarization util files (#3359)\n\n* Initial commit\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Update LM part and multiscale part in README.\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Removed redundant parts\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* modified example script\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Revised doc strings\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Changed paths_to_manifest.py script\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Reflected PR comments and revised tutorials\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Added ASR models and kenlm installation \n\nSigned-off-by: tango4j@gmail.com\n\n* Added ASR models and kenlm installation \n\nSigned-off-by: tango4j@gmail.com\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Changed docstrings and style fix\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Fixed unused import and vars\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\n* Added LM part in ASR_diar tutorial.\n\nSigned-off-by: Taejin Park <tango4j@gmail.com>\n\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "scripts/asr_language_modeling/ngram_lm/eval_beamsearch_ngram_ctc.py",
        "commit_date": "2023-10-19T17:04:06Z",
        "message": "fix hybrid eval (#7759) (#7760)\n\n* fix\n\n\n\n* rename\n\n\n\n* docs\n\n\n\n* warning\n\n\n\n* if\n\n\n\n---------\n\nSigned-off-by: Nikolay Karpov <nkarpov@nvidia.com>\nCo-authored-by: Nikolay Karpov <karpnv@gmail.com>\nCo-authored-by: Nikolay Karpov <nkarpov@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "examples/nlp/duplex_text_normalization/data/create_tarred_dataset.py",
        "commit_date": "2023-01-17T18:38:43Z",
        "message": "add constraint info on batch size for tar dataset (#5812)\n\n* add constraint info on batch size for tar dataset\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* style fix\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "examples/nlp/duplex_text_normalization/data/create_tarred_dataset.py",
        "commit_date": "2023-01-11T21:12:36Z",
        "message": "adding back tar script for decoder dataset for duplex (#5773)\n\n* adding back tar script for decoder dataset for duplex\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2023-02-15T22:22:50Z",
        "message": "[TTS/TN/G2P] Remove Text Processing from NeMo, move G2P to TTS (#5982)\n\n* remove TN\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix imports\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix import\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add missing init\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix import\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* rename unit test\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix import\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix modules test\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix imports\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* remove whitelist from config\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* delete wordid file\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* remove pynini_install from tutorials\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* update requirements\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add support warning\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* review\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n---------\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2022-08-24T20:18:02Z",
        "message": "Merge r1.11.0 main (#4787)\n\n* NeMo Megatron doc updates\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info and dockerfile\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix fastpitch export (#4676)\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* [TTS] fixed wrong pronunciations for r1.11. (#4677)\n\n* [TTS] fixed wrong pronunciations.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* incremented the version number to 22.08 as @blisc suggested.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* correct cmudict versions in world-wide places.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Fix for incorrect batch size issue while decoding (#4675)\n\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* [TTS] incremented the version number to 22.08 in tutorials. (#4684)\n\n* [TTS] incremented the version number to 22.08 in tutorials.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Megatron encode function with RPE fix (#4692)\n\n* Fix for RPE\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* fix to fetch config file (#4699)\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* Fix notebook for buffered inference (#4703)\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Prompt Learning Notebook Bug Fix (#4689)\n\n* Added back dataset class list of dict input for generation in tutorial notebook\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* updated argument name for build dataset\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* add psutils to mock imports (#4728)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Update Aligner model and tutorial to add NGC checkpoint loading (#4714)\n\n* Update Aligner model and tutorial to add NGC checkpoint loading\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Fix pynini install for Aligner notebook, minor formatting fix for model\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Aligner notebook formatting consistency\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* [TTS] bugfix for missing configs. (#4725)\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* docs typo fix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Fix pynini install in TTS tutorials (#4729)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Fix ASR notebooks (#4738)\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Multilingual VAD model (#4734)\n\n* add ngc link\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* add tuned VAD config on ASR data\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* yaml note\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update vad asr notebook with mVAD\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update vad infer config comment\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* mvad sd config for ch109\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update sd readme\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* add new mVAD model to doc\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* style fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* update sd tutorial with mVAD\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* typo fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* publish pretrained itn t5 model for English (#4748)\n\nSigned-off-by: Alexandra Antonova <aleksandraa@nvidia.com>\n\nSigned-off-by: Alexandra Antonova <aleksandraa@nvidia.com>\nCo-authored-by: Alexandra Antonova <aleksandraa@nvidia.com>\n\n* Updated docs and doc paths (#4754)\n\n* Updated docs and doc paths\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Update Multitask_Prompt_and_PTuning.ipynb\n\n* Update README.rst\n\n* Changed branch name to use single quotes\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* fix bug relating to ddp strategy in joint intent slot classification tutorial (#4762)\n\n* [TTS] updated config with a German IPA phoneme tokenizer (#4756)\n\n* [TTS] added a German IPA phoneme tokenizer\n* [TTS][ASR] enabled customized arguments for trimming the leading and trailing silence.\n* [TTS] disabled spline interpolation for beta-binomial distribution. Let it generate align prior and save to disks. Use a new phoneme tokenizer.\n* [TTS] use consistent spline interpolation with fastpitch checkpoint when generating mel-spectrograms for hifigan finetune.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Update r1.11 to new heteronyms list (#4745)\n\n* Update configs to new heteronyms list\n* Remove old heteronyms list, add alt 'merchandise' pron to CMUdict\n* Update remaining references to old heteronyms list\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* [TTS] Add multi-speaker German FastPitch and HiFiGAN NGC checkpoints (#4763)\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* [TTS] Add single male speaker German FastPitch and HiFiGAN NGC checkpoints (#4770)\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Update CMUdict with more recent 0.7b entries (#4768)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* Install pynini in docker container (#4733)\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix tutorial formatting (#4778)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* [TTS] deprecated old scripts for ljspeech. (#4780)\n\n* deprecated old scripts for ljspeech.\n* removed relevent function calls in TTS docs.\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info and requirements\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update container\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Update stragglers to new cmudict and heteronyms paths\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nSigned-off-by: ericharper <complex451@gmail.com>\nSigned-off-by: Jason <jasoli@nvidia.com>\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\nSigned-off-by: fayejf <fayejf07@gmail.com>\nSigned-off-by: Alexandra Antonova <aleksandraa@nvidia.com>\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>\nCo-authored-by: Rajesh Ilango <rilango@gmail.com>\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Virginia Adams <78445382+vadam5@users.noreply.github.com>\nCo-authored-by: Jocelyn <jocelynh@nvidia.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: bene-ges <61418381+bene-ges@users.noreply.github.com>\nCo-authored-by: Alexandra Antonova <aleksandraa@nvidia.com>\nCo-authored-by: Zhilin Wang <wangzhilin12061996@hotmail.com>\nCo-authored-by: Vladimir Bataev <vbataev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2022-08-04T17:03:39Z",
        "message": "Pynini dependency fix (#4674)\n\n* nlp guard, logging removed\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* pynini conda install for mac, add import guard to TN tests\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* tts pynini dependency\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add try/except block to tts models\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add missing file\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2022-07-26T13:51:16Z",
        "message": "fix tarred dataset len when num shards is not divisible by workers (#4553)\n\n* fix tarred dataset len when num shards is not divisible by workers\n\nSigned-off-by: Iztok Lebar Bajec <ilb@fri.uni-lj.si>\n\n* update error reporting on invalid `shard_strategy`\n\n* update NLP/PC tarred dataset docstring\n\n* add `shard_strategy` to NLP/PC `@dataclass`\n\n* update NLP/PC tarred dataset docstring\n\n* add `shard_strategy` to NLP/PC docs\n\n* revert test with Dataloader retruning the actual data length\n\n* make dataloader return actual num of samples, set `limit_train_baches` on `setup_*`\n\n* update `shard_strategy` docstrings\n\nSigned-off-by: Iztok Lebar Bajec <ilb@fri.uni-lj.si>\n\n* update `tarred_dataset` documentation\n\nSigned-off-by: Iztok Lebar Bajec <ilb@fri.uni-lj.si>\n\n* fix style\n\n* update documentation\n\nSigned-off-by: Iztok Lebar Bajec <ilb@fri.uni-lj.si>\n\n* updated docstrings\n\nSigned-off-by: Iztok Lebar Bajec <ilb@fri.uni-lj.si>\n\nCo-authored-by: PeganovAnton <peganoff2@mail.ru>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2022-07-15T19:00:50Z",
        "message": "added MLM Scoring (#4476)\n\n* added MLM Scoring\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix header\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* refactor\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix bug that made normalization options set\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix style\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix discrepancy of space versus no space to previous version e.g. < sixteen > and <sixteen>\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* remove and from cardinal when lm is used to reduce number of options\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix grammar\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix masked input for [MASK] token before mlm scoring\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* mask out everything apart from one semiotic token\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* reverted masking change and added roman to lm\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix slash, expand measure\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix masked scoring\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* audio based set fix for --lm\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix bug\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* added jenkins test\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* update jenkins\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix header\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix lgtm\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* add dependency\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* moved mlmscore file\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* moved hybrid to nemo_text_processing folder\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* update jenkins\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix path\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix test\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix dataset license\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\nCo-authored-by: ekmb <ebakhturina@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2022-06-27T17:50:35Z",
        "message": "Merge r1.10.0 main (#4448)\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix ASR Typos in tutorials (#4384)\n\n* Fix typos\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Quick wav2vec fix. In-place operation adding convolutional positions to encoder was overwriting leaf history. Wasn't caught on previous torch versions. (#4383)\n\nSigned-off-by: tbartley94 <tbartley@nvidia.com>\n\nCo-authored-by: tbartley94 <tbartley@nvidia.com>\n(cherry picked from commit 0322b158f26a0b690edca7a84714e33752283923)\n\nCo-authored-by: Travis Bartley <Travismbartley@gmail.com>\n\n* Punctuation and capitalization tests race condition (#4399)\n\n* Add draft of race condition fixes\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Minor improvements\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* More race condition fixes\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve error message\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve error message\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve error message\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix tutorial typos and docs (#4415)\n\n* Fix typos\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Fix typos\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Add reconfigure on validation epoch start (#4393)\n\n* Add reconfigure on validation epoch start\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove pdb\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* switch branch (#4424)\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* Add ASR Scores to Docs (#4412)\n\n* Fix link\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Correct model card\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Add ASR Results to Docs\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Update info\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Update info\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Re-apply fixes from r1.9.0 (#4425)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Replace all with /content/ (#4427)\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Fix hanging issue by multiprocessing in SD tutorial and add ETA for VAD processing (#4405)\n\n* cherry-pick pr 4317 and avoid signoff issue\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* workaround for mp nb issue\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* tdqm for mp functions in vad_utils\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* style fix\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* reflect comment\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* remove\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* [NLP] P&C Fix multi node cache issue, add pynini guard (#4410)\n\n* add sleep to fix multi node cache issue, add pynini guard\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix lgtm\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add tempfile\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* savfe tmp file to the same dir\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix the notebook (#4438)\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* update nemo version dialogue tutorial (#4437)\n\n* docs: add table overflow handling for nested sections (#4441)\n\nCo-authored-by: Nick Goncharenko <ngoncharenko@nvidia.com>\n\n* Docs: Decrease Font Size on Tables  (#4444)\n\n* docs: add table overflow handling for nested sections\n\n* docs: set table font-size to small\n\nCo-authored-by: Nick Goncharenko <ngoncharenko@nvidia.com>\n\n* unify intent slot dataset util functions in tutorials (#4445)\n\n* Notebook bug fix: add subfolder (#4442)\n\n* add subfolder\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* exp_dir update\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix typo in HiFi-GAN config's max steps (#4446)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Updated notebook to fix batch configuration and precision bugs (#4447)\n\n* Updated notebook to fix batch configuration and precision bugs\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Deleted cell outputs\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Set datasets back to full dataset\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Travis Bartley <Travismbartley@gmail.com>\nCo-authored-by: PeganovAnton <peganoff2@mail.ru>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: Jocelyn <jocelynh@nvidia.com>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\nCo-authored-by: Yi Dong <43824965+yidong72@users.noreply.github.com>\nCo-authored-by: Zhilin Wang <wangzhilin12061996@hotmail.com>\nCo-authored-by: Nick Goncharenko <8766167+nickolyamba@users.noreply.github.com>\nCo-authored-by: Nick Goncharenko <ngoncharenko@nvidia.com>\nCo-authored-by: Virginia Adams <78445382+vadam5@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2022-06-08T17:41:12Z",
        "message": "Tn install (#4055)\n\n* remove conda pynini requirement\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* remove remnants\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* merge with main\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* removing nlp collection dependency from text processing and thus breaking cyclyc imports\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix wrong requirement\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix bug in vi\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* update jenkins folders\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\nCo-authored-by: ekmb <ebakhturina@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2022-04-20T22:46:30Z",
        "message": "Merge r1.8.0 main (#4036)\n\n* update version\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Stateless timer fix for PTL 1.6 (#3925)\n\n* Stateless timer fix for PTL 1.6\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Stateless timer PTL test\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix year\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Remove unused imports\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* GPU test\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* clean import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: ericharper <complex451@gmail.com>\n\n* Fix issues with librosa deprecations (#3950)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix notebook bugs for branch r1.8.0 (#3948)\n\n* load the model from ngc\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix all biomegatron notebook\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix the typos\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* remove output\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix isort\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix merge error\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* change ntpath for isort workaround\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix unit test\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix ci\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix ci bert pretraining\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* make it compatible with main\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* add the teste for biomegatron ner\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix argument\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix usablity issue\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* work around\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Yi Dong <doyend@gmail.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix global batch fit loop (#3936)\n\n* add lightning module hooks for global batch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean scripts\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* DP=1 fix\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* set num dataset workers to 2\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update validation_loop with GlobalDataFetcher\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add test global data fetcher\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Drop last for test ds\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix test epoch end\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix eval\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix reconfigure microbatch in the complete method\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add comments\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Set init consumed samples\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* fix shuffle\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add save_restore_connector arg\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix padding for labels and loss mask\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* GLUE/XNLI CI tests\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* limit val batches in hydra fix\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Restart CI\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix unittest\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Exports 22.03 war (#3957)\n\n* Fixed fastpitch for 22.03\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* cleanup\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Restored mask expansion; added WAR for test container images\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* style\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Refactor restorefrom (#3927)\n\n* update package info (#3926)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Refactor restore_from\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Move export related python files to scripts/export/\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Return state dict after modification function\n\n* Remove Megatron legacy parameter in common.py restore_from function\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* ability to set log_predictions to false (#3929)\n\n* Bumping Python version\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fixing style\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* load the model from ngc\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix all biomegatron notebook\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix the typos\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* remove output\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix isort\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix merge error\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* change ntpath for isort workaround\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix unit test\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix ci\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix ci bert pretraining\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* Rearrage export files; Style fix; Extend legacy MegatronBert conversion to NLP models nemo version updation\n\n* Glu activation variants (#3951)\n\n* Temp\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Add reglu and swiglu activations\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style on unrelated file\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* CI changes to test activations\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix unused import\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fix beacuse of merge from main\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* make it compatible with main\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* add the teste for biomegatron ner\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix argument\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix usablity issue\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* FastPitch FT notebook - Improving Speech Quality clarifications (#3954)\n\n* FastPitch FT notebook - Improving Speech Quality clarifications\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Add pynini dependency install to FastPitch FT notebook\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Pin pynini install for FastPitch FT tutorial\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* work around\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\nCo-authored-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\nCo-authored-by: Dima Rekesh <bmwshop@gmail.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nCo-authored-by: Yi Dong <doyend@gmail.com>\nCo-authored-by: Yi Dong <43824965+yidong72@users.noreply.github.com>\nCo-authored-by: Boris Fomitchev <borisfom@users.noreply.github.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Jocelyn <jocelynh@nvidia.com>\n\n* Bump TTS deprecation version to 1.9 (#3955)\n\n* bump deprecation version\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update talknet depre\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* added conformer for zh. (#3970)\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* Add pinned pynini and scipy installs to TTS training tutorial (#3967)\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Fix variable name and move models to CPU in Change partition (#3972)\n\n* fixes\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* add CI\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\n\n* fix misconfiguration (#3975)\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Yi Dong <doyend@gmail.com>\n\n* Fix NMT variable passing bug (#3985)\n\n* fix\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* stylefix\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* Compatability override to load_state_dict for old TTS checkpoints (#3978)\n\n* Compatability override to load_state_dict for old TTS checkpoints\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Tacotron2 training notebook fix - add GPU argument\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Add hann window override warning for old model loading\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Notebook Bug Fixes for r1.8.0 (#3989)\n\n* Made config related bug fixes\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Fixed cfg.get syntax\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Fix compat override for TalkNet Aligner (#3993)\n\n* Fix compatibility override for TalkNet Aligner\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* Remove extraneous logging import\n\nSigned-off-by: Jocelyn Huang <jocelynh@nvidia.com>\n\n* docs fixes (#3987)\n\n* docs fixes\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* rename files in docs\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* docs improvement\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* arg renamed\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* Fix nemo megatron restore with artifacts (#3997)\n\n* update config_path in register_artifact\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix register_artifact calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix register_artifact calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update log messages to include merges file\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add default prompts to config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fixes val_check_interval, skip loading train data during eval (#3968)\n\n* Change stage check\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix bugs in megatron t5 glue eval scripts\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Fix reconfigure\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Change check\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix hasattr\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix typo in cfg structure\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Update megatron t5 glue eval config file\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Reconfigure to avoid drop last\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix for train step reconfigure as well\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Update megatron t5 glue eval config file drop_last to False\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* limit test batches\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: Yu Yao <54727607+yaoyu-33@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* LogProb calculation performance fix (#3984)\n\n* performance fix for logprob computation\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix redandant assign\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix bug to add gather from TP workers\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Yi Dong <doyend@gmail.com>\n\n* Fix link issues in export example notebook and fix pretrained model info for MegatronBert (#4004)\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\nCo-authored-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Fix single GPU training issue + change deprecated Lightning args (#4010)\n\n* change vars\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* style fix\n\nSigned-off-by: Abhinav Khattar <aklife97@gmail.com>\n\n* Fix P-Tune T5 model (#4001)\n\n* fix ptune t5\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix ci test\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\n* fix the ci fail because of the order problem\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Yi Dong <doyend@gmail.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Megatron work-arounds (#3998)\n\n* WAR around Apex issue, and making sure output is FP32\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixing merge issues; moving dummy Trainer; adding float() casts\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixing ColumnParallelLinear call\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Cleanup\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Cleanup#2\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* fix the broadcast shape mismatch (#4017)\n\nSigned-off-by: Yi Dong <doyend@gmail.com>\n\nCo-authored-by: Yi Dong <doyend@gmail.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* add known issues (#4024)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update readme with conda env setup instructions\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert apex guard removal\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert --language to --lang\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix apex guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove set_trace\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix apex guard\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unreachable statement\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove duplicate lines\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove duplicate lines\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Yi Dong <43824965+yidong72@users.noreply.github.com>\nCo-authored-by: Yi Dong <doyend@gmail.com>\nCo-authored-by: Boris Fomitchev <borisfom@users.noreply.github.com>\nCo-authored-by: Ramanathan Arunachalam <ramanathan.arun@rutgers.edu>\nCo-authored-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\nCo-authored-by: Dima Rekesh <bmwshop@gmail.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nCo-authored-by: Jocelyn <jocelynh@nvidia.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Vahid Noroozi <VahidooX@users.noreply.github.com>\nCo-authored-by: Abhinav Khattar <aklife97@gmail.com>\nCo-authored-by: Virginia Adams <78445382+vadam5@users.noreply.github.com>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\nCo-authored-by: Yu Yao <54727607+yaoyu-33@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2022-03-30T01:20:18Z",
        "message": "Megatron support (#3893)\n\n* Add MegatronBert training support for more NLP models; Replace check for nemo_file existence to decide if it's megatron training or not; Add support for finetuning a downstream NLP task model on a different downstream dataset using MegatronBert; Add skelton support for ONNX export of MegatronBert\n\n* Remove duplicate lm_checkpoint key in config\n\n* Adding new Apex classes for export replacement and default trainer support\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixing order of exported inputs in NLP models\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed typo\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed ORT check\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Refactor of NLP models initialization\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed style\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed runtime check\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Code style fixes\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Code style fixes\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Code style fixes\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Check for existence of downstream key before setting it\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Fix Huggingface download unit tests based on get_lm_model refactor\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Add register artifact for MegatronBert models; Remove unused import\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Fixed style\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed duplex decoder init\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* moved set_world_size up\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixing _trainer initialization\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed GPT tokenizer init\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fix Token classification and Q&A forward flag checks for MegatronBert\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Fix world_size init\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Skip GPT eval test\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Fix get_lm_model function calls based on recent refactoring\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Check for presence of keys in the Dict before trying to access them in BERTLMModel\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Check if tokenizer is present before accesing it in lm_utils\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Check for presence of keys in the Dict before trying to register them as artifacts\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Bypass NLP init statements pertaining to MegatronBert when using Ptune downstream task\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Revert NLPModel modification\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Skip the Jenkins Test Megatron P-Tuning GPT LM\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\n* Merge branch 'main' into megatron_support\n\nSigned-off-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\n\nCo-authored-by: Ramanathan Arunachalam <rarunachalam@nvidia.com>\nCo-authored-by: Boris Fomitchev <bfomitchev@nvidia.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nCo-authored-by: Boris Fomitchev <borisfom@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-11-05T18:24:47Z",
        "message": "update english tn ckpt (#3143)\n\n* update english tn ckpt\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* remove ununsed import\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-11-04T18:48:26Z",
        "message": "Tn add nn wfst and doc (#3135)\n\n* made tagger exportable\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* added whitelist wfst for nn\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* updated documentation\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* remove experimental\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* updated doc\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* made tagger exportable\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* added whitelist wfst for nn\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* updated documentation\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* remove experimental\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* updated doc\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* preserve punct after nn wfst\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-11-02T17:26:17Z",
        "message": "Tn clean upsample (#3024)\n\n* init\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* renamed file\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* adding all cleaning scripts\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* skip sentence if error\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* remove I-SAME\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix tyle\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* remove I the first from training\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* remove DM and Da from upsampling\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* remove I -> one/first, also add space around dash for alphanumerical context, remove rare currency from being upsampled\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* remove dalton and DM from being verbalized\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* remove Da and DM sentences competely\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* addressed review feedback, added data folder in examples\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* refactored code, added data utils functions\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix lgtm\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix lgtm\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* added electronic wfst for english neural TN\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* header and lgtm\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-10-20T21:51:23Z",
        "message": "delete nltk download for TN (#3028)\n\n* delete nltk\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* style fix\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* remove unused import\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-10-11T22:56:25Z",
        "message": "TN updates (#2983)\n\n* moses added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* updates to make eval with moses work\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* clean up\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* clean up\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix init\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* review\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-10-07T18:30:27Z",
        "message": "reading max_sequence_len parameter from config fixed (#2961)\n\nSigned-off-by: Fedor Streltsov <sfeaal@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-09-30T22:41:04Z",
        "message": "TN infer  (#2929)\n\n* en_small grammars added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* infer fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add whitelist arg\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add input fall back\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* docstring\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-09-22T20:44:24Z",
        "message": "TN/ITN update (#2854)\n\n* from file added for all modes\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* directions map\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* decoder eval\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* separate eval and inference added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* handle unk tokens and proper pre-post processing\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* clean up\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* review feedback\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-09-16T17:33:56Z",
        "message": "tar dataset for TN/ITN (#2826)\n\n* tar dataset added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* typo and ci test\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins format\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-08-30T16:58:16Z",
        "message": "num_workers set to 3 (#2748)\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-08-25T00:17:21Z",
        "message": "TN Duplex model update (#2704)\n\n* wip\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* wip\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* wip\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* wip\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* evaluation during training added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* evaluation during training added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add multiclass eval and avg metric\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* make compatible with old checkpoints\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* clean up\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix format\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix format\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* update\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add avg to log\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-08-24T22:21:59Z",
        "message": "Merge 1.3 bugfixes into main (#2715)\n\n* update jenkins branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update notebooks branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update readme\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update nemo version for Dockerfile\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update notebook branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Update colab links to Transducer notebooks (#2654)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix nmt grpc server, concatdataset for raw text files (#2656)\n\n* Fix nmt grpc server and concatdataset for raw text files\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Check if lang direction is provided correctly\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style fixes\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* add missing init (#2662)\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix qa inference for single example (#2668)\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* Fix max symbol per step updating for RNNT (#2672)\n\n* Fix max symbol per step updating for RNNT\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix notebooks\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Replaced unfold() with split_view() (#2671)\n\n* Replaced unfold() with split_view()\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* fixed typo\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\n\n* Correct voice app demo (#2682)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Import guard (#2692)\n\n* add asr and pynini import guard\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* remove asrmodel type\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* remove asrmodel type\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fixing branch (#2695)\n\nSigned-off-by: Ghasem Pasandi <gpasandi@nvidia.com>\n\nCo-authored-by: Ghasem Pasandi <gpasandi@nvidia.com>\n\n* fix for emojis (#2675)\n\n* fix for emojis\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* remove redundant line\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* raise error\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* use app_state\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix issues with ASR notebooks (#2698)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Allow non divisible split_size (#2699)\n\n* bugfix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* bugfix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* TN fix for corner cases (#2689)\n\n* serial added, weights to common defaults, decimal bug fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* one failing\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* all tests pass\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* remove redundant file\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix telephone, add test cases\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* money fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* clean format\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix edge case of greedy decoding for greedy_batch mode (#2701)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove time macro (#2703)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Minor FastPitch Fixes (#2697)\n\n* fixes\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* update CI\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* refix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* Fix ddp error. (#2678)\n\nTo avoid \"MisconfigurationException: Selected distributed backend ddp is not compatible with an interactive environment.\" error.\n\nCo-authored-by: ekmb <ebakhturina@nvidia.com>\n\n* update jenkins\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update notebooks\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add split_view back\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: Boris Fomitchev <borisfom@users.noreply.github.com>\nCo-authored-by: Ghasem <35242805+pasandi20@users.noreply.github.com>\nCo-authored-by: Ghasem Pasandi <gpasandi@nvidia.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\nCo-authored-by: khcs <khcs@users.noreply.github.com>\nCo-authored-by: ekmb <ebakhturina@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-08-07T23:01:32Z",
        "message": "Evaluate the performance of the decoder for each semiotic class (#2625)\n\n* Add class_based_decoding_evaluation.py\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Remove unused imports\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add evaluation for tagger to class_based_eval\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-08-07T22:19:57Z",
        "message": "Allow using covering grammars for neural English TN model (#2602)\n\n* Compute probability of each sequence\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Use CGs when the model is not confident\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add script for visualization\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add comments on how to generate visualizations\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Remove spaces in URLs when using CGs\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Allow setting n_tagged\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add docstring\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* if there is any exception, fall back to the input\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Minor changes to URL processing\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Style fix\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add docstrings and comments\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* PYNINI_AVAILABLE check\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-08-06T19:34:52Z",
        "message": "Allowed setting the train set size of duplex TN training (#2605)\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-08-03T19:03:14Z",
        "message": "import fix (#2597)\n\n* import fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* remove unused import\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* example import fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-07-30T21:52:58Z",
        "message": "Fixes for neural TN (#2581)\n\n* Preprocessed Google TN data not need basic tokenization\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Minor Fix\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Error fix\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Added test after train\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Minor Fix\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Allow data caching for Tagger Dataset\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Allow data caching for Decoder dataset\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Minor fixes\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-07-21T16:22:53Z",
        "message": "Extending the neural TN/ITN models for other languages (#2497)\n\n* extending the neural TN/ITN model to handle RU\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Support German\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Catch AttributeError instead of BaseException\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Style fix\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2021-07-08T05:26:37Z",
        "message": "Transformer-based Text Normalization Models (#2415)\n\n* Add notebook with recommendations for 8 kHz speech (#2326)\n\n* Added a notebook with best practices for telephony speech\n\n* Added datasets detaiils\n\n* Added training recommendations\n\n* Emptied out cells with results\n\n* Added tutorial to docs\n\nSigned-off-by: jbalam <jbalam@nvidia.com>\n\n* Addressed review comments\n\nSigned-off-by: jbalam <jbalam@nvidia.com>\n\n* Added a line to note original sampling rate of an4\n\nSigned-off-by: jbalam <jbalam@nvidia.com>\n\n* Made changes suggested in review\n\nSigned-off-by: jbalam <jbalam@nvidia.com>\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add FastEmit support for RNNT Losses (#2374)\n\n* Temp commit\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Initial code for fastemit forward pass\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct return reg value\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Initial cpu impl\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Try gpu impl\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Try gpu impl\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct few impl\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update fastemit scaling\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Cleanup fastemit\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Finalize FastEmit regularization PR\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Refactor code to support fastemit regularization\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Samuel Kriman <samuelkriman@gmail.com>\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Implement inference functions of TN models\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Minor Fix\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* fix bugs in hifigan code (#2392)\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Update setup.py (#2394)\n\nSigned-off-by: Jason <jasoli@nvidia.com>\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* update checkpointing (#2396)\n\nSigned-off-by: Jason <jasoli@nvidia.com>\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* byt5 unicode implementation (#2365)\n\n* Audio Norm (#2285)\n\n* add jenkins test, refactoring\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* update test\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix new test\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add serial to the default normalizer, add tests\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* manifest test added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* expose more params, new test cases\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix jenkins, serial clean, exclude range from cardinal\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins dollar sign format\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins dollar sign format\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* addressed review comments\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix decimal in measure\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* move serial in cardinal\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* clean up\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* update for SH zero -> oh\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* change n_tagger default\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* bumping version to 1.0.1\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* Add check for numba regardless of device\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* upper bound for webdataset\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* Correct Dockerfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* update readmes\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* update README (#2332)\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* ddp translate GPU allocation fix (#2312)\n\n* fixed branch in IR tutorial\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\n* ddp translate GPU allocation fix\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\n* map_location instead of set_device\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* Shallow fusion (#2315)\n\n* fixed branch in IR tutorial\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\n* shallow fusion init commit\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\n* debug info removed\n\nSigned-off-by: AlexGrinch <grinchuk.alexey@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* [BUGFIX] Add upper bound to hydra for 1.0.x (#2337)\n\n* upper bound hydra\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* upper bound hydra\n\nSigned-off-by: ericharper <complex451@gmail.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* update version number\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* update package version\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* sparrowhawk tests + punctuation post processing for pynini TN (#2320)\n\n* add jenkins test, refactoring\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* update test\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix new test\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add serial to the default normalizer, add tests\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* manifest test added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* expose more params, new test cases\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix jenkins, serial clean, exclude range from cardinal\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins dollar sign format\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins dollar sign format\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* addressed review comments\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix decimal in measure\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* move serial in cardinal\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* sh tests init\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* sparrowhawk container tests support added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add post process to normalize.py, update tests\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* remove duplication\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* Update notebooks to 1.0.2 release (#2338)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* Update ranges for omegaconf and hydra (#2336)\n\n* Update ranges\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Updates for Hydra and OmegaConf updates\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Style fixes\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct tests and revert patch for model utils\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct docstring\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Revert unnecessary change\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Revert unnecessary change\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Guard scheduler for None\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* default to 0.0 if bpe_dropout is None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Correctly log class that was restored\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Root patch *bpe_dropout\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: ericharper <complex451@gmail.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* Update FastPitch Export (#2355)\n\nSigned-off-by: Jason <jasoli@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* byt5 unicode implementation, first cut\n\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* add bytelevel tokenizer\n\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* update out_dir to not collide (#2358)\n\nSigned-off-by: ericharper <complex451@gmail.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* Update container version to 21.05 (#2309)\n\n* Update container version\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Temporarily change export format of waveglow\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add conda update for numba\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update numba compat via global flag for strictness level `--relax_numba_compat`, remove pytorchlightning.metrics, refactor out numba utils to core, update tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct order of numba minimum verion, remove wrong flag from test\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Double test of cuda numba\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Double test of cuda numba\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Enable RNNT tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* Text Normalization Update (#2356)\n\n* upper cased date support\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* update whitelist, change roman weights\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* docstrings, space fix, init file\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* lgtm\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fraction with measure class\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* address comment\n\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* Add ASR CTC tutorial on fine-tuning on another language (#2346)\n\n* Add ASR CTC Language finetuning notebook\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add to documentation\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Improve documentation\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct name of the dataset\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* Correct colab link to notebook (#2366)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* sgdqa update data directories for testing (#2323)\n\n* sgdqa update data directories for testing\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix syntax\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* check if data dir exists\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* fix\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* adding pretrained model\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* Added documentation for export() (#2330)\n\n* Added export document\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Addressed review comments\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* Update Citrinet model card info (#2369)\n\n* Update model card info\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Cleanup Docs\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* [NMT] Model Parallel Megatron Encoders (#2238)\n\n* add megatron encoder\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* added megatron to get_nmt_tokenizer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add vocab_size and hidden_size to megatron bert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add megatron encoder module\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fixed horrible typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix typo and add default\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* updating nlp overrides for mp nmt\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move some logic back to nlpmodel from overrides\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add checkpoint_file property\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix property\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* num_tokentypes=0\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* find_unused_parameters=True\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* get instead of pop\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove token type ids from megatron input example\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* pop vocab_size\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix checkpointing for model parallel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix bug in non model parallel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* convert cfg.trainer to dict\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make num_tokentypes configurable for nmt\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update checkpoint_file when using named megatron model in nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* make vocab_file configurable\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* dataclass can't have mutable default\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert input example\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* check that checkpoint version is not None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add mp jenkins test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update docstring\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add docs for pretrained encoders with nemo nmt\n\nSigned-off-by: ericharper <complex451@gmail.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* Add notebook with recommendations for 8 kHz speech (#2326)\n\n* Added a notebook with best practices for telephony speech\n\n* Added datasets detaiils\n\n* Added training recommendations\n\n* Emptied out cells with results\n\n* Added tutorial to docs\n\nSigned-off-by: jbalam <jbalam@nvidia.com>\n\n* Addressed review comments\n\nSigned-off-by: jbalam <jbalam@nvidia.com>\n\n* Added a line to note original sampling rate of an4\n\nSigned-off-by: jbalam <jbalam@nvidia.com>\n\n* Made changes suggested in review\n\nSigned-off-by: jbalam <jbalam@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* Add FastEmit support for RNNT Losses (#2374)\n\n* Temp commit\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Initial code for fastemit forward pass\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct return reg value\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Initial cpu impl\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Try gpu impl\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Try gpu impl\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct few impl\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update fastemit scaling\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Cleanup fastemit\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Finalize FastEmit regularization PR\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Refactor code to support fastemit regularization\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Samuel Kriman <samuelkriman@gmail.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* byt5 unicode implementation, first cut\n\nSigned-off-by: Mike Chrzanowski <mchrzanowski@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* add bytelevel tokenizer\n\nSigned-off-by: Mike Chrzanowski <mchrzanowski@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* update styling\n\nSigned-off-by: Mike Chrzanowski <mchrzanowski@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* avoid circular import\n\nSigned-off-by: Mike Chrzanowski <mchrzanowski@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* fix bugs in hifigan code (#2392)\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* Update setup.py (#2394)\n\nSigned-off-by: Jason <jasoli@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* Update bytelevel_tokenizer.py\n\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* Update bytelevel_tokenizer.py\n\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* typo\n\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* missed one\n\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* bug fixes\n\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* style fix\n\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* bytelevelprocessor is now generic.\n\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* style fix\n\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* update checkpointing (#2396)\n\nSigned-off-by: Jason <jasoli@nvidia.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* woops, didnt merge jenkinsfile the right way\n\n* add newline\n\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* undo changes to enja processor\n\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* processor selection decision fix\n\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\n* newline fix\n\nSigned-off-by: mchrzanowski <mchrzanowski@nvidia.com>\n\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Aleksey Grinchuk (Oleksii Hrinchuk) <grinchuk.alexey@gmail.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\nCo-authored-by: mchrzanowski <mchrzanowski@nvidia.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: Boris Fomitchev <borisfom@users.noreply.github.com>\nCo-authored-by: Jagadeesh Balam <4916480+jbalam-nv@users.noreply.github.com>\nCo-authored-by: Samuel Kriman <samuelkriman@gmail.com>\nCo-authored-by: Oktai Tatanov <oktai.tatanov@gmail.com>\nCo-authored-by: root <root@dgx0026.nsv.rno1.nvmetal.net>\nCo-authored-by: root <root@dgx0079.nsv.rno1.nvmetal.net>\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Minor Fix\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Minor Fixes\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add TextNormalizationTestDataset and testing/evaluation code\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add TextNormalizationTaggerDataset and training code for tagger\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Restore from local nemo ckpts\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add TextNormalizationDecoderDataset\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add interactive mode for neural_text_normalization_test.py\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add options to do training or not for tagger/decoder\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Renamed\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Implemented setup dataloader for decoder\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Implemented training and validation for decoder\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Data augmentation for decoder training\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Config change\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* add blossom-ci.yml (#2401)\n\nSigned-off-by: ericharper <complex451@gmail.com>\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Merge r1.1 bugfixes into main (#2407)\n\n* Update notebook branch and Jenkinsfile for 1.1.0 testing (#2378)\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkinsfile\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* [BUGFIX] NMT Multi-node was incorrectly computing num_replicas (#2380)\n\n* fix property when not using model parallel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix property when not using model parallel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add debug statement\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add debug statement\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* instantiate with NLPDDPPlugin with num_nodes from trainer config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Update ASR scripts for tokenizer building and tarred dataset building (#2381)\n\n* Update ASR scripts for tokenizer building and tarred dataset building\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update container\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add STT Zh Citrinet 1024 Gamma 0.25 model\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update notebook (#2391)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* ASR Notebooks fix for 1.1.0 (#2395)\n\n* nb fix for spring clean\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* remove outdated instruction\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* Mean normalization (#2397)\n\n* norm embeddings\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* move to utils\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* Bugfix adaptive spec augment time masking (#2398)\n\n* bugfix adaptive spec augment\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Revert freq mask guard\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Revert freq mask guard\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove static time width clamping\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct typos and issues with notebooks (#2402)\n\n* Fix Primer notebook\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Typo\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* remove accelerator=DDP in tutorial notebooks to avoid errors. (#2403)\n\nSigned-off-by: Hoo Chang Shin <hshin@nvidia.com>\n\nCo-authored-by: Hoo Chang Shin <hshin@nvidia.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update notebook branch to main\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: khcs <khcs@users.noreply.github.com>\nCo-authored-by: Hoo Chang Shin <hshin@nvidia.com>\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Remove unused imports\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add initial doc for text_normalization\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Fixed imports warnings\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Minor Fix\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Renamed\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Allowed duplex modes\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Minor Fix\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add docs for duplex_text_normalization_train and duplex_text_normalization_test\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* docstrings for model codes + minor fix\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add more comments and doc strings\n\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add doc for datasets + Use time.perf_counter()\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add code for preprocessing Google TN data\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add more docs and comments + Minor Fixes\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add more licenses + Fixed comments + Minors\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Moved evaluation logic to DuplexTextNormalizationModel\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add logging errors\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Updated validation code of tagger + Minors\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Also write tag preds to log file\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add data augmentation for tagger dataset\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Added experimental decorators\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Updated docs\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Updated duplex_tn_config.yaml\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Compute token precision of tagger using NeMo metrics\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Fixed saving issue when using ddp accelerator\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Refactoring\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Add option to keep punctuations in TextNormalizationTestDataset\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Changes to input preprocessing + decoder's postprocessing\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Fixed styles + Add references\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\n* Renamed examples/nlp/duplex_text_normalization/utils.py to helpers.py\nSigned-off-by: Tuan Lai <tuanl@nvidia.com>\n\nCo-authored-by: Jagadeesh Balam <4916480+jbalam-nv@users.noreply.github.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Samuel Kriman <samuelkriman@gmail.com>\nCo-authored-by: Oktai Tatanov <oktai.tatanov@gmail.com>\nCo-authored-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Mike Chrzanowski <mike.chrzanowski0@gmail.com>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Aleksey Grinchuk (Oleksii Hrinchuk) <grinchuk.alexey@gmail.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nCo-authored-by: mchrzanowski <mchrzanowski@nvidia.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: Boris Fomitchev <borisfom@users.noreply.github.com>\nCo-authored-by: root <root@dgx0026.nsv.rno1.nvmetal.net>\nCo-authored-by: root <root@dgx0079.nsv.rno1.nvmetal.net>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: khcs <khcs@users.noreply.github.com>\nCo-authored-by: Hoo Chang Shin <hshin@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "scripts/asr_context_biasing/eval_greedy_decoding_with_context_biasing.py",
        "commit_date": "2024-02-13T12:05:08Z",
        "message": "Context-biasing by CTC-based Word Spotter (CTC-WS) (#8223)\n\n* initial commit\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* some fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* fix blank_idx slow down\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add new non-blank pruning\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* some fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* some fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* descriptions fix\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* description fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add ctc only model\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* move scripts to nemo asr parts\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* remove scripts from scripts dir\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add first test\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add some tests\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add test\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* some fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix circular import\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix preds_output_folder\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* set loop_lables=True\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add .json to output manifest name\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* fix rnnt wer degradation\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add round(score) for test\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix bow token\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* review fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* review fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add epsilon shift in alignment\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* minor fix\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* fix transcribe modification\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix autocast\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n---------\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "scripts/asr_language_modeling/ngram_lm/eval_beamsearch_ngram_transducer.py",
        "commit_date": "2023-10-05T17:18:32Z",
        "message": "Fix py3.11 dataclasses issue  (#7616)\n\n* Fix py3.11 dataclasses issue  (#7582)\n\n* Update ASR configs to support Python 3.11\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update TTS configs to support Python 3.11\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Guard MeCab and Ipadic\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Fix remaining ASR dataclasses\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix remaining ASR dataclasses\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix scripts\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Update name to ConfidenceMethodConfig\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain (#7576) (#7586)\n\n* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Safeguard nemo_text_processing installation on ARM (#7485)\n\n* safeguard nemo_text_processing installing\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* update check\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n---------\n\nSigned-off-by: Jason <jasoli@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\n\n* Fix changes to confidence measure\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nSigned-off-by: Sangkug Lym <slym@nvidia.com>\nSigned-off-by: Jason <jasoli@nvidia.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: github-actions[bot] <41898282+github-actions[bot]@users.noreply.github.com>\nCo-authored-by: Sangkug Lym <slym@nvidia.com>\nCo-authored-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "scripts/asr_language_modeling/ngram_lm/eval_beamsearch_ngram_transducer.py",
        "commit_date": "2023-04-21T21:44:03Z",
        "message": "Update script for ngram rnnt and hat beam search decoding (#6370)\n\n* add rnnt ngram beamsearch script\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add return encoding embedding option\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* update script\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add rnnt and hat ngram decoding script\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add some parameters\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add return_encoder_embeddings parameter to RNNTDecodingConfig\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* replace return_encoder_embeddings parameter\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* generalization of scipt behavior\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* remove return_encoder_embeddings parameter\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* remove return_encoder_embeddings parameter\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add manual encoder_embeddings calculation\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix beam_width value to 8\n\nSigned-off-by: Andrei Andrusenko <52885736+andrusenkoau@users.noreply.github.com>\n\n* fix rescoring description\n\nSigned-off-by: Andrei Andrusenko <52885736+andrusenkoau@users.noreply.github.com>\n\n---------\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\nSigned-off-by: Andrei Andrusenko <52885736+andrusenkoau@users.noreply.github.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "scripts/asr_language_modeling/ngram_lm/eval_beamsearch_ngram_transducer.py",
        "commit_date": "2023-03-24T07:55:57Z",
        "message": "Hybrid Autoregressive Transducer (HAT) (#6260)\n\n* add hat joint network\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add HATJoint module\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add hat script\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add hat decoding option\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add hat related parameters to maes decoding\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* minor fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add hat decoding option\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* minor fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add hat related parameters\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* minor fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add hat to all rnnt decoding types\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add test for hatjoint\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* combine hatjoint with all rnntjoint tests\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* minor fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* rename hat file\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* fix hat double output\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* fix hat double output\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* fix hat double output\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* nemo/collections/asr/parts/submodules/rnnt_greedy_decoding.py\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* minor fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add return_hat_ilm property\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add HATJointOutput dataclass\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add resolve_joint_output function\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add local return_hat_ilm_default variable\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* minor fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n---------\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "scripts/asr_language_modeling/ngram_lm/eval_beamsearch_ngram_transducer.py",
        "commit_date": "2023-03-14T16:26:08Z",
        "message": "Ngram lm fusion for RNNT maes decoding (#6118)\n\n* add parameters for ngram_lm\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add parameters for ngram lm\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add RNNT model types for kenlm training\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add ngram lm fusion to maes decoding mode\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add a script for the rnnt beam search decoding with a ngram lm fusion for maes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* minor fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* minor fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix autocast\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* typing fix\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* minor fixes\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* add set_decoding_type function\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* remove tokens_type\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* remove tokens_type from config\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* import token_offset from train_kenlm\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* add DEFAULT_TOKEN_OFFSET variable\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fix applying token_offset for char models\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* fixe copyright year\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n* leave DEFAULT_TOKEN_OFFSET only\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\n\n---------\n\nSigned-off-by: andrusenkoau <andrusenkoau@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "examples/asr/asr_cache_aware_streaming/speech_to_text_cache_aware_streaming_infer.py",
        "commit_date": "2023-07-22T07:12:01Z",
        "message": "Adding docs and models for multiple lookahead cache-aware ASR (#7067) (#7094)"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "examples/asr/asr_cache_aware_streaming/speech_to_text_cache_aware_streaming_infer.py",
        "commit_date": "2023-04-25T19:42:29Z",
        "message": "Fix cache aware hybrid bugs (#6466) (#6484)"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "examples/asr/asr_cache_aware_streaming/speech_to_text_cache_aware_streaming_infer.py",
        "commit_date": "2023-04-03T08:47:09Z",
        "message": "chore: minor cleanup (#6311)\n\n* chore: minor cleanup\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* Adding docs and missing param\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* Clip cache_keep_size in causal_convs\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n---------\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "examples/asr/asr_cache_aware_streaming/speech_to_text_cache_aware_streaming_infer.py",
        "commit_date": "2023-03-14T02:11:32Z",
        "message": "Streaming conformer CTC export (#5837)\n\n* cache-aware streaming export\n\nTest onnx streaming conformer ctc WER\n\nConstant att cache width with len param\n\nRemove some extra functions in cache_aware runner\n\ntranspose cache so that batch is first for trt\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* fix export for full-context conformer\n\n* WIP trying to improve onnx perf\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* Adding test scripts\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* More perf testing script\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* Updates for jit torch_tensorrt tracing\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* Fixed trace warnings\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Rearranging tests\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixing non-caching case\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* testing\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed channel cache length issue\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* cache-aware streaming export\n\nTest onnx streaming conformer ctc WER\n\nConstant att cache width with len param\n\nRemove some extra functions in cache_aware runner\n\ntranspose cache so that batch is first for trt\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* fix export for full-context conformer\n\n* WIP trying to improve onnx perf\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* Adding test scripts\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* More perf testing script\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* Updates for jit torch_tensorrt tracing\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* stash\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Reverting non-essential changes\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Offset=None case\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Remove test scripts\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* Clean up speech_to_text_cache_aware_streaming_infer\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Revert pad -> constant_pad_nd\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* conformer-encoder set window_size from streaming_cfg\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* Fixes for working export(), using more constants\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Optional rand init for cahce\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* Folding update_cache with constants\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* More folding\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Reducing diff #1\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Reducing diff #2\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Reducing diff #3\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Fixed unit tests, more reverts\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Export fixes\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Reverted slice changes that ruined ONNX perf\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\n* Adding back keep_all_outputs and drop_extra_preencoded\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n* Fix export\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\n\n---------\n\nSigned-off-by: Greg Clark <grclark@nvidia.com>\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\nCo-authored-by: Boris Fomitchev <bfomitchev@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Vahid Noroozi <VahidooX@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "examples/asr/asr_cache_aware_streaming/speech_to_text_cache_aware_streaming_infer.py",
        "commit_date": "2022-12-06T05:52:20Z",
        "message": "Adding Hybrid RNNT-CTC model (#5364)\n\n* added initial code.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added the confs.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added the confs.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* changed name from joint to hybrid.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fixed format.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed format.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed bug.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fixed bug.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* addressed comments.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* addressed comments.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added docs.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added docs.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added docs.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added docs.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed bug.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fixed bug.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed bug.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed bug.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed bug.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fixed bug.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed bug.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed bug.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* addec CI test.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* addec CI test.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed bugs in change_vocabs.\n\nSigned-off-by: vahidoox <vnoroozi@nvidia.com>\n\n* fixed bugs in change_vocabs.\n\nSigned-off-by: vahidoox <vnoroozi@nvidia.com>\n\n* fixed style.\n\nSigned-off-by: vahidoox <vnoroozi@nvidia.com>\n\n* fixed style.\n\nSigned-off-by: vahidoox <vnoroozi@nvidia.com>\n\n* fixed style.\n\nSigned-off-by: vahidoox <vnoroozi@nvidia.com>\n\n* raise error for aux_ctc.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* raise error for aux_ctc.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* raise error for aux_ctc.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* raise error for aux_ctc.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* updated the streaming names.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added unittests.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added unittests.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added unittests.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed tests.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed tests.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed tests.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed tests.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fixed tests.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* fixed tests.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added methods.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added decoding.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* fxied the tests.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\nSigned-off-by: vahidoox <vnoroozi@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/token_classification/punctuation_capitalization_lexical_audio_model.py",
        "commit_date": "2023-01-23T20:55:58Z",
        "message": "Add SSL import functionality for Audio Lexical PNC Models (#5834)\n\n* Initial commit of changes for SSL functionality\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Deleted comment lines as per request\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\n\nSigned-off-by: Daniel Egert <degert@nvidia.com>\nCo-authored-by: Daniel Egert <degert@nvidia.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Matvei Novikov <mattyson.so@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/token_classification/punctuation_capitalization_lexical_audio_model.py",
        "commit_date": "2022-10-20T18:54:51Z",
        "message": "P&C tutorial, inference script (#5195)\n\n* Added tutorial, infrerence script\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Style fix\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Added missing import\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Reformat\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/token_classification/punctuation_capitalization_lexical_audio_model.py",
        "commit_date": "2022-09-08T20:41:11Z",
        "message": "removed unused imports for all domains. (#4901)\n\n\nSigned-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "nemo/collections/nlp/models/token_classification/punctuation_capitalization_lexical_audio_model.py",
        "commit_date": "2022-08-31T15:13:43Z",
        "message": "Added P&C lexical audio model (#4802)\n\n* Added P&C lexical audio model\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Added copyright header\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Default config fix\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Multiple dev/valid dataloaders fix\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Updated copyright header\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Updated config\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Added help to new arguments.\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Fixed description\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Refactor\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Added fusion related args to default config\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Config refactor\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Config refactor\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Removed redundant typings\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Updated config structure\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Added compatibility with other ASR models\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Added import guard for ASR collection\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Fixed type in `use_audio` param\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Added comments on `freeze` section in default config\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Added comments and default values for `adapter.config` config\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Fixed wrong class usage in train/evaluate script\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Import guard corrected\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\n* Check if path exists added for `restore_lexical_encoder_from`\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>\n\nSigned-off-by: Matvei Novikov <mattyson.so@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2024-02-06T00:26:43Z",
        "message": "Support uploading NeMo models to HF via `push_to_hf_hub()` (#8263)\n\n* Initial support for saving unpacked nemo file directly and support for uploading NeMo models to Huggingface Hub\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add support to restore nemo models from HF in unpacked format\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Correct input types for model card\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update License Section to template\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add unit test to restore via unpacked checkpoint\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix typo\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Address comments\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n* Address comments\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add docs and address comments\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* [pre-commit.ci] auto fixes from pre-commit.com hooks\n\nfor more information, see https://pre-commit.ci\n\n---------\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2023-11-15T03:16:59Z",
        "message": "Add back import guard (#7882)\n\n* add back import guard\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n* skip failing unit test\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\n\n---------\n\nSigned-off-by: Chen Cui <chcui@nvidia.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2023-04-02T04:58:37Z",
        "message": "[Core] return_config=True now extracts just config, not full tarfile (#6346)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2023-01-23T19:04:09Z",
        "message": "Support nested NeMo models (#5671)\n\nNested NeMo models support\n\nSigned-off-by: Vladimir Bataev <vbataev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\nCo-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>\nCo-authored-by: Sean Naren <sean.narenthiran@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2022-10-15T00:33:55Z",
        "message": "Support TorchScript export for Squeezeformer (#5164)\n\n* Support TorchScript export for Squeezeformer\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove prints\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2022-07-29T05:50:03Z",
        "message": "Fix HF check for model card info (#4628)\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2022-07-29T00:34:44Z",
        "message": "r1.10.0 MegaMolBART Compatibility (#4603)\n\n* 1. Added vocab_size property to RegExTokenizer.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Fixed passing hiddens directly.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Fixed style.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Added support in encoder outputs.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Added comments.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Added automatic mapping of kwargs to args in forward.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Added encode function.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Fixed style.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Fixed style.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. Fixed style.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@nvidia.com>\n\n* 1. PP and TP works (but not together)\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Separated get_forward_output_only_func_encode and get_forward_output_only_func_decode.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Set headscale false (#4364)\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Add wandb as dependency (#4365)\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Raise trainer error (#4356)\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\n\n* Set headscale false (#4364) (#4366)\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Finetuning changes for BART (#4003)\n\n* Temp\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Checkpoint converter to nemo for bart\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\n\n* Make position embedding expansion specific to a batch to avoid checkpoint size mismatches (#4357)\n\n* Style\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\n* Fix logging warning\n\nSigned-off-by: MaximumEntropy <sandeep.subramanian.1@umontreal.ca>\n\nCo-authored-by: Micha Livne <michalivne@users.noreply.github.com>\n\n* 1. Added return logits to validation.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Fixed unkown token during sampling.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Fixed RegExTokenizer loading.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Fixed ckpt file with samples int(0).\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Fixed regex tokenizer.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Fixed allowing enc_tokens to be None.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Added ability to ignore tokens by id during decode.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Fixed regex tokenizer .nemo loading issue.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Fixed style.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Fixed style.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Fixed RegEx test.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* r1.10.0 untie embeddings weights (#4519)\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Added independent decoder embeddings, and independent decoder token_head.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Added support in yaml config.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Fixed initialization.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Added tests for untied embeddings and decoder token head.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Updated share_word_embeddings to share_token_embeddings.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Fixed style.\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Fixed error in __del__ when TextMemMapDataset fails to build.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Fixed comments.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1.Made method private.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Fixed config names.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Fixed alerts and style.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Fixed PP, TP, PP+TP still fails.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\n* 1. Debugging.\n\nSigned-off-by: Micha Livne <mlivne@cs.toronto.edu>\n\nCo-authored-by: Micha Livne <mlivne@nvidia.com>\nCo-authored-by: ericharper <complex451@gmail.com>\nCo-authored-by: Sandeep Subramanian <sandeep.subramanian.1@umontreal.ca>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2022-07-27T22:12:53Z",
        "message": "Support listing Hugging Face model info (#4619)\n\n* Support listing Hugging Face model info\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Add documentation about usage\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Add documentation about usage\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Update name of method, support list of model filters\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>\n\n* Improve docstring\n\nSigned-off-by: smajumdar <smajumdar@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2022-04-28T00:39:51Z",
        "message": "[Core] Support pre-extracted nemo checkpoint for restoration (#4061)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2022-04-25T19:21:58Z",
        "message": "Cherry pick HF integration and bug fixes from 1.8.1 (#4052)\n\n* Patch commons.py (#4039)\n\n* revert export.py changes\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert hack\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused imports\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Add support for Huggingface Hub to NeMo `from_pretrained()` (#4030)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fixing pretrained name (#4022)\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\n\n* Add back Citrinet zh (#4040)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\n\n* cherry pick\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: Boris Fomitchev <borisfom@users.noreply.github.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Subhankar Ghosh <subhankar2321@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2022-01-31T22:20:29Z",
        "message": "Final merge r1.6.0 main (#3570)\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix the tutorial notebooks bug (#3465)\n\n* fix checkpoint loading and model config file\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* fix style\n\nSigned-off-by: Yi Dong <yidong@nvidia.com>\n\n* Fix checkpoint converter in O2 style (#3486)\n\n* Fix checkpoint converter in O2 style\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\n* Fix style\n\nSigned-off-by: Yu Yao <yuya@nvidia.com>\n\nCo-authored-by: Yu Yao <yuya@nvidia.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Remove pickled features from tarred dataset (#3491)\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\nCo-authored-by: ekmb <ebakhturina@nvidia.com>\n\n* adding missing init files (#3505)\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* typos (#3504)\n\n* typos\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* link fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* update titanet conf (#3507)\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* Fix link to NGC page for ASR (#3512)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* vad typo fix (#3490)\n\n* remove always broken ptl link\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* fix typo\n\nSigned-off-by: fayejf <fayejf07@gmail.com>\n\n* Add verification helper function and update docs (#3514)\n\n* Add verification helper function and update docs\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* typo fixes\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* fixed the num_classes bug of conv decoder. (#3525)\n\n* fixed the num_classes bug.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added logging info.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* Enforce utf-8 on all file r/w (#3520)\n\n* Update paths to subtask\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Enforce utf-8 on all file r/w\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fixed section typo (#3522)\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Pushing updated WFST Tutorial to r1.6.0 (#3521)\n\nSigned-off-by: tbartley94 <tbartley@nvidia.com>\n\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\n\n* Fixed duplicate cell bug (#3518)\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* WFST tutorial update (#3531)\n\n* Pushing updated WFST Tutorial to r1.6.0\n\nSigned-off-by: tbartley94 <tbartley@nvidia.com>\n\n* Hopefully final corrections to WFST tutorials.\n\nSigned-off-by: tbartley94 <tbartley@nvidia.com>\n\n* [TTS] Fix bug in inference tts notebook (#3532)\n\n* fix bug in inference tts notebook\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* Update Inference_ModelSelect.ipynb\n\n* fix space\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* remove space\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* Prompt tuning documentation (#3541)\n\n* Started prompt tuning doc\n\nSigned-off-by: Virginia Adams <vadams@nvidia.com>\n\n* Update prompt_tuning.rst\n\n* Update models.rst\n\n* Update models.rst\n\n* Update and rename megatron_finetuning.rst to megatron_downstream_tasks.rst\n\n* Update intro.rst\n\n* Update intro.rst\n\n* Update and rename megatron_downstream_tasks.rst to megatron_finetuning.rst\n\n* Update megatron_finetuning.rst\n\n* Delete prompt_tuning.rst\n\n* Update README.rst\n\n* Update docs/source/nlp/megatron_finetuning.rst\n\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* Fix nmt resume (#3539)\n\n* check for model attr\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update jenkins test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* TN bug fix (#3538)\n\n* ve and cel fixes\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* ve and cel fixes\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* add w to single digit roman and cardinal single digit graph (non det)\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* isn't fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: Eric Harper <complex451@gmail.com>\n\n* fix bug in tutorial (#3546)\n\nSigned-off-by: Oktai Tatanov <oktai.tatanov@gmail.com>\n\n* Update nvidia container check (#3535)\n\n* update nvidia container check\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update minor version\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add check to T5\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update bert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* forgot import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix an issue with wandb not displaying updated config changes (#3552)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* remove extra instance (#3551)\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update branch\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update package info\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\nCo-authored-by: Yi Dong <43824965+yidong72@users.noreply.github.com>\nCo-authored-by: yaoyu-33 <54727607+yaoyu-33@users.noreply.github.com>\nCo-authored-by: Yu Yao <yuya@nvidia.com>\nCo-authored-by: PeganovAnton <peganoff2@mail.ru>\nCo-authored-by: ekmb <ebakhturina@nvidia.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>\nCo-authored-by: Evelina <10428420+ekmb@users.noreply.github.com>\nCo-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: Vahid Noroozi <VahidooX@users.noreply.github.com>\nCo-authored-by: Virginia Adams <78445382+vadam5@users.noreply.github.com>\nCo-authored-by: tbartley94 <90423858+tbartley94@users.noreply.github.com>\nCo-authored-by: Oktai Tatanov <oktai.tatanov@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2022-01-07T20:27:12Z",
        "message": "TalkNet Fix (#3092)\n\n* Fix 'model' key and object collisionn.\n\nSigned-off-by: Stanislav Beliaev <stasbelyaev96@gmail.com>\n\n* Rename model config node to encoder.\n\nSigned-off-by: Stanislav Beliaev <stasbelyaev96@gmail.com>\n\n* Remove line adding.\n\nSigned-off-by: Stanislav Beliaev <stasbelyaev96@gmail.com>\n\n* Return TalkNet to README.\n\nSigned-off-by: Stanislav Beliaev <stasbelyaev96@gmail.com>\n\n* Add model.model test and remove some stuff.\n\nSigned-off-by: Stanislav Beliaev <stasbelyaev96@gmail.com>\n\n* Add moAdd typing to TalkNet.\n\nSigned-off-by: Stanislav Beliaev <stasbelyaev96@gmail.com>\n\n* TalkNet Training notebook fixed.\n\nSigned-off-by: Stanislav Beliaev <stasbelyaev96@gmail.com>\n\nCo-authored-by: Oktai Tatanov <oktai.tatanov@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2021-08-06T00:45:57Z",
        "message": "Add save restore connector to ModelPT (#2592)\n\n* add save restore connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add save restore connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add save restore connector property\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add _default_save_to\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* moving globals to app_state\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* moving globals to app_state\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add model attribute to connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add model attribute to connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix tabs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix tabs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove ModelPT import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add default restore\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add default restore\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove eff globals\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix tabs\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update globals, remove save restore property\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add setter\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add setter\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix app_state restore flag\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update paths\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add connector arg to from_pretrained\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update save restore connector after instantiating\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* get class from config in .nemo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add TODO\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move extract_state_dict to connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add methods for toch save and torch load\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* typo\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update mock model conf\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* revert\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move mock model to common collection\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update NLPModel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update test to use connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move artifacts to save restore connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add save_restore_connector arg to register_artifact\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* default save_restore_connector arg to None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* default save_restore_connector arg to None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* clean commented line\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* default save_restore_connector arg to None\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move MockModel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix docstrings, remove underscores, default from connector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update docstring\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update docstring\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* change name to is_model_being_restored\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* move constants from AppState to SaveRestoreConnector\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* encapsulate logic for model parallel checkpoint\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* style\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update mock config\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove unused import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add init_subclass, remove connector arg from register_artifact, move MockModel to tests\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* remove old import\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Add tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Finalize tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Finalize tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* fixing lgtm\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* fix lgtm\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update NLPModel.restore_from\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* Fix classpath resolution\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2021-06-03T22:49:50Z",
        "message": "Merge tag 'v1.0.0' into main\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2021-06-02T04:49:50Z",
        "message": "Adding new Models releases on NGC. (#2295)\n\n* added new models.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added tests for asr lm.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added tests for asr lm.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* dropped the test.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2021-05-26T06:32:31Z",
        "message": "Support multiple models being instantiated in same execution scope (#2245)\n\n* Support multiple models being instantiated in same execution scope\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Fix tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add locks to methods in appstate\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Perform locks only on write operations\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct deadlock issue\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add more tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add test for multi save and remove patch to change save type\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Update app state to preserve gidx of previous token\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct restoration logic for tarfiles\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2021-05-04T20:55:35Z",
        "message": "Update how artifacts work (#2138)\n\n* Update how artifacts work\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fixing some tests\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fix more tests\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* add __init__ to tests to make them discoverable\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* empty src support\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* updates plust unittest\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* add copyright check\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* copyright header\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fix style\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* handle hashed megatron checkpoint version in nlp restore_from\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add _MODEL_RESTORE_PATH to AppState\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* get rid of global folder caching\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* double register - warning instead of exception\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Add asr spe tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Pop out asr wpe pre-registered value\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct ASR tests and paths\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct tokenizer saving\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct ASR tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct ASR bpe mixin\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Patch up backward compatibility\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* update register_bert_model\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update all get_lm_model calls\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* return None if src not found\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* handle case with no tokenizer\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* do not add another hash is using tarfile_artifacts\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add return_none flag, update doc string\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* update default behavior of register_artifact for NLPModel\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* change kwarg name to verify_src_exists\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* use cfg instead of _cfg\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* some cleanups\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: ericharper <complex451@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2021-03-30T06:15:43Z",
        "message": "update to unittesting (#1983)\n\n* update to unittesting\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* expanding unittesting\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Update test_megatron.py\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* unskip export test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* try get test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add check to megatron test to make sure it is in\nourt CI environment\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2021-03-30T02:51:15Z",
        "message": "Support target classpath resolution for all ModelPT subclasses (#1982)\n\n* Support target classpath resolution for all ModelPT subclasses\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Support target classpath resolution for all ModelPT subclasses\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2021-03-25T04:10:48Z",
        "message": "Add conformer docs. (#1966)\n\n* added tests, initial docs on conformer.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* Added conformer encoder doc strings.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* Added conformer encoder doc strings.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added text classification model.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* added config table.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* addressed comments.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* addressed comments.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* addressed comments.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* addressed comments.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* addressed comments.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2021-03-15T21:54:53Z",
        "message": "NLP, Megatron and Tools docs (#1739)\n\n* wip\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* docs for nlp and tools init\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* tools docs\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* added script to convert raw data into nemo format\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* placeholders added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* punctuation model docs updated\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* Speech Regression Support (#1707)\n\n* Speech Regression support\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Speech Regression Support\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Speech Regression Support\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Refactoring after review\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Refactorings after review, fixes\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Refactorings after review, fixes\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Refactorings after review, fixes\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Refactorings after review, fixes\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Refactorings after review, fixes\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Refactorings after review, fixes\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Refactorings after review, fixes\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\n\n* update max seq len\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* tc_update\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* docs update\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* remove untouched files\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* review feedback\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* new ngc model names\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* text norm doc (#1893)\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* model name updated\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins rename model\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* quick start added, model_nlp added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* commnet changed\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: Diego Fustes Villad\u00f3niga <diegofustesfic@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2021-03-12T19:09:44Z",
        "message": "dropped conformer checkpoints. (#1897)\n\n* dropped conformer checkpoints.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>\n\n* dropped from unittest.\n\nSigned-off-by: Vahid <vnoroozi@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2021-03-11T22:12:21Z",
        "message": "Update ASR pretrained models (#1888)\n\n* Update ASR pretrained models\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct names for tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct Jenkinsfile\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add back BPE model to tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add back BPE model to tests\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Convert all QuartzNet15x5Base-En to stt_en_quartznet15x5\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Revert \"Convert all QuartzNet15x5Base-En to stt_en_quartznet15x5\"\n\nThis reverts commit 03424b32\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Add back QuartzNet15x5Base-En\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2021-02-05T00:49:31Z",
        "message": "Add save restore tests (#1717)\n\nSigned-off-by: smajumdar <titu1994@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/core/test_save_restore.py",
        "commit_date": "2020-11-24T21:34:31Z",
        "message": "Update ModelPT level save and restore (#1491)\n\n* Update ModelPT level save and restore\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Remove logging\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* polish style a little\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Correct model restoration from .nemo vs .pt checkpoint\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\n* Correct model restoration from .nemo vs .pt checkpoint\n\nSigned-off-by: smajumdar <titu1994@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/manualtest_model_downloads.py",
        "commit_date": "2021-09-20T01:58:04Z",
        "message": "Update model names (#2845)\n\n* updated speaker model names\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* update tutorial model names\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/manualtest_model_downloads.py",
        "commit_date": "2021-03-11T16:59:24Z",
        "message": "Renamed pretrained names (#1882)\n\n* Renamed pretrained names\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* Updated pretrained description format and updated README tutorials table with Speaker Diarization tutorials\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/manualtest_model_downloads.py",
        "commit_date": "2020-09-23T23:20:55Z",
        "message": "Aws2ngc (#1212)\n\n* change AWS links with NGC links\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* remove some experimental\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* bugfix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* bugfix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* bugfixes\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* fix test\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* attempted bugfix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* bugfixes\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* stylefix\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* file rename\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* download test refactor\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/collections/nlp/test_pretrained_models_performance.py",
        "commit_date": "2022-09-26T01:39:59Z",
        "message": "clean warnings from tests and CI runs, and prepare for upgrade to PTL 1.8 (#4830)\n\n* remove with_downloads marker warning from pytest\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* regex escape sequence and np float deprecation\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* improve speed of torchmetrics\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* fix python __int__ deprecation\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* multi binary accuracy\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* update topkaccuracy metric\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* trainer, text norm, qr -> linalg.qr\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* remove weights save path arg to trainer\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* ptl core warnings fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* on_pretrain_routine_start -> on_fit_start\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* add weights_save_path to deprecated args\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* style fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* Remove reference\n\nSigned-off-by: SeanNaren <snarenthiran@nvidia.com>\n\n* revert torch.long change\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\nSigned-off-by: SeanNaren <snarenthiran@nvidia.com>\nCo-authored-by: SeanNaren <snarenthiran@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/collections/nlp/test_pretrained_models_performance.py",
        "commit_date": "2022-02-23T21:40:46Z",
        "message": "upgrade PTL trainer flags (#3589)\n\n* upgrade PTL trainer flags\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* remove nlp override changes\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* fix test and update gpus -> devices\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* setting devices=1 for cpu case\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* update jenkins for gpus -> devices\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* single quote to double quote jenkins fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* single quote to double quote jenkins fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* devices in docs\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* update devices in tutorials :sigh:\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* checkpointing_callback -> enable_checkpointing\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* text normalization decoder trainer name fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* enable checkpoint callback name fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* NLPDDPPlugin overrides strategy ddp\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* more strategy cleaning for NLPDDPPlugin\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* now DDPPlugin for strategy removal\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* typo fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* NLPDDPPlugin more fixes\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* devices require accelerator as mandatory argument\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* moving megatron accelerator from gpu to cpu\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* accelerator null to strategy null fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* distrib_type taken from training_type_plugin\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* check for distributed type is removed\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* revert training type\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* revert transcribe_speech\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* style fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* typo fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* revert distributed backend type\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* remove flush_logs_every_n_steps trainer flag\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* rebase main\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* style fix\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* SGD gen update\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* NLPDDPPlugin change\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* remove strategy from dialogue conf\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* reverting find unused params\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* update jenkins\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* more nlp fixes\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>\n\n* num_nodes removal from NLPDDPPlugin\n\nSigned-off-by: nithinraok <nithinrao.koluguri@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/collections/nlp/test_pretrained_models_performance.py",
        "commit_date": "2021-11-30T15:55:49Z",
        "message": "Improve data pipeline for punctuation capitalization model and make other useful changes (#3159)\n\n* Fix: inference on short sequences problem\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add draft of new punctuation and capitalization model\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix debug config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add parameter check\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update punctuation training script\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix head config parameter names\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix ds_item and class_label parameters in config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix dataloader shuffling for tarred dataset\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce validation batch\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add debug print\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix metrics initialization\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix minor bug\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix device problem\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add debug print\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Register metrics properly\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Put metrics setup after module init\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce model size\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add wandb logging\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Change wandb name\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix logging names for metrics\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add debug print\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add returning from eval steps\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add second dev dataset\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Move config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix path to dataset\"\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add more tokenizer parameters\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add debug script for more tokenizer in creating tarred dataset\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update output path in debug script\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix minor bug in typing\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix bug in parsing arguments\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Do not pass tokenizer through queue\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Set hf tokenizer in debug script\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Try char vocabulary\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix typo\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve error message\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix OOV problem\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add label ids creation and getting\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: add missing parameter\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve error message for label ids building\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add short tar files repacking\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix minor bug and add more security\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix minor bug\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: replace Path with str\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: iter datasets\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve logging\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Turn off repacking\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Turn off repacking\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Turn on repacking\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Turn off repacking\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add debug print\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve unexpected removal\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Turn on repacking\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: remove repacked files\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add default config for testing\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve code style in evaluate script\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add docstrings\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove debug config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove commented code\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix code style in doc string\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix usage of parser.error function\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve working with config and fix restoring of old checkpoints\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Do not demand cfg as dataclass\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add backward compatibility for absense of use_tarred_dataset\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fight for backwards compatibility\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add tokens_in_batch backward compatibility\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Undo unintentional changes in tutorial\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Do not allow more workers than queries\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix metric names in tests\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix metric location\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix metric location\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Require ds_item or data_dir\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Disable multiprocessing data preparation by default\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Disable multiprocessing data preparation by default\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Disable multiprocessing data preparation by default\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Make minor improvements in docstrings and typing\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix finetuning code\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix shuffle train dataset config parameter\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix evaluation script\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update test\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add new test and make minor changes\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix repacked file names\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add assertion error\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix minor bug in regex\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve Jenkins command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: add name to Jenkins stage\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: add steps block to Jenkins stage\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: move nemo_experiments removal to post section\n\nPreviously I encoutered a weird error\n\n+ rm -rf nemo_experiments\nrm: cannot remove 'nemo_experiments': Directory not empty\nscript returned exit code 1\n\nAnd suspect that this could be because to parallel stages try to\nremove same directory simultaneously.\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Turn off cache usage in Jenkins for token classification models\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Stop pickling features\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reference webdataset in docs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Make multiple minor improvements\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add parameters tokens_in_batch, repack to documentation\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Refactoring and improving readability\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Make tar_shuffle_n optional parameter\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix path to label vocab files\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix metadata label vocab key\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Create for_nemo directory\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix tar_shuffle_n default value\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* First round of review fixes\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Return tokens_in_batch default value\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove duplicate parameters in `CommonDatasetParameters`\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove duplicate parameters in config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Refactor user interface\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: add missing parameter in calling setting dataloader up\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: replace data config with model config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: typo in config parameter name\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: location of label ids parameters in config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: transforming not first legacy data config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: num_samples can be negative\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: create directory for nemo ids files\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: remove unremoved with_label\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: features contain ids if loaded from pickle\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix kwargs parameters\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add label setting for testing case\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix: change parameter location in config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix: transform legacy config in init\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix: make minor improvement in checking config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: check label ids for None before checking pad label id\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: set labels when restoring\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: place where label ids are taken\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix minor bug\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: register artifacts in set_label_ids\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: perform checking only if label ids are not set\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: set label_ids_are_set\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix using of dataset in create tarred dataset\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: manipulate label ids if fragment_idx is zero\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: remove directory correctly\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: vocab file names\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: vocab file names\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add debug print\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add directories for cache and label info\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Minor fixes\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Minor fix\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Minor fix\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve debug config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Create missing directories\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve feature pkl file name\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* WORKING VERSION OF VOCAB CONFIG\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve vocab file extraction\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve vocab file extraction\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix register artifact calls\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: add class_labels to legacy fixing\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: add missing method\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add support for checkpoints without class labels artifact\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: add missing return values to function\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix saving label ids in creation of tarred dataset\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: adjust tarred dataset consistency check\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: consistency check call\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Try checking labels every time dataloader is set\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: add another label consistency check\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add more parameters to update_config function\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Small docstrings and refactoring\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Try to use ds_item in get_metrics test func\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Try new format get_metrics func\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* update data configs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix merging data configs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix test parameters\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix config parameter names\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve docstrings\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve docstrings and make small refactoring\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Minor fix in rst API\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add apex to autodoc_mock_imports\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix megatron func location\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update rst files\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: some fixes in docs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add configs to toctree\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Try 2 fixes in docs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: not f docstrings\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Try another small fix\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Try another small fix\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Make multiple type improvements\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add draft of correct doc strings\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix minor bug in head init and code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add and improve docs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix docs\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Make minor fix in overriding config parameters\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: restoring from checkpoint\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix minor bug\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix minor bug in command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix minor mistake in Jenkins command\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* set use_tarred_dataset in metrics test func\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix paths to tokenizer files\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve error messages\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix: consider case when cache is ready and ids are provided\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix: improve update_config method behaviour\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update tutorial\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Undo unintentional changes in tutorial\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Make many minor fixes\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* fix notebook\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove empty sell in the end of tutorial\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Make n_jobs parameter optional\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove unused imports\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix minor bug\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* change config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve updating of optim config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add debug print\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Extend debug print\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Extend debug print\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add more debug prints\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add more debug prints\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Replace accelerator with strategy\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add use_cache check\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Make minor fixes\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix func name in tutorial\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add punctuation inference test\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix script name\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove unused import\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix links documentation\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix links documentation\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix device setting\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve script help\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add comment for `tokens_in_batch` in config\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Reduce batch size in test\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/collections/nlp/test_pretrained_models_performance.py",
        "commit_date": "2021-09-21T13:31:24Z",
        "message": "Feat/punctuation capitalization/long queries signoff (#2683)\n\n* Move files from long_queries branch\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* remove sys.path modification\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Update tests\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Remove unused imports\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Move all code to punctuate_capitalize.py\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix minor bug\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve help message\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Improve help message\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add docstrings and typing\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Add remark about default parameter values\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* refactor\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Refactor\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix typo\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix typo\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix script name\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix script name\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\n* Fix code style\n\nSigned-off-by: PeganovAnton <peganoff2@mail.ru>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/collections/nlp/test_pretrained_models_performance.py",
        "commit_date": "2021-03-31T05:10:04Z",
        "message": "Merge branch 'main' of https://github.com/NVIDIA/NeMo into main\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/collections/nlp/test_pretrained_models_performance.py",
        "commit_date": "2021-03-31T01:38:57Z",
        "message": "Merge branch 'r1.0.0rc1' into main\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/collections/nlp/test_pretrained_models_performance.py",
        "commit_date": "2021-03-31T00:06:16Z",
        "message": "Autouse cleanup_local_folder fixture (#1990)\n\n* force cleanup\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* fix\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/collections/nlp/test_pretrained_models_performance.py",
        "commit_date": "2021-03-30T06:15:43Z",
        "message": "update to unittesting (#1983)\n\n* update to unittesting\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* expanding unittesting\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\n* Update test_megatron.py\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* unskip export test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* try get test\n\nSigned-off-by: ericharper <complex451@gmail.com>\n\n* add check to megatron test to make sure it is in\nourt CI environment\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>\n\nCo-authored-by: Eric Harper <complex451@gmail.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/collections/nlp/test_pretrained_models_performance.py",
        "commit_date": "2021-03-16T06:38:44Z",
        "message": "Merge branch 'r1.0.0rc1' into main\n\nSigned-off-by: Oleksii Kuchaiev <okuchaiev@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/collections/nlp/test_pretrained_models_performance.py",
        "commit_date": "2021-03-15T21:54:53Z",
        "message": "NLP, Megatron and Tools docs (#1739)\n\n* wip\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* docs for nlp and tools init\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* tools docs\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* added script to convert raw data into nemo format\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* placeholders added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* punctuation model docs updated\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* fix\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* Speech Regression Support (#1707)\n\n* Speech Regression support\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Speech Regression Support\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Speech Regression Support\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Refactoring after review\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Refactorings after review, fixes\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Refactorings after review, fixes\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Refactorings after review, fixes\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Refactorings after review, fixes\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Refactorings after review, fixes\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Refactorings after review, fixes\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\n* Refactorings after review, fixes\n\nSigned-off-by: diego-fustes <diegofustesfic@gmail.com>\n\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\n\n* update max seq len\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* tc_update\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* docs update\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* remove untouched files\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* review feedback\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* new ngc model names\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* text norm doc (#1893)\n\nSigned-off-by: Yang Zhang <yangzhang@nvidia.com>\n\n* model name updated\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* jenkins rename model\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* quick start added, model_nlp added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* commnet changed\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\nCo-authored-by: Diego Fustes Villad\u00f3niga <diegofustesfic@gmail.com>\nCo-authored-by: Somshubra Majumdar <titu1994@gmail.com>\nCo-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>\nCo-authored-by: Oleksii Kuchaiev <okuchaiev@users.noreply.github.com>\nCo-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/collections/nlp/test_pretrained_models_performance.py",
        "commit_date": "2021-03-04T19:50:30Z",
        "message": "CI Fixes for Lightning 1.2.1 (#1839)\n\n* updates\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add back pleasefixme\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* rmtree\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add cleanup_local_folder fixtures instead of rmtree\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* bugfix?\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* add back pleasefixme\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* typo\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* set melGAN to find_unused = True\n\nSigned-off-by: Jason <jasoli@nvidia.com>\n\n* force deletion\n\nSigned-off-by: Jason <jasoli@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/collections/nlp/test_pretrained_models_performance.py",
        "commit_date": "2021-02-26T18:47:00Z",
        "message": "set max seq length for inference (#1809)\n\n* update inference\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* update\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* make params explicit\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>"
    },
    {
        "repo_url": "github.com/NVIDIA/NeMo",
        "filepath": "tests/collections/nlp/test_pretrained_models_performance.py",
        "commit_date": "2021-01-22T21:22:55Z",
        "message": "pre-trained models performance test added and masking fix (#1656)\n\n* performance tests added\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* distilbert mertics updated\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* data_dir path updated to jenkins\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* header fixed\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>\n\n* run on gpu only\n\nSigned-off-by: ekmb <ebakhturina@nvidia.com>"
    },
    {
        "repo_url": "github.com/HumanSignal/label-studio-ml-backend",
        "filepath": "label_studio_ml/examples/nemo/asr.py",
        "commit_date": "2023-07-19T16:20:52Z",
        "message": "fix: LSDV-2775: v2 and ML backend /versions (#286)\n\n* fix: LSDV-2775: Switching to v2 version, change API for /versions, fix fit() function in ML backends\n\n* Remove key\n\n* Change README\n\n* Loosen requirements.txt version requirements to avoid conflict\n\n* Update simplest backend dockerfile to simplest setup which works, enable autoupdate feature\n\n* Simplify fit function to conform to latest data schema\n\n* Make OpenAIPredictor more generic\n\n* Fix log level\n\n* Fix prompt and output payload\n\n* Add file prompt\n\n* Fix the simplest ml backend\n\n* Revert package updates for testing\n\n* Add back in label studio ml requirement, removing it did not fix the tests\n\n* Fix train_output persistence\n\n* Remove broken dirs\n\n* Update to use current version\n\n* Try clearing unneeded space to avoid out of memory error\n\n* Remove test change\n\n---------\n\nCo-authored-by: nik <nik@heartex.net>\nCo-authored-by: andreasdivaris <dredivaris@gmail.com>"
    },
    {
        "repo_url": "github.com/HumanSignal/label-studio-ml-backend",
        "filepath": "label_studio_ml/examples/nemo/asr.py",
        "commit_date": "2021-10-14T15:23:30Z",
        "message": "[fix] Delete label studio dependency in label-studio-ml"
    },
    {
        "repo_url": "github.com/HumanSignal/label-studio-ml-backend",
        "filepath": "label_studio_ml/examples/nemo/asr.py",
        "commit_date": "2021-05-31T04:51:03Z",
        "message": "Add undefined field in other ml backends"
    },
    {
        "repo_url": "github.com/HumanSignal/label-studio-ml-backend",
        "filepath": "label_studio_ml/examples/nemo/asr.py",
        "commit_date": "2021-04-30T18:03:13Z",
        "message": "Update asr.py"
    },
    {
        "repo_url": "github.com/HumanSignal/label-studio-ml-backend",
        "filepath": "label_studio_ml/examples/nemo/asr.py",
        "commit_date": "2021-03-30T14:02:02Z",
        "message": "Make examples compatible with LS 1.0"
    },
    {
        "repo_url": "github.com/HumanSignal/label-studio-ml-backend",
        "filepath": "label_studio_ml/examples/nemo/asr.py",
        "commit_date": "2021-03-15T15:04:28Z",
        "message": "Add ML backend SDK code from label-studio"
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-11-06T17:39:31Z",
        "message": "Fix stall when pynini is imported before this library (#33)\n\n* Fix stall when pynini is imported before this library\n\nPreviously, doing this:\n\nimport pynini\nimport riva.asrlib.decoder\n\nwould end in a stall. This was because the FlagRegister template class\nhad a static variable Mutex, that ended up being shared by default in\nthe global symbol namespace. Because the openfst versions are\ndifferent between the two libraries (I think pynini's openfst 1.8.2\nuses absl::Mutex), the mutex layouts are different, probably causing\nthe stall.\n\nWe don't want the symbols to be shared in this case, so we disable\nunique symbols via \"-fno-gnu-unique\".\n\n* Increase error margin.\n\nHelps with flaky CI failures."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-09-07T18:57:15Z",
        "message": "Add improved flashlight tests.\n\nThis reads data from memory rather than from disk for a more\napples-to-apples comparison."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-05-22T23:12:56Z",
        "message": "0.4.0 release\n\n3.10 test does not work for bizarre reasons (see file changes)"
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-05-22T23:12:56Z",
        "message": "redo partial paths.\n\nSee kaldi commit for more information."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-05-22T23:12:56Z",
        "message": "Redo online decoding.\n\nChoose whether to depend on final state probabilities in lattice\ngeneration.\n\nAdd python interface to online decoder.\n\nUnit test that best path callbacks are working. Sometimes, they vary\nfrom the lattice-based \"offline\" decoder results, but this is rare. It\nis good enough for now."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-05-22T23:12:56Z",
        "message": "Add support for passing a list of tensors instead of a padded tensor"
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-04-03T21:46:00Z",
        "message": "Version 0.3.2\n\nActual hotfix.\n\nVersion 0.3.1 got yanked because I misspecified the version of\nnanobind in pyproject.toml"
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-04-03T21:46:00Z",
        "message": "0.3.0 release"
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-04-03T21:46:00Z",
        "message": "Add back Conformer CTC Large unit tests.\n\nThey are working! I just thought there was an error because of an\nerroneous error check."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-04-03T21:46:00Z",
        "message": "Add support for returning ilabels from nbest decoding."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-03-23T19:24:26Z",
        "message": "Remove useless commented out test."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-03-23T19:24:26Z",
        "message": "clang-format, black format, isort"
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-03-23T19:24:26Z",
        "message": "Add throughput tests.\n\nWe don't check that RTFx is the same right now. It might be too\nflakey.\n\nRecorded throughput results here: https://github.com/nvidia-riva/riva-asrlib-decoder/issues/19"
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-03-23T19:24:26Z",
        "message": "Add WER unit tests for alternate topologies other than Eessen.\n\nMinor cleanup."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-03-23T19:24:26Z",
        "message": "Fix memory leak by using \"class scope\" fixture.\n\nPreviously, 5 GiB were being created for every test because the\nlibrispeech test and dev sets were being loaded every time."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-03-23T19:24:26Z",
        "message": "Change to nanobind.\n\nFix GPU memory leak. My pybind11 DLPack integration was incorrect."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-03-23T19:24:26Z",
        "message": "Save work before trying nanobind."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-03-23T19:24:26Z",
        "message": "Add unit test for comparing NeMo and flashlight."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-03-23T19:24:26Z",
        "message": "Test throughput performance"
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-01-06T16:59:07Z",
        "message": "Fix bug where allocating a decoder, deallocating it, and then reallocating a new one crashed.\n\nAdd a sweep over the entirety of librispeech in the nemo unit test."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-01-05T00:53:30Z",
        "message": "Migrate to pytest, from unittest\n\npytest fixtures are helpful for setting things up.\n\nAnd unittest could never detect my test cases from within cibuildwheel\nfor some reason.\n\nAdd a half precision test for NeMo.\n\nTbhere is a crash when I create more than one cuda decoder object for\nsome reason. Will investigate later."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2023-01-05T00:53:30Z",
        "message": "Add NeMo end-to-end test\n\nThe WER is lower with beam search than with greedy decoding, which is good."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2022-12-13T23:32:22Z",
        "message": "cibuildwheel support\n\nCommit before trying to make a namespace package."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2022-12-13T23:31:53Z",
        "message": "WIP: Make lattice postprocessor optional.\n\nThis is to debug some WER regressions comapred to CPU-based decoding."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2022-10-21T22:22:23Z",
        "message": "Fix #3 (#4)\n\nSee https://github.com/kaldi-asr/kaldi/pull/4802"
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2022-07-20T18:33:01Z",
        "message": "Fix bug"
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2022-07-20T17:19:46Z",
        "message": "Fix creation of T.fst.\n\nPreviously, the units were sorted alphabetically. Fix this by\nproviding the \"--units\" option explicitly. Probably should make this a\nrequired argument."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2022-06-24T06:18:44Z",
        "message": "Formatting."
    },
    {
        "repo_url": "github.com/nvidia-riva/riva-asrlib-decoder",
        "filepath": "src/riva/asrlib/decoder/test_graph_construction.py",
        "commit_date": "2022-06-21T22:55:15Z",
        "message": "Open source commit."
    },
    {
        "repo_url": "github.com/dusty-nv/jetson-voice",
        "filepath": "scripts/nemo_export_onnx.py",
        "commit_date": "2021-06-07T18:00:31Z",
        "message": "added NeMo scripts"
    },
    {
        "repo_url": "github.com/k2-fsa/sherpa-onnx",
        "filepath": "scripts/nemo/speaker-verification/export-onnx.py",
        "commit_date": "2024-01-13T11:49:45Z",
        "message": "Export speaker verification models from NeMo to ONNX (#526)"
    },
    {
        "repo_url": "github.com/wefantasy/label-studio-demo",
        "filepath": "backend/examples/nemo/asr.py",
        "commit_date": "2022-11-24T09:16:57Z",
        "message": "\u57fa\u672c\u5b8c\u6210"
    },
    {
        "repo_url": "github.com/audio-df-ucb/ClonedVoiceDetection",
        "filepath": "src/packages/ExperimentPipeline.py",
        "commit_date": "2023-07-14T06:01:49Z",
        "message": "src folder with relevant pipeline code"
    },
    {
        "repo_url": "github.com/dusty-nv/jetson-containers",
        "filepath": "packages/nemo/test_qa.py",
        "commit_date": "2023-08-21T18:03:04Z",
        "message": "added apex to nemo container"
    },
    {
        "repo_url": "github.com/jsvir/vad",
        "filepath": "nemo/core/classes/common.py",
        "commit_date": "2023-03-08T13:31:39Z",
        "message": "."
    },
    {
        "repo_url": "github.com/jsvir/vad",
        "filepath": "nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2023-03-08T13:31:39Z",
        "message": "."
    },
    {
        "repo_url": "github.com/jsvir/vad",
        "filepath": "nemo/collections/asr/parts/utils/decoder_timestamps_utils.py",
        "commit_date": "2023-03-08T13:31:39Z",
        "message": "."
    },
    {
        "repo_url": "github.com/jsvir/vad",
        "filepath": "nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2023-03-08T13:31:39Z",
        "message": "."
    },
    {
        "repo_url": "github.com/daddydrac/NVIDIA-Rapids-NeMo-PyTorch-Tensorboard",
        "filepath": "examples/nlp/intent_detection_slot_tagging/joint_intent_slot_infer.py",
        "commit_date": "2020-03-17T03:29:14Z",
        "message": "Added mounted volumes"
    },
    {
        "repo_url": "github.com/daddydrac/NVIDIA-Rapids-NeMo-PyTorch-Tensorboard",
        "filepath": "examples/nlp/intent_detection_slot_tagging/joint_intent_slot_infer_b1.py",
        "commit_date": "2020-03-17T03:29:14Z",
        "message": "Added mounted volumes"
    },
    {
        "repo_url": "github.com/daddydrac/NVIDIA-Rapids-NeMo-PyTorch-Tensorboard",
        "filepath": "examples/nlp/intent_detection_slot_tagging/joint_intent_slot_with_bert.py",
        "commit_date": "2020-03-17T03:29:14Z",
        "message": "Added mounted volumes"
    },
    {
        "repo_url": "github.com/webaverse/tiktalknet",
        "filepath": "core/extract.py",
        "commit_date": "2022-01-08T14:20:33Z",
        "message": "Reverted auto-tune change"
    },
    {
        "repo_url": "github.com/webaverse/tiktalknet",
        "filepath": "core/extract.py",
        "commit_date": "2021-12-28T18:50:39Z",
        "message": "Reconstruction fixes"
    },
    {
        "repo_url": "github.com/webaverse/tiktalknet",
        "filepath": "core/extract.py",
        "commit_date": "2021-12-28T05:22:41Z",
        "message": "Added spectrogram reconstruction"
    },
    {
        "repo_url": "github.com/webaverse/tiktalknet",
        "filepath": "core/extract.py",
        "commit_date": "2021-12-26T03:38:21Z",
        "message": "Improved pitch detection"
    },
    {
        "repo_url": "github.com/webaverse/tiktalknet",
        "filepath": "core/extract.py",
        "commit_date": "2021-12-25T23:59:40Z",
        "message": "Refactor and license update"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/nemo/core/classes/common.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/nemo/core/classes/modelPT.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/tools/asr_webapp/model_api.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/tools/nmt_webapp/nmt_service.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/nemo/collections/tts/models/mixer_tts.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/nemo/collections/nlp/modules/common/lm_utils.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/nemo/collections/asr/parts/utils/transcribe_utils.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/scripts/asr_language_modeling/ngram_lm/train_kenlm.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/tools/ctc_segmentation/scripts/run_ctc_segmentation.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/nemo/collections/asr/parts/utils/decoder_timestamps_utils.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/scripts/asr_language_modeling/ngram_lm/eval_beamsearch_ngram.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/examples/nlp/duplex_text_normalization/data/create_tarred_dataset.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/nemo/collections/nlp/models/duplex_text_normalization/duplex_decoder.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/scripts/asr_language_modeling/ngram_lm/eval_beamsearch_ngram_transducer.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/examples/asr/asr_cache_aware_streaming/speech_to_text_cache_aware_streaming_infer.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/nemo/collections/nlp/models/token_classification/punctuation_capitalization_lexical_audio_model.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/tests/core/test_save_restore.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/tests/manualtest_model_downloads.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/Eric3911/OpenAGI",
        "filepath": "NeMo-master/tests/collections/nlp/test_pretrained_models_performance.py",
        "commit_date": "2023-05-06T06:44:54Z",
        "message": "\u6a21\u578b\u66f4\u65b0\n\nupdate"
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2024-02-27T11:11:47Z",
        "message": "[Update] An example for Gemma model was initially added.\n[Update] An example for Transformer Reinforcement Learning (TRL) library to train small LLMs (sLLMs) was initially added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2024-02-21T12:45:57Z",
        "message": "[Update] Examples for DINO and DPT models were implemented in hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2024-02-16T06:16:19Z",
        "message": "[Update] Placeholders for examples of Hugging Face TRL library were added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2024-02-08T03:52:31Z",
        "message": "[Update] Several examples for stable diffusion models of Stability AI were implemented.\n[Update] Information about Transformer Reinforcement Learning (TRL) library was moved from hugging_face_test.py to hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2024-01-31T08:31:27Z",
        "message": "[Update] A test was added to fine-tune a ResNet model using Dog/Cat dataset in pytorch_transfer_learning.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2024-01-28T13:07:24Z",
        "message": "[Update] An example of Zephyr-7B was added in hugging_face_transformers_test.py, but was not tested.\n[Update] The information about Transformer Reinforcement Learning (TRL) was described in hugging_face_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2024-01-11T04:04:23Z",
        "message": "[Update] An example for retrieval-augmented generation (RAG) was added in hugging_face_transformers_test.py.\n[Update] Information about TableMASTER-mmocr was removed from mmocr_usage_guide.txt."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-12-24T02:40:32Z",
        "message": "[Update] A few examples for Mistral-7B and Mixtral-8x7B models were added.\n[Update] The installation of TensorFlow 2 were updated."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-12-23T12:07:02Z",
        "message": "[Update] An example of ORCA-2 model was added.\n[Update] The examples for ViT, ViLT, BEiT, LayoutLM, and Donut models were merged respectively.\n[Update] The information about data preparation, training, evaluation, visualization, and model export were supplemented in paddle_ocr_usage_guide.txt."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-11-24T08:49:41Z",
        "message": "[Update] A customized version of ViT model was implemented and tested, which doesn't have classification token and head."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-11-20T04:48:59Z",
        "message": "[Update] A few examples for Falcon model were initially implemented.\n[Update] A few examples for StarCoder and Replit models were implemented, but yet tested."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-11-10T01:27:50Z",
        "message": "[Update] LLMs Yi-6B & Yi-34B were tested."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-11-06T12:24:53Z",
        "message": "[Update] The forecasts of transformers.TimeSeriesTransformerForPrediction were evaluated by MASE, MAPE, sMAPE.\n[Update] Metrics for evaluating ML models' performance in evaluate library were tested."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-11-03T10:46:04Z",
        "message": "[Update] Two examples for phi-1 & phi-1.5 models were initially added.\n[Update] A few examples for Kosmos-2 model were initially added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-10-12T12:13:43Z",
        "message": "[Update] A few examples for Probabilistic time series transformer model were added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-10-07T08:51:44Z",
        "message": "[Update] Several examples for Perceiver IO model were initially committed."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-09-26T10:56:44Z",
        "message": "[Update] A simple example for Code Llama model was initially added.\n[Update] A few commands were explained to profile Python scripts."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-09-21T12:31:58Z",
        "message": "[Update] A simple example for OpenLLaMA models was implemented."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-09-04T03:59:25Z",
        "message": "[New] A few examples for PID, MPC, LQR using python-control library was initially added.\n[Update] A simple example for trajectory transformer models was added in hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-09-02T12:30:02Z",
        "message": "[New] An example for model predictive control (MPC) was initially committed.\n[Update] A test for CodeParrot model was initially implemented in hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-08-31T06:01:24Z",
        "message": "[Update] Memory footprint and computing performance (FLOPS) Hugging Face transformers models was measured.\n[Update] A simple test for Hugging Face datasets was added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-08-04T08:13:21Z",
        "message": "[Update] An example for OpenFlamingo library was added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-07-25T12:07:07Z",
        "message": "[Update] A few examples for Llama 2 model were added in hugging_face_transformers_test.py.\n[Update] Model parallelism was tested based on Hugging Face Accelerate library in hugging_face_transformers_test.py.\n[Update] Information about Hugging Face Accelerate library was reinforced."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-07-22T06:48:12Z",
        "message": "[Update] Cross references about transformer and ViT models were reinforced.\n[Chore] vit_test.py was moved from sw_dev/python/rnd/test/machine_learning/vit_test.py to sw_dev/python/rnd/test/machine_vision/vit_test.py.\n[Update] The installation of node.js was explained."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-07-17T01:20:26Z",
        "message": "[Update] Several examples for CodeBERT, CodeBERTa, CodeT5+, CodeGen2, & CodeGen2.5 models were added.\n[Update] An example of SpeechT5 model was divied into 3 examples: ASR, TTS, & speech-to-speech."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-07-12T07:54:25Z",
        "message": "[Update] An example for Decision Transformer was initially committed.\n[Update] A few examples for NVIDIA Megatron-LM, ASR, TTS models were implemented.\n[Update] An example for SegFormer model was initially added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-06-30T14:20:26Z",
        "message": "[Update] The method, chain of thoughts (CoT) was tested on two LLMs, LLaMA & MPT."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-06-27T04:15:37Z",
        "message": "[Update] A few examples for MPT & TVLT models were implemented in hugging_face_transformers_test.py.\n[Chore] table_generation_usage_guide.txt was moved to SWLP repository."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-06-22T14:49:33Z",
        "message": "[Update] Three language models were tested: LLaMA, Galactica, & OPT models."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-06-15T07:51:37Z",
        "message": "[Update] The example of LLaMA model was reinforced."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-05-26T18:49:16Z",
        "message": "[Update] A test for data parallelism was implemented in PyTorch library."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-05-05T03:23:29Z",
        "message": "[Update] Two simple tests for two Facebook's language models, OPT and Galactica were initially implemented."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-04-30T14:34:59Z",
        "message": "[New] A simple tutorial for MMSegmentation library was initially committed."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-04-06T03:27:45Z",
        "message": "[Update] A couple of simple examples for LLaMa model were implemented, but they were not tested due to library version issue."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-04-04T11:52:41Z",
        "message": "[Update] Several examples for CodeT5 and CodeGen models were implemented to generate code.\n[Update] Several examples for GIT and BLIP models for vision-and-language modeling models were implemented.\n[Update] A few examples for TaPEx model were implemented to understand tables."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-04-01T14:10:48Z",
        "message": "[New] A couple of examples for GPT4All models were added, but they were not correctly working."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-04-01T06:26:08Z",
        "message": "[New] Two simple examples for PaLM and PaLM+RLHF models were implemented, but the models were not trained in the examples."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-30T08:06:47Z",
        "message": "[New] Several examples for table processing (Table Transformer, TATR), OCR (TrOCR), speech processing (SpeechT5) were initially added to hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-29T05:25:41Z",
        "message": "[Update] Several examples for speech recognition (whisper) & synthesis (tacotron2 & fastspeech2) were newly implemented in hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-26T07:02:13Z",
        "message": "[New] A few examples for ALIGN model were implemented in hugging_face_transformers_test.py.\n[Update] A couple of examples for CLIP model were added in hugging_face_transformers_test.py.\n[Update] Useful information about Transformer architectures was described."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-24T06:24:31Z",
        "message": "[Update] A simple example about dataclass in Python was added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-22T14:48:31Z",
        "message": "[Update] A couple of examples of seq-to-seq models for LoRA & Prefix Tuning were implemented in hugging_face_test.py.\n[Update] An example for CLIP model was implemented in hugging_face_transformers_test.py.\n[Update] A few examples for Whisper model were implemented in hugging_face_transformers_test.py.\n[New] A usage guide for Hugging Face library was added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-21T07:10:38Z",
        "message": "[Update] A simple example of Parameter-Efficient Fine-Tuning (PEFT) library was added to hugging_face_test.py.\n[Update] A simple test of tokenizers was added to hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-18T11:41:29Z",
        "message": "[Update] A couple of examples for diffusion models of StabilityAI and CompVis were added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-18T05:09:16Z",
        "message": "[Update] A few examples for Flan-T5 model were reinforced in hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-16T11:52:13Z",
        "message": "[Update] Information about Hugging Face models was supplemented."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-15T12:08:24Z",
        "message": "[Update] An example for question answering using GPT-neo was added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-14T02:43:49Z",
        "message": "[Update] A few examples for BLOOM and Flan-T5 models were implemented."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-09T01:51:43Z",
        "message": "[Update] A test for KLUE BERT models was implemented."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-09T01:49:32Z",
        "message": "[Update] A few examples of text summarization for Korean & English were implemented, but their results were not good.\n[Update] A few examples for T5 model were added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-07T17:44:21Z",
        "message": "[Update] A few tests were added for GPT & BERT models."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-01T14:37:43Z",
        "message": "[New] A few guides were initially committed for Hugging Face Hub library."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-01-19T10:11:50Z",
        "message": "[Update] Several examples for vision, vision and language models were added in HuggingFace library."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-01-19T08:06:44Z",
        "message": "[Update] Several examples for LayoutLM & Donut models were implemented in HugggingFace library."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2022-04-01T07:00:58Z",
        "message": "[Chore] transformers_test.py was renamed to hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/nvidia-riva/nemo2riva",
        "filepath": "tests/test_cli.py",
        "commit_date": "2022-12-19T21:29:15Z",
        "message": "reorganizing for release\n\nSigned-off-by: Boris Fomitchev <bfomitchev@nvidia.com>"
    }
]