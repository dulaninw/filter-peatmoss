[
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tools/g2p.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tools/g2p.py",
        "commit_date": "2023-07-31T13:50:49Z",
        "message": "Remove sys.exit() calls in recipes and tools"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tools/g2p.py",
        "commit_date": "2022-07-28T00:33:47Z",
        "message": "G2P: Minor typo fix"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tools/g2p.py",
        "commit_date": "2022-07-22T01:40:21Z",
        "message": "fix style"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tools/g2p.py",
        "commit_date": "2022-07-21T04:12:33Z",
        "message": "G2P: Minor edits, add support for overrides for G2P CLI when restoring a checkpoint"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tools/g2p.py",
        "commit_date": "2022-07-19T02:41:01Z",
        "message": "G2P: Add a fallback for loading older checkpoints without PER recorded"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tools/g2p.py",
        "commit_date": "2022-07-09T19:16:57Z",
        "message": "G2P: Fixes"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tools/g2p.py",
        "commit_date": "2022-07-09T18:51:23Z",
        "message": "G2P: Updated the tool to support word embeddings"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tools/g2p.py",
        "commit_date": "2022-07-09T03:19:29Z",
        "message": "G2P: Add the ability to load checkpoints (useful for testing fresh experiments)"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tools/g2p.py",
        "commit_date": "2022-06-23T03:19:16Z",
        "message": "G2P: Changes to pass consistency tests"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tools/g2p.py",
        "commit_date": "2022-02-23T12:55:37Z",
        "message": "G2P: Refactoring and clean-up"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tools/g2p.py",
        "commit_date": "2022-01-15T18:38:05Z",
        "message": "Fix a style issue"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tools/g2p.py",
        "commit_date": "2022-01-15T17:56:22Z",
        "message": "G2P: Move the transcribe script into tools, add documentation and examples"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/CVSS/S2ST/train.py",
        "commit_date": "2024-02-21T19:54:39Z",
        "message": "fix recipe tests - part1 (#2416)"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/CVSS/S2ST/train.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/CVSS/S2ST/train.py",
        "commit_date": "2023-10-27T16:13:39Z",
        "message": "Add speech-to-speech translation (#2044)\n\n* Add S2ST with cvss recipe\n\n* Refactor K-means training\n\n* Clean quantization training and unit-to-speech training in LJSpeech recipe\n\n* Add documentation and tests for UnitHiFiGAN\n\n* Add inference interface for UnitHiFiGAN\n\n* Clean U2S hparams\n\n* Add extra requirement for k-means training\n\n* Add ReadMe for LJSpeech S2ST recipe and update hprarams\n\n* Resolve comments on quantization\n\n* Resolve comments on HiFi-GAN training\n\n* Fix authors in HifiGAN model\n\n* Remove old stuff\n\n* Fix LJSpeech S2ST\n\n* Improve Wandb logger init, no longer require external yaml file\n\n* add wandb log folder to .gitignore\n\n* Add extra requirements to CVSS recipe\n\n* Update CVSS S2ST\n\n* Add verbose option to disable warnings when a model is loaded\n\n* Refactoring and adding evaluation pipeline\n\n* Fix ljspeech_prepare.py path according to new recipe structure\n\n* Update codes folder construction to allow easy testing\n\n* Add tests\n\n* Update CVSS\n\n* Update LJSpeech S2ST\n\n* Update tests\n\n* Add empty README for CVSS\n\n* Fix pre-commit\n\n* Fix pre-commit\n\n* Update kmeans model name\n\n* Update CVSS S2ST recipe & add HF pretrained vocoder model\n\n* Update tests\n\n* Update CVSS S2ST hparams\n\n* Fix docstrings\n\n* Update tests\n\n* Revert verbose argument addition\n\n* Revert verbose argument addition\n\n* Add automatic resampling in Quantization recipe\n\n* Add automatic resampling in Quantization recipe\n\n* Add automatic resampling in extract_code\n\n* Update README\n\n* Update CVSS S2ST recipe\n\n* Increase timeout in init_process_group to avoid crash during dataprep\n\n* Update CVSS tests\n\n* Fix transcript normalization for BLEU score\n\n* Update LJSpeech S2ST README.md\n\n* Update cvss_prepare.py\n\n* Update train_fr-en.yaml\n\n* Update cvss_prepare.py\n\n* Fix codes folder path\n\n* Fix file extension\n\n* Add docstring for wandb logger\n\n* Fix docstring for wandb logger\n\n* Add small subset for evalution and adapt training script\n\n* Update hparams\n\n* Update cvss_prepare.py\n\n* Update training scripts\n\n* Update docstring in LJSpeech S2ST recipe\n\n* Update docstring in LJSpeech S2ST recipe\n\n* Add automatic resampling\n\n* Add model weights and training logs\n\n* Update docstring in CVSS S2ST recipe\n\n* Add S2UT interface\n\n* Fix HiFi-GAN GeneratorLoss forward args\n\n* Update ljspeech_prepare path\n\n* Fix UnitHiFiGAN interface docstring\n\n* merged latest develop, switched to speechbrain dropbox, fixed small yaml issues\n\n* A. README files: point 1 and 2\n\n* B. File Organization: Relocate Quantization recipe\n\n* B. File Organization: Relocate Unit HiFi-GAN and update symbolic link\n\n* Sync with develop\n\n* Update requirements\n\n* Update README\n\n* Fix symbolic link\n\n* Fix merge\n\n* Fix tests\n\n* Fix mimport\n\n* Fix LJSpeech tests\n\n* Fix CVSS tests\n\n* Fix CVSS dataprep\n\n* Add a docstring for the process_duration function\n\n* Fix quantization path in test_recipe_list\n\n* Fix docstring in HifiGAN.py\n\n* Fix docstring in HifiGAN.py\n\n* Format interfaces.py\n\n* Update README for hifi_gan_unit and quantization\n\n* Update docstring\n\n* Fix audio loading\n\n* small fixes\n\n* recipe test with dataset uploaded in dropbox\n\n* remove local samples\n\n* Update README.md\n\n* Update README\n\n* Update README.md\n\n* minor changes in paths\n\n* Update HF link\n\n* add functions to map indices from the range [0, k] to [1, k+1] in HiFi-GAN Unit\n\n* Update HiFi-GAN Unit interface\n\n* Add verification for units sequence length during eval\n\n* Add option to evaluate the S2UT model every n epochs\n\n* Delete .gitignore\n\n* Update train.yaml\n\n* fix linters\n\n* fix test\n\n* fix test + making preparation compatible with other recipes + minor fixes\n\n* Fix typo\n\n* Add parameters\n\n* some fixes on LJSpeech tests\n\n* fix LJSpeech recipe test\n\n* making recipe test a bit faster\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tools/profiling/profile.py",
        "commit_date": "2024-02-21T19:59:00Z",
        "message": "fix import in profile.py (#2425)"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tools/profiling/profile.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tools/profiling/profile.py",
        "commit_date": "2022-06-20T21:22:49Z",
        "message": "update docstrings in the libraries"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tools/profiling/profile.py",
        "commit_date": "2022-06-01T16:18:34Z",
        "message": "backup of latest develop status (contents of PRs that were merged) before fixing rebase issue through another rebase"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "speechbrain/inference/ASR.py",
        "commit_date": "2024-02-25T17:27:30Z",
        "message": "fix torch.no_grad with streamableASR interface"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "speechbrain/inference/ASR.py",
        "commit_date": "2024-02-24T17:18:23Z",
        "message": "Streaming ASR interfaces (#2377)\n\n* Implemented high level streaming interfaces\n\nMore WIP\n\nBunch of filter properties impl\n\nMore WIP interfaces stuff\n\nFix type annotation in filter_analysis\n\nmore wip interfaces\n\nwip\n\nFix wrong context var set\n\nwip thoughts\n\nImplement file transcription\n\n* Renames and fixes\n\n* Add transcribe_file_streaming\n\n* Formatting fixes\n\n* Revert accidentally introduced change to max_batch_len\n\n* Reworking interface naming and docstring\n\n* Use the searcher directly, forwarding extra args\n\n* More docstrings\n\n* Fix parameter order\n\n* Add WIP StreamingTransducerASR example\n\n* Formatting\n\n* More docstrings and renames for interfaces\n\n* Docstrings for context\n\n* Merge the unnecessary wrapper\n\n* Rename StreamingTransducerASR to StreamingASR\n\n* Fix precommit\n\n* Remove unused fea_extractor field\n\n* Fix test error by commenting out inference stuff\n\n* Add some docstrings to streamingfeaturewrapper\n\n* More docs\n\n* Formatting\n\n* Feature extraction streaming wrapper docstrings\n\n* Add missing file docstring for filter_analysis\n\n* Tentative fix for docs gen error\n\n* Fix some missing docstring args in ASR\n\n* Allow using ffmpeg streaming with StreamingASR\n\n* Extract stream logic into _get_audio_stream\n\n* Docstring for _get_audio_stream\n\n* Formatting\n\n* Move out some streaming tokenizer logic\n\n* Accept stupid suggestions from formatter\n\n* Somewhat more generic StreamingASR\n\n* Tokenizer-agnostic StreamingASR\n\n* Add commented out tokenizer streaming hparams\n\n* Add missing docstring\n\n* Remove unused import from ASR\n\n* CI and configuration fixes; use python 3.9 in CI\n\n* Fix doctest using inconsistent left context size\n\n* Clarify on tokenizer_context init\n\n* Update HPARAMS_NEEDED for StreamingASR\n\n* Improve transducer forward docs for extra args\n\n* Fix code blocks in filter_analysis\n\n* Linting\n\n* fix broken indent in filter_analysis examples...\n\n* Update author lists\n\n* Remove currently unused has_overlap\n\n* Clarify on fea_streaming_extractor properties\n\n* Fix ASRStreamingContext doc wording\n\n* Improve docstring for `get_chunk_size_frames`\n\n* wip test\n\n* Streaming feature wrapper test + better docs\n\n* Improve StreamingFeatureWraper docstring\n\n* Improve docstring and comments on spm streaming decode\n\n* Fixed accidentally duplicated docstring\n\n* Fix very stupid typo\n\n* Add notice for trained streaming ASR inference\n\n* Use LengthsCapableSequential instead of custom wrapper\n\n* Precommit fix\n\n* Added mechanism to inject zero chunks at the end to fix trunc\n\n* Simplify apply in YAML\n\n* Add decoding_function abstraction for StreamingASR\n\n* Fix partial apply shenanigans\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "speechbrain/inference/ASR.py",
        "commit_date": "2024-02-11T21:54:16Z",
        "message": "Update WhisperASR inference interface (#2407)\n\n* Update ASR.py\n\n* Update ASR.py\n\n* Update ASR.py\n\n* Update ASR.py"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "speechbrain/inference/ASR.py",
        "commit_date": "2024-02-10T16:30:45Z",
        "message": "add kenlm (#2402)"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "speechbrain/inference/ASR.py",
        "commit_date": "2024-01-31T16:36:46Z",
        "message": "pre-commit"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "speechbrain/inference/ASR.py",
        "commit_date": "2024-01-31T16:34:10Z",
        "message": "update docstring"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "speechbrain/inference/ASR.py",
        "commit_date": "2024-01-31T16:17:28Z",
        "message": "working interface"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "speechbrain/inference/ASR.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "speechbrain/inference/TTS.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2024-02-25T02:53:59Z",
        "message": "last fixes"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2023-10-14T12:33:53Z",
        "message": "pre-commit"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2023-10-14T12:32:20Z",
        "message": "remove related doc with distributed_launch"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2023-08-14T20:07:00Z",
        "message": "fixed hard-coded device"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2023-08-10T12:34:14Z",
        "message": "slurp"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2023-08-10T11:12:22Z",
        "message": "self.hparams.wer_file -> self.hparams.test_wer_file"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2023-07-25T08:35:32Z",
        "message": "Merge pull request #2059 from pplantinga/feature/on-stage-end-run-all-procs\n\nRun \"on_stage_end\" on all processes and save on only a single process"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2023-07-20T15:52:28Z",
        "message": "fixed SLURP"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2023-07-07T23:38:50Z",
        "message": "Add if_main_process guard around writing WER files"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2022-07-21T17:02:08Z",
        "message": "fix distributed_launch=True in comments"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2021-11-22T23:36:27Z",
        "message": "correct when decodage not dict"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2021-11-18T10:44:04Z",
        "message": "Update train.py"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2021-11-15T16:41:28Z",
        "message": "add wav2vec2 encoder"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2021-03-12T05:05:35Z",
        "message": "local manifest + remove unnecessary columns in csv"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2021-03-11T23:32:00Z",
        "message": "merge develop + solved conflicts"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2021-03-11T18:20:11Z",
        "message": "remove pretrain tokenizer"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2021-03-11T05:43:39Z",
        "message": "remove pretrained folder + remove extra level (/train/)"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2021-01-20T02:48:48Z",
        "message": "convert SLURP direct recipe, add downloads to data preparation"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2021-01-19T15:33:13Z",
        "message": "Dataio without underscore"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2021-01-17T18:16:13Z",
        "message": "update latest recipes"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2020-12-20T00:33:09Z",
        "message": "add NLU for SLURP (train/test on gold transcripts)"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/SLURP/direct/train.py",
        "commit_date": "2020-12-19T19:21:16Z",
        "message": "SLU recipe for SLURP dataset"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "speechbrain/inference/classifiers.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2023-10-14T12:33:53Z",
        "message": "pre-commit"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2023-10-14T12:32:20Z",
        "message": "remove related doc with distributed_launch"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2023-08-14T20:07:53Z",
        "message": "fixed hard-coded device"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2023-08-10T12:41:37Z",
        "message": "timer"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2023-08-10T11:12:22Z",
        "message": "self.hparams.wer_file -> self.hparams.test_wer_file"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2023-07-07T23:38:50Z",
        "message": "Add if_main_process guard around writing WER files"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2022-07-21T17:02:08Z",
        "message": "fix distributed_launch=True in comments"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2021-03-21T22:29:59Z",
        "message": "dont exit"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2021-03-21T21:53:08Z",
        "message": "use dev synth if testing on all real data, avoid redundant"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2021-03-21T19:36:24Z",
        "message": "add comment"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2021-03-21T19:20:12Z",
        "message": "Remove comma preprocessing, add script for running multiple experiments, load checkpoint with best valid accuracy, add testing on all real splits"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2021-03-12T21:29:17Z",
        "message": "small fixes"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2021-03-11T23:32:00Z",
        "message": "merge develop + solved conflicts"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2021-03-11T18:20:11Z",
        "message": "remove pretrain tokenizer"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2021-03-11T05:43:39Z",
        "message": "remove pretrained folder + remove extra level (/train/)"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2021-01-18T01:01:11Z",
        "message": "librispeech: training, inference separation"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2021-01-17T02:43:17Z",
        "message": "Merge branch 'collab-new-data-loading' into use-hyperyaml"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2021-01-17T00:55:59Z",
        "message": "converted direct recipe (timers_and_such)"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2021-01-16T22:14:35Z",
        "message": "Rename \"hyperyaml\" to \"hyperpyyaml\""
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2021-01-15T19:29:13Z",
        "message": "Switch extended_yaml to hyperyaml"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2021-01-13T21:08:45Z",
        "message": "fix calling ddp_init_group"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2020-12-15T00:46:43Z",
        "message": "recipe conversion (data_prep in yaml) part 1"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2020-12-14T04:24:13Z",
        "message": "convert all recipes (part 1, exp_file)"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2020-12-12T19:56:29Z",
        "message": "add gradient check"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2020-12-08T00:32:36Z",
        "message": "multi-gpu support for slu recipe"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/timers-and-such/direct/train.py",
        "commit_date": "2020-12-02T02:56:04Z",
        "message": "converted direct + clean up"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2024-02-23T03:43:17Z",
        "message": "minor fixes emerged from recipe tesys"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2023-10-26T20:45:06Z",
        "message": "fix recipe tests tool (#2218)\n\n* fix location of pretrained models\n\n* fix a VERY annoying recipe.\n\n* full inference tests\n\n* pre-commit"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2023-09-29T17:18:01Z",
        "message": "fix hard-coded devices (#2178)"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2023-07-31T19:35:09Z",
        "message": "Merge remote-tracking branch 'upstream/develop' into bugfix/remove-sys-exit"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2023-07-31T13:50:49Z",
        "message": "Remove sys.exit() calls in recipes and tools"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2023-07-22T17:56:37Z",
        "message": "realm"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2023-06-27T15:03:41Z",
        "message": "Merge pull request #1808 from z-wony/loss_compare\n\nFix comparison order of train loss"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2023-03-08T08:52:07Z",
        "message": "addressing a few recipe tests"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2023-02-06T03:26:57Z",
        "message": "Remove the 'if hparams.dynamic_mixing' on real-m train.py. \n\nThe tests pass even without the argument added in this PR on line 161 of real-m train.py."
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2023-01-18T16:33:27Z",
        "message": "Fix comparison order of train loss\n\nIf batch size > 1 and all of the losses are less than threshold,\nRuntimeError raised from loss comparison block."
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2022-11-24T16:41:54Z",
        "message": "wrapping up testing flags and minimal data for testing"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2022-11-11T19:00:45Z",
        "message": "availing LibriSpeech to recipe testing"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2022-11-10T17:12:48Z",
        "message": "TIMIT; WHAM/R & fixes - added 39 phoneme test annotation"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2022-10-20T13:14:50Z",
        "message": "drop phn_list from annotation test samples"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2021-11-18T12:02:30Z",
        "message": "Auto mix prec + noprogressbar override via hyperparams"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2021-10-20T18:42:38Z",
        "message": "added mixed precision training"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2021-10-20T01:44:05Z",
        "message": "removed hard coded links from train.py"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2021-10-19T19:43:50Z",
        "message": "added automatic preprocessing for whamr dynamic mixing"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2021-10-17T18:54:47Z",
        "message": "fixed the comments in save_results function"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2021-10-17T18:50:36Z",
        "message": "added comments to train.py"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2021-10-17T18:30:01Z",
        "message": "removing the separate dynamic mixing file, using the one from WHAMandWHAMR recipe"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2021-10-15T01:28:02Z",
        "message": "correcting loss labels"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2021-10-14T17:33:10Z",
        "message": "added download from HF for pretrained separators and bug fixes"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/REAL-M/sisnr-estimation/train.py",
        "commit_date": "2021-10-14T03:47:51Z",
        "message": "getting done except loading separator models"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LibriTTS/TTS/mstacotron2/train.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LibriTTS/TTS/mstacotron2/train.py",
        "commit_date": "2023-12-13T18:07:01Z",
        "message": "multi-speaker tacotron2 enhancements (#2261)\n\n* use chars instead of phonemes, use 16k instead of 22k, limit audio length to 10 seconds\n\n* add inference function using char inputs"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LibriTTS/TTS/mstacotron2/train.py",
        "commit_date": "2023-10-17T02:46:20Z",
        "message": "fix one issue wit recipe tests"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LibriTTS/TTS/mstacotron2/train.py",
        "commit_date": "2023-09-22T13:31:01Z",
        "message": "update to latest dev + small fixes"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LibriTTS/TTS/mstacotron2/train.py",
        "commit_date": "2023-08-13T02:38:31Z",
        "message": "adding zero-shot multi-speaker Tacotron2"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2023-10-27T16:13:39Z",
        "message": "Add speech-to-speech translation (#2044)\n\n* Add S2ST with cvss recipe\n\n* Refactor K-means training\n\n* Clean quantization training and unit-to-speech training in LJSpeech recipe\n\n* Add documentation and tests for UnitHiFiGAN\n\n* Add inference interface for UnitHiFiGAN\n\n* Clean U2S hparams\n\n* Add extra requirement for k-means training\n\n* Add ReadMe for LJSpeech S2ST recipe and update hprarams\n\n* Resolve comments on quantization\n\n* Resolve comments on HiFi-GAN training\n\n* Fix authors in HifiGAN model\n\n* Remove old stuff\n\n* Fix LJSpeech S2ST\n\n* Improve Wandb logger init, no longer require external yaml file\n\n* add wandb log folder to .gitignore\n\n* Add extra requirements to CVSS recipe\n\n* Update CVSS S2ST\n\n* Add verbose option to disable warnings when a model is loaded\n\n* Refactoring and adding evaluation pipeline\n\n* Fix ljspeech_prepare.py path according to new recipe structure\n\n* Update codes folder construction to allow easy testing\n\n* Add tests\n\n* Update CVSS\n\n* Update LJSpeech S2ST\n\n* Update tests\n\n* Add empty README for CVSS\n\n* Fix pre-commit\n\n* Fix pre-commit\n\n* Update kmeans model name\n\n* Update CVSS S2ST recipe & add HF pretrained vocoder model\n\n* Update tests\n\n* Update CVSS S2ST hparams\n\n* Fix docstrings\n\n* Update tests\n\n* Revert verbose argument addition\n\n* Revert verbose argument addition\n\n* Add automatic resampling in Quantization recipe\n\n* Add automatic resampling in Quantization recipe\n\n* Add automatic resampling in extract_code\n\n* Update README\n\n* Update CVSS S2ST recipe\n\n* Increase timeout in init_process_group to avoid crash during dataprep\n\n* Update CVSS tests\n\n* Fix transcript normalization for BLEU score\n\n* Update LJSpeech S2ST README.md\n\n* Update cvss_prepare.py\n\n* Update train_fr-en.yaml\n\n* Update cvss_prepare.py\n\n* Fix codes folder path\n\n* Fix file extension\n\n* Add docstring for wandb logger\n\n* Fix docstring for wandb logger\n\n* Add small subset for evalution and adapt training script\n\n* Update hparams\n\n* Update cvss_prepare.py\n\n* Update training scripts\n\n* Update docstring in LJSpeech S2ST recipe\n\n* Update docstring in LJSpeech S2ST recipe\n\n* Add automatic resampling\n\n* Add model weights and training logs\n\n* Update docstring in CVSS S2ST recipe\n\n* Add S2UT interface\n\n* Fix HiFi-GAN GeneratorLoss forward args\n\n* Update ljspeech_prepare path\n\n* Fix UnitHiFiGAN interface docstring\n\n* merged latest develop, switched to speechbrain dropbox, fixed small yaml issues\n\n* A. README files: point 1 and 2\n\n* B. File Organization: Relocate Quantization recipe\n\n* B. File Organization: Relocate Unit HiFi-GAN and update symbolic link\n\n* Sync with develop\n\n* Update requirements\n\n* Update README\n\n* Fix symbolic link\n\n* Fix merge\n\n* Fix tests\n\n* Fix mimport\n\n* Fix LJSpeech tests\n\n* Fix CVSS tests\n\n* Fix CVSS dataprep\n\n* Add a docstring for the process_duration function\n\n* Fix quantization path in test_recipe_list\n\n* Fix docstring in HifiGAN.py\n\n* Fix docstring in HifiGAN.py\n\n* Format interfaces.py\n\n* Update README for hifi_gan_unit and quantization\n\n* Update docstring\n\n* Fix audio loading\n\n* small fixes\n\n* recipe test with dataset uploaded in dropbox\n\n* remove local samples\n\n* Update README.md\n\n* Update README\n\n* Update README.md\n\n* minor changes in paths\n\n* Update HF link\n\n* add functions to map indices from the range [0, k] to [1, k+1] in HiFi-GAN Unit\n\n* Update HiFi-GAN Unit interface\n\n* Add verification for units sequence length during eval\n\n* Add option to evaluate the S2UT model every n epochs\n\n* Delete .gitignore\n\n* Update train.yaml\n\n* fix linters\n\n* fix test\n\n* fix test + making preparation compatible with other recipes + minor fixes\n\n* Fix typo\n\n* Add parameters\n\n* some fixes on LJSpeech tests\n\n* fix LJSpeech recipe test\n\n* making recipe test a bit faster\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2023-07-14T21:51:08Z",
        "message": "freeze spn predictor after 8 epoch and suppress warning"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2023-07-13T20:54:45Z",
        "message": "add silence for punctuations, modify functions"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2023-07-13T20:46:58Z",
        "message": "spn loss equals zero after 8 epochs, threshold 0.8 for spn predictor"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2023-07-03T18:18:28Z",
        "message": "unknown token fix"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2023-06-16T00:37:54Z",
        "message": "changes to insert silent phonemes for pace"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2023-04-07T17:04:09Z",
        "message": "update recipe"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2023-01-18T21:23:50Z",
        "message": "modifications for phoneme input"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2022-12-14T04:25:42Z",
        "message": "Merge branch 'fastspeech2' of https://github.com/bloodraven66/speechbrain into fastspeech2"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2022-12-14T04:22:02Z",
        "message": "add custom clean code to ljspeech_prepare and clean durations link to yaml"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2022-12-04T17:54:46Z",
        "message": "output predicted mel lengths"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2022-12-02T14:23:02Z",
        "message": "generate validation audio without extracted duration, log all the losses"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2022-11-16T23:58:05Z",
        "message": "fix black"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2022-11-16T23:50:01Z",
        "message": "add mask in train.py + fix device mismatch"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2022-11-16T04:25:35Z",
        "message": "pre-compute pitch + fix incompatibility with pytorch 1.13"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2022-11-15T23:01:36Z",
        "message": "fix durarations folder"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2022-11-15T22:10:10Z",
        "message": "fix device"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2022-11-13T17:07:15Z",
        "message": "revised duration download"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2022-11-12T22:31:06Z",
        "message": "fix failing tests"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2022-11-12T21:54:23Z",
        "message": "fix yaml"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2022-11-12T20:29:42Z",
        "message": "first batch of small fixes"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2022-08-10T15:17:44Z",
        "message": "working fastspeech2"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train.py",
        "commit_date": "2022-06-20T16:17:26Z",
        "message": "added fastspeech2"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "speechbrain/inference/interpretability.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/fluent-speech-commands/direct/train.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/fluent-speech-commands/direct/train.py",
        "commit_date": "2023-10-14T12:33:53Z",
        "message": "pre-commit"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/fluent-speech-commands/direct/train.py",
        "commit_date": "2023-10-14T12:32:20Z",
        "message": "remove related doc with distributed_launch"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/fluent-speech-commands/direct/train.py",
        "commit_date": "2023-08-14T20:07:46Z",
        "message": "fixed hard-coded device"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/fluent-speech-commands/direct/train.py",
        "commit_date": "2023-08-10T12:38:41Z",
        "message": "remove timit line / modity fluent speech"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/fluent-speech-commands/direct/train.py",
        "commit_date": "2023-08-10T11:12:22Z",
        "message": "self.hparams.wer_file -> self.hparams.test_wer_file"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/fluent-speech-commands/direct/train.py",
        "commit_date": "2023-08-09T13:41:03Z",
        "message": "fix hparam wer_file never used in recipes"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/fluent-speech-commands/direct/train.py",
        "commit_date": "2023-07-07T23:38:50Z",
        "message": "Add if_main_process guard around writing WER files"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/fluent-speech-commands/direct/train.py",
        "commit_date": "2022-07-21T17:02:08Z",
        "message": "fix distributed_launch=True in comments"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/fluent-speech-commands/direct/train.py",
        "commit_date": "2021-06-04T00:43:22Z",
        "message": "improve fsc recipe by adoption super augment"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/fluent-speech-commands/direct/train.py",
        "commit_date": "2021-03-12T05:05:35Z",
        "message": "local manifest + remove unnecessary columns in csv"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/fluent-speech-commands/direct/train.py",
        "commit_date": "2021-03-11T23:32:00Z",
        "message": "merge develop + solved conflicts"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/fluent-speech-commands/direct/train.py",
        "commit_date": "2021-03-11T18:20:11Z",
        "message": "remove pretrain tokenizer"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/fluent-speech-commands/direct/train.py",
        "commit_date": "2021-03-09T20:21:13Z",
        "message": "convert Fluent Speech Commands recipe"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/fluent-speech-commands/direct/train.py",
        "commit_date": "2021-03-05T04:28:34Z",
        "message": "last fixes (see PR description)"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/fluent-speech-commands/direct/train.py",
        "commit_date": "2021-02-07T23:37:12Z",
        "message": "add a simple seq2seq model recipe for Fluent Speech Commands"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train_internal_alignment.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train_internal_alignment.py",
        "commit_date": "2023-10-27T16:13:39Z",
        "message": "Add speech-to-speech translation (#2044)\n\n* Add S2ST with cvss recipe\n\n* Refactor K-means training\n\n* Clean quantization training and unit-to-speech training in LJSpeech recipe\n\n* Add documentation and tests for UnitHiFiGAN\n\n* Add inference interface for UnitHiFiGAN\n\n* Clean U2S hparams\n\n* Add extra requirement for k-means training\n\n* Add ReadMe for LJSpeech S2ST recipe and update hprarams\n\n* Resolve comments on quantization\n\n* Resolve comments on HiFi-GAN training\n\n* Fix authors in HifiGAN model\n\n* Remove old stuff\n\n* Fix LJSpeech S2ST\n\n* Improve Wandb logger init, no longer require external yaml file\n\n* add wandb log folder to .gitignore\n\n* Add extra requirements to CVSS recipe\n\n* Update CVSS S2ST\n\n* Add verbose option to disable warnings when a model is loaded\n\n* Refactoring and adding evaluation pipeline\n\n* Fix ljspeech_prepare.py path according to new recipe structure\n\n* Update codes folder construction to allow easy testing\n\n* Add tests\n\n* Update CVSS\n\n* Update LJSpeech S2ST\n\n* Update tests\n\n* Add empty README for CVSS\n\n* Fix pre-commit\n\n* Fix pre-commit\n\n* Update kmeans model name\n\n* Update CVSS S2ST recipe & add HF pretrained vocoder model\n\n* Update tests\n\n* Update CVSS S2ST hparams\n\n* Fix docstrings\n\n* Update tests\n\n* Revert verbose argument addition\n\n* Revert verbose argument addition\n\n* Add automatic resampling in Quantization recipe\n\n* Add automatic resampling in Quantization recipe\n\n* Add automatic resampling in extract_code\n\n* Update README\n\n* Update CVSS S2ST recipe\n\n* Increase timeout in init_process_group to avoid crash during dataprep\n\n* Update CVSS tests\n\n* Fix transcript normalization for BLEU score\n\n* Update LJSpeech S2ST README.md\n\n* Update cvss_prepare.py\n\n* Update train_fr-en.yaml\n\n* Update cvss_prepare.py\n\n* Fix codes folder path\n\n* Fix file extension\n\n* Add docstring for wandb logger\n\n* Fix docstring for wandb logger\n\n* Add small subset for evalution and adapt training script\n\n* Update hparams\n\n* Update cvss_prepare.py\n\n* Update training scripts\n\n* Update docstring in LJSpeech S2ST recipe\n\n* Update docstring in LJSpeech S2ST recipe\n\n* Add automatic resampling\n\n* Add model weights and training logs\n\n* Update docstring in CVSS S2ST recipe\n\n* Add S2UT interface\n\n* Fix HiFi-GAN GeneratorLoss forward args\n\n* Update ljspeech_prepare path\n\n* Fix UnitHiFiGAN interface docstring\n\n* merged latest develop, switched to speechbrain dropbox, fixed small yaml issues\n\n* A. README files: point 1 and 2\n\n* B. File Organization: Relocate Quantization recipe\n\n* B. File Organization: Relocate Unit HiFi-GAN and update symbolic link\n\n* Sync with develop\n\n* Update requirements\n\n* Update README\n\n* Fix symbolic link\n\n* Fix merge\n\n* Fix tests\n\n* Fix mimport\n\n* Fix LJSpeech tests\n\n* Fix CVSS tests\n\n* Fix CVSS dataprep\n\n* Add a docstring for the process_duration function\n\n* Fix quantization path in test_recipe_list\n\n* Fix docstring in HifiGAN.py\n\n* Fix docstring in HifiGAN.py\n\n* Format interfaces.py\n\n* Update README for hifi_gan_unit and quantization\n\n* Update docstring\n\n* Fix audio loading\n\n* small fixes\n\n* recipe test with dataset uploaded in dropbox\n\n* remove local samples\n\n* Update README.md\n\n* Update README\n\n* Update README.md\n\n* minor changes in paths\n\n* Update HF link\n\n* add functions to map indices from the range [0, k] to [1, k+1] in HiFi-GAN Unit\n\n* Update HiFi-GAN Unit interface\n\n* Add verification for units sequence length during eval\n\n* Add option to evaluate the S2UT model every n epochs\n\n* Delete .gitignore\n\n* Update train.yaml\n\n* fix linters\n\n* fix test\n\n* fix test + making preparation compatible with other recipes + minor fixes\n\n* Fix typo\n\n* Add parameters\n\n* some fixes on LJSpeech tests\n\n* fix LJSpeech recipe test\n\n* making recipe test a bit faster\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train_internal_alignment.py",
        "commit_date": "2023-09-21T18:12:51Z",
        "message": "update to latest dev + minor modifications"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train_internal_alignment.py",
        "commit_date": "2023-08-16T15:54:45Z",
        "message": "add docstrings and examples"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train_internal_alignment.py",
        "commit_date": "2023-08-16T10:22:44Z",
        "message": "fixes"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "recipes/LJSpeech/TTS/fastspeech2/train_internal_alignment.py",
        "commit_date": "2023-08-11T15:08:06Z",
        "message": "add recipe for FastSpeech2 with internal alignment"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/utils/refactoring_checks.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/utils/refactoring_checks.py",
        "commit_date": "2023-03-02T14:11:45Z",
        "message": "log edits"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/utils/refactoring_checks.py",
        "commit_date": "2023-02-16T11:45:41Z",
        "message": "code example for readme"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/utils/refactoring_checks.py",
        "commit_date": "2023-02-16T09:30:11Z",
        "message": "path fixes"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/utils/refactoring_checks.py",
        "commit_date": "2023-01-23T11:26:26Z",
        "message": "comments & path updates"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/utils/refactoring_checks.py",
        "commit_date": "2023-01-19T15:54:32Z",
        "message": "minor fixes"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/utils/refactoring_checks.py",
        "commit_date": "2022-12-12T15:47:48Z",
        "message": "linters"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/utils/refactoring_checks.py",
        "commit_date": "2022-12-09T16:07:48Z",
        "message": "edits to checks"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/utils/refactoring_checks.py",
        "commit_date": "2022-12-06T14:55:29Z",
        "message": "test util for refactoring & pretrained models"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py",
        "commit_date": "2023-07-19T17:03:21Z",
        "message": "fix url"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py",
        "commit_date": "2023-02-20T15:23:28Z",
        "message": "comments++"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py",
        "commit_date": "2023-02-14T15:50:19Z",
        "message": "FetchedSource & path_split"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py",
        "commit_date": "2023-02-14T11:33:19Z",
        "message": "FetchSource"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py",
        "commit_date": "2023-01-31T11:21:00Z",
        "message": "DDP for test dataloaders & an example to DDP-gather WER MetricStats results"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py",
        "commit_date": "2023-01-25T16:21:50Z",
        "message": "fixes"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py",
        "commit_date": "2023-01-25T15:34:39Z",
        "message": "lints"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py",
        "commit_date": "2023-01-25T13:58:00Z",
        "message": "evals using batches"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py",
        "commit_date": "2023-01-24T12:56:38Z",
        "message": "minor fixes"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/templates/fetching_ddp_dynbatch_finetuning/finetune_fetch_once.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/templates/fetching_ddp_dynbatch_finetuning/finetune_fetch_once.py",
        "commit_date": "2023-07-19T17:03:30Z",
        "message": "fix url"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/templates/fetching_ddp_dynbatch_finetuning/finetune_fetch_once.py",
        "commit_date": "2023-02-22T14:24:21Z",
        "message": "parameter transfer w/ internal ddp option"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/templates/fetching_ddp_dynbatch_finetuning/finetune_fetch_once.py",
        "commit_date": "2023-02-21T18:22:58Z",
        "message": "4th multi-source fetching case"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/templates/fetching_ddp_dynbatch_finetuning/single_node_pretrained.py",
        "commit_date": "2024-01-07T20:42:33Z",
        "message": "Merge Unstable v0.6 into Dev (#2305)\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* rename HF's files\n\n* fix docstrings\n\n* fix args docstrings\n\n* fix docstrings\n\n* change classes' names\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Refactor HF interface, adapt recipes\n\n* Fix docstrings\n\n* commonvoice\n\n* switchboard\n\n* update readme\n\n* update readme\n\n* update lionk in test file\n\n* remove unused space token\n\n* update torchaudio\n\n* remove deprecated language model path\n\n* fix merge\n\n* fix vocab\n\n* fix switchboard\n\n* commit\n\n* fix test\n\n* fix style\n\n* remove unsued hparam\n\n* fix consistancy blank_skip_threshold\n\n* text frames\n\n* CTCPrefixBeamSearcher timestamps\n\n* pre-commit\n\n* test\n\n* test 2\n\n* fix prints\n\n* update ctcprefixbeamsearch timestamps\n\n* remove frames from prefix bs\n\n* \u2248Revert \"remove frames from prefix bs\"\n\nThis reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.\n\n* remove prefix bs\n\n* \u2248Revert \"remove prefix bs\"\n\nThis reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.\n\n* Revert \"update ctcprefixbeamsearch timestamps\"\n\nThis reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.\n\n* Revert \"fix prints\"\n\nThis reverts commit bf360373555855329355c982a80be33eaae41cf6.\n\n* Revert \"test 2\"\n\nThis reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.\n\n* Revert \"test\"\n\nThis reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.\n\n* Revert \"pre-commit\"\n\nThis reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.\n\n* Revert \"CTCPrefixBeamSearcher timestamps\"\n\nThis reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.\n\n* Revert \"text frames\"\n\nThis reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.\n\n* Revert \"fix consistancy blank_skip_threshold\"\n\nThis reverts commit f97a391f3574337f968135d41a9c2316014cb885.\n\n* Update ctc.py\n\n* arg / timestamps\n\n* precommit\n\n* timesteps -> text_frames\n\n* ls seq2seq\n\n* transformer ls\n\n* fix naming\n\n* librispeech\n\n* aishell\n\n* fix linter\n\n* precommit\n\n* switchboard\n\n* timit\n\n* Dynamic batching fixed\n\n* authors\n\n* fix conformer large\n\n* indent\n\n* Revert \"Fix dynamic batching\" (#2173)\n\n* update doctest skip\n\n* Fix dynamic batching (#2174)\n\n* Revert \"Revert \"Fix dynamic batching\" (#2173)\"\n\nThis reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.\n\n* Update interfaces.py\n\n* Update interfaces.py\n\n* Update text_to_sequence.py\n\n* fix w2v\n\n* aishell\n\n* cv\n\n* ls transformer\n\n* ls ssl\n\n* switchboard\n\n* timit\n\n* precommit\n\n* fix indent\n\n* fix arg\n\n* unit test sorting\n\n* unittests\n\n* remove if main\n\n* Small fixes in averaging checkpoints (#2181)\n\n* add ckpt avg unittest\n\n* avoid hard-coding number of averages\n\n* last fixes\n\n* fix recipe test\n\n* fix recipe test\n\n* convert print into logger\n\n* fix transducer recipe\n\n* remove typing\n\n* fix merge\n\n* precommit\n\n* Update LibriSpeech.csv\n\n* update to new dynamic batching args\n\n* Update unstable branch with new commits  (#2196)\n\n* hyper branch/conf -former fixes\n\n* remove ctc.py from doctest\n\n* get back ctc.py\n\n* remove doctest for torchaudio\n\n* adapt gpt recipe\n\n* adapt gpt recipe\n\n* small follow up fix on openrir\n\n* remove doc test (for now)\n\n* fix issue greedy search\n\n* docstring\n\n* pre-commit\n\n* Fix issues unstable (#2216)\n\nThank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.\n\n* Fix missing file / import in huggingface_transformers (#2224)\n\n* init/imports\n\n* comment\n\n* add partial import\n\n* wav2vec -> wav2vec2\n\n* fix ci\n\n* Text based HF (#2214)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* change authorship\n\n* remove comments\n\n* minor changes\n\n* change authorship\n\n* Fix recipe test\n\n* add info\n\n* Update README.md\n\n* Update README.md\n\n* change recipe structure\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\n\n* Neural LM Rescoring (#2187)\n\n* baserescorerinterface\n\n* add rescorers\n\n* first attempt\n\n* update code\n\n* 1.57 wer\n\n* update\n\n* update code\n\n* update code\n\n* docstring example rnn\n\n* updata loader\n\n* docstring example\n\n* tests\n\n* docstring example\n\n* update\n\n* tmpdir\n\n* change path\n\n* update doc\n\n* docstring\n\n* docstring args\n\n* doctest\n\n* fix docstring example\n\n* unnittest\n\n* interface\n\n* yamls update\n\n* full_infernece tests\n\n* model link\n\n* readme\n\n* yaml/inference tests\n\n* update res\n\n* fix wav2vec with wav2vec2\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add wrappers for Encodec and Vocos vocoders (#2231)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)\n\n* add mbart\n\n* Add tristage scheduler\n\n* Add mbart beam search\n\n* Add IWLST recipes\n\n* Add new models' inteference interface\n\n* Add info of new models\n\n* Add nllb scores\n\n* Add new models' info\n\n* Add test info IWSLT recipe\n\n* Add test info IWSLT recipe\n\n* add docstrings for S2STransformerBeamSearcher\n\n* Update IWSLT recipes\n\n* Update IWSLT recipes\n\n* fix doctest\n\n* add requirements\n\n* add protobuf\n\n* fix doctest\n\n* small fixes\n\n* Add protobuf install\n\n* Minor reform\n\n* Remove protobuf\n\n* Fix docstings\n\n* Fix docstrings\n\n* minor reform\n\n* remove labse\n\n* Add attention pooling\n\n* Add labse\n\n* Add info about SAMU\n\n* add iwslt recipes with samu\n\n* fix recipe test\n\n* fix comments\n\n* fix recipe test\n\n* change recipe structure\n\n* fix test recipe\n\n* Add new recipes\n\n* minor doctest change\n\n* minor doctest change\n\n* small changes\n\n* add dropbox links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* fix norm (#2237)\n\n* Discrete SSL (#2233)\n\n* clustering training recipies for LibriSpeech for different SSL model\n\n* add Discrete Hubert Model\n\n* load from HF, fix minor issues\n\n* fix hyper-param value\n\n* fix precommit\n\n* fix flake8\n\n* fix batch_size and n_clus values in hyperparams\n\n* fix typos\n\n* fix typo and some cleaning\n\n* fix precommit\n\n* fix device incompatibility and memroty issue\n\n* use fit instead of partial fit\n\n* add README file\n\n* add test recipies\n\n* remove unused fields from hparams\n\n* fix precommmit-yamllint - extra whitespace\n\n* add docstring for load_kmeans for Discrete_hubert.py\n\n* add discrete wavlm, wav2vec\n\n* avoid docstring testing for discrete_ssl models\n\n* fix docstring failed issue\n\n* add discrete_interface to conftest.py\n\n* fix precommit\n\n* Fixes for Encodec (#2240)\n\n* Add wrappers for Encodec and Vocos from Huggingface\n\n* Encodec: Add a comment\n\n* Encodec/Vocos: Add examples, restructure, fix masks\n\n* Vocos: Add a comment about the open pull request\n\n* Encodec/Vocos: Add the ability to customize save_path, fix a log message\n\n* Encodec/Vocos: Cosmetic changes\n\n* Vocos: Cosmetic changes\n\n* Encodec/Vocos: Remove the mandatory Vocos requirement\n\n* Vocos: Remove vocos from __init__.py\n\n* fix init\n\n* Vocos: Add a check for vocos in conftest.py\n\n* Vocos/Encodec: Update documentation, add bandwidth control\n\n* Fix old path in conftest.py\n\n* Cosmetic changes\n\n* Encodec/Vocos: Add support for embedding vectors\n\n* Encodec: Update example\n\n* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes\n\n* Encodec: Decoupled token extraction, fixed CPU/GPU issues\n\n* Encodec: Add renormalization\n\n---------\n\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactoring of the 'fit_batch' function (#2010)\n\n* add dataclass\n\n* turn False\n\n* remove valid_step\n\n* update core.py\n\n* update core.py\n\n* update core.py\n\n* precommit\n\n* self.autocast + GradScaler enabled\n\n* freeze opt\n\n* naming\n\n* update core.py\n\n* comments\n\n* example transducer conformer\n\n* update core.py\n\n* small changes\n\n* naming + skip_grad_nans\n\n* doc\n\n* check\n\n* support cpu training\n\n* precision + doctrsting\n\n* name\n\n* change w2v\n\n* restore ckpt\n\n* remove file\n\n* remove casting\n\n* tests\n\n* whisper + fix tests\n\n* seq2seq ls\n\n* update transducer / transformer\n\n* remove on_optimizers_step_end + comments\n\n* update check yaml\n\n* remove default arg\n\n* add precision in yamls\n\n* add precision inside of the yamls\n\n* ckpt and scaler\n\n* run_opt outside brain + test\n\n* several recipe updates\n\n* improve w2v fit_batch fn\n\n* add arg\n\n* update name\n\n* timit\n\n* context manager\n\n* on_fit_batch_start\n\n* update CV\n\n* should_step with noam\n\n* add flag precision\n\n* naming\n\n* aishell\n\n* aishell\n\n* update recipes\n\n* so many recipes 0.0\n\n* update recipes\n\n* last recipes\n\n* zero_grad\n\n* fix grad_accumulation_factor\n\n* update recipes\n\n* update auto_mix_prec flag\n\n* remove opt flag test\n\n* librispeech\n\n* cv ssl\n\n* audio mnist / realm\n\n* voicebank\n\n* fix rescuespeech\n\n* fix lr annealing\n\n* libritts\n\n* multiwoz\n\n* slurp nlu\n\n* should_step\n\n* update yamls\n\n* update yaml\n\n* update batch smpler tedlium\n\n* remove fit batch\n\n* precision flag\n\n* update sampler\n\n* add precision inside of the yamls\n\n* run_opt outside brain + test\n\n* fix auto_mix_prec flag\n\n* docstring\n\n* grad acc\n\n* failing test\n\n* update unittests\n\n* update jarod's pr\n\n* fix removed avg_checkpoint param\n\n* update path\n\n* fix some recipe tests\n\n* update samu recipe\n\n* fix hifigan/IWSLT\n\n* tedlium\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Refactor Augmentation (#2206)\n\n* update\n\n* update\n\n* change folder\n\n* remove unnecesary file\n\n* update folder structure\n\n* add noise, add rev\n\n* augmenter refactor\n\n* refactor augment + example in templace\n\n* fix tests + linters\n\n* address comments\n\n* supporting variable-length augmentations in augmenter (e.g., speed change)\n\n* lib refactor (splitting time and freq augmentations)\n\n* fine tune freq drop\n\n* refactor of specaugment (freq-domain) - part 1\n\n* converted specaument (freq domain)\n\n* refactor random shift\n\n* implemented cutcat, swap, and random selection\n\n* extended unittests + small fixes\n\n* improvements and fixes in augment\n\n* plugged feature augmentation + various fixes and improvements\n\n* add sum_batch noise (similat to babble) + various fixes\n\n* add drop bit resolution\n\n* added coded augmentation\n\n* added more unittests\n\n* restore all augmentations\n\n* making AddReveb more similar to AddNoise\n\n* fix device mismatch + fix last batch management\n\n* add workes to speed up AddNoise and AddRev\n\n* improve comments in template yaml\n\n* speed up template (sorting dev and test)\n\n* extend augmenter by adding activation provability\n\n* implemented enable augmentation flag (useful of hparam tuning) + other improvements\n\n* plugged coded augment\n\n* fixed coded augment\n\n* remove old files\n\n* fix integration test\n\n* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain\n\n* convert TIMIT\n\n* fix recipe\n\n* converted templates using EnvCorr\n\n* converted voxceleb\n\n* converted GSC + fixes on voxceleb\n\n* convrted UrbanSound8k\n\n* converted voicebank\n\n* converted other recipes\n\n* converted CommonLanguage, VoxLingua, timers-and-such\n\n* converted all recipes using envcorr\n\n* CommonVoice\n\n* REAL-M\n\n* Aishell1Mix\n\n* LibriMix\n\n* converted all recipes!\n\n* fix linters - part1\n\n* fix linters - part2\n\n* add a note in the template regarding augmentation\n\n* fix docstring tests\n\n* fix yamls\n\n* remove coded tests from docstring\n\n* revised coded tests\n\n* fix identation in codec.py\n\n* try to fix doc issue\n\n* revise lib header in codec.oy\n\n* fix doc\n\n* fix doc attempt\n\n* rename sections\n\n* fix doc\n\n* fix (most) recipe tests\n\n* fix other recipe tests\n\n* address comments\n\n* fix yaml\n\n* fix\n\n* convert recipe\n\n* fix recipes\n\n* fix aug in rescoring recipes\n\n* Delete tmpdir_vocoder directory\n\n* Refactor Inference (files and folders) (#2252)\n\n* refactor inference files and folders\n\n* fix some tests\n\n* fix some tests\n\n* fix doctest\n\n* import lib\n\n* small fixes\n\n* Fix beam search (#2253)\n\n* fix starting pos prefix_length\n\n* block path ctc + fix default value to the old one\n\n* fix issue with score being -inf\n\n* remoev print\n\n* precommit\n\n* Fix ctc beam search (#2263)\n\n* fix logprobs / space_token / warnings\n\n* fix space_token\n\n* pre-commit\n\n* space_token\n\n* simplify parameters\n\n* simplify yamls\n\n* remove comma\n\n* update beam search\n\n* fix vocab/str (#2265)\n\n* Fix blank index ctc (#2266)\n\n* update blank_index\n\n* whisper\n\n* revert change\n\n* mistake\n\n* Cv unstable merge (#2254)\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* add fr preproccesing to Common_voice_prepare.py\n\n* add CV , CTC, new languages\n\n* fix precommit and test\n\n* add transducer recipie\n\n* add transformer recipies\n\n* update augmentation of CTC recipies\n\n* update seq-to-seq recipies\n\n* fix whisper HF interface bug. (return str insted of list)\n\n* fix recipe tests\n\n* modify beamsearch for CTC: ar.es.pt and zh-CN\n\n* fix interface conflict\n\n* fix transducer interface bug\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Add warnings and fix numba (#2271)\n\n* upperbound torch/tochaudio + remove opt dependancy\n\n* add back automix/bf flags\n\n* linters\n\n* oops\n\n* transformers back\n\n* test requirements\n\n* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)\n\n* fix trnsfrm bug to load correct opt:adam vs sgd\n\n* add  data_root to the path of common_voice_prepare.py\n\n* add epoch/_counter pretrainer to fr and it recepie\n\n* revert releative path change\n\n* fix opt bug without the need to add epoch_ckpt\n\n* add log and delete launch file\n\n* update the log message\n\n* update WeightedSSLModel (#2272)\n\n* update WeightedSSLModel\n\n* requirements.txt\n\n* fix pre-commit\n\n* Sg/dac (#2246)\n\n* introducing DAC\n\n* lint errors\n\n* black\n\n* documenttion\n\n* remove unused init file\n\n* Fixing tests\n\n* More doc strings\n\n* More doc strings\n\n* PR review\n\n* PR review\n\n* PR review\n\n* Update dac.py\n\n* Update dac.py\n\n* Update dac.py\n\n* make doctests smaller to avoid memory issues in CI\n\n* even smaller tests\n\n---------\n\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)\n\n* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech\n\n* update discrete_ssl models\n\n* add iemocap_prepare to main folder + add test\n\n* ix test for iemocap\n\n* fik typos\n\n* fix test recepies,  minor dormat editting\n\n* fix typo in coomonvoice.csv\n\n* fix typo in yaml file\n\n* fix doctests (those that we do not run in the CI)\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)\n\n* Update CVSS (#2285)\n\n* Update CVSS\n\n* Update train_fr-en.yaml\n\n* Update train_fr-en.yaml\n\n* Update HF interface (#2293)\n\n* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)\n\n* Make lobes use fp32 when AMP is active (#2295)\n\n* Added utils.autocast with a fwd_default_precision function\n\n* Decorate all lobes to require float32 precision in AMP\n\n* Fix trailing space in docstring\n\n* Less confusing doc for fwd_default_precision\n\n* Be explicit that only fp inputs are affected by fwd_default_precision\n\n* Typo in docstring\n\n* Remove dtype annotation that is broken for some reason\n\n* Precommit checks will be the end of me\n\n* Fix tests\n\n* Add docstring to precision wrapper function\n\n* Fix style check again..\n\n* adding support for fp16 transducer loss numba\n\n* adding support for fp16 transducer loss numba\n\n* fix fp16 transducer recipe\n\n* add note on half precision\n\n---------\n\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Fix recipe tests for TransformerASR (#2282)\n\n* fix position embedding (#2283)\n\n* fix position embedding\n\n* use speechbrain internal postional encoding and generate mask from sequence lengths\n\n* call mask function from core for tacotron\n\n* minor fix\n\n* fix device\n\n* reduce training epochs\n\n* update links\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Gradscaler flags (#2281)\n\n* add flags for gradscaler\n\n* add check_loss_isfinite\n\n* update dict\n\n* typo\n\n* remove default\n\n* better message\n\n* fix pre-commit\n\n* remove checks\n\n* remove new arguments\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* add llama2 recipies (#2299)\n\n* add llama2 recipies\n\n* fix symbolic links\n\n* fix  bug\n\n* remove unneccary input in docstring\n\n* fix typo\n\n* cleaning llama2 recepies\n\n* update readme\n\n* update interface and add licence to readme\n\n* fic doc string\n\n* fix precommit\n\n* fix extra-dependency\n\n* remove  commented lines\n\n* inter epoch checkpoint\n\n* minor fixes\n\n* add extra req info in llama.py\n\n* fix linters\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* small fixes\n\n* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu\n\n* fix some broken links\n\n* remove link to private HF repo\n\n* remove link to private HF repo\n\n* fix libritts recipe test\n\n* fix ljspeech recipe test\n\n* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)\n\n* Introduce DCT+DCConv logic\n\n* DDP fix?\n\n* Batch of changes and things brought back\n\n* Streaming fixes (successfully trains)\n\n* WIP streaming code\n\n* WIP functional streaming code\n\n* Fix left context\n\n* Fix formatting\n\n* Cleanups and docs in streaming utils\n\n* Better comment hparams, change seed back to orig, improve naming\n\n* uncomment averaging stuff; it was some ipython issue\n\n* Remove pin_memory as it was not beneficial\n\n* More cleanups, comments on context stuff\n\n* More comments and TODOs\n\n* encode_streaming docstring\n\n* Dirty TransducerBeamSearcher change for streaming GS\n\n* Fix precommit\n\n* Fix encoders that do not support chunk_size\n\n* Pre-commit again\n\n* Make chunk_size type consistent\n\n* Fix formatting of doctest in split_wav_lens\n\n* Remove outdated TODO\n\n* Add hasattr streaming to retain model backcompat\n\n* Cleanup doc and naming for transducer_greedy_decode\n\n* Cite paper for chunked attention\n\n* Remove lost comment\n\n* Update comment in self-attention\n\n* Don't apply masked fill fix in the non-bool mask case\n\n* Added TODO README update\n\n* Revert change to custom_tgt_module; patching model instead\n\n* Remove added entry in README\n\n* Fix streaming conformer conv mismatch\n\n* More conformer conv adjustments\n\n* Adjust context size\n\n* Remove outdated comment\n\n* Fixed causal conformer decoder\n\n* Fix linting\n\n* Gate `custom_tgt_module` creation behind the presence of decoder layers\n\n* Re-enable checkpoint averaging\n\n* Change averaged ckpt count to 10\n\n* Add new model results to README\n\n* WIP refactor: Introduce DCTConfig dataclass\n\n* Improved notice in README\n\n* Formatting and linting fixes\n\n* Attempt at fixing circular import?\n\n* utils can't depend on core it seems; move dct\n\n* Whoops, missed file\n\n* Add DCT test, fix issues\n\n* Remove now obsolete yaml variables for streaming\n\n* Formatting\n\n* Add dummy dct_config parameter to keep unsupported encoders working\n\n* Linting fix\n\n* Fix typo\n\n* Add note on runtime autocast accuracy\n\n* Fix very bad typo from refactor in YAML\n\n* Fix hasattr streaming check\n\n* Remove legacy comment\n\n* Fix left context size calculation in new mask code\n\n* Fix causal models in TransformerASR\n\n* Remove comment on high-level inference code\n\n* YAML formatting + commenting dynchunktrain stuff\n\n* Remove outdated comment about DCConv left contexts\n\n* Remove commented out debug prints from TransformerASR\n\n* Move DCT into utils again\n\n* Rename all(?) mentions of DCT to explicit dynamic chunk training\n\n* Clarify padding logic\n\n* Remove now-useless _do_conv, fix horrible formatting\n\n* Slightly fix formatting further\n\n* Add docstrings to forward_streaming methods\n\n* Add a reference on Dynamic Chunk Training\n\n* Rework conformer docstring docs\n\n* Update conformer author list, fix doc formatting for authors\n\n* Fix trailing whitespace in conformer\n\n* Improved comments in Conformer.forward\n\n* Added random dynchunktrain sampler example\n\n* More explicit names for mask functions in TransformerASR\n\n* Added docstring example on encode_streaming\n\n* Pre-commit fix\n\n* Fix typo in conformer\n\n* Initial streaming integration test\n\n* Precommit fix\n\n* Fix indent in YAML\n\n* More consistent spelling in streaming integration test\n\n* Update CommonVoice.csv\n\n* Add KenLM n-gram training recepie (#2304)\n\n* add kenlm training\n\n* fix precommit\n\n* update readmefile with new result\n\n* fix pre-commit\n\n* fix typo\n\n* fix commit reviews\n\n* fix bug in testing\n\n* add docstring and fix indentation\n\n* fix bug in ASR interface\n\n* change encoderasr interface to support ctc beam\n\n* add suppourt fro kenlm in enoderasr interface\n\n* fix typo\n\n* little changes in REAMDE files to improve clarity)\n\n* use binaries sources in bashrc\n\n* fix trailing-whitespace\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* Create Performance file (automatically) (#2314)\n\n* add performance readme builder\n\n* update recipe csv files\n\n* update README files\n\n* add not in prerelease test\n\n* added performance.md\n\n* fix linters\n\n* update info in README\n\n* Llama2 interface bug (#2318)\n\n* fix llama2 interface bug\n\n* fix minor bug\n\n* update multiwox.csv with correct db and HF link\n\n* New README file (#2315)\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Update README.md\n\n* Optimize masked Dynamic Chunk Convolution (#2308)\n\n* Reorganized some conformer convolution module to be faster\n\n* Completely get rid of the list of slices in the conformer conv module\n\n* Fix linter check\n\n* Remove unused variable\n\n* More unused variables..\n\n* Remove unused import\n\n* Add conformer streaming code path test\n\n* Fix test formatting\n\n* small fixes in tests\n\n* Update RNNLM.yaml\n\n* BayesSpeech (#2326)\n\n* Create train_bayesspeech.py\n\n* Create bayesspeech.yaml\n\n* Update README.md\n\n* Update LibriSpeech.csv\n\n* add extra-req\n\n---------\n\nCo-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>\n\n* adding new controllable exp scheduler\n\n* adding new controllable exp scheduler\n\n* update performance file\n\n* Update PERFORMANCE.md\n\n* Update README.md\n\n---------\n\nCo-authored-by: mhn226 <mhn.22692@gmail.com>\nCo-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>\nCo-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>\nCo-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>\nCo-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>\nCo-authored-by: flexthink <flexthink@users.noreply.github.com>\nCo-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>\nCo-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>\nCo-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>\nCo-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>\nCo-authored-by: asu <sdelang@sdelang.fr>\nCo-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>\nCo-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>\nCo-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>\nCo-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
    },
    {
        "repo_url": "github.com/speechbrain/speechbrain",
        "filepath": "tests/templates/fetching_ddp_dynbatch_finetuning/single_node_pretrained.py",
        "commit_date": "2023-02-14T11:33:19Z",
        "message": "FetchSource"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/vad/segmenter.py",
        "commit_date": "2024-02-20T08:16:14Z",
        "message": "Release candidate for 3.0 (#741)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/vad/segmenter.py",
        "commit_date": "2023-10-12T04:56:41Z",
        "message": "Update for japanese model (#706)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/vad/segmenter.py",
        "commit_date": "2023-09-12T03:57:03Z",
        "message": "3.0.0a5 (#691)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/vad/segmenter.py",
        "commit_date": "2023-08-30T08:27:16Z",
        "message": "Further refactoring and fixes for anchor (#684)\n\n* Further refactoring and fixes for anchor\n\n* Update segmenting of transcripts"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/vad/segmenter.py",
        "commit_date": "2023-08-25T15:28:19Z",
        "message": "Fix how configuration works with threading (#681)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/vad/segmenter.py",
        "commit_date": "2023-08-22T16:58:55Z",
        "message": "Update to use kalpy as dependency (#679)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/vad/segmenter.py",
        "commit_date": "2023-03-07T06:18:32Z",
        "message": "2.2.4 (#576)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/vad/segmenter.py",
        "commit_date": "2023-02-17T04:41:13Z",
        "message": "2.2.3 (#574)\n\n* Migrate to using rich for terminal color and formatting"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/vad/segmenter.py",
        "commit_date": "2023-02-15T06:46:13Z",
        "message": "2.2.0: Add support for tokenizers (#566)\n\n* Add support for tokenizers"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/vad/segmenter.py",
        "commit_date": "2023-02-14T04:11:32Z",
        "message": "2.1.6 (#562)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/vad/segmenter.py",
        "commit_date": "2023-02-06T01:39:57Z",
        "message": "Update for PraatIO 6.0 and related fixes (#547)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/vad/segmenter.py",
        "commit_date": "2023-02-05T04:48:03Z",
        "message": "V2.1 (#536)\n\nResolves #527\nResolves #525\nResolves #522\nResolves #520\nResolves #511\nResolves #540\nResolves #541"
    },
    {
        "repo_url": "github.com/linto-ai/linto-stt",
        "filepath": "whisper/stt/processing/alignment_model.py",
        "commit_date": "2023-11-30T16:49:13Z",
        "message": "fix coding style"
    },
    {
        "repo_url": "github.com/linto-ai/linto-stt",
        "filepath": "whisper/stt/processing/alignment_model.py",
        "commit_date": "2023-11-29T17:49:00Z",
        "message": "Isolate what is specific to Whisper in a folder"
    },
    {
        "repo_url": "github.com/huggingface/open_asr_leaderboard",
        "filepath": "speechbrain/run_eval.py",
        "commit_date": "2023-08-03T18:32:48Z",
        "message": "Add Speechbrain toolkit (#4)\n\n* speechbrain initial get_model fn\n\n* wav2vec / run_eval.py working\n\n* conformer.sh\n\n* add .sh\n\n* remove pycache\n\n* fix batch size\n\n* docstring\n\n* docstring\n\n* updt\n\n* speechbrain requirements\n\n* speechbrain requirements\n\n* fix wer?\n\n* manifest\n\n* gitignore / remove savedir arg\n\n* remove speechbrain/ path\n\n* gitignore\n\n* update wav2vec\n\n* cv\n\n* update scripts\n\n* fix issue composite wer"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/multiprocessing.py",
        "commit_date": "2024-02-20T08:16:14Z",
        "message": "Release candidate for 3.0 (#741)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/multiprocessing.py",
        "commit_date": "2023-10-12T04:56:41Z",
        "message": "Update for japanese model (#706)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/multiprocessing.py",
        "commit_date": "2023-09-12T03:57:03Z",
        "message": "3.0.0a5 (#691)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/multiprocessing.py",
        "commit_date": "2023-08-28T06:50:40Z",
        "message": "Refactor tokenization and bug fixes (#683)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/multiprocessing.py",
        "commit_date": "2023-08-25T15:28:19Z",
        "message": "Fix how configuration works with threading (#681)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/multiprocessing.py",
        "commit_date": "2023-08-22T16:58:55Z",
        "message": "Update to use kalpy as dependency (#679)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/multiprocessing.py",
        "commit_date": "2023-03-07T06:18:32Z",
        "message": "2.2.4 (#576)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/multiprocessing.py",
        "commit_date": "2023-02-15T06:46:13Z",
        "message": "2.2.0: Add support for tokenizers (#566)\n\n* Add support for tokenizers"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/multiprocessing.py",
        "commit_date": "2023-02-09T21:25:40Z",
        "message": "2.1.4 (#555)\n\n* Rework connections again\n\n* Rework pgvector index creation"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/multiprocessing.py",
        "commit_date": "2023-02-09T04:35:34Z",
        "message": "2.1.3 (#553)\n\n* Rework connections\n\n* Better cleaning of databases"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/multiprocessing.py",
        "commit_date": "2023-02-07T00:50:11Z",
        "message": "2.1.2 changes (#549)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/multiprocessing.py",
        "commit_date": "2023-02-06T01:39:57Z",
        "message": "Update for PraatIO 6.0 and related fixes (#547)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/multiprocessing.py",
        "commit_date": "2023-02-05T04:48:03Z",
        "message": "V2.1 (#536)\n\nResolves #527\nResolves #525\nResolves #522\nResolves #520\nResolves #511\nResolves #540\nResolves #541"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/speaker_diarizer.py",
        "commit_date": "2024-02-20T08:16:14Z",
        "message": "Release candidate for 3.0 (#741)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/speaker_diarizer.py",
        "commit_date": "2023-11-02T01:18:55Z",
        "message": "Bug fixes (#712)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/speaker_diarizer.py",
        "commit_date": "2023-10-12T04:56:41Z",
        "message": "Update for japanese model (#706)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/speaker_diarizer.py",
        "commit_date": "2023-09-12T03:57:03Z",
        "message": "3.0.0a5 (#691)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/speaker_diarizer.py",
        "commit_date": "2023-08-30T08:27:16Z",
        "message": "Further refactoring and fixes for anchor (#684)\n\n* Further refactoring and fixes for anchor\n\n* Update segmenting of transcripts"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/speaker_diarizer.py",
        "commit_date": "2023-08-28T06:50:40Z",
        "message": "Refactor tokenization and bug fixes (#683)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/speaker_diarizer.py",
        "commit_date": "2023-08-25T15:28:19Z",
        "message": "Fix how configuration works with threading (#681)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/speaker_diarizer.py",
        "commit_date": "2023-08-22T16:58:55Z",
        "message": "Update to use kalpy as dependency (#679)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/speaker_diarizer.py",
        "commit_date": "2023-04-26T21:03:32Z",
        "message": "2.2.10 (#624)\n\n* Bug fixes"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/speaker_diarizer.py",
        "commit_date": "2023-03-07T06:18:32Z",
        "message": "2.2.4 (#576)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/speaker_diarizer.py",
        "commit_date": "2023-02-17T04:41:13Z",
        "message": "2.2.3 (#574)\n\n* Migrate to using rich for terminal color and formatting"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/speaker_diarizer.py",
        "commit_date": "2023-02-15T06:46:13Z",
        "message": "2.2.0: Add support for tokenizers (#566)\n\n* Add support for tokenizers"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/speaker_diarizer.py",
        "commit_date": "2023-02-14T04:11:32Z",
        "message": "2.1.6 (#562)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/speaker_diarizer.py",
        "commit_date": "2023-02-09T21:25:40Z",
        "message": "2.1.4 (#555)\n\n* Rework connections again\n\n* Rework pgvector index creation"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/speaker_diarizer.py",
        "commit_date": "2023-02-06T01:39:57Z",
        "message": "Update for PraatIO 6.0 and related fixes (#547)"
    },
    {
        "repo_url": "github.com/MontrealCorpusTools/Montreal-Forced-Aligner",
        "filepath": "montreal_forced_aligner/diarization/speaker_diarizer.py",
        "commit_date": "2023-02-05T04:48:03Z",
        "message": "V2.1 (#536)\n\nResolves #527\nResolves #525\nResolves #522\nResolves #520\nResolves #511\nResolves #540\nResolves #541"
    },
    {
        "repo_url": "github.com/jansel/pytorch-jit-paritybench",
        "filepath": "generated/test_speechbrain_speechbrain.py",
        "commit_date": "2023-01-10T06:06:44Z",
        "message": "Re-crawl & re-generate test suite(1479 projects & 14307 test cases)"
    },
    {
        "repo_url": "github.com/Ascend/ModelZoo-PyTorch",
        "filepath": "PyTorch/contrib/audio/tdnn/speechbrain/pretrained/interfaces.py",
        "commit_date": "2023-07-10T07:05:29Z",
        "message": "!5157 \u3010\u9700\u6c42\u3011\u3010PyTorch\u3011\u3010Tdnn\u3011\u8bad\u63a8\u4e00\u4f53\n* \u65b0\u589e\u8bad\u7ec3\u811a\u672c\uff0c\u4fee\u6539\u76f8\u5e94\u6587\u4ef6\n* \u4fee\u6539\u6587\u4ef6\uff0c\u6dfb\u52a0license\uff0c\u6dfb\u52a0readme\n* tdnn\u6a21\u578b\u4e0a\u4f20"
    },
    {
        "repo_url": "github.com/Ascend/ModelZoo-PyTorch",
        "filepath": "PyTorch/contrib/audio/tdnn/speechbrain/pretrained/interfaces.py",
        "commit_date": "2022-03-18T07:08:55Z",
        "message": "init"
    },
    {
        "repo_url": "github.com/speechbrain/benchmarks",
        "filepath": "tests/utils/refactoring_checks.py",
        "commit_date": "2023-06-29T21:21:56Z",
        "message": "upload files and tests"
    },
    {
        "repo_url": "github.com/radinshayanfar/speaker-verification",
        "filepath": "snorm_embeddings.py",
        "commit_date": "2022-03-16T12:01:08Z",
        "message": "files added."
    },
    {
        "repo_url": "github.com/radinshayanfar/speaker-verification",
        "filepath": "speaker_verification_cosine.py",
        "commit_date": "2022-03-16T12:01:08Z",
        "message": "files added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2024-02-27T11:11:47Z",
        "message": "[Update] An example for Gemma model was initially added.\n[Update] An example for Transformer Reinforcement Learning (TRL) library to train small LLMs (sLLMs) was initially added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2024-02-21T12:45:57Z",
        "message": "[Update] Examples for DINO and DPT models were implemented in hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2024-02-16T06:16:19Z",
        "message": "[Update] Placeholders for examples of Hugging Face TRL library were added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2024-02-08T03:52:31Z",
        "message": "[Update] Several examples for stable diffusion models of Stability AI were implemented.\n[Update] Information about Transformer Reinforcement Learning (TRL) library was moved from hugging_face_test.py to hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2024-01-31T08:31:27Z",
        "message": "[Update] A test was added to fine-tune a ResNet model using Dog/Cat dataset in pytorch_transfer_learning.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2024-01-28T13:07:24Z",
        "message": "[Update] An example of Zephyr-7B was added in hugging_face_transformers_test.py, but was not tested.\n[Update] The information about Transformer Reinforcement Learning (TRL) was described in hugging_face_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2024-01-11T04:04:23Z",
        "message": "[Update] An example for retrieval-augmented generation (RAG) was added in hugging_face_transformers_test.py.\n[Update] Information about TableMASTER-mmocr was removed from mmocr_usage_guide.txt."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-12-24T02:40:32Z",
        "message": "[Update] A few examples for Mistral-7B and Mixtral-8x7B models were added.\n[Update] The installation of TensorFlow 2 were updated."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-12-23T12:07:02Z",
        "message": "[Update] An example of ORCA-2 model was added.\n[Update] The examples for ViT, ViLT, BEiT, LayoutLM, and Donut models were merged respectively.\n[Update] The information about data preparation, training, evaluation, visualization, and model export were supplemented in paddle_ocr_usage_guide.txt."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-11-24T08:49:41Z",
        "message": "[Update] A customized version of ViT model was implemented and tested, which doesn't have classification token and head."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-11-20T04:48:59Z",
        "message": "[Update] A few examples for Falcon model were initially implemented.\n[Update] A few examples for StarCoder and Replit models were implemented, but yet tested."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-11-10T01:27:50Z",
        "message": "[Update] LLMs Yi-6B & Yi-34B were tested."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-11-06T12:24:53Z",
        "message": "[Update] The forecasts of transformers.TimeSeriesTransformerForPrediction were evaluated by MASE, MAPE, sMAPE.\n[Update] Metrics for evaluating ML models' performance in evaluate library were tested."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-11-03T10:46:04Z",
        "message": "[Update] Two examples for phi-1 & phi-1.5 models were initially added.\n[Update] A few examples for Kosmos-2 model were initially added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-10-12T12:13:43Z",
        "message": "[Update] A few examples for Probabilistic time series transformer model were added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-10-07T08:51:44Z",
        "message": "[Update] Several examples for Perceiver IO model were initially committed."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-09-26T10:56:44Z",
        "message": "[Update] A simple example for Code Llama model was initially added.\n[Update] A few commands were explained to profile Python scripts."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-09-21T12:31:58Z",
        "message": "[Update] A simple example for OpenLLaMA models was implemented."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-09-04T03:59:25Z",
        "message": "[New] A few examples for PID, MPC, LQR using python-control library was initially added.\n[Update] A simple example for trajectory transformer models was added in hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-09-02T12:30:02Z",
        "message": "[New] An example for model predictive control (MPC) was initially committed.\n[Update] A test for CodeParrot model was initially implemented in hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-08-31T06:01:24Z",
        "message": "[Update] Memory footprint and computing performance (FLOPS) Hugging Face transformers models was measured.\n[Update] A simple test for Hugging Face datasets was added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-08-04T08:13:21Z",
        "message": "[Update] An example for OpenFlamingo library was added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-07-25T12:07:07Z",
        "message": "[Update] A few examples for Llama 2 model were added in hugging_face_transformers_test.py.\n[Update] Model parallelism was tested based on Hugging Face Accelerate library in hugging_face_transformers_test.py.\n[Update] Information about Hugging Face Accelerate library was reinforced."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-07-22T06:48:12Z",
        "message": "[Update] Cross references about transformer and ViT models were reinforced.\n[Chore] vit_test.py was moved from sw_dev/python/rnd/test/machine_learning/vit_test.py to sw_dev/python/rnd/test/machine_vision/vit_test.py.\n[Update] The installation of node.js was explained."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-07-17T01:20:26Z",
        "message": "[Update] Several examples for CodeBERT, CodeBERTa, CodeT5+, CodeGen2, & CodeGen2.5 models were added.\n[Update] An example of SpeechT5 model was divied into 3 examples: ASR, TTS, & speech-to-speech."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-07-12T07:54:25Z",
        "message": "[Update] An example for Decision Transformer was initially committed.\n[Update] A few examples for NVIDIA Megatron-LM, ASR, TTS models were implemented.\n[Update] An example for SegFormer model was initially added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-06-30T14:20:26Z",
        "message": "[Update] The method, chain of thoughts (CoT) was tested on two LLMs, LLaMA & MPT."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-06-27T04:15:37Z",
        "message": "[Update] A few examples for MPT & TVLT models were implemented in hugging_face_transformers_test.py.\n[Chore] table_generation_usage_guide.txt was moved to SWLP repository."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-06-22T14:49:33Z",
        "message": "[Update] Three language models were tested: LLaMA, Galactica, & OPT models."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-06-15T07:51:37Z",
        "message": "[Update] The example of LLaMA model was reinforced."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-05-26T18:49:16Z",
        "message": "[Update] A test for data parallelism was implemented in PyTorch library."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-05-05T03:23:29Z",
        "message": "[Update] Two simple tests for two Facebook's language models, OPT and Galactica were initially implemented."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-04-30T14:34:59Z",
        "message": "[New] A simple tutorial for MMSegmentation library was initially committed."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-04-06T03:27:45Z",
        "message": "[Update] A couple of simple examples for LLaMa model were implemented, but they were not tested due to library version issue."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-04-04T11:52:41Z",
        "message": "[Update] Several examples for CodeT5 and CodeGen models were implemented to generate code.\n[Update] Several examples for GIT and BLIP models for vision-and-language modeling models were implemented.\n[Update] A few examples for TaPEx model were implemented to understand tables."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-04-01T14:10:48Z",
        "message": "[New] A couple of examples for GPT4All models were added, but they were not correctly working."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-04-01T06:26:08Z",
        "message": "[New] Two simple examples for PaLM and PaLM+RLHF models were implemented, but the models were not trained in the examples."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-30T08:06:47Z",
        "message": "[New] Several examples for table processing (Table Transformer, TATR), OCR (TrOCR), speech processing (SpeechT5) were initially added to hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-29T05:25:41Z",
        "message": "[Update] Several examples for speech recognition (whisper) & synthesis (tacotron2 & fastspeech2) were newly implemented in hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-26T07:02:13Z",
        "message": "[New] A few examples for ALIGN model were implemented in hugging_face_transformers_test.py.\n[Update] A couple of examples for CLIP model were added in hugging_face_transformers_test.py.\n[Update] Useful information about Transformer architectures was described."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-24T06:24:31Z",
        "message": "[Update] A simple example about dataclass in Python was added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-22T14:48:31Z",
        "message": "[Update] A couple of examples of seq-to-seq models for LoRA & Prefix Tuning were implemented in hugging_face_test.py.\n[Update] An example for CLIP model was implemented in hugging_face_transformers_test.py.\n[Update] A few examples for Whisper model were implemented in hugging_face_transformers_test.py.\n[New] A usage guide for Hugging Face library was added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-21T07:10:38Z",
        "message": "[Update] A simple example of Parameter-Efficient Fine-Tuning (PEFT) library was added to hugging_face_test.py.\n[Update] A simple test of tokenizers was added to hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-18T11:41:29Z",
        "message": "[Update] A couple of examples for diffusion models of StabilityAI and CompVis were added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-18T05:09:16Z",
        "message": "[Update] A few examples for Flan-T5 model were reinforced in hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-16T11:52:13Z",
        "message": "[Update] Information about Hugging Face models was supplemented."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-15T12:08:24Z",
        "message": "[Update] An example for question answering using GPT-neo was added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-14T02:43:49Z",
        "message": "[Update] A few examples for BLOOM and Flan-T5 models were implemented."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-09T01:51:43Z",
        "message": "[Update] A test for KLUE BERT models was implemented."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-09T01:49:32Z",
        "message": "[Update] A few examples of text summarization for Korean & English were implemented, but their results were not good.\n[Update] A few examples for T5 model were added."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-07T17:44:21Z",
        "message": "[Update] A few tests were added for GPT & BERT models."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-03-01T14:37:43Z",
        "message": "[New] A few guides were initially committed for Hugging Face Hub library."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-01-19T10:11:50Z",
        "message": "[Update] Several examples for vision, vision and language models were added in HuggingFace library."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2023-01-19T08:06:44Z",
        "message": "[Update] Several examples for LayoutLM & Donut models were implemented in HugggingFace library."
    },
    {
        "repo_url": "github.com/sangwook236/SWDT",
        "filepath": "sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py",
        "commit_date": "2022-04-01T07:00:58Z",
        "message": "[Chore] transformers_test.py was renamed to hugging_face_transformers_test.py."
    },
    {
        "repo_url": "github.com/CanKeles5/senh",
        "filepath": "models.py",
        "commit_date": "2022-02-09T21:26:43Z",
        "message": "Slight refactor."
    },
    {
        "repo_url": "github.com/CanKeles5/senh",
        "filepath": "models.py",
        "commit_date": "2022-02-07T19:34:15Z",
        "message": "."
    },
    {
        "repo_url": "github.com/CanKeles5/senh",
        "filepath": "models.py",
        "commit_date": "2022-02-07T12:50:06Z",
        "message": "Add files via upload\n\nCode needs lots of refactoring."
    },
    {
        "repo_url": "github.com/CanKeles5/senh",
        "filepath": "models.py",
        "commit_date": "2022-02-07T11:58:44Z",
        "message": "initial commit"
    },
    {
        "repo_url": "github.com/Ascend/ModelZoo-PyTorch",
        "filepath": "PyTorch/dev/perf/speechbrain-tdnn/tools/g2p.py",
        "commit_date": "2023-06-25T09:50:02Z",
        "message": "ECAPA-TDNN NPU\n\nNPU\u8fc1\u79fb\n\nNPU\u8fc1\u79fb\n\nNPU\u9002\u914d"
    },
    {
        "repo_url": "github.com/Ascend/ModelZoo-PyTorch",
        "filepath": "PyTorch/dev/perf/speechbrain-tdnn/tools/profiling/profile.py",
        "commit_date": "2023-06-25T09:50:02Z",
        "message": "ECAPA-TDNN NPU\n\nNPU\u8fc1\u79fb\n\nNPU\u8fc1\u79fb\n\nNPU\u9002\u914d"
    },
    {
        "repo_url": "github.com/Ascend/ModelZoo-PyTorch",
        "filepath": "PyTorch/dev/perf/speechbrain-tdnn/speechbrain/pretrained/interfaces.py",
        "commit_date": "2023-06-25T09:50:02Z",
        "message": "ECAPA-TDNN NPU\n\nNPU\u8fc1\u79fb\n\nNPU\u8fc1\u79fb\n\nNPU\u9002\u914d"
    },
    {
        "repo_url": "github.com/nuaazs/VAF",
        "filepath": "src/utils/preprocess/new_vad.py",
        "commit_date": "2023-04-21T02:56:39Z",
        "message": "update code"
    },
    {
        "repo_url": "github.com/amitpuri/Ask-picturize-it",
        "filepath": "Utils/TranscribeSpeechbrain.py",
        "commit_date": "2023-07-04T14:20:40Z",
        "message": "Update"
    }
]