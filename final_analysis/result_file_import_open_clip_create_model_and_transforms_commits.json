[
    {
        "message_summary": "Open-sourcing the code for \"CLIP as RNN: Segment Countless Visual Concepts without Training Endeavor\".",
        "ptm_name": "CLIP as RNN",
        "ptm_version": "N/A",
        "ptm_problem_addressed": "Segment Countless Visual Concepts without Training Endeavor",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "N/A",
                "Task Specificity": "N/A",
                "Community and Collaboration": "N/A",
                "Maintenance": "N/A",
                "Compliance and Standards": "N/A",
                "Performance Improvements": "N/A",
                "Compatibility": "N/A",
                "Deprecation and Replacement": "N/A",
                "Project Evolution": "N/A",
                "Technical Debt and Simplification": "N/A"
            }
        ]
    },
    {
        "message_summary": "None",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Multi-modal RAG template (#14186)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Added OpenCLIP embeddings and GPT-4V",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "Update Open CLIP embd (#14155)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Prior default model required a large amount of RAM and often crashed Jupyter notebook kernel",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Prior default model required a large amount of RAM and often crashed Jupyter notebook kernel"
            }
        ]
    },
    {
        "message_summary": "Add Chroma multimodal cookbook (#12952)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": {},
                "Task Specificity": {},
                "Community and Collaboration": {},
                "Maintenance": {},
                "Compliance and Standards": {},
                "Performance Improvements": {},
                "Compatibility": {},
                "Deprecation and Replacement": {},
                "Project Evolution": {},
                "Technical Debt and Simplification": {}
            }
        ]
    },
    {
        "message_summary": "Revert \"Replace most print()s with logging calls (#42)\" (#65)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "Revert of a previous commit to replace print() statements with logging calls."
            }
        ]
    },
    {
        "message_summary": "Replace most print()s with logging calls",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "send weights to target device instead of CPU memory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "send weights to target device instead of CPU memory"
            }
        ]
    },
    {
        "message_summary": "Use less RAM when creating models",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Use less RAM when creating models"
            }
        ]
    },
    {
        "message_summary": "make it possible to load SD1 checkpoints without CLIP",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "make it possible to load SD1 checkpoints without CLIP"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Fix for an error caused by skipping initialization",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Fixed TypeError: expected str, bytes or os.PathLike object, not NoneType",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix for an error caused by skipping initialization"
            },
            {
                "Maintenance": "Fixed TypeError: expected str, bytes or os.PathLike object, not NoneType"
            }
        ]
    },
    {
        "message_summary": "Add support for transformers==4.25.1",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Added fallback for when quick model creation fails",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Added support for transformers==4.25.1"
            },
            {
                "Maintenance": "Added fallback for when quick model creation fails"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "disable torch weight initialization and CLIP downloading/reading checkpoint to speedup creating sd model from config",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "disable torch weight initialization and CLIP downloading/reading checkpoint to speedup creating sd model from config"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Add ColoDiffusion codes",
        "ptm_name": "ColoDiffusion",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of ColoDiffusion codes"
            }
        ]
    },
    {
        "message_summary": "docs: add docstrings",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Addition of docstrings to the codebase"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "feature: Stable Diffusion 2.0",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "CUDA and MacOS support added. 512p model with all samplers, inpainting with all samplers, and 768p model with ddim sampler are now functional.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "[pre-commit.ci] auto fixes from pre-commit.com hooks",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "auto fixes from pre-commit.com hooks"
            }
        ]
    },
    {
        "message_summary": "Initial conversion of the sd_util.py file into a package with smaller modules in it.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Initial conversion of the sd_util.py file into a package with smaller modules in it."
            }
        ]
    },
    {
        "message_summary": "Cleaned some commented code that is no longer needed.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Cleaned some commented code that is no longer needed."
            }
        ]
    },
    {
        "message_summary": "Added support for webp images in the img2txt tab",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Added support for webp images in the img2txt tab"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Added logging back to the img2txt tab.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Added logging back to the img2txt tab."
            }
        ]
    },
    {
        "message_summary": "Improved the img2txt tab by having more tags.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "Improved the img2txt tab by having more tags."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "More renaming and changed to links related to the organization, docs and repo names.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "More renaming and changed to links related to the organization, docs and repo names."
            }
        ]
    },
    {
        "message_summary": "More renaming and changes to links related to the organization, docs an repo names.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Renaming and changes to links related to the organization, docs, and repo names."
            }
        ]
    },
    {
        "message_summary": "Fixed links so they point to the new repo and organization names.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Fixed links to point to the new repo and organization names."
            }
        ]
    },
    {
        "message_summary": "Made sure the log variable is still around on the img2txt after its being cleared.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Made sure the log variable is still around on the img2txt after its being cleared."
            }
        ]
    },
    {
        "message_summary": "Added reraise option for loguru.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Added reraise option for loguru."
            }
        ]
    },
    {
        "message_summary": "Replaced print statements with loguru for improved console output",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "Print statements replaced with loguru",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Print statements replaced with loguru"
            }
        ]
    },
    {
        "message_summary": "Added extra models back to img2txt.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Added extra models back to img2txt."
            }
        ]
    },
    {
        "message_summary": "img2txt speed + vram issues",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "img2txt speed"
            },
            {
                "Unrelated": "vram issues"
            }
        ]
    },
    {
        "message_summary": "Update img2txt.py",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "No significant Pre-Trained Models activities mentioned."
            }
        ]
    },
    {
        "message_summary": "Added WIP code for img2txt to get information dynamically from artstation.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Added WIP code for img2txt to get information dynamically from artstation."
            }
        ]
    },
    {
        "message_summary": "docker / local cache paths",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "N/A",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Improved img2txt layout and performance.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Improved img2txt layout and performance."
            }
        ]
    },
    {
        "message_summary": "Added open clip dependency which is needed for some CLIP models.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Added open clip dependency which is needed for some CLIP models."
            }
        ]
    },
    {
        "message_summary": "Img2txt working now but needs more than 8GB of VRAM to work. Will be trying to improve it as the next step.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Targets specific performance optimization and efficiency improvements in pre-trained models to boost system throughput and response times."
            }
        ]
    },
    {
        "message_summary": "Img2txt dependencies and necessary files.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            },
            {
                "Deprecation and Replacement": "Replacement of a Pre Trained Model:"
            },
            {
                "Deprecation and Replacement": "Removal of a Pre Trained model:"
            }
        ]
    },
    {
        "message_summary": "Changed the default streamlit import for hydralit as we will be using hydralit as replacement for the default streamlit library, hydralit provides better control over css as well as having a lot more options.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "hydralit replaces the default streamlit library for better control over CSS and more options",
        "removal_details": "",
        "text": [
            {
                "Replacement of a Pre Trained Model": "hydralit replaces the default streamlit library for better control over CSS and more options"
            }
        ]
    },
    {
        "message_summary": "docs: add docstrings",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Addition of docstrings"
            }
        ]
    },
    {
        "message_summary": "feature: stable diffusion video (SVD)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Gemini (#1520)",
        "ptm_name": "Google Gemini",
        "ptm_version": "N/A",
        "ptm_problem_addressed": "Embedding function",
        "update_details": "An embedding function for Google Gemini and an RAG chat example were added.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "Remove redundant check for \"requests\" module",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "Redundant check for the \"requests\" module was removed.",
        "text": [
            {
                "Maintenance": "Redundant check for the \"requests\" module was removed."
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "Revert of a previously added Multimodal Embeddings feature."
            }
        ]
    },
    {
        "message_summary": "Add Text2VecEmbeddingFunction for Chinese sentence embedding.",
        "ptm_name": "Text2VecEmbeddingFunction",
        "ptm_version": "",
        "ptm_problem_addressed": "Chinese sentence embedding",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "Add Google PaLM embedding function.",
        "ptm_name": "Google PaLM",
        "ptm_version": "N/A",
        "ptm_problem_addressed": "N/A",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a new pre-trained model"
            }
        ]
    },
    {
        "message_summary": "Adds a robust property-based testing suite to Chroma",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Adds a robust property-based testing suite to Chroma"
            }
        ]
    },
    {
        "message_summary": "Make api_key in OpenAIEmbeddingFunction optional",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "API key in OpenAIEmbeddingFunction made optional and functionality improved",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "[bugfix] Ensure Openai batch embeddings are sorted by index (#344)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Adds option to pass compute device like cpu, cuda, cuda:1 to SentenceTransformerEmbeddingFunction",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Adds option to pass compute device like cpu, cuda, cuda:1 to SentenceTransformerEmbeddingFunction"
            }
        ]
    },
    {
        "message_summary": "Add flake8 linter, address linter issues (#287)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add flake8 linter, address linter issues (#287)"
            }
        ]
    },
    {
        "message_summary": "added embedding function for the Instructor models.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "Dedicated to developing and deploying task-specific enhancements or capabilities that exploit the unique strengths of pre-trained models."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "add wrapper for hugging faces embedding api",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "addition"
            }
        ]
    },
    {
        "message_summary": "Add T5 as an option in comments",
        "ptm_name": "T5",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Add T5 as an option in comments"
            }
        ]
    },
    {
        "message_summary": "Unified error messages",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Unifies error messages across the project to make them more useful and consistent. Improves the error message for invalid collection names.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Unified error messages"
            }
        ]
    },
    {
        "message_summary": "Add support for cohere embeddings",
        "ptm_name": "cohere",
        "ptm_version": "latest",
        "ptm_problem_addressed": "Support for cohere embeddings",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": {
                    "repo_url": "github.com/chroma-core/chroma",
                    "filepath": "chromadb/utils/embedding_functions.py",
                    "commit_date": "2023-02-17T18:06:08Z",
                    "message_summary": "Add support for cohere embeddings",
                    "ptm_addition_details": {
                        "name": "cohere",
                        "version": "latest",
                        "problem_addressed": "Support for cohere embeddings"
                    }
                }
            }
        ]
    },
    {
        "message_summary": "Remove newlines to improve performance",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Remove newlines to improve performance"
            }
        ]
    },
    {
        "message_summary": "Adding OpenAI embedding functions",
        "ptm_name": "OpenAI",
        "ptm_version": "Not specified",
        "ptm_problem_addressed": "Embedding functions",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Adding OpenAI embedding functions"
            }
        ]
    },
    {
        "message_summary": "Remove einops exts for better PyTorch 2.0 compile compatibility",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Address the adaptation of pre-trained models to function optimally with newer systems or software versions, ensuring forward compatibility."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Fix for self conditioning in diffusion prior network",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Commit log is related to fixing self conditioning in diffusion prior network."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Updates related to Pre-Trained Models for DALL-E 2 extension",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Prediction of v objective added, combining insights from progressive distillation paper and imagen-video for the extension of DALL-E 2 to make-a-video",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Updates related to Pre-Trained Models for DALL-E 2 extension"
            },
            {
                "Task Specificity": "Prediction of v objective added, combining insights from progressive distillation paper and imagen-video for the extension of DALL-E 2 to make-a-video"
            }
        ]
    },
    {
        "message_summary": "Fix openclipadapter to be able to use the latest open-sourced SOTA model",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Fix a dtype conversion issue for the diffusion timesteps in the diffusion prior.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Commit log is related to fixing a dtype conversion issue for the diffusion timesteps in the diffusion prior."
            }
        ]
    },
    {
        "message_summary": "Fix for use with larger OpenAI CLIP models by extracting dimension of last layernorm in CLIP",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "handle open clip adapter image size being a tuple",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Adapter image size handling"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Fix bug with misnamed variable in diffusion prior network",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix bug with misnamed variable in diffusion prior network"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Cast attention matrix back to original dtype pre-softmax in attention",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Cast attention matrix back to original dtype pre-softmax in attention"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Add weight standardization behind feature flag",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Weight standardization added behind a feature flag, potentially working well with group norm",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Weight standardization added behind a feature flag, potentially working well with group norm"
            }
        ]
    },
    {
        "message_summary": "Update for diffusion prior to return unnormalized image embeddings",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update for diffusion prior to return unnormalized image embeddings"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Fix self conditioning shape in diffusion prior",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix self conditioning shape in diffusion prior"
            }
        ]
    },
    {
        "message_summary": "make self conditioning technique work with diffusion prior",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "make self conditioning technique work with diffusion prior"
            }
        ]
    },
    {
        "message_summary": "bet on the new self-conditioning technique out of geoffrey hintons group",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "bet on the new self-conditioning technique out of geoffrey hintons group"
            }
        ]
    },
    {
        "message_summary": "Add gradient checkpointing for all ResNet blocks",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Add gradient checkpointing for all ResNet blocks"
            }
        ]
    },
    {
        "message_summary": "make open clip available for use with dalle2 pytorch",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "make open clip available for use with dalle2 pytorch"
            }
        ]
    },
    {
        "message_summary": "quick fix for linear attention",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "quick fix for linear attention"
            }
        ]
    },
    {
        "message_summary": "Add cosine sim for self attention as well, as a setting",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Add cosine sim for self attention as well, as a setting"
            }
        ]
    },
    {
        "message_summary": "Change up epsilon in layernorm for using fp16",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Epsilon in layernorm was adjusted for better stability during training. Thanks to @Veldrovive for identifying this improvement.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Epsilon in layernorm was adjusted for better stability during training."
            }
        ]
    },
    {
        "message_summary": "Update to resolve issue on fp16",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Modified linear attention to resolve issue on fp16",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Rescaling values in linear attention to mitigate overflows in fp16 setting",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Rescaling values in linear attention to mitigate overflows in fp16 setting"
            }
        ]
    },
    {
        "message_summary": "N/A",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Complete inpainting ability using inpaint_image and inpaint_mask passed into sample function for decoder",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Complete inpainting ability using inpaint_image and inpaint_mask passed into sample function for decoder"
            }
        ]
    },
    {
        "message_summary": "Fix a bug with ddim and predict x0 objective",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix a bug with ddim and predict x0 objective"
            }
        ]
    },
    {
        "message_summary": "Complete imagen-like noise level conditioning",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Complete imagen-like noise level conditioning"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "protect against random cropping for base unet",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "protect against random cropping for base unet"
            }
        ]
    },
    {
        "message_summary": "Let the neural network peek at the low resolution conditioning one last time before making prediction, for upsamplers",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Involves ensuring compatibility with new systems or versions."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "fix non pixel shuffle upsample",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "fix non pixel shuffle upsample"
            }
        ]
    },
    {
        "message_summary": "Fix a potential bug with conditioning with blurred low-resolution image, blur should be applied only 50% of the time",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix a potential bug with conditioning with blurred low-resolution image, blur should be applied only 50% of the time"
            }
        ]
    },
    {
        "message_summary": "Fix issue with ddim and normalization of lowres conditioning image",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix issue with ddim and normalization of lowres conditioning image"
            }
        ]
    },
    {
        "message_summary": "Update in transformer output normalization",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Switched to using stable layernorm for final output normalization in the transformer.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Switched to using stable layernorm for final output normalization in the transformer."
            }
        ]
    },
    {
        "message_summary": "add yet another transformer stability measure",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "add yet another transformer stability measure"
            }
        ]
    },
    {
        "message_summary": "Add learned padding tokens for diffusion prior and remove masking in causal transformer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add learned padding tokens for diffusion prior and remove masking in causal transformer"
            }
        ]
    },
    {
        "message_summary": "Add setting to attend to all text encodings regardless of padding, for diffusion prior",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Add setting to attend to all text encodings regardless of padding, for diffusion prior"
            }
        ]
    },
    {
        "message_summary": "make sure text encodings being passed in has the correct batch dimension",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Remove text masking in favor of deriving from text encodings",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "Text masking removed, now deriving from text encodings",
        "text": [
            {
                "Maintenance": "Text masking removed, now deriving from text encodings"
            }
        ]
    },
    {
        "message_summary": "protect against bad text mask being passed into decoder",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Fix for text mask with length exceeding max_text_len",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Added an assert statement for better error message when the length of the text encoding exceeds max_text_len.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix for text mask with length exceeding max_text_len. Added an assert statement for better error message when the length of the text encoding exceeds max_text_len."
            }
        ]
    },
    {
        "message_summary": "generate text mask within the unet and diffusion prior itself from the text encodings, if not given",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Add PixelShuffleUpsample",
        "ptm_name": "PixelShuffleUpsample",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Thanks to @MalumaDev and @marunine for running the experiment and verifying the absence of checkboard artifacts",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": {
                    "PTM Name": "PixelShuffleUpsample",
                    "Details": "The commit involves adding the PixelShuffleUpsample pre-trained model to the repository for task-specific enhancement. The update was verified through an experiment conducted by @MalumaDev and @marunine to ensure the absence of checkboard artifacts."
                },
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "zero init final projection in unet, since openai and @crowsonkb are both doing it",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Update of a Pre Trained Model:"
            },
            {
                "Deprecation and Replacement": "Replacement of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Allow for final l2norm clamping of the sampled image embed",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Allow for final l2norm clamping of the sampled image embed"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "fix for small validation bug for sampling steps",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "fix for small validation bug for sampling steps"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Complete ddim integration of diffusion prior as well as decoder for each unet",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Complete ddim integration of diffusion prior as well as decoder for each unet"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Allow for control over use of nearest interp method of downsampling low res conditioning, in addition to being able to turn it off",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Allow for control over use of nearest interp method of downsampling low res conditioning, in addition to being able to turn it off"
            }
        ]
    },
    {
        "message_summary": "Fix a potential issue in the low resolution conditioner",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Fixed a potential issue in the low resolution conditioner when downsampling and then upsampling using resize right. Thanks to @marunine.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fixed a potential issue in the low resolution conditioner when downsampling and then upsampling using resize right. Thanks to @marunine."
            }
        ]
    },
    {
        "message_summary": "Fix condition_on_text_encodings in DALLE2 orchestrator class and readme",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix condition_on_text_encodings in DALLE2 orchestrator class and readme"
            }
        ]
    },
    {
        "message_summary": "More shots in the dark regarding fp16 with learned variance for deepspeed issue",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "More shots in the dark regarding fp16 with learned variance for deepspeed issue"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Remove forcing of softmax in f32",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "In case it is interfering with deepspeed",
        "text": [
            {
                "Maintenance": "Remove forcing of softmax in f32 in case it is interfering with deepspeed"
            }
        ]
    },
    {
        "message_summary": "Updates related to attention and layernorm for reducing overflow chances",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Two techniques from the cogview paper were implemented to reduce the chances of overflow in attention and layernorm.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Updates related to attention and layernorm for reducing overflow chances"
            }
        ]
    },
    {
        "message_summary": "Add ability to specify full self-attention on specific stages in the UNet",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of new integration patterns"
            }
        ]
    },
    {
        "message_summary": "Allow for returning low resolution conditioning image on forward through decoder with return_lowres_cond_image flag",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Allow for returning low resolution conditioning image on forward through decoder with return_lowres_cond_image flag"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Update default blur sigma value for upsampling training",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Changed the default blur sigma value for upsampling training from 0.6 to match the paper's setting.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Changed the default blur sigma value for upsampling training from 0.6 to match the paper's setting."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Update related to skip connection scaling factor",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Skip connection scaling factor introduced, inspired by imagen's unets, with citation to the original paper.",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Bug fixes for text conditioning update",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Bug fixes for text conditioning update"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Allow for setting beta schedules of unets differently in the decoder",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "What was used in the paper was cosine, cosine, linear",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model"
            },
            {
                "Compatibility": "Allow for setting beta schedules of unets differently in the decoder"
            }
        ]
    },
    {
        "message_summary": "VideoComposer: Compositional Video Synthesis with Motion Controllability (#431)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "VideoComposer: Compositional Video Synthesis with Motion Controllability",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:VideoComposer: Compositional Video Synthesis with Motion Controllability"
            },
            {
                "Deprecation and Replacement": "Replacement of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Fix typos",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix typos"
            }
        ]
    },
    {
        "message_summary": "Improve error handling and API error codes",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Improve image download validation and resource management",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Improve image download validation and resource management"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Update clip_utils.py",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Custom open_clip models were updated to use open_clip base tokenizer instead of clip.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Fp16 clip update (#331)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Update fp16 model and add tests",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Update fp16 model and add tests"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "change downloading path for clip",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Change downloading path for clip"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Separate clip and open_clip load",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Separate clip and open_clip load"
            }
        ]
    },
    {
        "message_summary": "Separate clip and open_clip load",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Separate clip and open_clip load"
            }
        ]
    },
    {
        "message_summary": "add generic clip model tests",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Addition of generic clip model tests"
            }
        ]
    },
    {
        "message_summary": "only load visual in clip",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Involves adapting pre-trained models to function optimally with newer systems or software versions, ensuring forward compatibility."
            }
        ]
    },
    {
        "message_summary": "only load visual in clip",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Involves adapting pre-trained models to function optimally with newer systems or software versions, ensuring forward compatibility."
            }
        ]
    },
    {
        "message_summary": "add unit test for multilingual clip",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Check HTTP status for remote image paths",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Check HTTP status for remote image paths"
            }
        ]
    },
    {
        "message_summary": "using clip model from open_clip",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "using clip model from open_clip"
            }
        ]
    },
    {
        "message_summary": "split the image load to be used elsewhere",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "split the image load to be used elsewhere"
            }
        ]
    },
    {
        "message_summary": "Fix word pubicly -> publicly",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Commit log is related to fixing a word in the codebase."
            }
        ]
    },
    {
        "message_summary": "feat: add option for visualizing cuts",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": "Commit log is related to adding features or functions with specific tasks in mind."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "feat: add name var substitute",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Task Specificity": "Dedicated to developing and deploying task-specific enhancements or capabilities that exploit the unique strengths of pre-trained models."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "feat: 0.8 add prompt scheduling",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of prompt scheduling feature"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "feat: allow customized remote url for diff models",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Allow customized remote URL for different models"
            }
        ]
    },
    {
        "message_summary": "feat: output gif for intermediate results (#76)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "Output gif for intermediate results"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "feat: move text transformer to cpu",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Move text transformer to CPU"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "feat: allow customize default files",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Allow customization of default files"
            }
        ]
    },
    {
        "message_summary": "feat: add complete tag (#26)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "feat: add comics diffusion model",
        "ptm_name": "comics diffusion model",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a new pre-trained model: comics diffusion model"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "feat: ipython deps is optional fix cpu support",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Optional ipython dependencies added for enhanced functionality.",
                "Compatibility": "Fixed CPU support for improved performance."
            }
        ]
    },
    {
        "message_summary": "feat: ipython deps is optional fix cpu support",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Optional ipython dependencies added for enhanced functionality."
            },
            {
                "Compatibility": "Fixed CPU support to ensure compatibility with a wider range of systems."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "feat: add open clip pretrained models",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a new pre-trained model"
            }
        ]
    },
    {
        "message_summary": "feat: add open clip pretrained models",
        "ptm_name": "OpenAI Open Clip",
        "ptm_version": "latest",
        "ptm_problem_addressed": "Addition of pretrained models for Open Clip",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of new pre-trained models"
            },
            {
                "Task Specificity": "Addition of pretrained models for Open Clip"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of OpenAI Open Clip pretrained models"
            }
        ]
    },
    {
        "message_summary": "feat: add clip model selector",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a new integration pattern."
            }
        ]
    },
    {
        "message_summary": "feat: add clip model selector",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a new integration pattern"
            }
        ]
    },
    {
        "message_summary": "feat: add clip model selector",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a new integration pattern"
            }
        ]
    },
    {
        "message_summary": "feat: add clip model selector",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a new integration pattern"
            }
        ]
    },
    {
        "message_summary": "Add VP test in Stable diffusion pipeline",
        "ptm_name": "openai clip",
        "ptm_version": "latest",
        "ptm_problem_addressed": "Visual Parity Testing",
        "update_details": "Visual Parity test based on openai clip model was added. Trigger rules were also included to check generated images and reduce unnecessary triggers.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "Update checkpoint to general_v0.1",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Add AnyDoor support",
        "ptm_name": "AnyDoor",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Added support for AnyDoor, included Dinov2, fixed bugs, converted RGB, updated AnyDoor pipeline, and added documentation.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Add AnyDoor support"
            }
        ]
    },
    {
        "message_summary": "Remove hardcoded path in rices.py",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Removal of a Pre Trained model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "added rices for captioning and vqa",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "added rices for captioning and vqa"
            }
        ]
    },
    {
        "message_summary": "change state dict comparison to ref compare",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "change state dict comparison to ref compare"
            }
        ]
    },
    {
        "message_summary": "send weights to target device instead of CPU memory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "send weights to target device instead of CPU memory"
            }
        ]
    },
    {
        "message_summary": "Use less RAM when creating models",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Use less RAM when creating models"
            }
        ]
    },
    {
        "message_summary": "make it possible to load SD1 checkpoints without CLIP",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "make it possible to load SD1 checkpoints without CLIP"
            }
        ]
    },
    {
        "message_summary": "fix missing field for aesthetic embedding extension",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "fix missing field for aesthetic embedding extension"
            }
        ]
    },
    {
        "message_summary": "Fix for an error caused by skipping initialization",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix for an error caused by skipping initialization"
            }
        ]
    },
    {
        "message_summary": "Add support for transformers==4.25.1 and fallback for quick model creation failure",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Add support for transformers==4.25.1"
            },
            {
                "Unrelated": "fallback for quick model creation failure"
            }
        ]
    },
    {
        "message_summary": "Add more stuff to ignore when creating model from config. Prevent .vae.safetensors files from being listed as stable diffusion models",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add more stuff to ignore when creating model from config."
            },
            {
                "Compliance and Standards": "Prevent .vae.safetensors files from being listed as stable diffusion models."
            }
        ]
    },
    {
        "message_summary": "Disable torch weight initialization and CLIP downloading/reading checkpoint to speed up creating sd model from config",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Disable torch weight initialization and CLIP downloading/reading checkpoint to speed up creating sd model from config"
            }
        ]
    },
    {
        "message_summary": "add video2video",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Fixed bugs in pre-commit, updated some files, fixed video write module, and fixed max_frames",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fixed bugs in pre-commit, updated some files, fixed video write module, and fixed max_frames"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Add Support for Specifying Custom `cache_dir` (#245)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Addresses the adaptation of pre-trained models to function optimally with newer systems or software versions, ensuring forward compatibility."
            }
        ]
    },
    {
        "message_summary": "Added new eval script that samples from query set",
        "ptm_name": "Not specified",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Added new eval script that samples from query set"
            }
        ]
    },
    {
        "message_summary": "Replaced HF clip with open_clip",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "HF clip replaced with open_clip",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "HF clip replaced with open_clip"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Reintroduce documentation and GitHub workflow changes",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Reintroduce documentation and GitHub workflow changes"
            }
        ]
    },
    {
        "message_summary": "Revert \"General cleaning up of the repo for Monday's release (#102)\" (#104)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "Removal of a Pre Trained model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "support more eleuther models out of the box",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "support more eleuther models out of the box"
            }
        ]
    },
    {
        "message_summary": "Add Hugging Face Language Model",
        "ptm_name": "Hugging Face LM",
        "ptm_version": "any",
        "ptm_problem_addressed": "Tested for GPT-Neo, OPT",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a Hugging Face Language Model"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "perceiver flag, enforce consistent notation for shapes",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Enforce consistent notation for shapes"
            }
        ]
    },
    {
        "message_summary": "Codebase restructured and interleaved format added",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Codebase restructured"
            }
        ]
    },
    {
        "message_summary": "[TinyCLIP] Inference Example (#196)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "Removal of a Pre Trained model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Refactor stream_generate and multi-turn demo",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Refactor stream_generate and multi-turn demo"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Refactor data configs to configs/data; add llama adapter",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Refactor data configs to configs/data"
            },
            {
                "Integration Patterns": "add llama adapter"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Added Stable Diffusion (SD) benchmark",
        "ptm_name": "Stable Diffusion (SD) benchmark",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Added Stable Diffusion (SD) benchmark"
            }
        ]
    },
    {
        "message_summary": "Rename timm models in tests",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Rename timm models in tests"
            }
        ]
    },
    {
        "message_summary": "Add xxlarge convnext and fix timm import for current pre-release of timm",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a new pre-trained model"
            },
            {
                "Maintenance": "Fixing import issues for current pre-release of timm"
            }
        ]
    },
    {
        "message_summary": "Rename ViT-G to ViT-bigG",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Rename ViT-G to ViT-bigG"
            }
        ]
    },
    {
        "message_summary": "create HF models without pretrained weights",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "HF model inference tests on random models",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "inference testing using pre-generated data",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "inference testing using pre-generated data"
            }
        ]
    },
    {
        "message_summary": "additional loss print unweighted value",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "additional loss print unweighted value"
            }
        ]
    },
    {
        "message_summary": "Cover jit and force_custom_text in simple tests",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Cover jit and force_custom_text in simple tests"
            }
        ]
    },
    {
        "message_summary": "Implement simple training test.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Fetch from Hugging Face Hub using hf_hub: prefix",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Fetch from Hugging Face Hub using hf_hub: prefix"
            }
        ]
    },
    {
        "message_summary": "Add checksum verification for pretrained model weights downloaded from mlfoundations github releases url",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add checksum verification for pretrained model weights downloaded from mlfoundations github releases url"
            }
        ]
    },
    {
        "message_summary": "Added Stable Diffusion (SD) benchmark - Part 2 (#661)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Added Stable Diffusion (SD) benchmark - Part 2"
            }
        ]
    },
    {
        "message_summary": "Added Stable Diffusion (SD) benchmark",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Added Stable Diffusion (SD) benchmark"
            }
        ]
    },
    {
        "message_summary": "Fix SPHINX inference memory with image input",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Fix embedding precision with image to save memory. Gradio version pinned.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Fix SPHINX inference memory with image input"
            },
            {
                "Performance Improvements": "Fix embedding precision with image to save memory"
            }
        ]
    },
    {
        "message_summary": "Fix sphinx sphinx-1k sphinx-2k quant",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Fix sphinx sphinx-1k sphinx-2k quant"
            }
        ]
    },
    {
        "message_summary": "provide blip config in Accessory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Integration of new pre-trained models into existing systems"
            }
        ]
    },
    {
        "message_summary": "Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "llama ens 10 ens5p2 pose demo",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            },
            {
                "Integration Patterns": "Replacement of a Pre Trained Model:"
            },
            {
                "Integration Patterns": "Removal of a Pre Trained model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Update llama_ens default to 13B",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "sort data list during dataset init for efficiency",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "sort data list during dataset init for efficiency"
            }
        ]
    },
    {
        "message_summary": "Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Fix text_to_video_synthesis_model device",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix text_to_video_synthesis_model device"
            }
        ]
    },
    {
        "message_summary": "VideoComposer: Compositional Video Synthesis with Motion Controllability (#431)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "VideoComposer model for Compositional Video Synthesis with Motion Controllability was added. Videocomposer pipeline was implemented. Pre-commit changes were made. Xformers were deleted.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Pre-commit changes were made."
            },
            {
                "Deprecation and Replacement": "Xformers were deleted."
            }
        ]
    },
    {
        "message_summary": "Add parameters height and width for text-to-video",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "add text-to-video-synthesis",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Fix SPHINX inference memory with image input",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Fix embedding precision with image to save memory. Gradio version pinned.",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Commit log is related to fixing SPHINX inference memory with image input."
            },
            {
                "Performance Improvements": "Commit log is related to fixing embedding precision with image to save memory."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "provide blip config in Accessory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Integration of new pre-trained models into existing systems."
            }
        ]
    },
    {
        "message_summary": "Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "Removal of a Pre Trained model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "llama ens 10 ens5p2 pose demo",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            },
            {
                "Deprecation and Replacement": "Replacement of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Rename DynamicBufferModule to DynamicBufferMixin",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Add unit tests for DynamicBufferMixin. Add logs to the changelog. Add minor changes to the comments",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Replacement of a Pre Trained Model:": {}
            },
            {
                "Update of a Pre Trained Model:": {}
            },
            {
                "Maintenance": {}
            }
        ]
    },
    {
        "message_summary": "Fix SPHINX inference memory with image input",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Fix embedding precision with image to save memory. Gradio version pinned.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Fix SPHINX inference memory with image input"
            },
            {
                "Maintenance": "Fix embedding precision with image to save memory. Gradio version pinned."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "provide blip config in Accessory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "blip config in Accessory"
            }
        ]
    },
    {
        "message_summary": "Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "llama ens 10 ens5p2 pose demo",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            },
            {
                "Task Specificity": "Replacement of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "additional loss print unweighted value",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "additional loss print unweighted value"
            }
        ]
    },
    {
        "message_summary": "provide blip config in Accessory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Integration of new pre-trained models into existing systems"
            }
        ]
    },
    {
        "message_summary": "Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "llama ens 10 ens5p2 pose demo",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            },
            {
                "Deprecation and Replacement": "Replacement of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "Removal of a Pre Trained model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "align llama_adapter to original repo, support padded resize",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "align llama_adapter to original repo"
            },
            {
                "Performance Improvements": "support padded resize"
            }
        ]
    },
    {
        "message_summary": "llama adpater v2 align with original",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "llama adpater v2 align with original"
            }
        ]
    },
    {
        "message_summary": "Update forward definition syntax to match llama_peft.py",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Syntax update for easier comparison with llama_peft.py",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Syntax update for easier comparison with llama_peft.py"
            }
        ]
    },
    {
        "message_summary": "llama_config nargs bug fix, llama_adapter refactor",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Bug fix and code refactoring"
            }
        ]
    },
    {
        "message_summary": "Add lora & bias support",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of new integration patterns"
            }
        ]
    },
    {
        "message_summary": "Add llama adapter",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Add llama adapter"
            }
        ]
    },
    {
        "message_summary": "additional loss print unweighted value",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "additional loss print unweighted value"
            }
        ]
    },
    {
        "message_summary": "provide blip config in Accessory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Integration of new pre-trained models into existing systems"
            }
        ]
    },
    {
        "message_summary": "Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "default to printing best candidate",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "default to printing best candidate"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Add i2vgen and t2v code and model",
        "ptm_name": "i2vgen, t2v",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of new integration patterns"
            }
        ]
    },
    {
        "message_summary": "follow_anything stop once it finishes reading offline video",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Code for detect, track, and follow + code for creating query features using DINO",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Code for detect, track, and follow + code for creating query features using DINO"
            }
        ]
    },
    {
        "message_summary": "additional loss print unweighted value",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "additional loss print unweighted value"
            }
        ]
    },
    {
        "message_summary": "Additional loss print unweighted value",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Additional loss print unweighted value"
            }
        ]
    },
    {
        "message_summary": "Redo imports from diffusers to satisfy Pylance",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Redo imports from diffusers to satisfy Pylance"
            }
        ]
    },
    {
        "message_summary": "Purge rich.progress and replace it with tqdm, queue progress added",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Purge rich.progress and replace it with tqdm, queue progress added"
            }
        ]
    },
    {
        "message_summary": "None",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Release codebase & Update README",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Release codebase & Update README"
            }
        ]
    },
    {
        "message_summary": "Relicense sd-webui-text2video under AGPL v3.0",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compliance and Standards": "Relicensing under AGPL v3.0"
            }
        ]
    },
    {
        "message_summary": "Fixes 3rd reported exception related to missing opts.use_old_emphasis_implementation in clip_hardcode",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Fixes 3rd reported exception related to missing opts.use_old_emphasis_implementation in clip_hardcode"
            }
        ]
    },
    {
        "message_summary": "generate features for Objaverse data",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "generate features for Objaverse data"
            }
        ]
    },
    {
        "message_summary": "TAO 5.2 Release - PyTorch",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            },
            {
                "Deprecation and Replacement": "Replacement of a Pre Trained Model:"
            },
            {
                "Deprecation and Replacement": "Removal of a Pre Trained model:"
            }
        ]
    },
    {
        "message_summary": "TAO 5.2 Release - PyTorch",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            },
            {
                "Deprecation and Replacement": "Replacement of a Pre Trained Model:"
            },
            {
                "Deprecation and Replacement": "Removal of a Pre Trained model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "load HPSv2 with the correct precision",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Match clip and fid score calculation",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Compatibility": "Update of a Pre Trained Model:None"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "The first version of the code and model",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "The first version of the code and model"
            }
        ]
    },
    {
        "message_summary": "This is the 1st commit",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "The first version of the code and model",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "The first version of the code and model"
            }
        ]
    },
    {
        "message_summary": "initial release. Sorry for the delay and potential missing bits, please see the important note in readme.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "initial release. Sorry for the delay and potential missing bits, please see the important note in readme."
            }
        ]
    },
    {
        "message_summary": "Complete the auxiliary clip contrastive loss",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Complete the auxiliary clip contrastive loss"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "clean solution to reconstruction loss from any fmap resolution in the discriminator",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "clean solution to reconstruction loss from any fmap resolution in the discriminator"
            }
        ]
    },
    {
        "message_summary": "make some headway into vision-aided gan loss",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "No significant Pre-Trained Models activities mentioned."
            }
        ]
    },
    {
        "message_summary": "#51 update package and copyright info",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Support for many different caption models",
        "ptm_name": "blip-base, blip-large, blip2-2.7b, blip2-flan-t5-xl, git-large-coco",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Support for many different caption models"
            }
        ]
    },
    {
        "message_summary": "Expose LabelTable and load_list and give example in README how they can be used to rank your own list of terms.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Expose LabelTable and load_list in clip_interrogator.py",
                "Task Specificity": "Provide example in README on how to use LabelTable and load_list to rank a list of terms"
            }
        ]
    },
    {
        "message_summary": "Move definition of clip_model_name",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move definition of clip_model_name"
            }
        ]
    },
    {
        "message_summary": "Minor fix to BLIP offloading",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Minor fix to BLIP offloading"
            }
        ]
    },
    {
        "message_summary": "More safetensor, download, and VRAM improvements",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "More safetensor, download, and VRAM improvements"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Bunch of updates! (#40)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Auto download the cache files from Hugging Face, experimental negative prompt mode, slight quality and performance improvement to best mode, analyze tab in Colab, and run_gradio to get a table of ranked terms",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Auto download the cache files from Hugging Face"
            },
            {
                "Task Specificity": "Experimental negative prompt mode, slight quality and performance improvement to best mode, analyze tab in Colab, and run_gradio to get a table of ranked terms"
            }
        ]
    },
    {
        "message_summary": "Make the BLIP model configurable, can set config.blip_model_type now to 'base' or 'large'",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "The commit allows for the configuration of the BLIP model type to be set to either 'base' or 'large'."
            }
        ]
    },
    {
        "message_summary": "Update to nicer BLIP packaging",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update to nicer BLIP packaging"
            }
        ]
    },
    {
        "message_summary": "Fix for running on CPU",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix for running on CPU"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Handle exception trying to load cached table",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Handle exception trying to load cached table"
            }
        ]
    },
    {
        "message_summary": "Default to ViT-L, lower intermediate count for Colab with ViT-H",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Default to ViT-L, lower intermediate count for Colab with ViT-H"
            }
        ]
    },
    {
        "message_summary": "Ability to swap CLIP models (takes about 5s for ViTL and 10s for ViTH), update Replicate cog",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Ability to swap CLIP models (takes about 5s for ViTL and 10s for ViTH)"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Handle differences in how open_clip does prompt truncation, run_gradio support for all the open_clip models and --share option.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Addresses the adaptation of pre-trained models to function optimally with newer systems or software versions, ensuring forward compatibility."
            }
        ]
    },
    {
        "message_summary": "Shuffle BLIP back to system RAM to help with 16GB Colab",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Shuffle BLIP back to system RAM to help with 16GB Colab"
            }
        ]
    },
    {
        "message_summary": "First test version with OpenCLIP and ViTH!",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Update notebook batch processing with option to rename files so can be used with [filewords] in Dreambooth!",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "New `quiet` config option added so CLIP Interrogator doesn't print and tqdm. Added `max_flavors` option to each interrogate method.",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Update notebook batch processing with option to rename files for use with [filewords] in Dreambooth."
            },
            {
                "Maintenance": "New `quiet` config option added to prevent printing and tqdm in CLIP Interrogator. Added `max_flavors` option to each interrogate method."
            }
        ]
    },
    {
        "message_summary": "Gradio version plus classic and fast modes",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Split in one file per model.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Split in one file per model."
            }
        ]
    },
    {
        "message_summary": "highlight updates, fix typo, add regularization images",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "highlight updates, fix typo, add regularization images"
            }
        ]
    },
    {
        "message_summary": "[feats] release basic code for AnyObject3D",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Release of basic code for AnyObject3D"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Style fix (#35)"
            }
        ]
    },
    {
        "message_summary": "Update paths+configs to nerfstudio 1.0 version",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Update paths+configs to nerfstudio 1.0 version"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "code for using new viewer with custom ViewerText",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Move `reproduce` to `examples` root",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move `reproduce` to `examples` root"
            }
        ]
    },
    {
        "message_summary": "V0.6 Txt batch function added",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Added a text batch function"
            }
        ]
    },
    {
        "message_summary": "add sem seg evaluation script on replica",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Addition of a new script for semantic segmentation evaluation on a replica system."
            }
        ]
    },
    {
        "message_summary": "replace customized config class w/ dataclass",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Technical Debt and Simplification": "Replacement of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "No significant Pre-Trained Models activities mentioned."
            }
        ]
    },
    {
        "message_summary": "added yolo world detection option",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "added yolo world detection option"
            }
        ]
    },
    {
        "message_summary": "Change outdated tag2text stuff to RAM stuff",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Technical Debt and Simplification": "Change outdated tag2text stuff to RAM stuff"
            }
        ]
    },
    {
        "message_summary": "replace customized config class w/ dataclass",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Replacement of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Add a function that can accept OpenAI's Open Clip, a list of prompts as strings, and return the C covariance matrix.",
        "ptm_name": "OpenAI Open Clip",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a function to accept OpenAI's Open Clip and prompts to return the C covariance matrix."
            }
        ]
    },
    {
        "message_summary": "pass typecheck/importcheck hundreds more changes to nuwa",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "pass typecheck/importcheck hundreds more changes to nuwa"
            }
        ]
    },
    {
        "message_summary": "add dragnuwa, add motion vector editor to front end and back end, numerous changes",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "add dragnuwa, add motion vector editor to front end and back end, numerous changes"
            }
        ]
    },
    {
        "message_summary": "add ccsr, fix hotshot motion attn",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "add ccsr"
            },
            {
                "Maintenance": "fix hotshot motion attn"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "added vision to all models",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "added vision to all models"
            }
        ]
    },
    {
        "message_summary": "Add min/max CLIP length, don't adjust image size unless we tell it to",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add min/max CLIP length, don't adjust image size unless we tell it to"
            }
        ]
    },
    {
        "message_summary": "Super Update",
        "ptm_name": "CLIP v2.1 interrogator",
        "ptm_version": "2.1",
        "ptm_problem_addressed": "Image and text processing",
        "update_details": "Add WD14 tagger. Allow filtering wd14, booru tags by score. Add don't rename option. Update ReallySafe. Bump BLIP version. Completely overhaul smartprocess.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "update sd-webui version to torch2.0 and add extension support",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "update sd-webui version to torch2.0 and add extension support"
            }
        ]
    },
    {
        "message_summary": "Update sd-webui version to torch2.0 and add extension support",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Update sd-webui version to torch2.0 and add extension support"
            }
        ]
    },
    {
        "message_summary": "Modify retrieval evaluation information to improve readibility",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "make it possible to load SD1 checkpoints without CLIP",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "make it possible to load SD1 checkpoints without CLIP"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Fix for an error caused by skipping initialization",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Fixed TypeError: expected str, bytes or os.PathLike object, not NoneType",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix for an error caused by skipping initialization"
            },
            {
                "Maintenance": "Fixed TypeError: expected str, bytes or os.PathLike object, not NoneType"
            }
        ]
    },
    {
        "message_summary": "Add support for transformers==4.25.1",
        "ptm_name": "transformers",
        "ptm_version": "4.25.1",
        "ptm_problem_addressed": "Fallback for quick model creation failure",
        "update_details": "Fallback mechanism added for cases where quick model creation fails",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a new pre-trained model"
            },
            {
                "Maintenance": "Update of a Pre Trained Model:Fallback mechanism added for cases where quick model creation fails"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "disable torch weight initialization and CLIP downloading/reading checkpoint to speedup creating sd model from config",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "disable torch weight initialization and CLIP downloading/reading checkpoint to speedup creating sd model from config"
            }
        ]
    },
    {
        "message_summary": "make HF shut up when loading CLIP subsections",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "make HF shut up when loading CLIP subsections"
            }
        ]
    },
    {
        "message_summary": "None",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "more refactoring, loads now but HF dataset eats itself",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Refactoring"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Merge the clip model code from leptonai/lepton to the current repository.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Merge the clip model code from leptonai/lepton to the current repository."
            }
        ]
    },
    {
        "message_summary": "add clip as an example",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "addition to the repository"
            }
        ]
    }
]