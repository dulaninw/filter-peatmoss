[
    {
        "message_summary": "Rough outline of a semgrex interface demo program",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Rough outline of a semgrex interface demo program"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Rename stanza.resource to stanza.resources; rename resources.py to common.py",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Rename stanza.resource to stanza.resources; rename resources.py to common.py"
            }
        ]
    },
    {
        "message_summary": "Move all resources related scripts to stanza/resource",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move all resources related scripts to stanza/resource"
            }
        ]
    },
    {
        "message_summary": "N/A",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Revert temporary fix for download logic",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Revert temporary fix for download logic"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix download logic"
            },
            {
                "Unrelated": "Fix help message in demo script"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Quick fix for demo script"
            }
        ]
    },
    {
        "message_summary": "Separate the classes for Tokens and syntactic Words",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Separate the classes for Tokens and syntactic Words"
            }
        ]
    },
    {
        "message_summary": "Undo changes to use_gpu argument",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Undo changes to use_gpu argument"
            }
        ]
    },
    {
        "message_summary": "Modify the way devices are specified in pipeline",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Swap French demo input with one that has MWT in the first sentence",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "Commit log is related to adding features or functions with specific tasks in mind."
            }
        ]
    },
    {
        "message_summary": "Accommodate Vietnamese in the pipeline tokenizer processor; Add a Vietnamese example to demo script",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "Demo script goes multi-lingual",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Default overwrite confirmation behavior changed in the demo script",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Default overwrite confirmation behavior changed in the demo script"
            }
        ]
    },
    {
        "message_summary": "Change demo to match logic of new download function: existence of models is checked in download() now; Add easy toggle for other demo languages",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Modernizing the demo script; make the download interface more user-friendly",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Modernizing the demo script; make the download interface more user-friendly"
            }
        ]
    },
    {
        "message_summary": "update and simplify basic demo",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Technical Debt and Simplification": {},
                "Maintenance": {}
            }
        ]
    },
    {
        "message_summary": "Add a flag to semgrex to read patterns from a file instead of command line",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Add a flag to semgrex to read patterns from a file instead of command line"
            }
        ]
    },
    {
        "message_summary": "Make echoing the input an option, not the default, in the Semgrex command line tool",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Make echoing the input an option, not the default, in the Semgrex command line tool"
            }
        ]
    },
    {
        "message_summary": "Instead of dumping out a completely inscrutable semgrex result, add comments to the doc to explain where the sentences matched",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Add flags to semgrex.py to load a conllu file and execute the semgrex on it, possibly changing the semgrex used. Add a sample file for demoing the semgrex",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Add flags to semgrex.py to load a conllu file and execute the semgrex on it, possibly changing the semgrex used."
            },
            {
                "Maintenance": "Add a sample file for demoing the semgrex"
            }
        ]
    },
    {
        "message_summary": "Add a bit of documentation to the process method of a semgrex context",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add a bit of documentation to the process method of a semgrex context"
            }
        ]
    },
    {
        "message_summary": "Update an incorrect doc in the semgrex context manager",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update an incorrect doc in the semgrex context manager"
            }
        ]
    },
    {
        "message_summary": "Add a context which connects to the multi-request semgrex",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Separate out some common functions from the semgrex interface",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Separation of common functions from the semgrex interface"
            }
        ]
    },
    {
        "message_summary": "Update the sample to something which triggers obj in the current models",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "Dedicated to developing and deploying task-specific enhancements or capabilities that exploit the unique strengths of pre-trained models."
            }
        ]
    },
    {
        "message_summary": "Add doc to the semgrex module",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add doc to the semgrex module"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Update the semgrex tool to send across lemma, ner, tag & cpos as well",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Python interface to the semgrex processor",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Python interface to the semgrex processor"
            }
        ]
    },
    {
        "message_summary": "Add a tiny bit of doc to the resplit_mwt util",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add a tiny bit of doc to the resplit_mwt util"
            }
        ]
    },
    {
        "message_summary": "Add a bit more doc",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add a bit more doc"
            }
        ]
    },
    {
        "message_summary": "Add a utility function to resplit raw tokens into MWT using a tokenize/mwt Pipeline.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": {
                    "description": "A utility function has been added to resplit raw tokens into MWT using a tokenize/mwt Pipeline."
                },
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "Removal of a Pre Trained model"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Temporary use of $CLASSPATH for a feature not yet released"
            }
        ]
    },
    {
        "message_summary": "Tool that connects to the Java UD enhancer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Tool that connects to the Java UD enhancer"
            }
        ]
    },
    {
        "message_summary": "Count all words, not just tokens",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Count all words, not just tokens"
            }
        ]
    },
    {
        "message_summary": "Add a test for matching an NER trait and add a link to the tokensregex doc",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "Add a test for matching an NER trait and add a link to the tokensregex doc"
            }
        ]
    },
    {
        "message_summary": "Add an interface between stanza docs and corenlp tokensregex",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of an interface between stanza docs and corenlp tokensregex"
            }
        ]
    },
    {
        "message_summary": "Update demo code to include constituency parsing",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "Replacement of a Pre Trained Model"
            }
        ]
    },
    {
        "message_summary": "Add some debug logging when building a retag_pipeline - goal is to make sure it's calling the correct POS model",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add some debug logging when building a retag_pipeline - goal is to make sure it's calling the correct POS model"
            }
        ]
    },
    {
        "message_summary": "Add an option to turn off saving the optimizer when saving each constituency model",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add an option to turn off saving the optimizer when saving each constituency model"
            }
        ]
    },
    {
        "message_summary": "Remove unnecessary repetition of existing save_each argument",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Remove unnecessary repetition of existing save_each argument"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "No significant Pre-Trained Models activities mentioned."
            }
        ]
    },
    {
        "message_summary": "Integrate peft with the constituency parser.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Add a test that the two-stage peft is correctly turning off fine-tuning for the second half of training",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Involves integrating new pre-trained models into existing systems, focusing on seamless incorporation and initial feature enhancement for these models."
            }
        ]
    },
    {
        "message_summary": "Add oracle_level as a parameter to the save name",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Add a flag to not check the transitions or constituents in the dev set",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Add a bit to the name expansion for when to begin finetuning a transformer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a bit to the name expansion for when to begin finetuning a transformer"
            }
        ]
    },
    {
        "message_summary": "Use the fancy new savename constructions in the run_constituency script",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Use the fancy new savename constructions in the run_constituency script"
            }
        ]
    },
    {
        "message_summary": "Comments on an experiment which didn't work out for mixing bert layers",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Comments on an experiment which didn't work out for mixing bert layers"
            }
        ]
    },
    {
        "message_summary": "Add a log of the tensor sizes",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add a log of the tensor sizes"
            }
        ]
    },
    {
        "message_summary": "Add the constituency parser arguments to the run_constituency script, similar to what is done for the lemmatizer & charlm",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Model names were being created with blank spaces in them :/",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Model names were being created with blank spaces in them :/"
            }
        ]
    },
    {
        "message_summary": "Update con learning rates using a reduce-on-plateau scheme instead of the warmup",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Update con learning rates using a reduce-on-plateau scheme instead of the warmup"
            }
        ]
    },
    {
        "message_summary": "Add a parameter which attempts to download a saved model for further processing",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Add a --tokenized_dir argument to the conparser and ensemble scripts which tokenizes all of the text files in a directory in one invocation.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Integration Patterns": "Add a --tokenized_dir argument to the conparser and ensemble scripts which tokenizes all of the text files in a directory in one invocation."
            }
        ]
    },
    {
        "message_summary": "Add notes on an experiment that did nothing in the conparser",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add notes on an experiment that did nothing in the conparser"
            }
        ]
    },
    {
        "message_summary": "Add a long description of some experiments with low LR for bert and adamw as the second stage optimizer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Experiments with low learning rate for BERT and AdamW as the second stage optimizer"
            }
        ]
    },
    {
        "message_summary": "Fix a comment on the experimental differences",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix a comment on the experimental differences"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Start passing around device instead of use_cuda",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "All models now work via the pipeline. Need to double check that they work everywhere",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Start passing around device instead of use_cuda"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Add a reference to more info on nonlinearity",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Add a reference to more info on nonlinearity"
            }
        ]
    },
    {
        "message_summary": "Add a maxout linear such as in\n\nhttps://arxiv.org/pdf/1302.4389v4.pdf\n\n.get() the arg to keep old models alive\n\nIncludes some comments on accuracy with maxout",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Integration of a maxout linear function based on the paper referenced in the commit message to enhance the existing model's performance."
            }
        ]
    },
    {
        "message_summary": "Add large_margin as an option for the loss.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Added a note on a large margin experiment with no improvement",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to adding a new option for the loss function."
            }
        ]
    },
    {
        "message_summary": "Add a focal loss option using an external library",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Focal loss option was added using an external library. However, it was noted that this addition did not improve results.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a focal loss option using an external library."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "No significant Pre-Trained Models activities mentioned."
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Add an --oracle_level flag which optionally restricts which level to use for the oracle",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Addresses the adaptation of pre-trained models to function optimally with newer systems or software versions, ensuring forward compatibility."
            }
        ]
    },
    {
        "message_summary": "Refactor adjusting the prediction string format",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Refactor adjusting the prediction string format"
            }
        ]
    },
    {
        "message_summary": "Add an option to not delete duplicate trees.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Relevant in the case of Vietnamese trees including multiple copies of quad, for example",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Add nonlinearity experiments numbers",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Update numbers for the tests on nonlinearity. The numbers for the optimizers will follow later.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Add nonlinearity experiments numbers"
            },
            {
                "Maintenance": "Update numbers for the tests on nonlinearity. The numbers for the optimizers will follow later."
            }
        ]
    },
    {
        "message_summary": "Add a format specifier which includes the index for the Vietnamese bakeoff",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Add an argument for partitioning / not partitioning lattn",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Add an argument for partitioning / not partitioning lattn"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Rough draft of using silver trees.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Add functionality to turn a tokenized text file into a file of parse trees",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Refactor the retagging args & pipeline creation into a separate modeule",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Refactor the retagging args & pipeline creation into a separate module"
            }
        ]
    },
    {
        "message_summary": "Add a --predict_format option which will allow the user to specify how to write trees when outputting the model predictions",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a --predict_format option for specifying tree output format"
            }
        ]
    },
    {
        "message_summary": "By default, turn off pattn & lattn (at least until we figure out how to extract value from them)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Turn off pattn & lattn by default until value extraction is figured out"
            }
        ]
    },
    {
        "message_summary": "Add a flag to control the learning rate in the adadelta portion of --multistage",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Add a flag to control the learning rate in the adadelta portion of --multistage"
            }
        ]
    },
    {
        "message_summary": "Add learning_ in front of momentum and weight_decay to make it clear those parameters are for the optimizer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to code maintenance and clarity improvement."
            }
        ]
    },
    {
        "message_summary": "Add an option to choose an exact model path for retagging in the conparser",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Add an option to choose an exact model path for retagging in the conparser"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Don't double save_dir if the user gives save_dir as part of the model filename",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Grad clipping in the constituency parser.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Not a clear benefit yet, so just leaving this as an option.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Grad clipping in the constituency parser."
            },
            {
                "Deprecation and Replacement": "Not a clear benefit yet, so just leaving this as an option."
            }
        ]
    },
    {
        "message_summary": "Notes on a couple updates to defaults",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Notes on a couple updates to defaults"
            }
        ]
    },
    {
        "message_summary": "None",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Make momentum an argument for the optimizer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Make momentum an argument for the optimizer"
            }
        ]
    },
    {
        "message_summary": "Add a brief comment on beta2",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Add a brief comment on beta2"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Add a projection to a smaller dimension to the lattn inputs",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Add a projection to a smaller dimension to the lattn inputs"
            }
        ]
    },
    {
        "message_summary": "A couple notes on other options in the conparser training",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "A couple notes on other options in the conparser training"
            }
        ]
    },
    {
        "message_summary": "Making combining the input the default for the lattn layer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Making combining the input the default for the lattn layer"
            }
        ]
    },
    {
        "message_summary": "None",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Save all conparser models if a particular command line option is set",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Save all conparser models if a particular command line option is set"
            }
        ]
    },
    {
        "message_summary": "Adding an LR warmup to the optimizer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Save & load scheduler as part of the trainer files",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Adding an LR warmup to the optimizer"
            },
            {
                "Maintenance": "Update of a Pre Trained Model: Save & load scheduler as part of the trainer files"
            }
        ]
    },
    {
        "message_summary": "Finetune a model to use pattn",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Successfully trains pattn layers, resulting in improved scores compared to adadelta or adamw alone",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Successfully trains pattn layers, resulting in improved scores compared to adadelta or adamw alone"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix broken conparse finetune :/"
            }
        ]
    },
    {
        "message_summary": "Automagically fix xpos being None for the POS tagger used for a conparser retagging",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Automagically fix xpos being None for the POS tagger used for a conparser retagging"
            }
        ]
    },
    {
        "message_summary": "Very simple wandb integration for NER, tokenizer, mwt, lemma, depparse, pos, charlm, classifier, conparse",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Very simple wandb integration for NER, tokenizer, mwt, lemma, depparse, pos, charlm, classifier, conparse"
            }
        ]
    },
    {
        "message_summary": "Add arguments for epsilon and beta2 to initializing an AdamW optimizer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Add arguments for epsilon and beta2 to initializing an AdamW optimizer"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Add some notes on an MLP experiment which didn't work",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Add some notes on an MLP experiment which didn't work"
            }
        ]
    },
    {
        "message_summary": "ATTN method to build larger constituents out of smaller constituents",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "method to build larger constituents out of smaller constituents"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fixed a comment in the code"
            }
        ]
    },
    {
        "message_summary": "Minor changes related to removing optimizers from conparser models",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Minor changes related to removing optimizers from conparser models"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Remove the specialized unary transform",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Add a note on the use of TOP_DOWN_UNARY",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "Remove the specialized unary transform"
            },
            {
                "Compatibility": "Add a note on the use of TOP_DOWN_UNARY"
            }
        ]
    },
    {
        "message_summary": "One last comment on a possible bilstm modification",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "One last comment on a possible bilstm modification"
            }
        ]
    },
    {
        "message_summary": "None",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "Remove an unused option which hurts scores. (Not having this option makes other subsequent changes easier.) Leave a bunch of comments explaining how it hurt the scores",
        "text": [
            {
                "Maintenance": "Remove an unused option which hurts scores. (Not having this option makes other subsequent changes easier.) Leave a bunch of comments explaining how it hurt the scores"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Update of a Pre Trained Model"
            }
        ]
    },
    {
        "message_summary": "Some notes on an adamw hill climb",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            },
            {
                "Deprecation and Replacement": "Replacement of a Pre Trained Model:"
            },
            {
                "Deprecation and Replacement": "Removal of a Pre Trained model:"
            }
        ]
    },
    {
        "message_summary": "Add a regex to output the norms and grads of a subset of weights if requested",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Update notes on failed experiments with a couple results",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update notes on failed experiments with a couple results"
            }
        ]
    },
    {
        "message_summary": "Log norms of matrices in the model when given a flag",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Log norms of matrices in the model when given a flag"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Add a comment and a citation on what label_attention does",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add a comment and a citation on what label_attention does"
            }
        ]
    },
    {
        "message_summary": "Changes to the partitioned transformer for compactness and reusability with bias option",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Partitioned attention separated as a module for reusability. Added an option for bias with a default value of false.",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Changes to the partitioned transformer for compactness and reusability with bias option"
            },
            {
                "Maintenance": "Partitioned attention separated as a module for reusability. Added an option for bias with a default value of false."
            }
        ]
    },
    {
        "message_summary": "Ignore punc as part of the labels",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Ignore punctuation as part of the labels"
            }
        ]
    },
    {
        "message_summary": "Add flags to the convert_amt script to ignore or remap certain labels",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add flags to the convert_amt script to ignore or remap certain labels"
            }
        ]
    },
    {
        "message_summary": "Add a tool to convert from an AMT annotation file to a bio/json NER file for Stanza",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a tool to convert from an AMT annotation file to a bio/json NER file for Stanza"
            }
        ]
    },
    {
        "message_summary": "For archival purposes, add a script which converted Misc to Date (mostly, some hand correcting needed)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "None",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "None",
                "Task Specificity": "None",
                "Community and Collaboration": "None",
                "Maintenance": "None",
                "Compliance and Standards": "None",
                "Performance Improvements": "None",
                "Compatibility": "None",
                "Deprecation and Replacement": "Update of a Pre Trained Model:",
                "Project Evolution": "None",
                "Technical Debt and Simplification": "None"
            }
        ]
    },
    {
        "message_summary": "None",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Myanmar NER processing of a dataset provided by UCSY",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "Dedicated to developing and deploying task-specific enhancements or capabilities that exploit the unique strengths of pre-trained models."
            }
        ]
    },
    {
        "message_summary": "Fix error with default when building HY NER",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix error with default when building HY NER"
            }
        ]
    },
    {
        "message_summary": "Add a flag to not download the Armenian pipeline when producing an Armenian NER dataset.",
        "ptm_name": "Armenian NER pipeline",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Add a flag to not download the Armenian pipeline when producing an Armenian NER dataset."
            }
        ]
    },
    {
        "message_summary": "convert_hy_armtdp was creating an Armenian pipeline on import, which should be turned off",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "Removal of a Pre Trained model:"
            }
        ]
    },
    {
        "message_summary": "Added code for hy_armtdp - Armenian NER dataset",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Added code for hy_armtdp - Armenian NER dataset"
            }
        ]
    },
    {
        "message_summary": "None",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Move get_tqdm() to a separate utils file for easier installation of CoreNLP",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Move TextTooLongError to the bert_embedding module where it is used",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move TextTooLongError to the bert_embedding module where it is used"
            }
        ]
    },
    {
        "message_summary": "Discard Devanagari text from the VI wikipedia",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Discard Devanagari text from the VI wikipedia"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "throw out long JA sentences as well when tokenizing Wikipedia",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "throw out long JA sentences as well when tokenizing Wikipedia"
            }
        ]
    },
    {
        "message_summary": "Specifically exclude one sentence from VI Wikipedia which makes Bert sad",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Exclude one sentence from VI Wikipedia which makes Bert sad"
            }
        ]
    },
    {
        "message_summary": "Refactor the tokenization method from tokenize_wiki.py to add an option to selftrain_vi_quad for tokenizing data without parsing",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Refactor the tokenization method from tokenize_wiki.py to add an option to selftrain_vi_quad for tokenizing data without parsing"
            }
        ]
    },
    {
        "message_summary": "Upgrades to the silver scripts with PTB tree printing and FoundationCache usage",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Upgrades include allowing printing trees in PTB format, skipping large datasets for testing, and utilizing FoundationCache to reduce GPU memory usage",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Upgrades to the silver scripts with PTB tree printing and FoundationCache usage"
            }
        ]
    },
    {
        "message_summary": "Initial version of a script to process some IT datasets",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Initial version of a script to process some IT datasets"
            }
        ]
    },
    {
        "message_summary": "Remove empty documents and empty chunks when building selftrain datasets",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Remove empty documents and empty chunks when building selftrain datasets"
            }
        ]
    },
    {
        "message_summary": "Prototype process single file",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Prototype process single file"
            }
        ]
    },
    {
        "message_summary": "Add Karel's method to reattach heads using the conjunction - here we use CCONJ instead of CC (upos)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Initial version of script to convert OntoNotes from HF using Stanza's depparse",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Initial version of script to convert OntoNotes from HF using Stanza's depparse"
            }
        ]
    },
    {
        "message_summary": "Add a corona text classification dataset",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a corona text classification dataset"
            }
        ]
    },
    {
        "message_summary": "Add some more description in the event of an IndexError",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add some more description in the event of an IndexError"
            }
        ]
    },
    {
        "message_summary": "Extend read_snippets for sentiment datasets to read multiple columns and combine them into a single sentiment value",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Extend read_snippets for sentiment datasets to read multiple columns and combine them into a single sentiment value"
            }
        ]
    },
    {
        "message_summary": "Move SentimentDatum to classifiers/data.py and make the reading code read in SentimentDatum",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move SentimentDatum to classifiers/data.py and make the reading code read in SentimentDatum"
            }
        ]
    },
    {
        "message_summary": "Add a couple tests of the building block methods from the Sentiment conversion tools",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Rename Fragment -> SentimentDatum to make a more understandable name for potential external users",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Rename Fragment -> SentimentDatum to make a more understandable name for potential external users"
            }
        ]
    },
    {
        "message_summary": "Further refactor - put the utility method in the utility methods file",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Refactor - put the utility method in the utility methods file"
            }
        ]
    },
    {
        "message_summary": "Add a processing for the MR l3cube sentiment",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a processing for the MR l3cube sentiment"
            }
        ]
    },
    {
        "message_summary": "Generalize the sentiment csv reading code and move it to process_utils",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Generalize the sentiment csv reading code and move it to process_utils"
            }
        ]
    },
    {
        "message_summary": "Instead of blank items, remove http altogether in the sentiment preprocessing",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Instead of blank items, remove http altogether in the sentiment preprocessing"
            }
        ]
    },
    {
        "message_summary": "Read & write sentiment datasets as json",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Read & write sentiment datasets as json"
            }
        ]
    },
    {
        "message_summary": "Pass around lists of tokens instead of single strings. Will make it easier to switch the input/output to a json format",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Pass around lists of tokens instead of single strings. Will make it easier to switch the input/output to a json format"
            }
        ]
    },
    {
        "message_summary": "Refactor out the PTB retokenization",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Refactor out the PTB retokenization"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Move SentimentDatum to classifiers/data.py and make the reading code read in SentimentDatum",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move SentimentDatum to classifiers/data.py and make the reading code read in SentimentDatum"
            }
        ]
    },
    {
        "message_summary": "Rename Fragment -> SentimentDatum to make a more understandable name for potential external users",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Rename Fragment -> SentimentDatum to make a more understandable name for potential external users"
            }
        ]
    },
    {
        "message_summary": "Switch all sentiment data scripts to use .json as the output name, not .txt",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Pass around lists of tokens instead of single strings. Will make it easier to switch the input/output to a json format",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Pass around lists of tokens instead of single strings. Will make it easier to switch the input/output to a json format"
            }
        ]
    },
    {
        "message_summary": "Convert the .sh prep_sentiment script to .py",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Conversion of script from .sh to .py"
            }
        ]
    },
    {
        "message_summary": "move the scripts/sentiment python scripts to stanza/utils/datasets/sentiment",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "The commit involves moving Python scripts related to sentiment analysis to a new directory within the repository."
            }
        ]
    },
    {
        "message_summary": "Add a corona text classification dataset",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a corona text classification dataset"
            }
        ]
    },
    {
        "message_summary": "Add arguments for choosing the tokenizer model and download method to the wikipedia tokenization script",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Add a flag to remove all sentences which don't fit in a bert tokenizer when processing Wikipedia",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Addition of a flag to remove sentences incompatible with a BERT tokenizer during Wikipedia processing"
            }
        ]
    },
    {
        "message_summary": "Refactor the tokenization method from tokenize_wiki.py",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Add min_len and max_len args to tokenize_wiki.py.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Skip one line wiki docs, since those are likely to be useless",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Code maintenance and enhancement"
            }
        ]
    },
    {
        "message_summary": "ignore em dashes in Wikipedia, as that seems to be lists",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "ignore em dashes in Wikipedia, as that seems to be lists"
            }
        ]
    },
    {
        "message_summary": "A script for tokenizing a Wikipedia file and writing it out",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "A script for tokenizing a Wikipedia file and writing it out"
            }
        ]
    },
    {
        "message_summary": "None",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Eliminate some single word trees from it_turin",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Eliminate some single word trees from it_turin"
            }
        ]
    },
    {
        "message_summary": "Start to integrate it_turin as a conversion script",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Start to integrate it_turin as a conversion script"
            }
        ]
    },
    {
        "message_summary": "Move SentimentDatum to classifiers/data.py and make the reading code read in SentimentDatum",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move SentimentDatum to classifiers/data.py and make the reading code read in SentimentDatum"
            }
        ]
    },
    {
        "message_summary": "Wrapper for converting Spanish TASS2020 for sentiment",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Conversion script for the dataset - reads data directly from the .zip files",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Wrapper for converting Spanish TASS2020 for sentiment and the activity of the pre trained realated activity of an addition to the respository"
            },
            {
                "Maintenance": "Update of a Pre Trained Model:Conversion script for the dataset - reads data directly from the .zip files"
            },
            {
                "Deprecation and Replacement": "Removal of a Pre Trained model:"
            }
        ]
    },
    {
        "message_summary": "Move SentimentDatum to classifiers/data.py and make the reading code read in SentimentDatum",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move SentimentDatum to classifiers/data.py and make the reading code read in SentimentDatum"
            }
        ]
    },
    {
        "message_summary": "Rename Fragment -> SentimentDatum to make a more understandable name for potential external users",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Rename Fragment -> SentimentDatum to make a more understandable name for potential external users"
            }
        ]
    },
    {
        "message_summary": "Switch all sentiment data scripts to use .json as the output name, not .txt",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Pass around lists of tokens instead of single strings. Will make it easier to switch the input/output to a json format",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Pass around lists of tokens instead of single strings. Will make it easier to switch the input/output to a json format"
            }
        ]
    },
    {
        "message_summary": "Convert the .sh prep_sentiment script to .py",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Conversion of script from .sh to .py"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Refactor the tokenization method from tokenize_wiki.py to add an option to selftrain_vi_quad for tokenizing data without parsing",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Refactor the tokenization method from tokenize_wiki.py to add an option to selftrain_vi_quad for tokenizing data without parsing"
            }
        ]
    },
    {
        "message_summary": "Move SentimentDatum to classifiers/data.py and make the reading code read in SentimentDatum",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move SentimentDatum to classifiers/data.py and make the reading code read in SentimentDatum"
            }
        ]
    },
    {
        "message_summary": "Rename Fragment -> SentimentDatum to make a more understandable name for potential external users",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Rename Fragment -> SentimentDatum to make a more understandable name for potential external users"
            }
        ]
    },
    {
        "message_summary": "Switch all sentiment data scripts to use .json as the output name, not .txt",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Switch all sentiment data scripts to use .json as the output name, not .txt"
            }
        ]
    },
    {
        "message_summary": "Pass around lists of tokens instead of single strings. Will make it easier to switch the input/output to a json format",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Pass around lists of tokens instead of single strings. Will make it easier to switch the input/output to a json format"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Add an argument to the IT sentiment preparation to split the mixed class in various ways",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "Add an argument to the IT sentiment preparation to split the mixed class in various ways"
            }
        ]
    },
    {
        "message_summary": "Move SentimentDatum to classifiers/data.py and make the reading code read in SentimentDatum",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move SentimentDatum to classifiers/data.py and make the reading code read in SentimentDatum"
            }
        ]
    },
    {
        "message_summary": "Rename Fragment -> SentimentDatum to make a more understandable name for potential external users",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Rename Fragment -> SentimentDatum to make a more understandable name for potential external users"
            }
        ]
    },
    {
        "message_summary": "Switch the VI model to use words tokenized from the stanza tokenizer rather than white space split.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "The Vietnamese model now uses words tokenized from the stanza tokenizer instead of white space split. The change was made due to GPU overheating issues.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "The Vietnamese model now uses words tokenized from the stanza tokenizer instead of white space split."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Initial version of a script to score the constituency parser as a dependency parser",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Initial version of a script to score the constituency parser as a dependency parser"
            }
        ]
    },
    {
        "message_summary": "Update for new version of the poetry data",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update for new version of the poetry data"
            }
        ]
    },
    {
        "message_summary": "Script to turn Prof. Delmonte's poetry text into a sentiment dataset",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "Dedicated to developing and deploying task-specific enhancements or capabilities that exploit the unique strengths of pre-trained models."
            }
        ]
    },
    {
        "message_summary": "Updated GUM MWT model behavior improvement",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "The updated GUM MWT model shows improved behavior compared to the previous version.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "The updated GUM MWT model shows improved behavior compared to the previous version."
            }
        ]
    },
    {
        "message_summary": "Add a utility function to resplit raw tokens into MWT using a tokenize/mwt Pipeline.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Includes an option to keep or ignore existing token boundaries",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a utility function to resplit raw tokens into MWT using a tokenize/mwt Pipeline."
            }
        ]
    },
    {
        "message_summary": "This is embarrassing... perhaps adding in the CoNLL data will fix it",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of CoNLL data"
            }
        ]
    },
    {
        "message_summary": "Add a doc_id field to the Sentence object, by request",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add a doc_id field to the Sentence object, by request"
            }
        ]
    },
    {
        "message_summary": "Update related to setting sent_id as a comment",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Specifically setting sent_id as a comment now updates the Sentence object's sent_id as well",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to updating the setting of sent_id as a comment in the codebase."
            }
        ]
    },
    {
        "message_summary": "Add a method to reindex sentences. Use it to keep the sent_id increasing even when using a 'stream' of documents",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add a method to reindex sentences."
            }
        ]
    },
    {
        "message_summary": "Use comments to store the sentiment values as well",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Use comments to store the sentiment values as well"
            }
        ]
    },
    {
        "message_summary": "N/A",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Add comments to the serialized format when saving a document.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "This will keep any user added comments, but at the cost of making the files larger because they now have the text in a couple different places.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to adding comments to the serialized format when saving a document."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Add mwt to expected results for several more EN downloads",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Update NER packages to reflect the new ontonotes_charlm default NER",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Allow for loading a pipeline for a language that doesn't exist, as long as everything is specified",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Allow for loading a pipeline for a language that doesn't exist"
            }
        ]
    },
    {
        "message_summary": "Add a test that download_method=None doesn't clobber the wrong model",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Notes on which embeddings are used for which NER, in the form of a map of default pretrains",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Use the default pretrains when using run_ner.py. Update prepare_resources to use the new ner embedding info",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model"
            },
            {
                "Compatibility": "Use the default pretrains when using run_ner.py. Update prepare_resources to use the new ner embedding info"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Allow for selectively using processors. Answers #945",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Allow for selectively using processors"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Use the correct pretrain path for the new NER default",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Use the correct pretrain path for the new NER default"
            }
        ]
    },
    {
        "message_summary": "Return entity F1 for each entity as part of the score_by_entity function in the scorer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Return entity F1 for each entity as part of the score_by_entity function in the scorer"
            }
        ]
    },
    {
        "message_summary": "Update NER packages to reflect the new ontonotes_charlm default NER",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Unnecessary print at the end of a test",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Removal of a Pre Trained model:"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Removal of a Pre Trained model"
            }
        ]
    },
    {
        "message_summary": "Add a flag to output all the NER results to a file when evaluating",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a flag to output all the NER results to a file when evaluating"
            }
        ]
    },
    {
        "message_summary": "Add a simple test of ner_tagger.evaluate()",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Rearrange NER tests to their own directory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Rearranging NER tests to their own directory"
            }
        ]
    },
    {
        "message_summary": "Add a test for not capturing . at the end of a sentence if it was part of an AMT label",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Oops, finish an incomplete comment",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Finish an incomplete comment"
            }
        ]
    },
    {
        "message_summary": "Add a tool to convert from an AMT annotation file to a bio/json NER file for Stanza",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a tool to convert from an AMT annotation file to a bio/json NER file for Stanza"
            }
        ]
    },
    {
        "message_summary": "Update NER packages to reflect the new ontonotes_charlm default NER",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Add a utility method for extracting the resources for a specific language, possibly following 'alias' links",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a utility method for extracting resources for a specific language"
            }
        ]
    },
    {
        "message_summary": "Add a piece of doc",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add a piece of doc"
            }
        ]
    },
    {
        "message_summary": "Change a bunch of tempdirs to be under TEST_WORKING_DIR",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Change a bunch of tempdirs to be under TEST_WORKING_DIR"
            }
        ]
    },
    {
        "message_summary": "Notes on which embeddings are used for which NER, in the form of a map of default pretrains",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Use the default pretrains when using run_ner.py. Update prepare_resources to use the new ner embedding info",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Use the default pretrains when using run_ner.py."
            },
            {
                "Maintenance": "Update prepare_resources to use the new ner embedding info."
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Allow specifying multiple packages of NER to download at the same time",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Allow specifying multiple packages of NER to download at the same time"
            }
        ]
    },
    {
        "message_summary": "Add a test for the download of a single model and its dependencies",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a test for the download of a single model and its dependencies"
            }
        ]
    },
    {
        "message_summary": "None",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Separate tests of different components into different files",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Separate tests of different components into different files"
            }
        ]
    },
    {
        "message_summary": "Squeeze a little bit more - only use depparse in the depparse pipeline",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "depparse requires lemmatization to get the right results",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "depparse requires lemmatization to get the right results"
            }
        ]
    },
    {
        "message_summary": "Move a couple tests into their own pipeline directory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move a couple tests into their own pipeline directory"
            }
        ]
    },
    {
        "message_summary": "None",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "None",
                "Task Specificity": "None",
                "Community and Collaboration": "None",
                "Maintenance": "None",
                "Compliance and Standards": "None",
                "Performance Improvements": "None",
                "Compatibility": "None",
                "Deprecation and Replacement": "Update of a Pre Trained Model:",
                "Project Evolution": "None",
                "Technical Debt and Simplification": "None"
            }
        ]
    },
    {
        "message_summary": "spaCy tokenizer won't have MWT",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "Removal of a Pre Trained model:"
            }
        ]
    },
    {
        "message_summary": "Update the postprocessing test for the new English MWT default",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update the postprocessing test for the new English MWT default"
            }
        ]
    },
    {
        "message_summary": "Update a couple tests for the MWT change",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Move a bunch of tests to more appropriate homes",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move a bunch of tests to more appropriate homes"
            }
        ]
    },
    {
        "message_summary": "Move a bunch of tests to a separate directory specifically for the corenlp client",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move a bunch of tests to a separate directory specifically for the corenlp client"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "Dedicated to developing and deploying task-specific enhancements or capabilities that exploit the unique strengths of pre-trained models."
            }
        ]
    },
    {
        "message_summary": "Update unit tests to match the newly trained POS models",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update unit tests to match the newly trained POS models"
            }
        ]
    },
    {
        "message_summary": "Rearrange most of the tests in stanza/tests",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Rearranging tests in stanza/tests"
            }
        ]
    },
    {
        "message_summary": "Update the caseless test to reflect the new models.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Add a flag to the pipeline lemmatizer which tells it to remember word,pos combinations it has seen before.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Compatibility": "Add a flag to the pipeline lemmatizer which tells it to remember word,pos combinations it has seen before."
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move a bunch of tests to more appropriate homes"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Rearrange most of the tests in stanza/tests",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Rearranged tests in stanza/tests"
            }
        ]
    },
    {
        "message_summary": "Refactor spaces_after and spaces_before to be actual members of the Token",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "The commit modifies the Token structure to include spaces_after and spaces_before as direct members instead of being attached to the MISC field.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "The commit modifies the Token structure to include spaces_after and spaces_before as direct members instead of being attached to the MISC field."
            }
        ]
    },
    {
        "message_summary": "Add a couple test cases of SpacesBefore and Space[s]After",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Update a couple tests for the MWT change",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Move a bunch of tests to more appropriate homes",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move a bunch of tests to more appropriate homes"
            }
        ]
    },
    {
        "message_summary": "Update test to reflect changed defaults",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Add finetuning of the transformer to the CNN Classifier.",
        "ptm_name": "tiny bert",
        "ptm_version": "",
        "ptm_problem_addressed": "Finetuning for CNN Classifier",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "None",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "None",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "None",
                "Task Specificity": "None",
                "Community and Collaboration": "None",
                "Maintenance": "None",
                "Compliance and Standards": "None",
                "Performance Improvements": "None",
                "Compatibility": "None",
                "Deprecation and Replacement": "Update of a Pre Trained Model:",
                "Project Evolution": "None",
                "Technical Debt and Simplification": "None"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Make saved models smaller in the classifier test. Will hopefully save disk space and time",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Make saved models smaller in the classifier test. Will hopefully save disk space and time"
            }
        ]
    },
    {
        "message_summary": "Update a couple defaults based on recent experiments",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre-Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Add a checkpoint mechanism to sentiment",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Pass checkpoint_file to train_model in the unittest, but TODO: need to add tests for checkpointing",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "Simplify the load mechanism in classifier Trainer so that the load() call loads the pretrain, charlm, etc",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Simplify the load mechanism in classifier Trainer"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Add the ability to add a list of filter output sizes instead of just one-size-fits-all",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Add the ability to add a list of filter output sizes instead of just one-size-fits-all"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Begin writing a test for the classifier",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Tests building a model, saving & loading, iterating a couple times on a couple varieties of models, and some of the utility methods. Tests bilstm & maxpool widths",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Commit log is related to writing a test for the classifier and testing various model building, saving, loading, and utility methods. It includes testing bilstm and maxpool widths."
            }
        ]
    },
    {
        "message_summary": "Change a bunch of tempdirs to be under TEST_WORKING_DIR",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Change a bunch of tempdirs to be under TEST_WORKING_DIR"
            }
        ]
    },
    {
        "message_summary": "Separate tests of different components into different files",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Separate tests of different components into different files"
            }
        ]
    },
    {
        "message_summary": "Move the installation test to its own directory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move the installation test to its own directory"
            }
        ]
    },
    {
        "message_summary": "Integrating spacy-huggingface-pipelines and refactoring NlpEngine logic",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Integration Patterns": "Involves integrating new pre-trained models into existing systems, focusing on seamless incorporation and initial feature enhancement for these models."
            },
            {
                "Maintenance": "Pertains to the upkeep, technical updates, and refactoring of pre-trained models to ensure ongoing reliability and efficiency."
            }
        ]
    },
    {
        "message_summary": "updated call to stanza via spacy-stanza",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Updated call to stanza via spacy-stanza"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Fix up the unit tests now that the output formats expect to have the Spaces annotations on the MISC columns",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix up the unit tests now that the output formats expect to have the Spaces annotations on the MISC columns"
            }
        ]
    },
    {
        "message_summary": "None",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "None",
                "Task Specificity": "None",
                "Community and Collaboration": "None",
                "Maintenance": "None",
                "Compliance and Standards": "None",
                "Performance Improvements": "None",
                "Compatibility": "None",
                "Deprecation and Replacement": "Update of a Pre Trained Model:",
                "Project Evolution": "None",
                "Technical Debt and Simplification": "None"
            }
        ]
    },
    {
        "message_summary": "Add a test which checks that all models from a pipeline are on the expected device",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Add a test which checks that all models from a pipeline are on the expected device"
            }
        ]
    },
    {
        "message_summary": "Update FR depparse test.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "The new model is more accurate, unsure about the correct label.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "Replacement of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Latest POS models change this word to NOUN",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Addresses the adaptation of pre-trained models to function optimally with newer systems or software versions, ensuring forward compatibility."
            }
        ]
    },
    {
        "message_summary": "Move a couple tests into their own pipeline directory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move a couple tests into their own pipeline directory"
            }
        ]
    },
    {
        "message_summary": "Add a small test of Arabic MWT and POS",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Fix up the unit tests now that the output formats expect to have the Spaces annotations on the MISC columns",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix up the unit tests now that the output formats expect to have the Spaces annotations on the MISC columns"
            }
        ]
    },
    {
        "message_summary": "Fix an empty bulk process not processing correctly",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fixing an issue with the bulk process"
            }
        ]
    },
    {
        "message_summary": "Add a method to reindex sentences. Use it to keep the sent_id increasing even when using a 'stream' of documents",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add a method to reindex sentences. Use it to keep the sent_id increasing even when using a 'stream' of documents"
            }
        ]
    },
    {
        "message_summary": "Add a streaming interface, as requested in #550",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Add a streaming interface"
            }
        ]
    },
    {
        "message_summary": "Add a bulk_process method which does the Document wrapping for the user - try to make the interface a bit simpler for the user",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Use comments to store the sentiment values as well",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Use comments to store the sentiment values as well"
            }
        ]
    },
    {
        "message_summary": "Move the token to conll text functionality to doc.py.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Use this to create C (with comments) and c (no comments) formats for Document and Sentence.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move the token to conll text functionality to doc.py."
            },
            {
                "Compatibility": "Use this to create C (with comments) and c (no comments) formats for Document and Sentence."
            }
        ]
    },
    {
        "message_summary": "Add a test which checks that all models from a pipeline are on the expected device",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a test to check models on expected device"
            }
        ]
    },
    {
        "message_summary": "New models get the features correct",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "New models get the features correct"
            }
        ]
    },
    {
        "message_summary": "Write NER tags to conll docs",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Don't put NER on the word misc field",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Add a #text comment to each sentence in a doc if it doesn't already exist",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Add #text markers to the unit tests where expected",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Add a #text comment to each sentence in a doc if it doesn't already exist"
            },
            {
                "Task Specificity": "Add #text markers to the unit tests where expected"
            }
        ]
    },
    {
        "message_summary": "Move a couple tests into their own pipeline directory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move tests into their own pipeline directory"
            }
        ]
    },
    {
        "message_summary": "Extend read_snippets for sentiment datasets to read multiple columns and combine them into a single sentiment value",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Extend read_snippets for sentiment datasets to read multiple columns and combine them into a single sentiment value"
            }
        ]
    },
    {
        "message_summary": "Move SentimentDatum to classifiers/data.py and make the reading code read in SentimentDatum",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move SentimentDatum to classifiers/data.py and make the reading code read in SentimentDatum"
            }
        ]
    },
    {
        "message_summary": "Add a couple tests of the building block methods from the Sentiment conversion tools",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "Dedicated to developing and deploying task-specific enhancements or capabilities that exploit the unique strengths of pre-trained models."
            }
        ]
    },
    {
        "message_summary": "Fix that it takes forever to tokenize a really long non-numeric token",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Commit log is related to fixing issues with tokenization process."
            }
        ]
    },
    {
        "message_summary": "Add a few tests of the NUMERIC_RE",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add a few tests of the NUMERIC_RE"
            }
        ]
    },
    {
        "message_summary": "Add the skip_newlines test to the file reading version of the tokenizer data as well",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Abstract away labels() rather than having the eval code know the format of the data object",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Run some basic tests on the dictionary in the ZH tokenizer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Run some basic tests on the dictionary in the ZH tokenizer"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Move a bunch of tests to more appropriate homes",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move a bunch of tests to more appropriate homes"
            }
        ]
    },
    {
        "message_summary": "Update speed benchmark",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Speed benchmark was updated. Install command without torch URL was restored.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": {}
            },
            {
                "Unrelated": {}
            }
        ]
    },
    {
        "message_summary": "Update speed benchmarking project (#29)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Added token_splitter to Spacy's TRF model for speed benchmarking. Updated readme to clarify private files. Limited Stanza's GPU memory usage. Added depparse_batch_size. Fixed comments. Added textcat_multilabel fix.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "None",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Fix up the unit tests now that the output formats expect to have the Spaces annotations on the MISC columns",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix up the unit tests now that the output formats expect to have the Spaces annotations on the MISC columns"
            }
        ]
    },
    {
        "message_summary": "MWT expansion with MEXP attribute tags",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Uses an enum to signify the manual MWT processing. Manual MWT information is in a field instead of the misc field. Default of the manual expansion is `None`",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Uses an enum to signify the manual MWT processing. Manual MWT information is in a field instead of the misc field. Default of the manual expansion is `None`"
            }
        ]
    },
    {
        "message_summary": "Add a (brief) test of turning a tokenizer training file into a lexicon",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Add a utility method for constructing a Document from pretokenized sentences and an original text",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Integration Patterns": "None",
                "Task Specificity": "None",
                "Community and Collaboration": "None",
                "Maintenance": "None",
                "Compliance and Standards": "None",
                "Performance Improvements": "None",
                "Compatibility": "None",
                "Deprecation and Replacement": "None",
                "Project Evolution": "None",
                "Technical Debt and Simplification": "None"
            }
        ]
    },
    {
        "message_summary": "Move a bunch of tests to more appropriate homes",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move a bunch of tests to more appropriate homes"
            }
        ]
    },
    {
        "message_summary": "Rearrange most of the tests in stanza/tests",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Rearranged tests in stanza/tests"
            }
        ]
    },
    {
        "message_summary": "Update NER packages to reflect the new ontonotes_charlm default NER",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "No significant Pre-Trained Models activities mentioned."
            }
        ]
    },
    {
        "message_summary": "NER get_known_tags possibly applies to multiple models",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "NER get_known_tags possibly applies to multiple models"
            }
        ]
    },
    {
        "message_summary": "Add a field for multiple NER annotations in a tuple",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "Add a mechanism for using multiple NER models at once",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Integration Patterns": "Add a mechanism for using multiple NER models at once"
            }
        ]
    },
    {
        "message_summary": "Move a couple tests into their own pipeline directory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move a couple tests into their own pipeline directory"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Add getting all possible values for each feat",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "Add getting all possible values for each feat"
            }
        ]
    },
    {
        "message_summary": "Add methods for getting the xpos, upos, and feats from a pos model in the pos_processor.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": {
                    "description": "Added methods for extracting xpos, upos, and feats from a part-of-speech (POS) model in the pos_processor module."
                },
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "Rearrange most of the tests in stanza/tests",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Add BPE encoding, prefix/suffix tokens, target suffix support",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Add BPE encoding, prefix/suffix tokens, target suffix support"
            }
        ]
    },
    {
        "message_summary": "Fix sort order in CompositeTranslation",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix sort order in CompositeTranslation"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Document translation by code helper functions",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Document translation by code helper functions"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Tag translation improvements",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Tag translation improvements"
            }
        ]
    },
    {
        "message_summary": "Upgraded to CTranslate2 2.0",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Upgraded to CTranslate2 2.0 version for improvements.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Upgraded to CTranslate2 2.0 version for improvements."
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Set min beam size of 4"
            }
        ]
    },
    {
        "message_summary": "Filter available packages by sbd available",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Filter available packages by sbd available"
            }
        ]
    },
    {
        "message_summary": "Filter installed languages for sbd",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Filter installed languages for sbd"
            }
        ]
    },
    {
        "message_summary": "Added code formatting with black",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Added code formatting with black"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Use CTranslate2 to split batches",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Use CTranslate2 to split batches"
            }
        ]
    },
    {
        "message_summary": "Break long translations over multiple batches",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Break long translations over multiple batches"
            }
        ]
    },
    {
        "message_summary": "Use list-comprehension instead of `[]*` (multiple reference)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Use list-comprehension instead of `[]*` (multiple reference)"
            }
        ]
    },
    {
        "message_summary": "Add `@staticmethod` to static methods of `ITranslation`",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Add `@staticmethod` to static methods of `ITranslation`"
            }
        ]
    },
    {
        "message_summary": "Port the new combine-results loop from CachedTranslation to PackageTranslation",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Use a more precise and easier-to-read way for Hypothesis.__str__",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Use a more precise and easier-to-read way for Hypothesis.__str__"
            }
        ]
    },
    {
        "message_summary": "Fix typo in method signature",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix typo in method signature"
            }
        ]
    },
    {
        "message_summary": "Implement __str__ and __repr__ for Hypothesis",
        "ptm_name": "Hypothesis",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Implement __str__ and __repr__ for Hypothesis"
            }
        ]
    },
    {
        "message_summary": "Added assertion that sentences within batch size",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Added assertion that sentences within batch size"
            }
        ]
    },
    {
        "message_summary": "Renamed multi_translation",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "Renamed multi_translation"
            }
        ]
    },
    {
        "message_summary": "Keep the API backwards compatible",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Keep the API backwards compatible"
            }
        ]
    },
    {
        "message_summary": "Make it possible to return more than one 'hypothetical' translations",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Added functionality to pass `num_hypotheses` and `beam_size` to CTranslate for multiple results, which are then combined and returned as a list.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "Added more debug statements",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Added more debug statements"
            }
        ]
    },
    {
        "message_summary": "N/A",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Replaced unknowns with source tokens",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Replacement of a Pre Trained Model:": null
            }
        ]
    },
    {
        "message_summary": "Changed CTranslate length_penalty to 0.2",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Defaulted to English as the from language",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Commit log is related to defaulting to English as the from language."
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Replacement of a Pre Trained Model:": {}
            }
        ]
    },
    {
        "message_summary": "Cleaned up the logic for splitting paragraphs",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Cleaned up the logic for splitting paragraphs"
            }
        ]
    },
    {
        "message_summary": "Swithed translation.Translation to a better interface system",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Added support for maintaining newlines into translated text",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Added support for maintaining newlines into translated text"
            }
        ]
    },
    {
        "message_summary": "Improved documentation",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Improved documentation"
            }
        ]
    },
    {
        "message_summary": "Fixed bug in translating with multiple packages installed",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fixed bug in translating with multiple packages installed"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Improved documentation and some refactoring."
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Check for and replace excessively long tokens with \"UNK\"; addresses issue 1137 (#1140)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Added simple test for tokenizer maxlen check. Moved length check to post tokenization stage.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Moved length check to post tokenization stage."
            }
        ]
    },
    {
        "message_summary": "Add a test that a fake constituency classifier can be loaded into the pipeline and run on a sentence",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a test for a fake constituency classifier in the pipeline"
            }
        ]
    },
    {
        "message_summary": "Add an option to the constituency classifier which uses all words instead of just first/last",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "The classifier itself uses a max() to pick just one dim to pay attention to",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": {
                    "PTM Integration": false
                },
                "Task Specificity": {
                    "Task": "Add an option to the constituency classifier to consider all words instead of just the first and last"
                }
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Reducing the scope on various pipelines to prevent running out of GPU memory"
            }
        ]
    },
    {
        "message_summary": "Add a method to extract the known relations from a dependency parser in a pipeline.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Maintenance": "Commit log is related to adding a method for extracting known relations from a dependency parser in a pipeline."
            }
        ]
    },
    {
        "message_summary": "Move a couple tests into their own pipeline directory",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move tests into their own pipeline directory"
            }
        ]
    },
    {
        "message_summary": "Maybe save a little GPU memory (fragmentation, at least) by reusing some large data structures",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Save GPU memory by reusing large data structures"
            }
        ]
    },
    {
        "message_summary": "Add a method to get the constituents known by a conparser, as requested in #1066",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "Addition of a method to get the constituents known by a conparser"
            }
        ]
    },
    {
        "message_summary": "Order the items in a constituency query correctly. Fixes #882",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Order the items in a constituency query correctly."
            }
        ]
    },
    {
        "message_summary": "Add method for generating words only",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Clean notebooks, prepare for urban dictionary run",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Clean notebooks, prepare for urban dictionary run"
            }
        ]
    },
    {
        "message_summary": "N/A",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Word generation: add a hail mary when failing, only do one pass",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a hail mary feature for word generation"
            },
            {
                "Task Specificity": "Limiting word generation to one pass"
            }
        ]
    },
    {
        "message_summary": "Wire up basic word service, move word generator interface to own file",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Move word generator interface to own file"
            },
            {
                "Integration Patterns": "Wire up basic word service"
            }
        ]
    },
    {
        "message_summary": "Use custom inference in twitter bot",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Use custom inference in twitter bot"
            }
        ]
    },
    {
        "message_summary": "Get rid of example expansion",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Get rid of example expansion"
            }
        ]
    },
    {
        "message_summary": "Add custom modeling utils with early exit for blacklist / end of sentence",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Add twitter card to website, move to training script with creativity evaluation",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Fix pretokenized input format",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix pretokenized input format"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fixes issue with disabling spacy components and resolves disable_sbd problem"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "update to spacy v3 pipeline",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "add ability to use is_tokenized for udpipe",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a new feature to support is_tokenized for udpipe"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "Dedicated to developing and deploying task-specific enhancements or capabilities that exploit the unique strengths of pre-trained models."
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Dependencies: Add VADER; Utils: Add VADER's sentiment analyzers",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of VADER sentiment analyzers",
                "Task Specificity": "Addition of VADER's sentiment analyzers",
                "Maintenance": "Update of a Pre Trained Model",
                "Replacement of a Pre Trained Model": "Replacement of a Pre Trained Model",
                "Removal of a Pre Trained model": "Removal of a Pre Trained model"
            }
        ]
    },
    {
        "message_summary": "Dependencies upgraded to Stanza 1.7.0; Added Stanza's Sindhi part-of-speech tagger",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Dependencies upgraded to Stanza 1.7.0"
            },
            {
                "Integration Patterns": "Added Stanza's Sindhi part-of-speech tagger"
            }
        ]
    },
    {
        "message_summary": "Dependencies: Upgrade spaCy to 3.7.2; Utils: Fix downloading of Stanza models",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Upgrade spaCy to version 3.7.2"
            },
            {
                "Maintenance": "Fix downloading of Stanza models"
            }
        ]
    },
    {
        "message_summary": "Dependencies: Upgrade PyInstaller to 6.0",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Upgrade PyInstaller to version 6.0"
            }
        ]
    },
    {
        "message_summary": "Utils: Add Stanza's French (Old) lemmatizer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a new pre-trained model"
            }
        ]
    },
    {
        "message_summary": "Utils: Remove Stanza's Swedish Sign Language sentence tokenizer, word tokenizer, part-of-speech tagger, and dependency parser",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "Removal of a Pre Trained model:"
            }
        ]
    },
    {
        "message_summary": "Dependencies upgraded to Stanza 1.5.1; Added Stanza's Hebrew (Ancient), Kyrgyz, Manx, and Pomak NLP components",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Stanza's Hebrew (Ancient), Kyrgyz, Manx, and Pomak sentence tokenizers, word tokenizers, part-of-speech taggers, lemmatizers, and dependency parsers were added",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Added new NLP components to the repository."
            }
        ]
    },
    {
        "message_summary": "Utils: Add Stanza's sentiment analyzers",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of new sentiment analysis tools"
            }
        ]
    },
    {
        "message_summary": "Dependencies: Add Stanza; Utils: Add Stanza's sentence tokenizers, word tokenizers, part-of-speech taggers, lemmatizers, and dependency parsers",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Dependencies: Add Stanza"
            },
            {
                "Maintenance": "Utils: Add Stanza's sentence tokenizers, word tokenizers, part-of-speech taggers, lemmatizers, and dependency parsers"
            }
        ]
    },
    {
        "message_summary": "Dependencies: Add Dostoevsky; Settings: Add Settings - Sentiment Analysis; Utils: Add Dostoevsky's Russian sentiment analyzer",
        "ptm_name": "Dostoevsky",
        "ptm_version": "",
        "ptm_problem_addressed": "Russian sentiment analysis",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "Utils: Update spaCy's sentence recognizers, word tokenizers, part-of-speech taggers, lemmatizers, and dependency parsers",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Utils: Add spaCy's Slovenian sentence recognizer, part-of-speech tagger, lemmatizer, and dependency parser",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of new pre-trained models"
            }
        ]
    },
    {
        "message_summary": "Utils: Add spaCy's Korean sentence recognizer, word tokenizer, part-of-speech tagger, lemmatizer, and dependency parser",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of new pre-trained models"
            }
        ]
    },
    {
        "message_summary": "Dependencies: Add python-mecab-ko; Utils: Add python-mecab-ko's MeCab",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Dependencies: Add python-mecab-ko"
            },
            {
                "Integration Patterns": "Utils: Add python-mecab-ko's MeCab"
            }
        ]
    },
    {
        "message_summary": "Dependencies: 1. Add pymorphy3 2. Remove pymorphy2",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of pymorphy3 for integration"
            },
            {
                "Deprecation and Replacement": "Removal of pymorphy2"
            }
        ]
    },
    {
        "message_summary": "Settings: Update global settings - measures",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update global settings - measures"
            }
        ]
    },
    {
        "message_summary": "Utils: Speed up n-gram/skip-gram generation",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Speed up n-gram/skip-gram generation"
            }
        ]
    },
    {
        "message_summary": "Work Area: Add Dependency Parser",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a Dependency Parser"
            }
        ]
    },
    {
        "message_summary": "Utils: Update spaCy's sentence tokenizers, word tokenizers, part-of-speech taggers, and lemmatizers",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Utils: Update spaCy's sentence recognizers",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Utils: Add spaCy's Ukrainian part-of-speech tagger and lemmatizer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a new pre-trained model"
            }
        ]
    },
    {
        "message_summary": "Utils: Add spaCy's Finnish part-of-speech tagger and lemmatizer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a new pre-trained model"
            }
        ]
    },
    {
        "message_summary": "Utils: Add spaCy's Croatian and Swedish part-of-speech taggers",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of new pre-trained models"
            }
        ]
    },
    {
        "message_summary": "Utils: 1. Add spaCy's Sorbian (Lower) word tokenizer and stop word list 2. Add spaCy's Sorbian (Upper) word tokenizer and stop word list",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of new word tokenizers and stop word lists for Sorbian language in spaCy."
            }
        ]
    },
    {
        "message_summary": "Utils: Add Pyphen's Catalan syllable tokenizer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of a new tool for text processing"
            }
        ]
    },
    {
        "message_summary": "Utils: Add NLTK's legality syllable tokenizer and sonority sequencing syllable tokenizer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of new integration patterns"
            }
        ]
    },
    {
        "message_summary": "Tests: Add CI - SonarCloud",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Utils: Add NLTK's regular-expression tokenizer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition of NLTK's regular-expression tokenizer"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": {}
            },
            {
                "Deprecation and Replacement": {}
            }
        ]
    },
    {
        "message_summary": "Work Area: Add Profiler - Count of Sentence Segments / Paragraph Length in Sentence Segments / Sentence Segment Length in Tokens / Count of n-length Sentence Segments",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            },
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Doc: Add README - Pylint badge",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Various improvements, clients and clients docs.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Various improvements, clients and clients docs."
            }
        ]
    },
    {
        "message_summary": "Updated pythondocs, clean up code",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Updated pythondocs, clean up code"
            }
        ]
    },
    {
        "message_summary": "Require newer Stanza, test for Stanza pipe",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Require newer Stanza, test for Stanza pipe"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix some code style issues"
            }
        ]
    },
    {
        "message_summary": "Add support for space tokens.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            },
            {
                "Deprecation and Replacement": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Better squeezing of multiword tokens",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Better squeezing of multiword tokens"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Fix stanza lib problem.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Oddly something seems to have changed in how stanza represents ids. Apparently this was string before and is int now. Just to be safe, we always convert to string for now.",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to fixing an issue with the stanza library."
            }
        ]
    },
    {
        "message_summary": "A few more for the changed annset.add method.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Re-implementation of Features, updated documentation.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Re-implementation of Features, updated documentation."
            }
        ]
    },
    {
        "message_summary": "Add support for Stanford Stanza",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Require newer Stanza, test for Stanza pipe",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Require newer Stanza"
            },
            {
                "Maintenance": "test for Stanza pipe"
            }
        ]
    },
    {
        "message_summary": "Stanza unit test: do not use GPU",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Do not use GPU"
            }
        ]
    },
    {
        "message_summary": "Improve unit tests.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Improve unit tests."
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Unit tests added and bugs fixed."
            }
        ]
    },
    {
        "message_summary": "Avoid downloading the model if it is already there.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "Try to make the test work on travis",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Make the test work on travis"
            }
        ]
    },
    {
        "message_summary": "Fix bug in setup, remove stanfordnlp. Add instead a test for stanza",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix bug in setup, remove stanfordnlp. Add instead a test for stanza"
            }
        ]
    },
    {
        "message_summary": "text2ud: show progress during Stanza parsing",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Many improvements to the Bilinguo demo",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "Improved generation from Python. Fixed conjugation table number for some verbs in lexicon-en.json",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Many improvements to the Bilinguo demo"
            },
            {
                "Maintenance": "Improved generation from Python. Fixed conjugation table number for some verbs in lexicon-en.json"
            }
        ]
    },
    {
        "message_summary": "Bilinguo: add Python generator + README.md",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "addition"
            }
        ]
    },
    {
        "message_summary": "N/A",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Fix potential bugs of `add_tokens`",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix potential bugs of `add_tokens`"
            }
        ]
    },
    {
        "message_summary": "Strip tokenized tokens in extended vocab",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Strip tokenized tokens in extended vocab"
            }
        ]
    },
    {
        "message_summary": "Consider added tokens as well",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Consider added tokens as well"
            }
        ]
    },
    {
        "message_summary": "Syntax sugars for dist training",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Syntax sugars for dist training"
            }
        ]
    },
    {
        "message_summary": "Handle tok with `ByteLevel` pre_tokenizer properly",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Handle tok with `ByteLevel` pre_tokenizer properly"
            }
        ]
    },
    {
        "message_summary": "Try loading local transformers files first",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Try loading local transformers files first"
            }
        ]
    },
    {
        "message_summary": "Handle unk case for `TransformerTokenizer`",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Handle unk case for `TransformerTokenizer`"
            }
        ]
    },
    {
        "message_summary": "Skip special tokens and keep spaces while decoding",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Skip special tokens and keep spaces while decoding"
            }
        ]
    },
    {
        "message_summary": "Fix vocab bug within BPE decoding",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fix vocab bug within BPE decoding"
            }
        ]
    },
    {
        "message_summary": "Provide `min_freq` for BPE Tokenizer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Added feature to the BPE Tokenizer"
            }
        ]
    },
    {
        "message_summary": "Specify word suffix for BPE Trainer",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Specify word suffix for BPE Trainer"
            }
        ]
    },
    {
        "message_summary": "Syntactic sugar for Transformer tokenizers",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Syntactic sugar for Transformer tokenizers"
            }
        ]
    },
    {
        "message_summary": "added allosaurus, surfboard, and blabla featurizers",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": null,
                "Task Specificity": null,
                "Community and Collaboration": null,
                "Maintenance": null,
                "Compliance and Standards": null,
                "Performance Improvements": null,
                "Compatibility": null,
                "Deprecation and Replacement": null,
                "Project Evolution": null,
                "Technical Debt and Simplification": null
            }
        ]
    },
    {
        "message_summary": "Update for srl_span with msp2.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Update for srl_span with msp2."
            }
        ]
    },
    {
        "message_summary": "UD in word service, bug fixes",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "UD in word service, bug fixes"
            }
        ]
    },
    {
        "message_summary": "Add word already exists warning",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "Word generation: add a hail mary when failing, only do one pass",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "add a hail mary when failing, only do one pass"
            }
        ]
    },
    {
        "message_summary": "Webpack, website that queries backend",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Webpack, website that queries backend"
            }
        ]
    },
    {
        "message_summary": "N/A",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "to_tree() changed into BOX DRAWINGS DOUBLE",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "to_tree() changed into BOX DRAWINGS DOUBLE"
            }
        ]
    },
    {
        "message_summary": "Bug fix for \u30d5\u30a3\u30e9\u30fc of ipadic",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Bug fix for \u30d5\u30a3\u30e9\u30fc of ipadic"
            }
        ]
    },
    {
        "message_summary": "Version 0.9.8 raw option supported",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "raw option supported"
            }
        ]
    },
    {
        "message_summary": "bug fix for Translit of \"spoken\"",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Bug fix"
            }
        ]
    },
    {
        "message_summary": "Bug fix for Translit of \"gendai\"",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Bug fix for Translit of \"gendai\""
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "adding a new dir for path sampling scripts",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Adding a new directory for path sampling scripts"
            }
        ]
    },
    {
        "message_summary": "fixes for keeping \\n in text",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Fixes for keeping \\n in text"
            }
        ]
    },
    {
        "message_summary": "Add binyan lookup for any VERB without binyan prediction",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Addition to the repository"
            }
        ]
    },
    {
        "message_summary": "support Windows cp1255 Hebrew encoding",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "support Windows cp1255 Hebrew encoding"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Commit log is related to general maintenance, code refactoring."
            }
        ]
    },
    {
        "message_summary": "manage GPU memory for large single files",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "manage GPU memory for large single files"
            }
        ]
    },
    {
        "message_summary": "add `--from_pipes` option",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {
                "Integration Patterns": "None",
                "Task Specificity": "None",
                "Community and Collaboration": "None",
                "Maintenance": "None",
                "Compliance and Standards": "None",
                "Performance Improvements": "None",
                "Compatibility": "None",
                "Deprecation and Replacement": "None",
                "Project Evolution": "None",
                "Technical Debt and Simplification": "None"
            }
        ]
    },
    {
        "message_summary": "include id for passage qg",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Updated inference notebook for PassageQG",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Updated inference notebook for PassageQG"
            }
        ]
    },
    {
        "message_summary": "PassageQG can take answers as input",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "PassageQG can take answers as input"
            }
        ]
    },
    {
        "message_summary": "Merge branch 'passageqg' into tableqg",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Merge branch 'passageqg' into tableqg"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Answer sampler uses NERs from Stanza: en, ru, ar, fi",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "NERs from Stanza: en, ru, ar, fi"
            }
        ]
    },
    {
        "message_summary": "Inference notebooks for TableQG and TyDi",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Task Specificity": "Inference notebooks for TableQG and TyDi"
            }
        ]
    },
    {
        "message_summary": "PassageQG inference works. en_core_web_sm downloades with setup",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "en_core_web_sm download with setup"
            }
        ]
    },
    {
        "message_summary": "Benchmarks scripts - genia & bigtext file",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Benchmarks scripts - genia & bigtext file"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "None",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "None",
        "replacement_info": "None",
        "removal_details": "None",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "Clean tokenizer and nlp interfaces",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Clean tokenizer and nlp interfaces"
            }
        ]
    },
    {
        "message_summary": "Use context words to boost score",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Performance Improvements": "Use context words to boost score"
            }
        ]
    },
    {
        "message_summary": "Use spaCy tokenizer because stanza's mwts alter the original text",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Use spaCy tokenizer because stanza's mwts alter the original text"
            }
        ]
    },
    {
        "message_summary": "",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Refactor and fix bugs"
            }
        ]
    },
    {
        "message_summary": "Update machine learning scripts with NNMF and TextRank-GloVe techniques",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Update machine learning scripts with NNMF and TextRank-GloVe techniques",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Update of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "pre-aligned pair upload: upload one pair per annotator",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "upload one pair per annotator"
            }
        ]
    },
    {
        "message_summary": "fix bug uploading pre-aligned & pre-split n:m pairs",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "fix bug uploading pre-aligned & pre-split n:m pairs"
            }
        ]
    },
    {
        "message_summary": "align documents with different simplified versions (references) and export them",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "align documents with different simplified versions (references) and export them"
            }
        ]
    },
    {
        "message_summary": "bug fix: counting sentence ids of pre-split data",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "bug fix: counting sentence ids of pre-split data"
            }
        ]
    },
    {
        "message_summary": "Downgrade to Spacy 2.3.7 from 3.2.0",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Deprecation and Replacement": "Replacement of a Pre Trained Model:"
            }
        ]
    },
    {
        "message_summary": "Downgrade to Spacy 2.3.7 from 3.2.0",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Downgrade to Spacy 2.3.7 from 3.2.0"
            }
        ]
    },
    {
        "message_summary": "\"show most similar sentence\"-button for alignment support",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Compatibility": "Integration of a new feature for alignment support."
            }
        ]
    },
    {
        "message_summary": "export document level (aligned and not-aligned)",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "export document level (aligned and not-aligned)"
            }
        ]
    },
    {
        "message_summary": "huge update including user fields, local and web import, IAA alignment, config files annotation, web scraping",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "local and web import, config files annotation, web scraping"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "add overview of all corpora and overview per corpus",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "Overview of all corpora and overview per corpus"
            }
        ]
    },
    {
        "message_summary": "import title in file header",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Unrelated": "import title in file header"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    },
    {
        "message_summary": "New URL structure, previous and next button, improved HTML structure, change log",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Integration Patterns": "New URL structure, previous and next button, improved HTML structure, change log"
            }
        ]
    },
    {
        "message_summary": "automatic transformations in evaluation added",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "automatic transformations in evaluation added"
            }
        ]
    },
    {
        "message_summary": "code clean up (new model structure) Part II",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "Code clean up with new model structure"
            }
        ]
    },
    {
        "message_summary": "code clean up (new model structure) Part I",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {
                "Maintenance": "code clean up (new model structure) Part I"
            }
        ]
    },
    {
        "message_summary": "No significant Pre-Trained Models activities mentioned.",
        "ptm_name": "",
        "ptm_version": "",
        "ptm_problem_addressed": "",
        "update_details": "",
        "replacement_info": "",
        "removal_details": "",
        "text": [
            {}
        ]
    }
]