repo_url,filepath,Creation Date,PR Comment,PR/Issue Number
github.com/nedap/deidentify,deidentify/tokenizer/tokenizer_de.py,2021-08-06T13:35:44Z,"Hi @bbieniek, thanks for adding this. The changes look good to me.

I noticed that the CI is failing. It seems to be a false-positive of pylint. I will try to address this issue as soon as possible and afterwards merge the PR.",60
github.com/nedap/deidentify,deidentify/tokenizer/tokenizer_de.py,2021-08-06T13:41:23Z,"Yes, I saw the CI error as well.
It looks like pylint in requirements-dev.txt is not constrained to a specific version.
Perhaps new rules were added in the latest version.

Thanks for addressing the issue :)",60
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2021-12-03T23:19:37Z,"This pull request **introduces 3 alerts** when merging 4b9e2247754e1b548d425b4c867d6dcd1d69f735 into e10928f5fa87ef2ac9eaabe28f1f2dc0e142b0de - [view on LGTM.com](https://lgtm.com/projects/g/capreolus-ir/capreolus/rev/pr-fade68b466dceeaf4924f6dacaf82b922827ca82)

**new alerts:**

* 1 for Unused local variable
* 1 for Unused import
* 1 for Variable defined multiple times",199
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2022-01-05T22:38:07Z,"This pull request **introduces 3 alerts** when merging bac04a02d67203a305c2fc0d623f751fb8dc7063 into e10928f5fa87ef2ac9eaabe28f1f2dc0e142b0de - [view on LGTM.com](https://lgtm.com/projects/g/capreolus-ir/capreolus/rev/pr-be1f6985507407df1576477646f5a41c1b7e8414)

**new alerts:**

* 1 for Unused local variable
* 1 for Unused import
* 1 for Variable defined multiple times",199
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2022-01-09T22:55:27Z,"This pull request **introduces 2 alerts** when merging 3e0c979af32603e65ebdc85201cbf983fe852873 into e10928f5fa87ef2ac9eaabe28f1f2dc0e142b0de - [view on LGTM.com](https://lgtm.com/projects/g/capreolus-ir/capreolus/rev/pr-890ac6c2d1f5da94b45a2470b7dac44612397cb4)

**new alerts:**

* 1 for Unused import
* 1 for Variable defined multiple times",199
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2022-01-10T00:26:23Z,"This pull request **introduces 2 alerts** when merging e9cf9a670f81c2bf784e96a0f2eee4763233cfbd into e10928f5fa87ef2ac9eaabe28f1f2dc0e142b0de - [view on LGTM.com](https://lgtm.com/projects/g/capreolus-ir/capreolus/rev/pr-2565307bea52253b22e5888e139bd77c8c090b7e)

**new alerts:**

* 1 for Unused import
* 1 for Variable defined multiple times",199
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2022-01-10T02:22:24Z,"This pull request **introduces 2 alerts** and **fixes 1** when merging 2ec75ad6dbd0b6e09d1d1ac332dac1902775b738 into e10928f5fa87ef2ac9eaabe28f1f2dc0e142b0de - [view on LGTM.com](https://lgtm.com/projects/g/capreolus-ir/capreolus/rev/pr-6d7d9d1fe9d7908d4643a97f75e09a7fb5806584)

**new alerts:**

* 1 for Unused import
* 1 for Variable defined multiple times

**fixed alerts:**

* 1 for Unused import",199
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2022-01-10T04:42:48Z,"This pull request **introduces 2 alerts** and **fixes 1** when merging c3edfe84dbeeceea17f9c7029c7a73058f7773b8 into e10928f5fa87ef2ac9eaabe28f1f2dc0e142b0de - [view on LGTM.com](https://lgtm.com/projects/g/capreolus-ir/capreolus/rev/pr-bf58550a16256a89431594dc5b3cea036603545b)

**new alerts:**

* 1 for Unused import
* 1 for Variable defined multiple times

**fixed alerts:**

* 1 for Unused import",199
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2022-01-10T17:43:31Z,"the PR looks good to me now. have run the LCE with nneg=4 and 7 at commit `bac04a0`, got score MRR@10 0.397 and 0.405 respectively. Running on the latest commit now.",199
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2022-01-10T18:11:03Z,"This pull request **introduces 2 alerts** and **fixes 1** when merging d068d012a5615cf4bea6f02ca0004fc562c898e8 into e10928f5fa87ef2ac9eaabe28f1f2dc0e142b0de - [view on LGTM.com](https://lgtm.com/projects/g/capreolus-ir/capreolus/rev/pr-04f3c5de184f3a2bc060da965e10b1d610cdabdd)

**new alerts:**

* 1 for Unused import
* 1 for Variable defined multiple times

**fixed alerts:**

* 1 for Unused import",199
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2022-01-11T17:17:03Z,"This pull request **introduces 2 alerts** and **fixes 1** when merging 319155f7899b67456392e05b4b002d16126b24b4 into e10928f5fa87ef2ac9eaabe28f1f2dc0e142b0de - [view on LGTM.com](https://lgtm.com/projects/g/capreolus-ir/capreolus/rev/pr-9783182daaccd61290a1e8e967a244ffef2da340)

**new alerts:**

* 1 for Unused import
* 1 for Variable defined multiple times

**fixed alerts:**

* 1 for Unused import",199
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2022-01-14T07:00:13Z,"This pull request **introduces 3 alerts** and **fixes 1** when merging 1b405b763912b00540dfdea0e9fad20bb13d7913 into e10928f5fa87ef2ac9eaabe28f1f2dc0e142b0de - [view on LGTM.com](https://lgtm.com/projects/g/capreolus-ir/capreolus/rev/pr-4570a04e35997696c749433374fad3606a2394cf)

**new alerts:**

* 2 for Unused import
* 1 for Variable defined multiple times

**fixed alerts:**

* 1 for Unused import",199
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2022-01-15T23:23:04Z,"This pull request **fixes 1 alert** when merging 0600a9aae5dceefe735bc214f88cdd256cbceea0 into e10928f5fa87ef2ac9eaabe28f1f2dc0e142b0de - [view on LGTM.com](https://lgtm.com/projects/g/capreolus-ir/capreolus/rev/pr-610e121dc3b16fc99e6d939a250d6a335d7a7f60)

**fixed alerts:**

* 1 for Unused import",199
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2022-01-27T16:22:33Z,"This pull request **fixes 1 alert** when merging dd3a1dfdf3c855be151e0f8a6878d2e2bc0a0caf into 2ba1b7e380cc3f6d6751f826ce8899841a1a56f9 - [view on LGTM.com](https://lgtm.com/projects/g/capreolus-ir/capreolus/rev/pr-f845bdb3f5e627873e9487b236f7036013d3200b)

**fixed alerts:**

* 1 for Unused import",199
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2022-02-09T04:44:14Z,"This pull request **fixes 1 alert** when merging 0600a9aae5dceefe735bc214f88cdd256cbceea0 into 2ba1b7e380cc3f6d6751f826ce8899841a1a56f9 - [view on LGTM.com](https://lgtm.com/projects/g/capreolus-ir/capreolus/rev/pr-191d40de26ffacb43f033f1a960133b027995992)

**fixed alerts:**

* 1 for Unused import",199
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2022-02-10T03:10:23Z,"This pull request **fixes 1 alert** when merging 27b081ec1a37d2af6afa6b61eb1cb7cc4ec9db1c into 2ba1b7e380cc3f6d6751f826ce8899841a1a56f9 - [view on LGTM.com](https://lgtm.com/projects/g/capreolus-ir/capreolus/rev/pr-c2623b6a890497dd2c22fe85690e47434fbfce6b)

**fixed alerts:**

* 1 for Unused import",199
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2022-02-11T18:05:15Z,"the model with monoELECTRA (nneg=31) is put on huggingface - https://huggingface.co/crystina-z/monoELECTRA_LCE_nneg31
with MRR@10 = 0.412",199
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2021-05-24T13:04:52Z,"scores reproduced by `python -m capreolus.run rerank.traineval with file=docs/reproduction/config_parade.txt` at this point:
```
2021-05-24 07:18:55,735 - INFO - capreolus.task.rerank.evaluate -                      P_20: 0.4751
2021-05-24 07:18:55,735 - INFO - capreolus.task.rerank.evaluate -                 judged_20: 0.9380
2021-05-24 07:18:55,735 - INFO - capreolus.task.rerank.evaluate -                       map: 0.3738
2021-05-24 07:18:55,735 - INFO - capreolus.task.rerank.evaluate -               ndcg_cut_20: 0.5535   <----
2021-05-24 07:18:55,735 - INFO - capreolus.task.rerank.evaluate -               recall_1000: 0.7761
2021-05-24 07:18:55,735 - INFO - capreolus.task.rerank.evaluate -                recip_rank: 0.8050
2021-05-24 07:18:55,735 - INFO - capreolus.task.rerank.evaluate - interpolated with alphas = [0.0, 0.15000000000000002, 0.15000000000000002, 0.2, 0.25]
2021-05-24 07:18:55,736 - INFO - capreolus.task.rerank.evaluate -             P_20 [interp]: 0.4835
2021-05-24 07:18:55,736 - INFO - capreolus.task.rerank.evaluate -        judged_20 [interp]: 0.9633
2021-05-24 07:18:55,736 - INFO - capreolus.task.rerank.evaluate -              map [interp]: 0.3901
2021-05-24 07:18:55,736 - INFO - capreolus.task.rerank.evaluate -      ndcg_cut_20 [interp]: 0.5633
2021-05-24 07:18:55,736 - INFO - capreolus.task.rerank.evaluate -      recall_1000 [interp]: 0.7761
2021-05-24 07:18:55,736 - INFO - capreolus.task.rerank.evaluate -       recip_rank [interp]: 0.8153
```

```
rerank: fold=s1 test metrics: P_1=0.620 P_10=0.496 P_20=0.425 P_5=0.568 judged_10=0.934 judged_20=0.913 judged_200=0.701 map=0.361 ndcg_cut_10=0.502 ndcg_cut_20=0.502 ndcg_cut_5=0.540 recall_100=0.516 recall_1000=0.755 recip_rank=0.710
rerank: fold=s2 test metrics: P_1=0.755 P_10=0.555 P_20=0.482 P_5=0.678 judged_10=0.967 judged_20=0.938 judged_200=0.695 map=0.377 ndcg_cut_10=0.592 ndcg_cut_20=0.564 ndcg_cut_5=0.658 recall_100=0.531 recall_1000=0.773 recip_rank=0.842
rerank: fold=s3 test metrics: P_1=0.780 P_10=0.606 P_20=0.512 P_5=0.696 judged_10=0.958 judged_20=0.935 judged_200=0.700 map=0.364 ndcg_cut_10=0.653 ndcg_cut_20=0.609 ndcg_cut_5=0.700 recall_100=0.488 recall_1000=0.727 recip_rank=0.861
rerank: fold=s4 test metrics: P_1=0.680 P_10=0.550 P_20=0.486 P_5=0.616 judged_10=0.978 judged_20=0.951 judged_200=0.729 map=0.392 ndcg_cut_10=0.553 ndcg_cut_20=0.543 ndcg_cut_5=0.574 recall_100=0.595 recall_1000=0.835 recip_rank=0.788
rerank: fold=s5 test metrics: P_1=0.740 P_10=0.560 P_20=0.471 P_5=0.644 judged_10=0.974 judged_20=0.953 judged_200=0.735 map=0.375 ndcg_cut_10=0.591 ndcg_cut_20=0.550 ndcg_cut_5=0.646 recall_100=0.545 recall_1000=0.789 recip_rank=0.825
```
",162
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2021-05-25T13:16:18Z,"scores reproduced by `python -m capreolus.run rerank.traineval with file=docs/reproduction/config_parade.txt reranker.trainer.amp=True` at this point:

```
2021-05-25 09:04:18,100 - INFO - capreolus.task.rerank.evaluate -                      P_20: 0.4819
2021-05-25 09:04:18,102 - INFO - capreolus.task.rerank.evaluate -                 judged_20: 0.9480
2021-05-25 09:04:18,103 - INFO - capreolus.task.rerank.evaluate -                       map: 0.3768
2021-05-25 09:04:18,104 - INFO - capreolus.task.rerank.evaluate -               ndcg_cut_20: 0.5551   <---
2021-05-25 09:04:18,107 - INFO - capreolus.task.rerank.evaluate -               recall_1000: 0.7761
2021-05-25 09:04:18,107 - INFO - capreolus.task.rerank.evaluate -                recip_rank: 0.7913
2021-05-25 09:04:18,108 - INFO - capreolus.task.rerank.evaluate - interpolated with alphas = [0.1, 0.1, 0.2, 0.2, 0.2]
2021-05-25 09:04:18,111 - INFO - capreolus.task.rerank.evaluate -             P_20 [interp]: 0.4942
2021-05-25 09:04:18,113 - INFO - capreolus.task.rerank.evaluate -        judged_20 [interp]: 0.9685
2021-05-25 09:04:18,115 - INFO - capreolus.task.rerank.evaluate -              map [interp]: 0.3903
2021-05-25 09:04:18,116 - INFO - capreolus.task.rerank.evaluate -      ndcg_cut_20 [interp]: 0.5681
2021-05-25 09:04:18,119 - INFO - capreolus.task.rerank.evaluate -      recall_1000 [interp]: 0.7761
2021-05-25 09:04:18,120 - INFO - capreolus.task.rerank.evaluate -       recip_rank [interp]: 0.7968
```

```
rerank: fold=s1 test metrics: P_1=0.560 P_10=0.504 P_20=0.442 P_5=0.544 judged_10=0.932 judged_20=0.919 judged_200=0.698 map=0.365 ndcg_cut_10=0.500 ndcg_cut_20=0.504 ndcg_cut_5=0.512 recall_100=0.518 recall_1000=0.755 recip_rank=0.664
rerank: fold=s2 test metrics: P_1=0.694 P_10=0.569 P_20=0.452 P_5=0.645 judged_10=0.971 judged_20=0.936 judged_200=0.695 map=0.367 ndcg_cut_10=0.589 ndcg_cut_20=0.536 ndcg_cut_5=0.629 recall_100=0.525 recall_1000=0.773 recip_rank=0.802
rerank: fold=s3 test metrics: P_1=0.720 P_10=0.612 P_20=0.508 P_5=0.676 judged_10=0.976 judged_20=0.941 judged_200=0.702 map=0.358 ndcg_cut_10=0.642 ndcg_cut_20=0.599 ndcg_cut_5=0.666 recall_100=0.490 recall_1000=0.727 recip_rank=0.825
rerank: fold=s4 test metrics: P_1=0.720 P_10=0.572 P_20=0.508 P_5=0.640 judged_10=0.990 judg ed_20=0.975 judged_200=0.755 map=0.403 ndcg_cut_10=0.567 ndcg_cut_20=0.561 ndcg_cut_5=0.592 recall_100=0.597 recall_1000=0.835 recip_rank=0.808
rerank: fold=s5 test metrics: P_1=0.800 P_10=0.594 P_20=0.499 P_5=0.652 judged_10=0.986 judged_20=0.969 judged_200=0.759 map=0.390 ndcg_cut_10=0.618 ndcg_cut_20=0.575 ndcg_cut_5=0.656 recall_100=0.554 recall_1000=0.789 recip_rank=0.858
```",162
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2021-05-26T00:01:01Z,"scores with `reranker.name=ptparade` (same config with `docs/reproduction/config_parade.txt`, but removing the `bertlr` and `trainer.loss` lines), `amp=both`
```
2021-05-26 01:47:48,367 - INFO - capreolus.task.rerank.evaluate -                      P_20: 0.4783
2021-05-26 01:47:48,367 - INFO - capreolus.task.rerank.evaluate -                 judged_20: 0.9480
2021-05-26 01:47:48,367 - INFO - capreolus.task.rerank.evaluate -                       map: 0.3666
2021-05-26 01:47:48,367 - INFO - capreolus.task.rerank.evaluate -               ndcg_cut_20: 0.5478   <---
2021-05-26 01:47:48,367 - INFO - capreolus.task.rerank.evaluate -               recall_1000: 0.7761
2021-05-26 01:47:48,367 - INFO - capreolus.task.rerank.evaluate -                recip_rank: 0.7963
2021-05-26 01:47:48,367 - INFO - capreolus.task.rerank.evaluate - interpolated with alphas = [0.05, 0.05, 0.1, 0.2, 0.25]
2021-05-26 01:47:48,367 - INFO - capreolus.task.rerank.evaluate -             P_20 [interp]: 0.4896
2021-05-26 01:47:48,367 - INFO - capreolus.task.rerank.evaluate -        judged_20 [interp]: 0.9639
2021-05-26 01:47:48,367 - INFO - capreolus.task.rerank.evaluate -              map [interp]: 0.3782
2021-05-26 01:47:48,368 - INFO - capreolus.task.rerank.evaluate -      ndcg_cut_20 [interp]: 0.5580
2021-05-26 01:47:48,368 - INFO - capreolus.task.rerank.evaluate -      recall_1000 [interp]: 0.7761
2021-05-26 01:47:48,368 - INFO - capreolus.task.rerank.evaluate -       recip_rank [interp]: 0.7821
```


and score with `python rerank.traineval` (knrm on rob04):
```
2021-05-25 17:26:12,834 - INFO - capreolus.task.rerank.evaluate -                      P_20: 0.3293
2021-05-25 17:26:12,834 - INFO - capreolus.task.rerank.evaluate -                 judged_20: 0.9384
2021-05-25 17:26:12,834 - INFO - capreolus.task.rerank.evaluate -                judged_200: 0.7469
2021-05-25 17:26:12,834 - INFO - capreolus.task.rerank.evaluate -                       map: 0.2325
2021-05-25 17:26:12,834 - INFO - capreolus.task.rerank.evaluate -               ndcg_cut_20: 0.3859   <---
2021-05-25 17:26:12,835 - INFO - capreolus.task.rerank.evaluate -               recall_1000: 0.6989
2021-05-25 17:26:12,835 - INFO - capreolus.task.rerank.evaluate -                recip_rank: 0.6545
2021-05-25 17:26:12,835 - INFO - capreolus.task.rerank.evaluate - interpolated with alphas = [0.05, 0.45, 0.5, 0.65, 0.7000000000000001]
2021-05-25 17:26:12,835 - INFO - capreolus.task.rerank.evaluate -             P_20 [interp]: 0.3725
2021-05-25 17:26:12,835 - INFO - capreolus.task.rerank.evaluate -        judged_20 [interp]: 0.9763
2021-05-25 17:26:12,835 - INFO - capreolus.task.rerank.evaluate -              map [interp]: 0.2625
2021-05-25 17:26:12,835 - INFO - capreolus.task.rerank.evaluate -      ndcg_cut_20 [interp]: 0.4350   <---
2021-05-25 17:26:12,835 - INFO - capreolus.task.rerank.evaluate -      recall_1000 [interp]: 0.6989
2021-05-25 17:26:12,835 - INFO - capreolus.task.rerank.evaluate -       recip_rank [interp]: 0.6981
```",162
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2021-05-29T20:11:45Z,"using torch==1.8.1 seems to decrease the score a bit on my end:
the score of running the command below are (on the latest commit):
```
python -m capreolus.run rerank.traineval with file=docs/reproduction/config_paradept.txt reranker.trainer.amp=both
```

`torch` version | mAP | P@20 | NDCG@20
-- | -- | -- | --
1.6 | 0.3687 | 0.4851 | 0.5533
1.7 | 0.3687 | 0.4851 | 0.5533
1.8 | 0.3666 | 0.4783 | 0.5478

(btw I've run the experiment for torch-1.8 twice, and the results are exactly the same)",162
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-07-17T12:52:02Z,"This pull request **introduces 7 alerts** when merging e6d17478e2fcd1bb878dd32aa8d6ff64cbdf70af into b31f2ab324b7add54a5598a549618f9cf9eaa407 - [view on LGTM.com](https://lgtm.com/projects/g/capreolus-ir/capreolus/rev/pr-60c47e1482851acd163137d06aedc6d3325bde28)

**new alerts:**

* 7 for Unused import",77
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-07-02T11:02:11Z,"This pull request **fixes 53 alerts** when merging a2839fa50137e62ac3a3fb34ab3999fcce5bda4e into 75cd2421246e4bd0fed65b203d8813a23727c7e0 - [view on LGTM.com](https://lgtm.com/projects/g/capreolus-ir/capreolus/rev/pr-48486da144401c30fed876746fdf0f06fa6f98a3)

**fixed alerts:**

* 47 for Unused import
* 3 for Unused local variable
* 1 for Unnecessary &#39;else&#39; clause in loop
* 1 for Suspicious unused loop iteration variable
* 1 for Module is imported with &#39;import&#39; and &#39;import from&#39;",72
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-05-29T23:40:34Z,"any suggestions where to pass this from? add a 'doc_to_exclude' in `query_from_file ` parameter would make it clumsy for all the other searchers since they can't really do anything with it; (or we can refactor all the searcher to make all of them support doc filtering)

or another way, does it make sense to let searcher depends on benchmark? since sometimes the `topicreader` might not be `trec` but depends on the type of topic_fn in benchmark. say there we could also use `-topicreader Covid`. ",47
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-05-28T09:56:22Z,"> 5. support transfer learning?, i.e. use different dataset (collection+benchmark) at training & test stage

We will want to do this, but I think we can handle it in a generic way outside the dataset

> 6. udel query generator?

Good catch. Can we add this?",47
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-05-29T23:45:37Z,and since the covid dataset is 80% done (only the paragraph index is not supported now); shall we start to try some methods that can be done only with this? Then at the same time I'll also add the other dataset in,47
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-05-29T23:40:34Z,"any suggestions where to pass this from? add a 'doc_to_exclude' in `query_from_file ` parameter would make it clumsy for all the other searchers since they can't really do anything with it; (or we can refactor all the searcher to make all of them support doc filtering)

or another way, does it make sense to let searcher depends on benchmark? since sometimes the `topicreader` might not be `trec` but depends on the type of topic_fn in benchmark. say there we could also use `-topicreader Covid`. ",47
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-05-28T09:56:22Z,"> 5. support transfer learning?, i.e. use different dataset (collection+benchmark) at training & test stage

We will want to do this, but I think we can handle it in a generic way outside the dataset

> 6. udel query generator?

Good catch. Can we add this?",47
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-05-29T23:45:37Z,and since the covid dataset is 80% done (only the paragraph index is not supported now); shall we start to try some methods that can be done only with this? Then at the same time I'll also add the other dataset in,47
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-27T18:33:00Z,Msmarco,38
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-27T18:33:44Z,New caching logic,38
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-27T18:35:34Z,The new config flags,38
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-27T18:37:31Z,No longer uses git lfs. The caveat is that we should remember to update the link if folds/qrels ever change or if we add a new dataset. This is not really that much of a big deal since the unit tests only make use of the dummy dataset and the dummy dataset would never really change.,38
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-31T15:30:16Z,Is this used anywhere?,38
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-31T15:32:54Z,"I think this isn't used -- it was before the rewrite, but now it's a config option of the tokenizer dependency",38
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-31T15:34:34Z,Good catch. Will fix in a separate PR cleaning up the pipeline init,38
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-31T15:41:10Z,"Maybe this should be based on `niters` rather than `iters_so_far`, so that the same iters are checked against the validation set even if `fastforward=True` causes training to be resumed?",38
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-31T16:05:34Z,No I was copy pasting things from the old code. ,38
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-27T18:33:00Z,Msmarco,38
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-27T18:33:44Z,New caching logic,38
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-27T18:35:34Z,The new config flags,38
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-27T18:37:31Z,No longer uses git lfs. The caveat is that we should remember to update the link if folds/qrels ever change or if we add a new dataset. This is not really that much of a big deal since the unit tests only make use of the dummy dataset and the dummy dataset would never really change.,38
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-31T15:30:16Z,Is this used anywhere?,38
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-31T15:32:54Z,"I think this isn't used -- it was before the rewrite, but now it's a config option of the tokenizer dependency",38
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-31T15:34:34Z,Good catch. Will fix in a separate PR cleaning up the pipeline init,38
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-31T15:41:10Z,"Maybe this should be based on `niters` rather than `iters_so_far`, so that the same iters are checked against the validation set even if `fastforward=True` causes training to be resumed?",38
github.com/capreolus-ir/capreolus,capreolus/utils/common.py,2020-03-31T16:05:34Z,No I was copy pasting things from the old code. ,38
github.com/andrewrosss/rake-spacy,rake_spacy/rake.py,2020-09-15T06:27:25Z,"# [Codecov](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=h1) Report
> :exclamation: No coverage uploaded for pull request base (`master@3e365a5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8/graphs/tree.svg?width=650&height=150&src=pr&token=JV5LGKM3LZ)](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##             master       #8   +/-   ##
=========================================
  Coverage          ?   86.74%           
=========================================
  Files             ?        8           
  Lines             ?      181           
  Branches          ?        0           
=========================================
  Hits              ?      157           
  Misses            ?       24           
  Partials          ?        0           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=footer). Last update [3e365a5...8010737](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",8
github.com/andrewrosss/rake-spacy,rake_spacy/rake.py,2020-09-15T06:27:25Z,"# [Codecov](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=h1) Report
> :exclamation: No coverage uploaded for pull request base (`master@3e365a5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8/graphs/tree.svg?width=650&height=150&src=pr&token=JV5LGKM3LZ)](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##             master       #8   +/-   ##
=========================================
  Coverage          ?   86.74%           
=========================================
  Files             ?        8           
  Lines             ?      181           
  Branches          ?        0           
=========================================
  Hits              ?      157           
  Misses            ?       24           
  Partials          ?        0           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=footer). Last update [3e365a5...8010737](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",8
github.com/andrewrosss/rake-spacy,rake_spacy/rake.py,2020-09-15T06:27:25Z,"# [Codecov](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=h1) Report
> :exclamation: No coverage uploaded for pull request base (`master@3e365a5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8/graphs/tree.svg?width=650&height=150&src=pr&token=JV5LGKM3LZ)](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##             master       #8   +/-   ##
=========================================
  Coverage          ?   86.74%           
=========================================
  Files             ?        8           
  Lines             ?      181           
  Branches          ?        0           
=========================================
  Hits              ?      157           
  Misses            ?       24           
  Partials          ?        0           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=footer). Last update [3e365a5...8010737](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",8
github.com/andrewrosss/rake-spacy,tests/conftest.py,2020-09-15T06:27:25Z,"# [Codecov](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=h1) Report
> :exclamation: No coverage uploaded for pull request base (`master@3e365a5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8/graphs/tree.svg?width=650&height=150&src=pr&token=JV5LGKM3LZ)](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##             master       #8   +/-   ##
=========================================
  Coverage          ?   86.74%           
=========================================
  Files             ?        8           
  Lines             ?      181           
  Branches          ?        0           
=========================================
  Hits              ?      157           
  Misses            ?       24           
  Partials          ?        0           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=footer). Last update [3e365a5...8010737](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",8
github.com/andrewrosss/rake-spacy,tests/conftest.py,2020-09-15T06:27:25Z,"# [Codecov](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=h1) Report
> :exclamation: No coverage uploaded for pull request base (`master@3e365a5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8/graphs/tree.svg?width=650&height=150&src=pr&token=JV5LGKM3LZ)](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##             master       #8   +/-   ##
=========================================
  Coverage          ?   86.74%           
=========================================
  Files             ?        8           
  Lines             ?      181           
  Branches          ?        0           
=========================================
  Hits              ?      157           
  Misses            ?       24           
  Partials          ?        0           
```



------

[Continue to review full report at Codecov](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=footer). Last update [3e365a5...8010737](https://codecov.io/gh/andrewrosss/rake-spacy/pull/8?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",8
github.com/vseloved/prj-nlp-2020,students/IgorBurian/10-vectors/vectors.py,2020-05-23T12:51:37Z,"Ще шкода, що не спробував поекспериментувати з векторами документу.
Оцінка: 90 ",122
github.com/vseloved/prj-nlp-2020,students/IgorBurian/10-vectors/vectors.py,2020-05-23T15:58:59Z,"@vseloved дякую за коментарі!

> використання class_weight=balanced навчання у вcіх класифікаторах, очевидно, погано вплинуло на якість, через наявність переважної кількості малорепрезентованих класів. Тому, в такій задачі треба шукати якісь складніші шляхи, ніж 1 класифікатор на все.

Зрозумів! А щоб можна було спробувати? Можливо є роботи інших студентів які можна було б взяти за приклад?

> Ще шкода, що не спробував поекспериментувати з векторами документу.

А які саме експерименти я б міг зробити? Підбір параметрів doc2vec? Інші вектори з lang-uk? Чи річ про щось інше?",122
github.com/vseloved/prj-nlp-2020,students/IgorBurian/10-vectors/vectors.py,2020-05-31T16:10:19Z,Написав у загальних висновках в слеку трохи,122
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework4/sparql.py,2020-06-13T12:48:19Z,Гарна робота. Напишу кілька коментарів у чаті вже :) ,154
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/04-homework/parse.py,2020-04-11T18:34:15Z,"> Гарна робота! А як щодо курсового?

Все силы на курсовой сейчас! 


> Гарна робота, мені сподобався підхід до розробки правил. Також дякую за зрозумілий опис.
> Єдине питання по вимірюванню точності: ти рахуєш суму поділити на загальну кількість гонок. (до речі, ти в останньому коміті пишеш 25%->35%, але не оновив це у ноутбуку). А, може, на сторінці Шумахера перелічені в тексті не всі гонки, де він досяг якось результату? Бо виглядає дивно, що ти зміг знайти тільки 46 гонок з 91-ї. Тут точно нема проблеми?
> P.S. Можна було б ще попарсити записи у Вікіпедії про ті всі сезони F1 і перевірити якість на них. Тоді був би повний комплект

да, многие гонки имеют формат описания где очень турдно выкопать кто-же выиграл. Думаю это связано с тем, что автор добавляет результаты в инфобокс а в основном тексте пишет только моменты которые он нашёл интересными. Больше всего этим грешит автор  который пришет про гп Испании :)), например 
```
Schumacher got a perfect start despite the green light failing to illuminate. He led from start to finish on a two stop strategy. Team mate Herbert memorably left the pits with the rear jack attached to his car. This was not the only drama in the pit lane as Gachot suffered a small refuelling fire when pulling away from his second stop. 
``` 
т.е. нужно анализировать окном больше чем одно предложение. Что абсолютно doable но в данный момент уже будут направлять все силы на курсовой. ",58
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/04-homework/parse.py,2020-04-16T09:58:26Z,Оцінка: 70. Бо є куди покращувати якість і ітерувати (не вистачає хоча б однієї ітерації ще),58
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/04-homework/parse.py,2020-04-11T18:34:15Z,"> Гарна робота! А як щодо курсового?

Все силы на курсовой сейчас! 


> Гарна робота, мені сподобався підхід до розробки правил. Також дякую за зрозумілий опис.
> Єдине питання по вимірюванню точності: ти рахуєш суму поділити на загальну кількість гонок. (до речі, ти в останньому коміті пишеш 25%->35%, але не оновив це у ноутбуку). А, може, на сторінці Шумахера перелічені в тексті не всі гонки, де він досяг якось результату? Бо виглядає дивно, що ти зміг знайти тільки 46 гонок з 91-ї. Тут точно нема проблеми?
> P.S. Можна було б ще попарсити записи у Вікіпедії про ті всі сезони F1 і перевірити якість на них. Тоді був би повний комплект

да, многие гонки имеют формат описания где очень турдно выкопать кто-же выиграл. Думаю это связано с тем, что автор добавляет результаты в инфобокс а в основном тексте пишет только моменты которые он нашёл интересными. Больше всего этим грешит автор  который пришет про гп Испании :)), например 
```
Schumacher got a perfect start despite the green light failing to illuminate. He led from start to finish on a two stop strategy. Team mate Herbert memorably left the pits with the rear jack attached to his car. This was not the only drama in the pit lane as Gachot suffered a small refuelling fire when pulling away from his second stop. 
``` 
т.е. нужно анализировать окном больше чем одно предложение. Что абсолютно doable но в данный момент уже будут направлять все силы на курсовой. ",58
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/04-homework/parse.py,2020-04-16T09:58:26Z,Оцінка: 70. Бо є куди покращувати якість і ітерувати (не вистачає хоча б однієї ітерації ще),58
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/04-homework/parse.py,2020-04-11T18:34:15Z,"> Гарна робота! А як щодо курсового?

Все силы на курсовой сейчас! 


> Гарна робота, мені сподобався підхід до розробки правил. Також дякую за зрозумілий опис.
> Єдине питання по вимірюванню точності: ти рахуєш суму поділити на загальну кількість гонок. (до речі, ти в останньому коміті пишеш 25%->35%, але не оновив це у ноутбуку). А, може, на сторінці Шумахера перелічені в тексті не всі гонки, де він досяг якось результату? Бо виглядає дивно, що ти зміг знайти тільки 46 гонок з 91-ї. Тут точно нема проблеми?
> P.S. Можна було б ще попарсити записи у Вікіпедії про ті всі сезони F1 і перевірити якість на них. Тоді був би повний комплект

да, многие гонки имеют формат описания где очень турдно выкопать кто-же выиграл. Думаю это связано с тем, что автор добавляет результаты в инфобокс а в основном тексте пишет только моменты которые он нашёл интересными. Больше всего этим грешит автор  который пришет про гп Испании :)), например 
```
Schumacher got a perfect start despite the green light failing to illuminate. He led from start to finish on a two stop strategy. Team mate Herbert memorably left the pits with the rear jack attached to his car. This was not the only drama in the pit lane as Gachot suffered a small refuelling fire when pulling away from his second stop. 
``` 
т.е. нужно анализировать окном больше чем одно предложение. Что абсолютно doable но в данный момент уже будут направлять все силы на курсовой. ",58
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/04-homework/parse.py,2020-04-16T09:58:26Z,Оцінка: 70. Бо є куди покращувати якість і ітерувати (не вистачає хоча б однієї ітерації ще),58
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-27T21:22:12Z,"Не раджу використовувати маленьку модель, бо вона досить поганої якості. Краще використати середнього розміру - ""md"".",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-27T21:31:20Z,"Оцей рядок є причиною, чому ти не знайшов прикметників вищого і найвищого ступенів у заголовках.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-27T21:31:34Z,"Це не найбільш надійний спосіб, адже є такі прикметники як ""clever"", ""eager"", ""honest"", ""modest"" і багато інших. Які є ще варіанти зі spaCy:
- перевірити Penn-теги (JJR, JJS, RBR, RBS)
- порівняти слово з лемою",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-27T21:36:41Z,"Ти назбирав дуже мало колокацій, бо перевіряєш тут не лему слова, а словоформу. Тому коли в реченні було ""say"" з прислівником, ти його піймав, а ""said"", ""says"" та ""saying"" — ні.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-27T21:38:12Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.

Тобі і не шкода більшу модельку використати.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-27T21:40:09Z,"Це не дуже надійний спосіб пошуку прислівників для дієслова, бо вони не завжди будуть іти одразу після дієслова. Наприклад: _""He spoke about the issue calmly.""_

Набагато краще використати дерева залежностей для цього.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-27T21:41:47Z,"`if c.lower() in ""aeuio"":` :)",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-28T13:22:08Z,"Краще таки `""ly\b""`, щоб урахувати пунктуацію.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-28T13:23:00Z,Цей рядок вже зайвий.,17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-27T21:22:12Z,"Не раджу використовувати маленьку модель, бо вона досить поганої якості. Краще використати середнього розміру - ""md"".",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-27T21:31:20Z,"Оцей рядок є причиною, чому ти не знайшов прикметників вищого і найвищого ступенів у заголовках.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-27T21:31:34Z,"Це не найбільш надійний спосіб, адже є такі прикметники як ""clever"", ""eager"", ""honest"", ""modest"" і багато інших. Які є ще варіанти зі spaCy:
- перевірити Penn-теги (JJR, JJS, RBR, RBS)
- порівняти слово з лемою",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-27T21:36:41Z,"Ти назбирав дуже мало колокацій, бо перевіряєш тут не лему слова, а словоформу. Тому коли в реченні було ""say"" з прислівником, ти його піймав, а ""said"", ""says"" та ""saying"" — ні.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-27T21:38:12Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.

Тобі і не шкода більшу модельку використати.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-27T21:40:09Z,"Це не дуже надійний спосіб пошуку прислівників для дієслова, бо вони не завжди будуть іти одразу після дієслова. Наприклад: _""He spoke about the issue calmly.""_

Набагато краще використати дерева залежностей для цього.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-27T21:41:47Z,"`if c.lower() in ""aeuio"":` :)",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-28T13:22:08Z,"Краще таки `""ly\b""`, щоб урахувати пунктуацію.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/viral.py,2020-03-28T13:23:00Z,Цей рядок вже зайвий.,17
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:44:59Z,Тут і далі не врахована кінцева пунктуація після останнього слова.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:46:19Z,"Додай, будь ласка, вивід програми. Можна прямо тут коментарем.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:51:19Z,"Треба було ще вищий ступінь порівняння врахувати: better, smaller, more.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:52:01Z,"Одруківка: ""PESRON"".",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:57:31Z,"Користуйся, будь ласка, `.pos_` замість `.pos` і не треба буде прописувати числові ідентифікатори тегів.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:58:43Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T18:00:27Z,"Ти назбирав дуже мало колокацій, бо перевіряєш тут не лему слова, а словоформу. Тому коли в реченні було ""say"" з прислівником, ти його піймав, а ""said"", ""says"" та ""saying"" — ні.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T18:06:38Z,Ці три рядки (25-27) — це явно залишки якогось дебагу.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T18:08:19Z,"Замість того, щоб двічі ітерватися по реченню, можна було спершу знайти прикметник, тоді витягнути його `head` і тоді вирішити, чи запам'ятати цю пару.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T12:23:49Z,виправив # Header accuracy  90.00%,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T12:42:29Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T12:43:35Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T13:09:09Z,додав вищий ступінь,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T13:19:08Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T14:19:06Z,добавив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T15:07:18Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T15:08:35Z,"так, видалив",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T15:38:48Z,переписав,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-27T20:07:36Z,"На домашку згодиться, але цей алгоритм ненадійний, адже є такі прикметники як ""clever"", ""eager"", ""honest"", ""modest"" і багато інших. Які є ще варіанти зі spaCy:
- перевірити Penn-теги (JJR, JJS, RBR, RBS)
- порівняти слово з лемою
",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-27T20:04:44Z,"@yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-27T20:13:14Z,"> @yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.

@mariana-scorp забрав файл з 3ї домашки",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:44:59Z,Тут і далі не врахована кінцева пунктуація після останнього слова.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:46:19Z,"Додай, будь ласка, вивід програми. Можна прямо тут коментарем.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:51:19Z,"Треба було ще вищий ступінь порівняння врахувати: better, smaller, more.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:52:01Z,"Одруківка: ""PESRON"".",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:57:31Z,"Користуйся, будь ласка, `.pos_` замість `.pos` і не треба буде прописувати числові ідентифікатори тегів.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:58:43Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T18:00:27Z,"Ти назбирав дуже мало колокацій, бо перевіряєш тут не лему слова, а словоформу. Тому коли в реченні було ""say"" з прислівником, ти його піймав, а ""said"", ""says"" та ""saying"" — ні.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T18:06:38Z,Ці три рядки (25-27) — це явно залишки якогось дебагу.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T18:08:19Z,"Замість того, щоб двічі ітерватися по реченню, можна було спершу знайти прикметник, тоді витягнути його `head` і тоді вирішити, чи запам'ятати цю пару.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T12:23:49Z,виправив # Header accuracy  90.00%,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T12:42:29Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T12:43:35Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T13:09:09Z,додав вищий ступінь,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T13:19:08Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T14:19:06Z,добавив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T15:07:18Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T15:08:35Z,"так, видалив",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T15:38:48Z,переписав,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-27T20:07:36Z,"На домашку згодиться, але цей алгоритм ненадійний, адже є такі прикметники як ""clever"", ""eager"", ""honest"", ""modest"" і багато інших. Які є ще варіанти зі spaCy:
- перевірити Penn-теги (JJR, JJS, RBR, RBS)
- порівняти слово з лемою
",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-27T20:04:44Z,"@yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-27T20:13:14Z,"> @yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.

@mariana-scorp забрав файл з 3ї домашки",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:44:59Z,Тут і далі не врахована кінцева пунктуація після останнього слова.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:46:19Z,"Додай, будь ласка, вивід програми. Можна прямо тут коментарем.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:51:19Z,"Треба було ще вищий ступінь порівняння врахувати: better, smaller, more.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:52:01Z,"Одруківка: ""PESRON"".",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:57:31Z,"Користуйся, будь ласка, `.pos_` замість `.pos` і не треба буде прописувати числові ідентифікатори тегів.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T17:58:43Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T18:00:27Z,"Ти назбирав дуже мало колокацій, бо перевіряєш тут не лему слова, а словоформу. Тому коли в реченні було ""say"" з прислівником, ти його піймав, а ""said"", ""says"" та ""saying"" — ні.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T18:06:38Z,Ці три рядки (25-27) — це явно залишки якогось дебагу.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-25T18:08:19Z,"Замість того, щоб двічі ітерватися по реченню, можна було спершу знайти прикметник, тоді витягнути його `head` і тоді вирішити, чи запам'ятати цю пару.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T12:23:49Z,виправив # Header accuracy  90.00%,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T12:42:29Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T12:43:35Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T13:09:09Z,додав вищий ступінь,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T13:19:08Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T14:19:06Z,добавив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T15:07:18Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T15:08:35Z,"так, видалив",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-26T15:38:48Z,переписав,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-27T20:07:36Z,"На домашку згодиться, але цей алгоритм ненадійний, адже є такі прикметники як ""clever"", ""eager"", ""honest"", ""modest"" і багато інших. Які є ще варіанти зі spaCy:
- перевірити Penn-теги (JJR, JJS, RBR, RBS)
- порівняти слово з лемою
",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-27T20:04:44Z,"@yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-2.py,2020-03-27T20:13:14Z,"> @yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.

@mariana-scorp забрав файл з 3ї домашки",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T17:44:59Z,Тут і далі не врахована кінцева пунктуація після останнього слова.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T17:46:19Z,"Додай, будь ласка, вивід програми. Можна прямо тут коментарем.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T17:51:19Z,"Треба було ще вищий ступінь порівняння врахувати: better, smaller, more.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T17:52:01Z,"Одруківка: ""PESRON"".",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T17:57:31Z,"Користуйся, будь ласка, `.pos_` замість `.pos` і не треба буде прописувати числові ідентифікатори тегів.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T17:58:43Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T18:00:27Z,"Ти назбирав дуже мало колокацій, бо перевіряєш тут не лему слова, а словоформу. Тому коли в реченні було ""say"" з прислівником, ти його піймав, а ""said"", ""says"" та ""saying"" — ні.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T18:06:38Z,Ці три рядки (25-27) — це явно залишки якогось дебагу.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T18:08:19Z,"Замість того, щоб двічі ітерватися по реченню, можна було спершу знайти прикметник, тоді витягнути його `head` і тоді вирішити, чи запам'ятати цю пару.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T12:23:49Z,виправив # Header accuracy  90.00%,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T12:42:29Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T12:43:35Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T13:09:09Z,додав вищий ступінь,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T13:19:08Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T14:19:06Z,добавив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T15:07:18Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T15:08:35Z,"так, видалив",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T15:38:48Z,переписав,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-27T20:07:36Z,"На домашку згодиться, але цей алгоритм ненадійний, адже є такі прикметники як ""clever"", ""eager"", ""honest"", ""modest"" і багато інших. Які є ще варіанти зі spaCy:
- перевірити Penn-теги (JJR, JJS, RBR, RBS)
- порівняти слово з лемою
",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-27T20:04:44Z,"@yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-27T20:13:14Z,"> @yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.

@mariana-scorp забрав файл з 3ї домашки",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T17:44:59Z,Тут і далі не врахована кінцева пунктуація після останнього слова.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T17:46:19Z,"Додай, будь ласка, вивід програми. Можна прямо тут коментарем.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T17:51:19Z,"Треба було ще вищий ступінь порівняння врахувати: better, smaller, more.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T17:52:01Z,"Одруківка: ""PESRON"".",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T17:57:31Z,"Користуйся, будь ласка, `.pos_` замість `.pos` і не треба буде прописувати числові ідентифікатори тегів.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T17:58:43Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T18:00:27Z,"Ти назбирав дуже мало колокацій, бо перевіряєш тут не лему слова, а словоформу. Тому коли в реченні було ""say"" з прислівником, ти його піймав, а ""said"", ""says"" та ""saying"" — ні.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T18:06:38Z,Ці три рядки (25-27) — це явно залишки якогось дебагу.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-25T18:08:19Z,"Замість того, щоб двічі ітерватися по реченню, можна було спершу знайти прикметник, тоді витягнути його `head` і тоді вирішити, чи запам'ятати цю пару.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T12:23:49Z,виправив # Header accuracy  90.00%,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T12:42:29Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T12:43:35Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T13:09:09Z,додав вищий ступінь,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T13:19:08Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T14:19:06Z,добавив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T15:07:18Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T15:08:35Z,"так, видалив",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-26T15:38:48Z,переписав,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-27T20:07:36Z,"На домашку згодиться, але цей алгоритм ненадійний, адже є такі прикметники як ""clever"", ""eager"", ""honest"", ""modest"" і багато інших. Які є ще варіанти зі spaCy:
- перевірити Penn-теги (JJR, JJS, RBR, RBS)
- порівняти слово з лемою
",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-27T20:04:44Z,"@yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-3.py,2020-03-27T20:13:14Z,"> @yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.

@mariana-scorp забрав файл з 3ї домашки",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework6/preprocess1.py,2020-05-31T18:05:45Z,"Знайшла покращене рішення. Годиться :) Молодець, що розібрався з даними і побудував класифікатор!

Було б добре ще подивитись на топ фічі. Ну і шкода, що до енграмів не добрався. ",145
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework6/preprocess1.py,2020-05-31T18:05:45Z,"Знайшла покращене рішення. Годиться :) Молодець, що розібрався з даними і побудував класифікатор!

Було б добре ще подивитись на топ фічі. Ну і шкода, що до енграмів не добрався. ",145
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-27T21:22:12Z,"Не раджу використовувати маленьку модель, бо вона досить поганої якості. Краще використати середнього розміру - ""md"".",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-27T21:31:20Z,"Оцей рядок є причиною, чому ти не знайшов прикметників вищого і найвищого ступенів у заголовках.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-27T21:31:34Z,"Це не найбільш надійний спосіб, адже є такі прикметники як ""clever"", ""eager"", ""honest"", ""modest"" і багато інших. Які є ще варіанти зі spaCy:
- перевірити Penn-теги (JJR, JJS, RBR, RBS)
- порівняти слово з лемою",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-27T21:36:41Z,"Ти назбирав дуже мало колокацій, бо перевіряєш тут не лему слова, а словоформу. Тому коли в реченні було ""say"" з прислівником, ти його піймав, а ""said"", ""says"" та ""saying"" — ні.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-27T21:38:12Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.

Тобі і не шкода більшу модельку використати.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-27T21:40:09Z,"Це не дуже надійний спосіб пошуку прислівників для дієслова, бо вони не завжди будуть іти одразу після дієслова. Наприклад: _""He spoke about the issue calmly.""_

Набагато краще використати дерева залежностей для цього.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-27T21:41:47Z,"`if c.lower() in ""aeuio"":` :)",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-28T13:22:08Z,"Краще таки `""ly\b""`, щоб урахувати пунктуацію.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-28T13:23:00Z,Цей рядок вже зайвий.,17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-27T21:22:12Z,"Не раджу використовувати маленьку модель, бо вона досить поганої якості. Краще використати середнього розміру - ""md"".",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-27T21:31:20Z,"Оцей рядок є причиною, чому ти не знайшов прикметників вищого і найвищого ступенів у заголовках.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-27T21:31:34Z,"Це не найбільш надійний спосіб, адже є такі прикметники як ""clever"", ""eager"", ""honest"", ""modest"" і багато інших. Які є ще варіанти зі spaCy:
- перевірити Penn-теги (JJR, JJS, RBR, RBS)
- порівняти слово з лемою",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-27T21:36:41Z,"Ти назбирав дуже мало колокацій, бо перевіряєш тут не лему слова, а словоформу. Тому коли в реченні було ""say"" з прислівником, ти його піймав, а ""said"", ""says"" та ""saying"" — ні.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-27T21:38:12Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.

Тобі і не шкода більшу модельку використати.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-27T21:40:09Z,"Це не дуже надійний спосіб пошуку прислівників для дієслова, бо вони не завжди будуть іти одразу після дієслова. Наприклад: _""He spoke about the issue calmly.""_

Набагато краще використати дерева залежностей для цього.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-27T21:41:47Z,"`if c.lower() in ""aeuio"":` :)",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-28T13:22:08Z,"Краще таки `""ly\b""`, щоб урахувати пунктуацію.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/headlines.py,2020-03-28T13:23:00Z,Цей рядок вже зайвий.,17
github.com/vseloved/prj-nlp-2020,students/AlisaMansurova/10-vectors/10-vectors.py,2020-05-30T20:43:26Z,"Все зроблено на базовому рівні. Як видно з картинки, ось сильно розділити не вдалося :)
Оскільки особливих спроб покращення зроблено не було (якщо не вважати за таку групування всіх категорії ГВП/ХВП та різне), то загальна оцінка - 60 ",123
github.com/vseloved/prj-nlp-2020,students/AlisaMansurova/10-vectors/10-vectors.py,2020-05-30T20:43:26Z,"Все зроблено на базовому рівні. Як видно з картинки, ось сильно розділити не вдалося :)
Оскільки особливих спроб покращення зроблено не було (якщо не вважати за таку групування всіх категорії ГВП/ХВП та різне), то загальна оцінка - 60 ",123
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:44:59Z,Тут і далі не врахована кінцева пунктуація після останнього слова.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:46:19Z,"Додай, будь ласка, вивід програми. Можна прямо тут коментарем.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:51:19Z,"Треба було ще вищий ступінь порівняння врахувати: better, smaller, more.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:52:01Z,"Одруківка: ""PESRON"".",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:57:31Z,"Користуйся, будь ласка, `.pos_` замість `.pos` і не треба буде прописувати числові ідентифікатори тегів.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:58:43Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:00:27Z,"Ти назбирав дуже мало колокацій, бо перевіряєш тут не лему слова, а словоформу. Тому коли в реченні було ""say"" з прислівником, ти його піймав, а ""said"", ""says"" та ""saying"" — ні.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:06:38Z,Ці три рядки (25-27) — це явно залишки якогось дебагу.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:08:19Z,"Замість того, щоб двічі ітерватися по реченню, можна було спершу знайти прикметник, тоді витягнути його `head` і тоді вирішити, чи запам'ятати цю пару.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:23:49Z,виправив # Header accuracy  90.00%,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:42:29Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:43:35Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T13:09:09Z,додав вищий ступінь,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T13:19:08Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T14:19:06Z,добавив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:07:18Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:08:35Z,"так, видалив",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:38:48Z,переписав,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:07:36Z,"На домашку згодиться, але цей алгоритм ненадійний, адже є такі прикметники як ""clever"", ""eager"", ""honest"", ""modest"" і багато інших. Які є ще варіанти зі spaCy:
- перевірити Penn-теги (JJR, JJS, RBR, RBS)
- порівняти слово з лемою
",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:04:44Z,"@yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:13:14Z,"> @yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.

@mariana-scorp забрав файл з 3ї домашки",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:44:59Z,Тут і далі не врахована кінцева пунктуація після останнього слова.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:46:19Z,"Додай, будь ласка, вивід програми. Можна прямо тут коментарем.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:51:19Z,"Треба було ще вищий ступінь порівняння врахувати: better, smaller, more.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:52:01Z,"Одруківка: ""PESRON"".",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:57:31Z,"Користуйся, будь ласка, `.pos_` замість `.pos` і не треба буде прописувати числові ідентифікатори тегів.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:58:43Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:00:27Z,"Ти назбирав дуже мало колокацій, бо перевіряєш тут не лему слова, а словоформу. Тому коли в реченні було ""say"" з прислівником, ти його піймав, а ""said"", ""says"" та ""saying"" — ні.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:06:38Z,Ці три рядки (25-27) — це явно залишки якогось дебагу.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:08:19Z,"Замість того, щоб двічі ітерватися по реченню, можна було спершу знайти прикметник, тоді витягнути його `head` і тоді вирішити, чи запам'ятати цю пару.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:23:49Z,виправив # Header accuracy  90.00%,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:42:29Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:43:35Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T13:09:09Z,додав вищий ступінь,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T13:19:08Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T14:19:06Z,добавив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:07:18Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:08:35Z,"так, видалив",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:38:48Z,переписав,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:07:36Z,"На домашку згодиться, але цей алгоритм ненадійний, адже є такі прикметники як ""clever"", ""eager"", ""honest"", ""modest"" і багато інших. Які є ще варіанти зі spaCy:
- перевірити Penn-теги (JJR, JJS, RBR, RBS)
- порівняти слово з лемою
",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:04:44Z,"@yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:13:14Z,"> @yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.

@mariana-scorp забрав файл з 3ї домашки",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:44:59Z,Тут і далі не врахована кінцева пунктуація після останнього слова.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:46:19Z,"Додай, будь ласка, вивід програми. Можна прямо тут коментарем.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:51:19Z,"Треба було ще вищий ступінь порівняння врахувати: better, smaller, more.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:52:01Z,"Одруківка: ""PESRON"".",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:57:31Z,"Користуйся, будь ласка, `.pos_` замість `.pos` і не треба буде прописувати числові ідентифікатори тегів.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:58:43Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:00:27Z,"Ти назбирав дуже мало колокацій, бо перевіряєш тут не лему слова, а словоформу. Тому коли в реченні було ""say"" з прислівником, ти його піймав, а ""said"", ""says"" та ""saying"" — ні.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:06:38Z,Ці три рядки (25-27) — це явно залишки якогось дебагу.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:08:19Z,"Замість того, щоб двічі ітерватися по реченню, можна було спершу знайти прикметник, тоді витягнути його `head` і тоді вирішити, чи запам'ятати цю пару.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:23:49Z,виправив # Header accuracy  90.00%,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:42:29Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:43:35Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T13:09:09Z,додав вищий ступінь,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T13:19:08Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T14:19:06Z,добавив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:07:18Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:08:35Z,"так, видалив",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:38:48Z,переписав,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:07:36Z,"На домашку згодиться, але цей алгоритм ненадійний, адже є такі прикметники як ""clever"", ""eager"", ""honest"", ""modest"" і багато інших. Які є ще варіанти зі spaCy:
- перевірити Penn-теги (JJR, JJS, RBR, RBS)
- порівняти слово з лемою
",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:04:44Z,"@yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:13:14Z,"> @yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.

@mariana-scorp забрав файл з 3ї домашки",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:44:59Z,Тут і далі не врахована кінцева пунктуація після останнього слова.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:46:19Z,"Додай, будь ласка, вивід програми. Можна прямо тут коментарем.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:51:19Z,"Треба було ще вищий ступінь порівняння врахувати: better, smaller, more.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:52:01Z,"Одруківка: ""PESRON"".",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:57:31Z,"Користуйся, будь ласка, `.pos_` замість `.pos` і не треба буде прописувати числові ідентифікатори тегів.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:58:43Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:00:27Z,"Ти назбирав дуже мало колокацій, бо перевіряєш тут не лему слова, а словоформу. Тому коли в реченні було ""say"" з прислівником, ти його піймав, а ""said"", ""says"" та ""saying"" — ні.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:06:38Z,Ці три рядки (25-27) — це явно залишки якогось дебагу.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:08:19Z,"Замість того, щоб двічі ітерватися по реченню, можна було спершу знайти прикметник, тоді витягнути його `head` і тоді вирішити, чи запам'ятати цю пару.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:23:49Z,виправив # Header accuracy  90.00%,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:42:29Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:43:35Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T13:09:09Z,додав вищий ступінь,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T13:19:08Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T14:19:06Z,добавив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:07:18Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:08:35Z,"так, видалив",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:38:48Z,переписав,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:07:36Z,"На домашку згодиться, але цей алгоритм ненадійний, адже є такі прикметники як ""clever"", ""eager"", ""honest"", ""modest"" і багато інших. Які є ще варіанти зі spaCy:
- перевірити Penn-теги (JJR, JJS, RBR, RBS)
- порівняти слово з лемою
",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:04:44Z,"@yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:13:14Z,"> @yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.

@mariana-scorp забрав файл з 3ї домашки",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:44:59Z,Тут і далі не врахована кінцева пунктуація після останнього слова.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:46:19Z,"Додай, будь ласка, вивід програми. Можна прямо тут коментарем.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:51:19Z,"Треба було ще вищий ступінь порівняння врахувати: better, smaller, more.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:52:01Z,"Одруківка: ""PESRON"".",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:57:31Z,"Користуйся, будь ласка, `.pos_` замість `.pos` і не треба буде прописувати числові ідентифікатори тегів.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:58:43Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:00:27Z,"Ти назбирав дуже мало колокацій, бо перевіряєш тут не лему слова, а словоформу. Тому коли в реченні було ""say"" з прислівником, ти його піймав, а ""said"", ""says"" та ""saying"" — ні.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:06:38Z,Ці три рядки (25-27) — це явно залишки якогось дебагу.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:08:19Z,"Замість того, щоб двічі ітерватися по реченню, можна було спершу знайти прикметник, тоді витягнути його `head` і тоді вирішити, чи запам'ятати цю пару.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:23:49Z,виправив # Header accuracy  90.00%,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:42:29Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:43:35Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T13:09:09Z,додав вищий ступінь,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T13:19:08Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T14:19:06Z,добавив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:07:18Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:08:35Z,"так, видалив",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:38:48Z,переписав,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:07:36Z,"На домашку згодиться, але цей алгоритм ненадійний, адже є такі прикметники як ""clever"", ""eager"", ""honest"", ""modest"" і багато інших. Які є ще варіанти зі spaCy:
- перевірити Penn-теги (JJR, JJS, RBR, RBS)
- порівняти слово з лемою
",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:04:44Z,"@yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:13:14Z,"> @yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.

@mariana-scorp забрав файл з 3ї домашки",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:44:59Z,Тут і далі не врахована кінцева пунктуація після останнього слова.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:46:19Z,"Додай, будь ласка, вивід програми. Можна прямо тут коментарем.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:51:19Z,"Треба було ще вищий ступінь порівняння врахувати: better, smaller, more.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:52:01Z,"Одруківка: ""PESRON"".",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:57:31Z,"Користуйся, будь ласка, `.pos_` замість `.pos` і не треба буде прописувати числові ідентифікатори тегів.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T17:58:43Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:00:27Z,"Ти назбирав дуже мало колокацій, бо перевіряєш тут не лему слова, а словоформу. Тому коли в реченні було ""say"" з прислівником, ти його піймав, а ""said"", ""says"" та ""saying"" — ні.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:06:38Z,Ці три рядки (25-27) — це явно залишки якогось дебагу.,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-25T18:08:19Z,"Замість того, щоб двічі ітерватися по реченню, можна було спершу знайти прикметник, тоді витягнути його `head` і тоді вирішити, чи запам'ятати цю пару.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:23:49Z,виправив # Header accuracy  90.00%,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:42:29Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T12:43:35Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T13:09:09Z,додав вищий ступінь,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T13:19:08Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T14:19:06Z,добавив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:07:18Z,виправив,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:08:35Z,"так, видалив",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-26T15:38:48Z,переписав,33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:07:36Z,"На домашку згодиться, але цей алгоритм ненадійний, адже є такі прикметники як ""clever"", ""eager"", ""honest"", ""modest"" і багато інших. Які є ще варіанти зі spaCy:
- перевірити Penn-теги (JJR, JJS, RBR, RBS)
- порівняти слово з лемою
",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:04:44Z,"@yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.",33
github.com/vseloved/prj-nlp-2020,students/BohdanYatsyna/homework2/task-02-spacy.py,2020-03-27T20:13:14Z,"> @yatsinaba, сюди додався файл із третьої домашки. Його потрібно перенести в новий пул-ріквест. Тоді зможу змерджити цей.

@mariana-scorp забрав файл з 3ї домашки",33
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/10-word2vec/classifier.py,2020-05-25T06:09:08Z,"> Загалом, все ок. Єдине, у kNN треба було використовувати метрику не Мінковського, а cosine.

my bad. дякую",133
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-27T21:22:12Z,"Не раджу використовувати маленьку модель, бо вона досить поганої якості. Краще використати середнього розміру - ""md"".",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-27T21:31:20Z,"Оцей рядок є причиною, чому ти не знайшов прикметників вищого і найвищого ступенів у заголовках.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-27T21:31:34Z,"Це не найбільш надійний спосіб, адже є такі прикметники як ""clever"", ""eager"", ""honest"", ""modest"" і багато інших. Які є ще варіанти зі spaCy:
- перевірити Penn-теги (JJR, JJS, RBR, RBS)
- порівняти слово з лемою",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-27T21:36:41Z,"Ти назбирав дуже мало колокацій, бо перевіряєш тут не лему слова, а словоформу. Тому коли в реченні було ""say"" з прислівником, ти його піймав, а ""said"", ""says"" та ""saying"" — ні.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-27T21:38:12Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.

Тобі і не шкода більшу модельку використати.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-27T21:40:09Z,"Це не дуже надійний спосіб пошуку прислівників для дієслова, бо вони не завжди будуть іти одразу після дієслова. Наприклад: _""He spoke about the issue calmly.""_

Набагато краще використати дерева залежностей для цього.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-27T21:41:47Z,"`if c.lower() in ""aeuio"":` :)",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-28T13:22:08Z,"Краще таки `""ly\b""`, щоб урахувати пунктуацію.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-28T13:23:00Z,Цей рядок вже зайвий.,17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-27T21:22:12Z,"Не раджу використовувати маленьку модель, бо вона досить поганої якості. Краще використати середнього розміру - ""md"".",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-27T21:31:20Z,"Оцей рядок є причиною, чому ти не знайшов прикметників вищого і найвищого ступенів у заголовках.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-27T21:31:34Z,"Це не найбільш надійний спосіб, адже є такі прикметники як ""clever"", ""eager"", ""honest"", ""modest"" і багато інших. Які є ще варіанти зі spaCy:
- перевірити Penn-теги (JJR, JJS, RBR, RBS)
- порівняти слово з лемою",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-27T21:36:41Z,"Ти назбирав дуже мало колокацій, бо перевіряєш тут не лему слова, а словоформу. Тому коли в реченні було ""say"" з прислівником, ти його піймав, а ""said"", ""says"" та ""saying"" — ні.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-27T21:38:12Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.

Тобі і не шкода більшу модельку використати.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-27T21:40:09Z,"Це не дуже надійний спосіб пошуку прислівників для дієслова, бо вони не завжди будуть іти одразу після дієслова. Наприклад: _""He spoke about the issue calmly.""_

Набагато краще використати дерева залежностей для цього.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-27T21:41:47Z,"`if c.lower() in ""aeuio"":` :)",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-28T13:22:08Z,"Краще таки `""ly\b""`, щоб урахувати пунктуацію.",17
github.com/vseloved/prj-nlp-2020,students/YehorShapanov/02-homework/colocations_en.py,2020-03-28T13:23:00Z,Цей рядок вже зайвий.,17
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/04-nlp-full-circle/parse_wiki.py,2020-04-08T18:23:39Z,"Гарний аналіз, але дуже вже маленька вибірка. Варто було взяти більше даних. Наприклад, всі харківські метал-гурти.

Чи є ідеї щодо метрик для курсового?",61
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/04-nlp-full-circle/parse_wiki.py,2020-04-09T14:06:46Z,"¯\_(ツ)_/¯ згоден, на більшій вибірці було б  ̶с̶к̶л̶а̶д̶н̶і̶ш̶е̶ цікавіше (:

З приводу метрик - я поки ще з ними не розібрався ): ",61
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/04-nlp-full-circle/parse_wiki.py,2020-04-20T11:26:04Z,"@holdbar, додай, будь ласка, вимірювання якості і змерджимо. Я розумію, що 12 прикладів можна і руками порахувати, але в цій домашці розробка метрики, яка враховує часткові збіги, є власне важливим моментом.",61
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/04-nlp-full-circle/parse_wiki.py,2020-04-21T06:57:26Z,постараюся сьогодні-завтра додати,61
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/04-nlp-full-circle/parse_wiki.py,2020-04-22T09:16:57Z,@holdbar варто чекати оновлень чи мерджити як є?,61
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/04-nlp-full-circle/parse_wiki.py,2020-04-22T11:39:38Z,"хочу сьогодні доробити

ср, 22 квіт. 2020 о 12:17 Vsevolod Dyomkin <notifications@github.com> пише:

> @holdbar <https://github.com/holdbar> варто чекати оновлень чи мерджити
> як є?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/vseloved/prj-nlp-2020/pull/61#issuecomment-617658299>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AFJY3HMTIZS26TZVLEM3OHLRN2YZRANCNFSM4L7CFBTA>
> .
>
",61
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/04-nlp-full-circle/parse_wiki.py,2020-04-22T15:19:18Z,"трохи не зрозумілий вивід, але, в кінці кінців, до мені дійшло. Думаю, не варто було домножати індивідуальні метрики на коефіцієнт. Тоді і виглядало би краще, і було б більше зрозуміло, наскільки якісно та чи інша працює (бо вага перезважує оцінку якості).
Фінальна оцінка: 50 (з 80).",61
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/04-nlp-full-circle/parse_wiki.py,2020-04-08T18:23:39Z,"Гарний аналіз, але дуже вже маленька вибірка. Варто було взяти більше даних. Наприклад, всі харківські метал-гурти.

Чи є ідеї щодо метрик для курсового?",61
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/04-nlp-full-circle/parse_wiki.py,2020-04-09T14:06:46Z,"¯\_(ツ)_/¯ згоден, на більшій вибірці було б  ̶с̶к̶л̶а̶д̶н̶і̶ш̶е̶ цікавіше (:

З приводу метрик - я поки ще з ними не розібрався ): ",61
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/04-nlp-full-circle/parse_wiki.py,2020-04-20T11:26:04Z,"@holdbar, додай, будь ласка, вимірювання якості і змерджимо. Я розумію, що 12 прикладів можна і руками порахувати, але в цій домашці розробка метрики, яка враховує часткові збіги, є власне важливим моментом.",61
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/04-nlp-full-circle/parse_wiki.py,2020-04-21T06:57:26Z,постараюся сьогодні-завтра додати,61
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/04-nlp-full-circle/parse_wiki.py,2020-04-22T09:16:57Z,@holdbar варто чекати оновлень чи мерджити як є?,61
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/04-nlp-full-circle/parse_wiki.py,2020-04-22T11:39:38Z,"хочу сьогодні доробити

ср, 22 квіт. 2020 о 12:17 Vsevolod Dyomkin <notifications@github.com> пише:

> @holdbar <https://github.com/holdbar> варто чекати оновлень чи мерджити
> як є?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/vseloved/prj-nlp-2020/pull/61#issuecomment-617658299>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AFJY3HMTIZS26TZVLEM3OHLRN2YZRANCNFSM4L7CFBTA>
> .
>
",61
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/04-nlp-full-circle/parse_wiki.py,2020-04-22T15:19:18Z,"трохи не зрозумілий вивід, але, в кінці кінців, до мені дійшло. Думаю, не варто було домножати індивідуальні метрики на коефіцієнт. Тоді і виглядало би краще, і було б більше зрозуміло, наскільки якісно та чи інша працює (бо вага перезважує оцінку якості).
Фінальна оцінка: 50 (з 80).",61
github.com/vseloved/prj-nlp-2020,students/DariaKarpenko/02-structural-lingvo/2-headlines.py,2020-03-25T15:19:59Z,Замість `is_notional_pos(t) == True` можна писати просто `is_notional_pos(t)`.,23
github.com/vseloved/prj-nlp-2020,students/DariaKarpenko/02-structural-lingvo/2-headlines.py,2020-03-25T15:22:57Z,"Не знайшла відповіді на цей пункт з домашки:

> 3. проженіть вашу програму на корпусі заголовків з The Examiner і вирахуйте, скільки заголовків там відформатовано за правилами (скільки заголовків залишились незмінними після форматування)

Додай, будь ласка.",23
github.com/vseloved/prj-nlp-2020,students/DariaKarpenko/02-structural-lingvo/2-headlines.py,2020-03-25T15:19:59Z,Замість `is_notional_pos(t) == True` можна писати просто `is_notional_pos(t)`.,23
github.com/vseloved/prj-nlp-2020,students/DariaKarpenko/02-structural-lingvo/2-headlines.py,2020-03-25T15:22:57Z,"Не знайшла відповіді на цей пункт з домашки:

> 3. проженіть вашу програму на корпусі заголовків з The Examiner і вирахуйте, скільки заголовків там відформатовано за правилами (скільки заголовків залишились незмінними після форматування)

Додай, будь ласка.",23
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/viral_news.py,2020-03-27T22:33:57Z,"Отут варто було врахувати слова, які вже написані великими літерами (наприклад, USA) та ""n't"" (яке тегується як прислівник).",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/viral_news.py,2020-03-27T22:36:53Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/viral_news.py,2020-03-27T22:38:38Z,"Щоб не робити два проходи по токенах, можна або зробити цикл по дітях дієслова (`.children`), або шукати спершу прислівник, а тоді перевіряти, чи його батьком є потрібне нам дієслово.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/viral_news.py,2020-03-27T22:43:30Z,"Тут треба було запам'ятовувати леми (`.normal_form`), бо інакше в результати потрапляє те саме словосполучення по кілька разів. У твоїх результатах: _великий начальник, великим начальником, великому начальникові, великого начальника._",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/viral_news.py,2020-03-27T22:18:38Z,"Видали, будь ласка, `data/`, щоб не роздувати репозиторій.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/viral_news.py,2020-03-27T22:33:57Z,"Отут варто було врахувати слова, які вже написані великими літерами (наприклад, USA) та ""n't"" (яке тегується як прислівник).",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/viral_news.py,2020-03-27T22:36:53Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/viral_news.py,2020-03-27T22:38:38Z,"Щоб не робити два проходи по токенах, можна або зробити цикл по дітях дієслова (`.children`), або шукати спершу прислівник, а тоді перевіряти, чи його батьком є потрібне нам дієслово.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/viral_news.py,2020-03-27T22:43:30Z,"Тут треба було запам'ятовувати леми (`.normal_form`), бо інакше в результати потрапляє те саме словосполучення по кілька разів. У твоїх результатах: _великий начальник, великим начальником, великому начальникові, великого начальника._",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/viral_news.py,2020-03-27T22:18:38Z,"Видали, будь ласка, `data/`, щоб не роздувати репозиторій.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/viral_news.py,2020-03-27T22:33:57Z,"Отут варто було врахувати слова, які вже написані великими літерами (наприклад, USA) та ""n't"" (яке тегується як прислівник).",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/viral_news.py,2020-03-27T22:36:53Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/viral_news.py,2020-03-27T22:38:38Z,"Щоб не робити два проходи по токенах, можна або зробити цикл по дітях дієслова (`.children`), або шукати спершу прислівник, а тоді перевіряти, чи його батьком є потрібне нам дієслово.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/viral_news.py,2020-03-27T22:43:30Z,"Тут треба було запам'ятовувати леми (`.normal_form`), бо інакше в результати потрапляє те саме словосполучення по кілька разів. У твоїх результатах: _великий начальник, великим начальником, великому начальникові, великого начальника._",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/viral_news.py,2020-03-27T22:18:38Z,"Видали, будь ласка, `data/`, щоб не роздувати репозиторій.",29
github.com/vseloved/prj-nlp-2020,students/DariaKarpenko/02-structural-lingvo/3-collocations-eng.py,2020-03-25T15:31:44Z,"Додай, будь ласка, текстовий файл з виводом програми:

> 5. збережіть програму та результати аналізу на корпусі (вивід) у директорії з вашим іменем",28
github.com/vseloved/prj-nlp-2020,students/DariaKarpenko/02-structural-lingvo/3-collocations-eng.py,2020-03-25T15:33:45Z,"У цьому рішенні є один момент — воно не розрізняє сурядних і підрядних дітей прислівника. Наприклад, у цих двох реченнях ""adequately"" має дітей-прислівників на ""ly"", але тільки в другому прикладі зв'язок до другого прислівника сурядний і він стосується дієслова:

_She implemented this really adequately._
_She implemented this adequately and consciously._",28
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:20:55Z,Цей файлик потрібно забрати з цього пул-ріквеста. Для кожної домашки треба створювати нову гілку з мастера.,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:25:19Z,"Так і має бути :) Стеммінг повинен прибирати словотворчі (derivational) афікси, а лематизація — лише формотворчі (inflectional).",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:25:53Z,"Я певно погано пояснювала, бо ці два типи ми розбирали на занятті. ;)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:47:34Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:52:28Z,"Оця ознака не дуже підходить для виявлення істот:
1. багато іменників-істот не є власними назвами (людина, вчитель, дядько, кіт тощо)
2. багато власних назв не є істотами (Сибір, ВКП, Амур)

У StanfordNLP можна використати граматичну ознаку Animacy=Anim.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T10:57:12Z,"Але для цього треба токени, або писати якийсь регулярний вираз з урахуванням пунктуації... Тобто або зовсім просто, або якось складно. Так наче красивіше. :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T10:58:06Z,"Так, розбирали. Я там далі написав, що забувся спочатку у лекції подивитись )) ",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T10:58:57Z,наче пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T11:00:27Z,"Але я тоді не розумію... Якщо прибрати і словотворчі і формотворчі, то залишиться корінь, так? Чим тоді стем відрізняється від кореня?",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T11:47:30Z,Стем - то і є корінь :) ,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T11:51:29Z,"Для цього не треба токени :) Ось весь регулярний вираз: `""ly\b""`. А час опрацювання корпусу зменшиться у кілька разів.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T13:44:30Z,"Я довго не могла зрозуміти, чому у тебе таі дивні результати вийшли. Аж ось вона, бажина! Там індексація з одиниці починається. Зміни на `s.words[w.head-1]` і перепрожени :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T14:11:19Z,пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T19:20:48Z,"добавив. та протестив що нічого не загубилося ) дійсно, ""трохи"" легше стало )",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:20:55Z,Цей файлик потрібно забрати з цього пул-ріквеста. Для кожної домашки треба створювати нову гілку з мастера.,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:25:19Z,"Так і має бути :) Стеммінг повинен прибирати словотворчі (derivational) афікси, а лематизація — лише формотворчі (inflectional).",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:25:53Z,"Я певно погано пояснювала, бо ці два типи ми розбирали на занятті. ;)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:47:34Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:52:28Z,"Оця ознака не дуже підходить для виявлення істот:
1. багато іменників-істот не є власними назвами (людина, вчитель, дядько, кіт тощо)
2. багато власних назв не є істотами (Сибір, ВКП, Амур)

У StanfordNLP можна використати граматичну ознаку Animacy=Anim.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T10:57:12Z,"Але для цього треба токени, або писати якийсь регулярний вираз з урахуванням пунктуації... Тобто або зовсім просто, або якось складно. Так наче красивіше. :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T10:58:06Z,"Так, розбирали. Я там далі написав, що забувся спочатку у лекції подивитись )) ",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T10:58:57Z,наче пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T11:00:27Z,"Але я тоді не розумію... Якщо прибрати і словотворчі і формотворчі, то залишиться корінь, так? Чим тоді стем відрізняється від кореня?",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T11:47:30Z,Стем - то і є корінь :) ,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T11:51:29Z,"Для цього не треба токени :) Ось весь регулярний вираз: `""ly\b""`. А час опрацювання корпусу зменшиться у кілька разів.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T13:44:30Z,"Я довго не могла зрозуміти, чому у тебе таі дивні результати вийшли. Аж ось вона, бажина! Там індексація з одиниці починається. Зміни на `s.words[w.head-1]` і перепрожени :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T14:11:19Z,пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T19:20:48Z,"добавив. та протестив що нічого не загубилося ) дійсно, ""трохи"" легше стало )",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:20:55Z,Цей файлик потрібно забрати з цього пул-ріквеста. Для кожної домашки треба створювати нову гілку з мастера.,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:25:19Z,"Так і має бути :) Стеммінг повинен прибирати словотворчі (derivational) афікси, а лематизація — лише формотворчі (inflectional).",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:25:53Z,"Я певно погано пояснювала, бо ці два типи ми розбирали на занятті. ;)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:47:34Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:52:28Z,"Оця ознака не дуже підходить для виявлення істот:
1. багато іменників-істот не є власними назвами (людина, вчитель, дядько, кіт тощо)
2. багато власних назв не є істотами (Сибір, ВКП, Амур)

У StanfordNLP можна використати граматичну ознаку Animacy=Anim.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T10:57:12Z,"Але для цього треба токени, або писати якийсь регулярний вираз з урахуванням пунктуації... Тобто або зовсім просто, або якось складно. Так наче красивіше. :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T10:58:06Z,"Так, розбирали. Я там далі написав, що забувся спочатку у лекції подивитись )) ",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T10:58:57Z,наче пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T11:00:27Z,"Але я тоді не розумію... Якщо прибрати і словотворчі і формотворчі, то залишиться корінь, так? Чим тоді стем відрізняється від кореня?",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T11:47:30Z,Стем - то і є корінь :) ,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T11:51:29Z,"Для цього не треба токени :) Ось весь регулярний вираз: `""ly\b""`. А час опрацювання корпусу зменшиться у кілька разів.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T13:44:30Z,"Я довго не могла зрозуміти, чому у тебе таі дивні результати вийшли. Аж ось вона, бажина! Там індексація з одиниці починається. Зміни на `s.words[w.head-1]` і перепрожени :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T14:11:19Z,пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T19:20:48Z,"добавив. та протестив що нічого не загубилося ) дійсно, ""трохи"" легше стало )",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:20:55Z,Цей файлик потрібно забрати з цього пул-ріквеста. Для кожної домашки треба створювати нову гілку з мастера.,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:25:19Z,"Так і має бути :) Стеммінг повинен прибирати словотворчі (derivational) афікси, а лематизація — лише формотворчі (inflectional).",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:25:53Z,"Я певно погано пояснювала, бо ці два типи ми розбирали на занятті. ;)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:47:34Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T00:52:28Z,"Оця ознака не дуже підходить для виявлення істот:
1. багато іменників-істот не є власними назвами (людина, вчитель, дядько, кіт тощо)
2. багато власних назв не є істотами (Сибір, ВКП, Амур)

У StanfordNLP можна використати граматичну ознаку Animacy=Anim.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T10:57:12Z,"Але для цього треба токени, або писати якийсь регулярний вираз з урахуванням пунктуації... Тобто або зовсім просто, або якось складно. Так наче красивіше. :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T10:58:06Z,"Так, розбирали. Я там далі написав, що забувся спочатку у лекції подивитись )) ",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T10:58:57Z,наче пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T11:00:27Z,"Але я тоді не розумію... Якщо прибрати і словотворчі і формотворчі, то залишиться корінь, так? Чим тоді стем відрізняється від кореня?",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T11:47:30Z,Стем - то і є корінь :) ,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T11:51:29Z,"Для цього не треба токени :) Ось весь регулярний вираз: `""ly\b""`. А час опрацювання корпусу зменшиться у кілька разів.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T13:44:30Z,"Я довго не могла зрозуміти, чому у тебе таі дивні результати вийшли. Аж ось вона, бажина! Там індексація з одиниці починається. Зміни на `s.words[w.head-1]` і перепрожени :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T14:11:19Z,пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.2.headlines.py,2020-03-28T19:20:48Z,"добавив. та протестив що нічого не загубилося ) дійсно, ""трохи"" легше стало )",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:20:55Z,Цей файлик потрібно забрати з цього пул-ріквеста. Для кожної домашки треба створювати нову гілку з мастера.,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:25:19Z,"Так і має бути :) Стеммінг повинен прибирати словотворчі (derivational) афікси, а лематизація — лише формотворчі (inflectional).",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:25:53Z,"Я певно погано пояснювала, бо ці два типи ми розбирали на занятті. ;)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:47:34Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:52:28Z,"Оця ознака не дуже підходить для виявлення істот:
1. багато іменників-істот не є власними назвами (людина, вчитель, дядько, кіт тощо)
2. багато власних назв не є істотами (Сибір, ВКП, Амур)

У StanfordNLP можна використати граматичну ознаку Animacy=Anim.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T10:57:12Z,"Але для цього треба токени, або писати якийсь регулярний вираз з урахуванням пунктуації... Тобто або зовсім просто, або якось складно. Так наче красивіше. :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T10:58:06Z,"Так, розбирали. Я там далі написав, що забувся спочатку у лекції подивитись )) ",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T10:58:57Z,наче пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T11:00:27Z,"Але я тоді не розумію... Якщо прибрати і словотворчі і формотворчі, то залишиться корінь, так? Чим тоді стем відрізняється від кореня?",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T11:47:30Z,Стем - то і є корінь :) ,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T11:51:29Z,"Для цього не треба токени :) Ось весь регулярний вираз: `""ly\b""`. А час опрацювання корпусу зменшиться у кілька разів.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T13:44:30Z,"Я довго не могла зрозуміти, чому у тебе таі дивні результати вийшли. Аж ось вона, бажина! Там індексація з одиниці починається. Зміни на `s.words[w.head-1]` і перепрожени :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T14:11:19Z,пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T19:20:48Z,"добавив. та протестив що нічого не загубилося ) дійсно, ""трохи"" легше стало )",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:20:55Z,Цей файлик потрібно забрати з цього пул-ріквеста. Для кожної домашки треба створювати нову гілку з мастера.,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:25:19Z,"Так і має бути :) Стеммінг повинен прибирати словотворчі (derivational) афікси, а лематизація — лише формотворчі (inflectional).",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:25:53Z,"Я певно погано пояснювала, бо ці два типи ми розбирали на занятті. ;)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:47:34Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:52:28Z,"Оця ознака не дуже підходить для виявлення істот:
1. багато іменників-істот не є власними назвами (людина, вчитель, дядько, кіт тощо)
2. багато власних назв не є істотами (Сибір, ВКП, Амур)

У StanfordNLP можна використати граматичну ознаку Animacy=Anim.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T10:57:12Z,"Але для цього треба токени, або писати якийсь регулярний вираз з урахуванням пунктуації... Тобто або зовсім просто, або якось складно. Так наче красивіше. :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T10:58:06Z,"Так, розбирали. Я там далі написав, що забувся спочатку у лекції подивитись )) ",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T10:58:57Z,наче пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T11:00:27Z,"Але я тоді не розумію... Якщо прибрати і словотворчі і формотворчі, то залишиться корінь, так? Чим тоді стем відрізняється від кореня?",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T11:47:30Z,Стем - то і є корінь :) ,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T11:51:29Z,"Для цього не треба токени :) Ось весь регулярний вираз: `""ly\b""`. А час опрацювання корпусу зменшиться у кілька разів.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T13:44:30Z,"Я довго не могла зрозуміти, чому у тебе таі дивні результати вийшли. Аж ось вона, бажина! Там індексація з одиниці починається. Зміни на `s.words[w.head-1]` і перепрожени :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T14:11:19Z,пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T19:20:48Z,"добавив. та протестив що нічого не загубилося ) дійсно, ""трохи"" легше стало )",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:20:55Z,Цей файлик потрібно забрати з цього пул-ріквеста. Для кожної домашки треба створювати нову гілку з мастера.,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:25:19Z,"Так і має бути :) Стеммінг повинен прибирати словотворчі (derivational) афікси, а лематизація — лише формотворчі (inflectional).",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:25:53Z,"Я певно погано пояснювала, бо ці два типи ми розбирали на занятті. ;)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:47:34Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:52:28Z,"Оця ознака не дуже підходить для виявлення істот:
1. багато іменників-істот не є власними назвами (людина, вчитель, дядько, кіт тощо)
2. багато власних назв не є істотами (Сибір, ВКП, Амур)

У StanfordNLP можна використати граматичну ознаку Animacy=Anim.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T10:57:12Z,"Але для цього треба токени, або писати якийсь регулярний вираз з урахуванням пунктуації... Тобто або зовсім просто, або якось складно. Так наче красивіше. :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T10:58:06Z,"Так, розбирали. Я там далі написав, що забувся спочатку у лекції подивитись )) ",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T10:58:57Z,наче пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T11:00:27Z,"Але я тоді не розумію... Якщо прибрати і словотворчі і формотворчі, то залишиться корінь, так? Чим тоді стем відрізняється від кореня?",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T11:47:30Z,Стем - то і є корінь :) ,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T11:51:29Z,"Для цього не треба токени :) Ось весь регулярний вираз: `""ly\b""`. А час опрацювання корпусу зменшиться у кілька разів.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T13:44:30Z,"Я довго не могла зрозуміти, чому у тебе таі дивні результати вийшли. Аж ось вона, бажина! Там індексація з одиниці починається. Зміни на `s.words[w.head-1]` і перепрожени :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T14:11:19Z,пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T19:20:48Z,"добавив. та протестив що нічого не загубилося ) дійсно, ""трохи"" легше стало )",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:20:55Z,Цей файлик потрібно забрати з цього пул-ріквеста. Для кожної домашки треба створювати нову гілку з мастера.,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:25:19Z,"Так і має бути :) Стеммінг повинен прибирати словотворчі (derivational) афікси, а лематизація — лише формотворчі (inflectional).",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:25:53Z,"Я певно погано пояснювала, бо ці два типи ми розбирали на занятті. ;)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:47:34Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:52:28Z,"Оця ознака не дуже підходить для виявлення істот:
1. багато іменників-істот не є власними назвами (людина, вчитель, дядько, кіт тощо)
2. багато власних назв не є істотами (Сибір, ВКП, Амур)

У StanfordNLP можна використати граматичну ознаку Animacy=Anim.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T10:57:12Z,"Але для цього треба токени, або писати якийсь регулярний вираз з урахуванням пунктуації... Тобто або зовсім просто, або якось складно. Так наче красивіше. :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T10:58:06Z,"Так, розбирали. Я там далі написав, що забувся спочатку у лекції подивитись )) ",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T10:58:57Z,наче пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T11:00:27Z,"Але я тоді не розумію... Якщо прибрати і словотворчі і формотворчі, то залишиться корінь, так? Чим тоді стем відрізняється від кореня?",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T11:47:30Z,Стем - то і є корінь :) ,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T11:51:29Z,"Для цього не треба токени :) Ось весь регулярний вираз: `""ly\b""`. А час опрацювання корпусу зменшиться у кілька разів.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T13:44:30Z,"Я довго не могла зрозуміти, чому у тебе таі дивні результати вийшли. Аж ось вона, бажина! Там індексація з одиниці починається. Зміни на `s.words[w.head-1]` і перепрожени :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T14:11:19Z,пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T19:20:48Z,"добавив. та протестив що нічого не загубилося ) дійсно, ""трохи"" легше стало )",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:20:55Z,Цей файлик потрібно забрати з цього пул-ріквеста. Для кожної домашки треба створювати нову гілку з мастера.,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:25:19Z,"Так і має бути :) Стеммінг повинен прибирати словотворчі (derivational) афікси, а лематизація — лише формотворчі (inflectional).",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:25:53Z,"Я певно погано пояснювала, бо ці два типи ми розбирали на занятті. ;)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:47:34Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T00:52:28Z,"Оця ознака не дуже підходить для виявлення істот:
1. багато іменників-істот не є власними назвами (людина, вчитель, дядько, кіт тощо)
2. багато власних назв не є істотами (Сибір, ВКП, Амур)

У StanfordNLP можна використати граматичну ознаку Animacy=Anim.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T10:57:12Z,"Але для цього треба токени, або писати якийсь регулярний вираз з урахуванням пунктуації... Тобто або зовсім просто, або якось складно. Так наче красивіше. :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T10:58:06Z,"Так, розбирали. Я там далі написав, що забувся спочатку у лекції подивитись )) ",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T10:58:57Z,наче пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T11:00:27Z,"Але я тоді не розумію... Якщо прибрати і словотворчі і формотворчі, то залишиться корінь, так? Чим тоді стем відрізняється від кореня?",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T11:47:30Z,Стем - то і є корінь :) ,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T11:51:29Z,"Для цього не треба токени :) Ось весь регулярний вираз: `""ly\b""`. А час опрацювання корпусу зменшиться у кілька разів.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T13:44:30Z,"Я довго не могла зрозуміти, чому у тебе таі дивні результати вийшли. Аж ось вона, бажина! Там індексація з одиниці починається. Зміни на `s.words[w.head-1]` і перепрожени :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T14:11:19Z,пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/2.1.headlines.py,2020-03-28T19:20:48Z,"добавив. та протестив що нічого не загубилося ) дійсно, ""трохи"" легше стало )",36
github.com/vseloved/prj-nlp-2020,students/DmytroMindra/06-language-as-sequence/src/03-ngram-builder.py,2020-04-25T13:17:10Z,"кажуть, що не гарно поєднувати різні case-стилі: camelCase та underscore_case ;)",80
github.com/vseloved/prj-nlp-2020,students/DmytroMindra/06-language-as-sequence/src/03-ngram-builder.py,2020-05-30T09:26:41Z,"`cross_val_score` за замовчуванням видає тобі `accuracy`, що нічого не говорить про якість визначення цільового класу. Тут варто було використати `cross_validate` і міряти хоча б по `f1_macro`.",80
github.com/vseloved/prj-nlp-2020,students/DmytroMindra/06-language-as-sequence/src/03-ngram-builder.py,2020-05-30T09:30:41Z,"Бачу, що CRF нічого не навчився. Маю підозру, що проблема у вхідних даних. Якщо для логрегресії потрібно передавати список ознак і список міток, то CRF варто передавати список списків ознак і список списків міток, де кожен внутрішній список — це окземе речення. CRF вчиться передбачати повну послідовність (як HMM).",80
github.com/vseloved/prj-nlp-2020,students/DmytroMindra/06-language-as-sequence/src/03-ngram-builder.py,2020-04-25T13:49:11Z,"коротше, без jupyter-ноутбуку все набагато складніше зрозуміти :(",80
github.com/vseloved/prj-nlp-2020,students/DmytroMindra/06-language-as-sequence/src/03-ngram-builder.py,2020-04-25T13:56:03Z,"Согласен. Я думаю, что будет правильно, если я перенесу эксперименты в jupyter ноутбук и   добавлю sequence-модель: HMM, CRF.  Завтра в течение дня я смогу все исправить.",80
github.com/vseloved/prj-nlp-2020,students/DmytroMindra/06-language-as-sequence/src/03-ngram-builder.py,2020-05-09T06:45:31Z,"@DmytroMindra, будеш додавати ще оновлення чи фокусуємось на інших задачах?",80
github.com/vseloved/prj-nlp-2020,students/DmytroMindra/06-language-as-sequence/src/03-ngram-builder.py,2020-05-09T15:06:44Z,"@mariana-scorp, я хочу добавить HMM и CRF. У меня уже данные заготовлены на Google Drive. Отсалось совсем чуть-чуть. Обидно уже бросать.",80
github.com/vseloved/prj-nlp-2020,students/DmytroMindra/06-language-as-sequence/src/03-ngram-builder.py,2020-05-26T17:53:41Z,"Добавил CRF, Summary и переделал работу в Jupyter Notebook. ",80
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/en_collocations.py,2020-03-27T22:33:57Z,"Отут варто було врахувати слова, які вже написані великими літерами (наприклад, USA) та ""n't"" (яке тегується як прислівник).",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/en_collocations.py,2020-03-27T22:36:53Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/en_collocations.py,2020-03-27T22:38:38Z,"Щоб не робити два проходи по токенах, можна або зробити цикл по дітях дієслова (`.children`), або шукати спершу прислівник, а тоді перевіряти, чи його батьком є потрібне нам дієслово.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/en_collocations.py,2020-03-27T22:43:30Z,"Тут треба було запам'ятовувати леми (`.normal_form`), бо інакше в результати потрапляє те саме словосполучення по кілька разів. У твоїх результатах: _великий начальник, великим начальником, великому начальникові, великого начальника._",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/en_collocations.py,2020-03-27T22:18:38Z,"Видали, будь ласка, `data/`, щоб не роздувати репозиторій.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/en_collocations.py,2020-03-27T22:33:57Z,"Отут варто було врахувати слова, які вже написані великими літерами (наприклад, USA) та ""n't"" (яке тегується як прислівник).",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/en_collocations.py,2020-03-27T22:36:53Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/en_collocations.py,2020-03-27T22:38:38Z,"Щоб не робити два проходи по токенах, можна або зробити цикл по дітях дієслова (`.children`), або шукати спершу прислівник, а тоді перевіряти, чи його батьком є потрібне нам дієслово.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/en_collocations.py,2020-03-27T22:43:30Z,"Тут треба було запам'ятовувати леми (`.normal_form`), бо інакше в результати потрапляє те саме словосполучення по кілька разів. У твоїх результатах: _великий начальник, великим начальником, великому начальникові, великого начальника._",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/en_collocations.py,2020-03-27T22:18:38Z,"Видали, будь ласка, `data/`, щоб не роздувати репозиторій.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/en_collocations.py,2020-03-27T22:33:57Z,"Отут варто було врахувати слова, які вже написані великими літерами (наприклад, USA) та ""n't"" (яке тегується як прислівник).",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/en_collocations.py,2020-03-27T22:36:53Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/en_collocations.py,2020-03-27T22:38:38Z,"Щоб не робити два проходи по токенах, можна або зробити цикл по дітях дієслова (`.children`), або шукати спершу прислівник, а тоді перевіряти, чи його батьком є потрібне нам дієслово.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/en_collocations.py,2020-03-27T22:43:30Z,"Тут треба було запам'ятовувати леми (`.normal_form`), бо інакше в результати потрапляє те саме словосполучення по кілька разів. У твоїх результатах: _великий начальник, великим начальником, великому начальникові, великого начальника._",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/en_collocations.py,2020-03-27T22:18:38Z,"Видали, будь ласка, `data/`, щоб не роздувати репозиторій.",29
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T00:20:55Z,Цей файлик потрібно забрати з цього пул-ріквеста. Для кожної домашки треба створювати нову гілку з мастера.,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T00:25:19Z,"Так і має бути :) Стеммінг повинен прибирати словотворчі (derivational) афікси, а лематизація — лише формотворчі (inflectional).",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T00:25:53Z,"Я певно погано пояснювала, бо ці два типи ми розбирали на занятті. ;)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T00:47:34Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T00:52:28Z,"Оця ознака не дуже підходить для виявлення істот:
1. багато іменників-істот не є власними назвами (людина, вчитель, дядько, кіт тощо)
2. багато власних назв не є істотами (Сибір, ВКП, Амур)

У StanfordNLP можна використати граматичну ознаку Animacy=Anim.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T10:57:12Z,"Але для цього треба токени, або писати якийсь регулярний вираз з урахуванням пунктуації... Тобто або зовсім просто, або якось складно. Так наче красивіше. :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T10:58:06Z,"Так, розбирали. Я там далі написав, що забувся спочатку у лекції подивитись )) ",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T10:58:57Z,наче пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T11:00:27Z,"Але я тоді не розумію... Якщо прибрати і словотворчі і формотворчі, то залишиться корінь, так? Чим тоді стем відрізняється від кореня?",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T11:47:30Z,Стем - то і є корінь :) ,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T11:51:29Z,"Для цього не треба токени :) Ось весь регулярний вираз: `""ly\b""`. А час опрацювання корпусу зменшиться у кілька разів.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T13:44:30Z,"Я довго не могла зрозуміти, чому у тебе таі дивні результати вийшли. Аж ось вона, бажина! Там індексація з одиниці починається. Зміни на `s.words[w.head-1]` і перепрожени :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T14:11:19Z,пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T19:20:48Z,"добавив. та протестив що нічого не загубилося ) дійсно, ""трохи"" легше стало )",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T00:20:55Z,Цей файлик потрібно забрати з цього пул-ріквеста. Для кожної домашки треба створювати нову гілку з мастера.,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T00:25:19Z,"Так і має бути :) Стеммінг повинен прибирати словотворчі (derivational) афікси, а лематизація — лише формотворчі (inflectional).",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T00:25:53Z,"Я певно погано пояснювала, бо ці два типи ми розбирали на занятті. ;)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T00:47:34Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T00:52:28Z,"Оця ознака не дуже підходить для виявлення істот:
1. багато іменників-істот не є власними назвами (людина, вчитель, дядько, кіт тощо)
2. багато власних назв не є істотами (Сибір, ВКП, Амур)

У StanfordNLP можна використати граматичну ознаку Animacy=Anim.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T10:57:12Z,"Але для цього треба токени, або писати якийсь регулярний вираз з урахуванням пунктуації... Тобто або зовсім просто, або якось складно. Так наче красивіше. :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T10:58:06Z,"Так, розбирали. Я там далі написав, що забувся спочатку у лекції подивитись )) ",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T10:58:57Z,наче пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T11:00:27Z,"Але я тоді не розумію... Якщо прибрати і словотворчі і формотворчі, то залишиться корінь, так? Чим тоді стем відрізняється від кореня?",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T11:47:30Z,Стем - то і є корінь :) ,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T11:51:29Z,"Для цього не треба токени :) Ось весь регулярний вираз: `""ly\b""`. А час опрацювання корпусу зменшиться у кілька разів.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T13:44:30Z,"Я довго не могла зрозуміти, чому у тебе таі дивні результати вийшли. Аж ось вона, бажина! Там індексація з одиниці починається. Зміни на `s.words[w.head-1]` і перепрожени :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T14:11:19Z,пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T19:20:48Z,"добавив. та протестив що нічого не загубилося ) дійсно, ""трохи"" легше стало )",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T00:20:55Z,Цей файлик потрібно забрати з цього пул-ріквеста. Для кожної домашки треба створювати нову гілку з мастера.,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T00:25:19Z,"Так і має бути :) Стеммінг повинен прибирати словотворчі (derivational) афікси, а лематизація — лише формотворчі (inflectional).",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T00:25:53Z,"Я певно погано пояснювала, бо ці два типи ми розбирали на занятті. ;)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T00:47:34Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T00:52:28Z,"Оця ознака не дуже підходить для виявлення істот:
1. багато іменників-істот не є власними назвами (людина, вчитель, дядько, кіт тощо)
2. багато власних назв не є істотами (Сибір, ВКП, Амур)

У StanfordNLP можна використати граматичну ознаку Animacy=Anim.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T10:57:12Z,"Але для цього треба токени, або писати якийсь регулярний вираз з урахуванням пунктуації... Тобто або зовсім просто, або якось складно. Так наче красивіше. :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T10:58:06Z,"Так, розбирали. Я там далі написав, що забувся спочатку у лекції подивитись )) ",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T10:58:57Z,наче пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T11:00:27Z,"Але я тоді не розумію... Якщо прибрати і словотворчі і формотворчі, то залишиться корінь, так? Чим тоді стем відрізняється від кореня?",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T11:47:30Z,Стем - то і є корінь :) ,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T11:51:29Z,"Для цього не треба токени :) Ось весь регулярний вираз: `""ly\b""`. А час опрацювання корпусу зменшиться у кілька разів.",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T13:44:30Z,"Я довго не могла зрозуміти, чому у тебе таі дивні результати вийшли. Аж ось вона, бажина! Там індексація з одиниці починається. Зміни на `s.words[w.head-1]` і перепрожени :)",36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T14:11:19Z,пофіксив,36
github.com/vseloved/prj-nlp-2020,students/OleksandrPetrov/02-structural-linguistics/3.1.collocations.py,2020-03-28T19:20:48Z,"добавив. та протестив що нічого не загубилося ) дійсно, ""трохи"" легше стало )",36
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:33:57Z,"Отут варто було врахувати слова, які вже написані великими літерами (наприклад, USA) та ""n't"" (яке тегується як прислівник).",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:36:53Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:38:38Z,"Щоб не робити два проходи по токенах, можна або зробити цикл по дітях дієслова (`.children`), або шукати спершу прислівник, а тоді перевіряти, чи його батьком є потрібне нам дієслово.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:43:30Z,"Тут треба було запам'ятовувати леми (`.normal_form`), бо інакше в результати потрапляє те саме словосполучення по кілька разів. У твоїх результатах: _великий начальник, великим начальником, великому начальникові, великого начальника._",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:18:38Z,"Видали, будь ласка, `data/`, щоб не роздувати репозиторій.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:33:57Z,"Отут варто було врахувати слова, які вже написані великими літерами (наприклад, USA) та ""n't"" (яке тегується як прислівник).",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:36:53Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:38:38Z,"Щоб не робити два проходи по токенах, можна або зробити цикл по дітях дієслова (`.children`), або шукати спершу прислівник, а тоді перевіряти, чи його батьком є потрібне нам дієслово.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:43:30Z,"Тут треба було запам'ятовувати леми (`.normal_form`), бо інакше в результати потрапляє те саме словосполучення по кілька разів. У твоїх результатах: _великий начальник, великим начальником, великому начальникові, великого начальника._",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:18:38Z,"Видали, будь ласка, `data/`, щоб не роздувати репозиторій.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:33:57Z,"Отут варто було врахувати слова, які вже написані великими літерами (наприклад, USA) та ""n't"" (яке тегується як прислівник).",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:36:53Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:38:38Z,"Щоб не робити два проходи по токенах, можна або зробити цикл по дітях дієслова (`.children`), або шукати спершу прислівник, а тоді перевіряти, чи його батьком є потрібне нам дієслово.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:43:30Z,"Тут треба було запам'ятовувати леми (`.normal_form`), бо інакше в результати потрапляє те саме словосполучення по кілька разів. У твоїх результатах: _великий начальник, великим начальником, великому начальникові, великого начальника._",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:18:38Z,"Видали, будь ласка, `data/`, щоб не роздувати репозиторій.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:33:57Z,"Отут варто було врахувати слова, які вже написані великими літерами (наприклад, USA) та ""n't"" (яке тегується як прислівник).",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:36:53Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:38:38Z,"Щоб не робити два проходи по токенах, можна або зробити цикл по дітях дієслова (`.children`), або шукати спершу прислівник, а тоді перевіряти, чи його батьком є потрібне нам дієслово.",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:43:30Z,"Тут треба було запам'ятовувати леми (`.normal_form`), бо інакше в результати потрапляє те саме словосполучення по кілька разів. У твоїх результатах: _великий начальник, великим начальником, великому начальникові, великого начальника._",29
github.com/vseloved/prj-nlp-2020,students/KostiantynZuiev/02-structural-linguistics/headline_formatter.py,2020-03-27T22:18:38Z,"Видали, будь ласка, `data/`, щоб не роздувати репозиторій.",29
github.com/vseloved/prj-nlp-2020,students/DmytroMindra/02-structural-linguistics/2-headlines/headlines/formatting/formatting.py,2020-03-25T20:30:55Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами. Тоді ти зміг би і середню модельку використати.",35
github.com/vseloved/prj-nlp-2020,students/DmytroMindra/02-structural-linguistics/2-headlines/headlines/formatting/formatting.py,2020-03-25T20:04:00Z,"Видали, будь ласка, `2-headlines/examiner-headlines-output.txt`, щоб не роздувати репозиторій.",35
github.com/vseloved/prj-nlp-2020,students/DmytroMindra/02-structural-linguistics/2-headlines/headlines/virality/rate_header_virality.py,2020-03-25T20:30:55Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами. Тоді ти зміг би і середню модельку використати.",35
github.com/vseloved/prj-nlp-2020,students/DmytroMindra/02-structural-linguistics/2-headlines/headlines/virality/rate_header_virality.py,2020-03-25T20:04:00Z,"Видали, будь ласка, `2-headlines/examiner-headlines-output.txt`, щоб не роздувати репозиторій.",35
github.com/vseloved/prj-nlp-2020,students/DmytroMindra/02-structural-linguistics/2-headlines/headlines/tests/test_separate_word_processing.py,2020-03-25T20:30:55Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами. Тоді ти зміг би і середню модельку використати.",35
github.com/vseloved/prj-nlp-2020,students/DmytroMindra/02-structural-linguistics/2-headlines/headlines/tests/test_separate_word_processing.py,2020-03-25T20:04:00Z,"Видали, будь ласка, `2-headlines/examiner-headlines-output.txt`, щоб не роздувати репозиторій.",35
github.com/vseloved/prj-nlp-2020,students/DmytroMindra/02-structural-linguistics/3-collocations/english_collocations/tests/test_collocations.py,2020-03-25T20:30:55Z,"Щоб пришвидшити програму (і не парсити кожне речення в корпусі), можна було спершу перевірити, що в реченні є слово, що закінчується на ""-ly"". Наприклад, регекспами. Тоді ти зміг би і середню модельку використати.",35
github.com/vseloved/prj-nlp-2020,students/DmytroMindra/02-structural-linguistics/3-collocations/english_collocations/tests/test_collocations.py,2020-03-25T20:04:00Z,"Видали, будь ласка, `2-headlines/examiner-headlines-output.txt`, щоб не роздувати репозиторій.",35
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-24T11:45:06Z,"```suggestion
    tokens_number = data[Columns.Split].apply(lambda x: len(str(x).split()))
```
I think it fits more.",784
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-25T08:42:56Z,"```suggestion
        ""adjust_frequencies"": True,  # Whether to divide identifiers frequencies by tokens number.
```
Please adjust the comment if I get it wrongly. ",784
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-24T12:21:49Z,"It doesn't affect performance significantly afaik, but this way the distribution for sample is more fair, like more correct. Actually this division by the number of tokens makes sense only for some data format, that is used by default, and probably it should be made a function argument.
WDYT? ",784
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-24T12:43:32Z,let's put it to `config`.,784
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-24T11:45:06Z,"```suggestion
    tokens_number = data[Columns.Split].apply(lambda x: len(str(x).split()))
```
I think it fits more.",784
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-25T08:42:56Z,"```suggestion
        ""adjust_frequencies"": True,  # Whether to divide identifiers frequencies by tokens number.
```
Please adjust the comment if I get it wrongly. ",784
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-24T12:21:49Z,"It doesn't affect performance significantly afaik, but this way the distribution for sample is more fair, like more correct. Actually this division by the number of tokens makes sense only for some data format, that is used by default, and probably it should be made a function argument.
WDYT? ",784
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-24T12:43:32Z,let's put it to `config`.,784
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:02:59Z,sorted is already a list,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:04:21Z,"`else` is not required, though it's up to you",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:05:49Z,"How big is the file? Can we download it directly to the memory?

We need to cache it if it is big enough to require an FS file. ",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:08:23Z,"Wow this is a big hack :) First of all, you should always use subprocess.
Second, sys.executable instead of hardcoding python3. Third, you can do the same by a Python import and running the function inplace. ",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:08:44Z,Single quotes,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:21:29Z,"4MB, I was not sure whether it's good to keep it in our repo.",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:22:17Z,Compress it with xz and include then,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:22:38Z,"```suggestion
def generate_vocabulary(frequencies_path: str, config: Mapping[str, Any]) -> Dict[str, int]:
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:23:19Z,"```suggestion
    Compose vocabulary from a set of tokens with known frequencies.
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:24:00Z,"```suggestion
                   stable: How many tokens, which don't have more frequent \
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:24:11Z,"```suggestion
                   suspicious: How many tokens, whose more frequent edit-distance-neighbor is
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:24:19Z,"```suggestion
                   non_suspicious: How many tokens, whose more frequent edit-distance-neighbor \
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-03T08:59:17Z,@irinakhismatullina conflicts,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-03T10:18:28Z,"@zurk A lot of [test failures](https://travis-ci.com/src-d/style-analyzer/jobs/204907620#L2229) with annotations, only out-of-docker",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-03T14:57:18Z,should fix the issue https://github.com/src-d/style-analyzer/pull/777,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-03T15:33:18Z,"@irinakhismatullina Konst has fixed the tests, can you please rebase",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:02:59Z,sorted is already a list,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:04:21Z,"`else` is not required, though it's up to you",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:05:49Z,"How big is the file? Can we download it directly to the memory?

We need to cache it if it is big enough to require an FS file. ",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:08:23Z,"Wow this is a big hack :) First of all, you should always use subprocess.
Second, sys.executable instead of hardcoding python3. Third, you can do the same by a Python import and running the function inplace. ",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:08:44Z,Single quotes,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:21:29Z,"4MB, I was not sure whether it's good to keep it in our repo.",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:22:17Z,Compress it with xz and include then,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:22:38Z,"```suggestion
def generate_vocabulary(frequencies_path: str, config: Mapping[str, Any]) -> Dict[str, int]:
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:23:19Z,"```suggestion
    Compose vocabulary from a set of tokens with known frequencies.
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:24:00Z,"```suggestion
                   stable: How many tokens, which don't have more frequent \
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:24:11Z,"```suggestion
                   suspicious: How many tokens, whose more frequent edit-distance-neighbor is
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:24:19Z,"```suggestion
                   non_suspicious: How many tokens, whose more frequent edit-distance-neighbor \
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-03T08:59:17Z,@irinakhismatullina conflicts,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-03T10:18:28Z,"@zurk A lot of [test failures](https://travis-ci.com/src-d/style-analyzer/jobs/204907620#L2229) with annotations, only out-of-docker",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-03T14:57:18Z,should fix the issue https://github.com/src-d/style-analyzer/pull/777,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-03T15:33:18Z,"@irinakhismatullina Konst has fixed the tests, can you please rebase",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:02:59Z,sorted is already a list,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:04:21Z,"`else` is not required, though it's up to you",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:05:49Z,"How big is the file? Can we download it directly to the memory?

We need to cache it if it is big enough to require an FS file. ",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:08:23Z,"Wow this is a big hack :) First of all, you should always use subprocess.
Second, sys.executable instead of hardcoding python3. Third, you can do the same by a Python import and running the function inplace. ",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:08:44Z,Single quotes,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:21:29Z,"4MB, I was not sure whether it's good to keep it in our repo.",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:22:17Z,Compress it with xz and include then,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:22:38Z,"```suggestion
def generate_vocabulary(frequencies_path: str, config: Mapping[str, Any]) -> Dict[str, int]:
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:23:19Z,"```suggestion
    Compose vocabulary from a set of tokens with known frequencies.
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:24:00Z,"```suggestion
                   stable: How many tokens, which don't have more frequent \
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:24:11Z,"```suggestion
                   suspicious: How many tokens, whose more frequent edit-distance-neighbor is
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:24:19Z,"```suggestion
                   non_suspicious: How many tokens, whose more frequent edit-distance-neighbor \
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-03T08:59:17Z,@irinakhismatullina conflicts,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-03T10:18:28Z,"@zurk A lot of [test failures](https://travis-ci.com/src-d/style-analyzer/jobs/204907620#L2229) with annotations, only out-of-docker",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-03T14:57:18Z,should fix the issue https://github.com/src-d/style-analyzer/pull/777,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-03T15:33:18Z,"@irinakhismatullina Konst has fixed the tests, can you please rebase",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:02:59Z,sorted is already a list,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:04:21Z,"`else` is not required, though it's up to you",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:05:49Z,"How big is the file? Can we download it directly to the memory?

We need to cache it if it is big enough to require an FS file. ",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:08:23Z,"Wow this is a big hack :) First of all, you should always use subprocess.
Second, sys.executable instead of hardcoding python3. Third, you can do the same by a Python import and running the function inplace. ",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:08:44Z,Single quotes,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:21:29Z,"4MB, I was not sure whether it's good to keep it in our repo.",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-24T14:22:17Z,Compress it with xz and include then,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:22:38Z,"```suggestion
def generate_vocabulary(frequencies_path: str, config: Mapping[str, Any]) -> Dict[str, int]:
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:23:19Z,"```suggestion
    Compose vocabulary from a set of tokens with known frequencies.
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:24:00Z,"```suggestion
                   stable: How many tokens, which don't have more frequent \
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:24:11Z,"```suggestion
                   suspicious: How many tokens, whose more frequent edit-distance-neighbor is
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:24:19Z,"```suggestion
                   non_suspicious: How many tokens, whose more frequent edit-distance-neighbor \
```",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-03T08:59:17Z,@irinakhismatullina conflicts,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-03T10:18:28Z,"@zurk A lot of [test failures](https://travis-ci.com/src-d/style-analyzer/jobs/204907620#L2229) with annotations, only out-of-docker",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-03T14:57:18Z,should fix the issue https://github.com/src-d/style-analyzer/pull/777,773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-06-03T15:33:18Z,"@irinakhismatullina Konst has fixed the tests, can you please rebase",773
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:21:44Z,@irinakhismatullina `./lookout/style/typos/preparation.py:17:1: F401 'lookout.style.typos.utils.filter_splits' imported but unused`,775
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-05-25T10:21:44Z,@irinakhismatullina `./lookout/style/typos/preparation.py:17:1: F401 'lookout.style.typos.utils.filter_splits' imported but unused`,775
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-04-03T15:25:13Z,??? Some new test is unstable? https://travis-ci.com/src-d/style-analyzer/jobs/190041356#L3794,742
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-04-03T15:31:16Z,"Try to rebuild, looks like a Babelfish failure.",742
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-04-03T17:38:14Z,"@vmarkovtsev Ok, it's fine.",742
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T15:03:45Z,"let's try to avoid as many `config.get(""something"", {})`  as possible. You can merge the config with a `DEFAULT_CONFIG` via `merge_dicts` function.

I think with this change many configs in `__init__` methods become non-optional which is good. ",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T15:06:01Z,"```python
        ""boost_param"": {
            ""max_depth"": 6,
            ...
```",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T15:08:11Z,Let's call it `DEFAULT_PRETRAIN_CONFIG` or something to not confuse with `DEFAULT_CONFIG` which is for Analyzer in FormatAnalyzer,718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T15:15:24Z,"```suggestion
        self.generator.set_config(config)
```
I assume",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T15:16:52Z,I hope that all parameters description are moved somewhere and not just deleted. ,718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T15:28:58Z,"I do not think we should allow changing the config. Let's just inline this function into __init__.
Or rename it to `_set_config`,

For all `set_config` functions.",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:09:24Z,"It's the only place i do that, here it's unavoidable: we get the config with possible `""ranking"" and ""generation""` fields, but the `train_and_evaluate` function expects them separately.",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:10:37Z,Yes that is so,718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:15:14Z,"```python
config = merge_dicts(DEFAULT_CONFIG, config)
model = train_and_evaluate(train, test, vocabulary_path, frequencies_path, fasttext_path,
                               config[""generation""], config[""ranking""]))
```
Can be a solution?",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:17:18Z,"I'm not shure this is so important. Both Ranker and Generator can be used several times with different configurations after init, and it won't break anything. In the same time loading other non-config data can time some time.
TLDR i want to use that feature while experimenting with configurations, so i think it has some value",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:23:24Z,"No, too much excessive information will be added that way",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:24:47Z,BTW about merge_configs - what would really improve the situation is to accept also None dict and treat is as empty one.,718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:28:56Z,ok,718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:32:25Z,"The colution here would be for example to do smth like that `""corrector"": {""generation"": {}, ""ranking""}}`(and pass this `config[""corrector""]` to the function). This was actually my first idea, but i decided to change it to the present one to avoid the growth of the nesting (`DEFAULT_CORRECTOR_CONFIG[""corrector""][""generation""]).",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:42:27Z,"ok, let's keep it",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T12:06:50Z,"Pro tip: you can use [munchify](https://github.com/Infinidat/munch) to work with it like `self.config.chunksize` instead of `self.config[""chunk_size""]` while leaving it a `dict`.",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T12:07:31Z,"Missing ""\"" in the ends of lines.",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T12:09:42Z,"```suggestion
                       edit_dist_number: Number of the most frequent tokens among tokens at \
```",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T12:11:33Z,"```suggestion
                       edit_dist_number: Number of the most frequent tokens among tokens at \
```",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T12:12:05Z,"```suggestion
                       edit_dist_number: Number of the most frequent tokens among tokens at \
```",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T12:12:37Z,Would be nice if you also document the types,718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T12:13:31Z,"Not required in this PR, of course",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T15:01:49Z,"Missing what exactly? ""\"" will put everything in one line afaik",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T15:02:02Z,"Oh i see:) I also tried to write`""\""`",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T14:54:45Z,"No, here i merged only the configs for generating TyposCorrector model (and those configs that I added are actually saved with the model, as was before). Here just all the defaults for the model creating and training are stored in one place. The changes are in no way connected to the analyzer.",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T15:03:45Z,"let's try to avoid as many `config.get(""something"", {})`  as possible. You can merge the config with a `DEFAULT_CONFIG` via `merge_dicts` function.

I think with this change many configs in `__init__` methods become non-optional which is good. ",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T15:06:01Z,"```python
        ""boost_param"": {
            ""max_depth"": 6,
            ...
```",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T15:08:11Z,Let's call it `DEFAULT_PRETRAIN_CONFIG` or something to not confuse with `DEFAULT_CONFIG` which is for Analyzer in FormatAnalyzer,718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T15:15:24Z,"```suggestion
        self.generator.set_config(config)
```
I assume",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T15:16:52Z,I hope that all parameters description are moved somewhere and not just deleted. ,718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T15:28:58Z,"I do not think we should allow changing the config. Let's just inline this function into __init__.
Or rename it to `_set_config`,

For all `set_config` functions.",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:09:24Z,"It's the only place i do that, here it's unavoidable: we get the config with possible `""ranking"" and ""generation""` fields, but the `train_and_evaluate` function expects them separately.",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:10:37Z,Yes that is so,718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:15:14Z,"```python
config = merge_dicts(DEFAULT_CONFIG, config)
model = train_and_evaluate(train, test, vocabulary_path, frequencies_path, fasttext_path,
                               config[""generation""], config[""ranking""]))
```
Can be a solution?",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:17:18Z,"I'm not shure this is so important. Both Ranker and Generator can be used several times with different configurations after init, and it won't break anything. In the same time loading other non-config data can time some time.
TLDR i want to use that feature while experimenting with configurations, so i think it has some value",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:23:24Z,"No, too much excessive information will be added that way",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:24:47Z,BTW about merge_configs - what would really improve the situation is to accept also None dict and treat is as empty one.,718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:28:56Z,ok,718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:32:25Z,"The colution here would be for example to do smth like that `""corrector"": {""generation"": {}, ""ranking""}}`(and pass this `config[""corrector""]` to the function). This was actually my first idea, but i decided to change it to the present one to avoid the growth of the nesting (`DEFAULT_CORRECTOR_CONFIG[""corrector""][""generation""]).",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T16:42:27Z,"ok, let's keep it",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T12:06:50Z,"Pro tip: you can use [munchify](https://github.com/Infinidat/munch) to work with it like `self.config.chunksize` instead of `self.config[""chunk_size""]` while leaving it a `dict`.",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T12:07:31Z,"Missing ""\"" in the ends of lines.",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T12:09:42Z,"```suggestion
                       edit_dist_number: Number of the most frequent tokens among tokens at \
```",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T12:11:33Z,"```suggestion
                       edit_dist_number: Number of the most frequent tokens among tokens at \
```",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T12:12:05Z,"```suggestion
                       edit_dist_number: Number of the most frequent tokens among tokens at \
```",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T12:12:37Z,Would be nice if you also document the types,718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T12:13:31Z,"Not required in this PR, of course",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T15:01:49Z,"Missing what exactly? ""\"" will put everything in one line afaik",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-25T15:02:02Z,"Oh i see:) I also tried to write`""\""`",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-21T14:54:45Z,"No, here i merged only the configs for generating TyposCorrector model (and those configs that I added are actually saved with the model, as was before). Here just all the defaults for the model creating and training are stored in one place. The changes are in no way connected to the analyzer.",718
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:37:47Z,"If `repr` includes the class name, we should remove redundant ""Ranker"" from the logs.",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:37:56Z,same here,698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:38:28Z,"```suggestion
            self._log.info(""Candidates were not provided and will be generated."")
```",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:39:23Z,"```suggestion
        self._log.info(""Train input: %s of %s"", data.shape, data.dtype)
```",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:40:21Z,(it is better to make logs shorter and don't write long NL sentences - they make it longer to understand the logs),698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:41:28Z,"```suggestion
            self._log.info(""Loaded candidates from %s"", candidates)
```",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:42:13Z,"```suggestion
        log.warning(""Raw dataset was not found. Downloading to %s from %s"",
```",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:42:48Z,"Order: first ""from"", second ""to"" 😄 ",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:43:22Z,"```suggestion
    log.info(""Derive the new vocabulary"")
```",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:43:52Z,The logs should all start with a capital letter or with a small letter,698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:44:13Z,"```suggestion
    log.info(""Tokens with frequencies data are saved to %s"", frequencies_tokens_filepath)
```",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:45:06Z,"```suggestion
        self._log.info(""Fitting has started."")
```",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:50:47Z,"dtype is always the same so I'd rather use
```python
self._log.info(""Train input shape: %s"", data.shape)
```",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:59:02Z,"wdym the same? I will call this function on an array of strings and watch it burn in fire.

After all, the purpose of this line is to be a replacement for `repr`, but without the array contents. Let's be consistent.",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T12:09:33Z,@zurk Missed this ^,698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T12:29:55Z,All logs start with small letter now:),698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T13:22:19Z,Oh 😄 ,698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T12:01:50Z,"Thanks, @vmarkovtsev, fixed!",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:37:47Z,"If `repr` includes the class name, we should remove redundant ""Ranker"" from the logs.",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:37:56Z,same here,698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:38:28Z,"```suggestion
            self._log.info(""Candidates were not provided and will be generated."")
```",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:39:23Z,"```suggestion
        self._log.info(""Train input: %s of %s"", data.shape, data.dtype)
```",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:40:21Z,(it is better to make logs shorter and don't write long NL sentences - they make it longer to understand the logs),698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:41:28Z,"```suggestion
            self._log.info(""Loaded candidates from %s"", candidates)
```",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:42:13Z,"```suggestion
        log.warning(""Raw dataset was not found. Downloading to %s from %s"",
```",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:42:48Z,"Order: first ""from"", second ""to"" 😄 ",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:43:22Z,"```suggestion
    log.info(""Derive the new vocabulary"")
```",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:43:52Z,The logs should all start with a capital letter or with a small letter,698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:44:13Z,"```suggestion
    log.info(""Tokens with frequencies data are saved to %s"", frequencies_tokens_filepath)
```",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:45:06Z,"```suggestion
        self._log.info(""Fitting has started."")
```",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:50:47Z,"dtype is always the same so I'd rather use
```python
self._log.info(""Train input shape: %s"", data.shape)
```",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T11:59:02Z,"wdym the same? I will call this function on an array of strings and watch it burn in fire.

After all, the purpose of this line is to be a replacement for `repr`, but without the array contents. Let's be consistent.",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T12:09:33Z,@zurk Missed this ^,698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T12:29:55Z,All logs start with small letter now:),698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T13:22:19Z,Oh 😄 ,698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T12:01:50Z,"Thanks, @vmarkovtsev, fixed!",698
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T12:16:57Z,"We shouldn't change this. Most likely this caused problems for you because you have outdated version of gensim. The requirements were updated recently, you should use the version stated there.",700
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T12:19:37Z,"Thank you, this needed to be done, but I suggest moving it to the beginning of `prepare_data()` function, as the same problem (directory doesn't exist) may also happen when the raw dataset is loaded from the local path.",700
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-14T12:07:24Z,At this point I have got the idea of a very very simple Lookout analyzer to find these goddamn double whitespaces everywhere and bust them. I have hit this problem again and again since many years ago. @marnovo @campoy @smola ,699
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T16:17:45Z,`slogging.setup` is not needed,691
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T16:18:50Z,"```python
for log_arg in (""log_level"", ""...""):
    delattr(args, log_arg)
```",691
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T16:20:09Z,"Can you please add ""erase_args"" boolean parameter to `add_logging_args` in sdk-ml so that it delattr-s those three arguments automatically (separately of this PR).",691
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T16:21:14Z,I miss one last command here: `do_everything_in_one_single_command_without_parameters` 😄 ,691
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T16:48:40Z,"Hm, this actually must be done right here, in `train_from_scratch`, just by using default for `save_model_path`:)",691
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T16:59:05Z,"Ah OK. Can you please mark it with

```python
########################################
# single command to rule them all
########################################
```

so that nobody misses it :)",691
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T16:17:45Z,`slogging.setup` is not needed,691
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T16:18:50Z,"```python
for log_arg in (""log_level"", ""...""):
    delattr(args, log_arg)
```",691
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T16:20:09Z,"Can you please add ""erase_args"" boolean parameter to `add_logging_args` in sdk-ml so that it delattr-s those three arguments automatically (separately of this PR).",691
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T16:21:14Z,I miss one last command here: `do_everything_in_one_single_command_without_parameters` 😄 ,691
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T16:48:40Z,"Hm, this actually must be done right here, in `train_from_scratch`, just by using default for `save_model_path`:)",691
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T16:59:05Z,"Ah OK. Can you please mark it with

```python
########################################
# single command to rule them all
########################################
```

so that nobody misses it :)",691
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:16:56Z,Would be nice to have a comment here what does this huge size mean,684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:18:22Z,"Better to use long names: embeddings.bin

And btw what is `bin`? If it is the numpy format, we should use `npy`, etc.",684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:19:02Z,"```suggestion
                   vocabulary_filename: Name of the .csv file in `data_dir` to save vocabulary to.
```

(the same below)",684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:19:54Z,You should never hardcode these values. `multiprocessing.cpu_count()`,684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:20:17Z,same here - `threads_number`,684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:22:26Z,It's fasttext default format for saving full model.,684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T10:30:49Z,"multiprocessing works with processes, not with threads. Those two are very different, especially for Python. So do you mean `processes_number` here?",684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T13:30:15Z,"Yes, it's processes, changing it everywhere.",684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:16:56Z,Would be nice to have a comment here what does this huge size mean,684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:18:22Z,"Better to use long names: embeddings.bin

And btw what is `bin`? If it is the numpy format, we should use `npy`, etc.",684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:19:02Z,"```suggestion
                   vocabulary_filename: Name of the .csv file in `data_dir` to save vocabulary to.
```

(the same below)",684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:19:54Z,You should never hardcode these values. `multiprocessing.cpu_count()`,684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:20:17Z,same here - `threads_number`,684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:22:26Z,It's fasttext default format for saving full model.,684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T10:30:49Z,"multiprocessing works with processes, not with threads. Those two are very different, especially for Python. So do you mean `processes_number` here?",684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T13:30:15Z,"Yes, it's processes, changing it everywhere.",684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:16:56Z,Would be nice to have a comment here what does this huge size mean,684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:18:22Z,"Better to use long names: embeddings.bin

And btw what is `bin`? If it is the numpy format, we should use `npy`, etc.",684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:19:02Z,"```suggestion
                   vocabulary_filename: Name of the .csv file in `data_dir` to save vocabulary to.
```

(the same below)",684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:19:54Z,You should never hardcode these values. `multiprocessing.cpu_count()`,684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:20:17Z,same here - `threads_number`,684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-11T13:22:26Z,It's fasttext default format for saving full model.,684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T10:30:49Z,"multiprocessing works with processes, not with threads. Those two are very different, especially for Python. So do you mean `processes_number` here?",684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-12T13:30:15Z,"Yes, it's processes, changing it everywhere.",684
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-07T08:58:32Z,thanks!,669
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-05T16:04:10Z,"```suggestion
    Create and train TyposCorrector model on the given data.
```",661
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-05T16:04:27Z,Should always be a dataframe only,661
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-05T16:05:01Z,"```suggestion
                       Columns.CorrectToken, column Columns.Split is optional, but used \
```",661
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-05T16:05:17Z,same here: only dataframe,661
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-05T16:05:27Z,"```suggestion
    :param test_data: Dataframe or its .csv dump, containing columns \
```",661
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-06T07:52:10Z,"One build has failed for no reason, looks like it has nothing to do with the code, how to rerun it without pushing smth?",661
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-06T11:49:36Z,Conflicts here and in #660 after merging #659,661
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-06T12:12:02Z,"> One build has failed for no reason, looks like it has nothing to do with the code, how to rerun it without pushing smth?

You should be able to restart the build in Travis. Usually it happens because of random networking problems.",661
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-06T13:42:32Z,@irinakhismatullina Conflicts again :(,661
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-05T16:04:10Z,"```suggestion
    Create and train TyposCorrector model on the given data.
```",661
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-05T16:04:27Z,Should always be a dataframe only,661
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-05T16:05:01Z,"```suggestion
                       Columns.CorrectToken, column Columns.Split is optional, but used \
```",661
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-05T16:05:17Z,same here: only dataframe,661
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-05T16:05:27Z,"```suggestion
    :param test_data: Dataframe or its .csv dump, containing columns \
```",661
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-06T07:52:10Z,"One build has failed for no reason, looks like it has nothing to do with the code, how to rerun it without pushing smth?",661
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-06T11:49:36Z,Conflicts here and in #660 after merging #659,661
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-06T12:12:02Z,"> One build has failed for no reason, looks like it has nothing to do with the code, how to rerun it without pushing smth?

You should be able to restart the build in Travis. Usually it happens because of random networking problems.",661
github.com/src-d/style-analyzer,lookout/style/typos/preparation.py,2019-03-06T13:42:32Z,@irinakhismatullina Conflicts again :(,661
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-06-06T07:58:37Z,"Ok, I see that cmd module was not added to sourced.ml.core. 
I think it is fine to copy-paste this util function here. ",778
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-06-07T05:17:11Z,It's not OK to remove tests. ,778
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-06-11T12:48:18Z,But it's OK to add tests :),778
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-22T10:48:30Z,Awesome. We should not make the same mistake twice and check PEP8 in the future research projects. ,769
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-16T08:57:58Z,"`commits_with_typo` already filtered from https://github.com/src-d/style-analyzer/blob/master/lookout/style/typos/research/eval_dataset/typos_dataset.csv.xz

We should replace the old `""commits_with_typo.csv.xz""` file with a new one. ",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-16T08:58:05Z,Can you add a docstring with the same explanation you add to a PR? ,763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T14:47:26Z,"```suggestion
    Extract non-typo-ed identifiers from the dataset.
```
Someone has to write a linter rule to disable repeating the function name parts in the docstring.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T14:49:18Z,"```suggestion
    1. Filter items, where token splits of the wrong and the correct identifiers are equal (they differ in non-alpha \
```",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T14:51:43Z,"```suggestion
    chars or casing).
```",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T14:52:17Z,**test** dataset?,763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T14:52:36Z,Single quotes.,763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:05:53Z,"Don't you think that it's cool if the function name really reflects the best way you would describe it's work in a text?
Anyway I thought of the better name which gives clearer understanding of what the function does.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:17:31Z,"Totally cool, that's right. Not cool to have a docstring which does not give any additional information about the function, that's my point :)",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:21:17Z,"I particularly don't like the word ""filter"" in source code because it can mean different things:

1. Remove something and return the rest.
2. Extract something, return it, and discard the rest.

Those are two opposite actions. Many programmers all over the world keep using ""filter"" at random and it really puzzles every time when you read their code. This is why repeating ""filter"" in the docstring is so unhelpful.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:23:25Z,"Totally agree, I think I myself sometimes use it for both, and always feel confused, so i really like the new name:)",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:44:17Z,This line is 120 characters. How come that it passed the CI?,763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:45:19Z,"Ah, because we do not check `research` for formatting. We should change this.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-16T09:45:08Z,"Btw src-d/ml-core has [old TokenParser](https://github.com/src-d/ml-core/blob/master/sourced/ml/core/algorithms/token_parser.py), so right now it cannot be used.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-16T09:54:18Z,"Ok, I will update it.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-16T11:46:55Z,PR with an update: https://github.com/src-d/ml-core/pull/13,763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-16T08:57:58Z,"`commits_with_typo` already filtered from https://github.com/src-d/style-analyzer/blob/master/lookout/style/typos/research/eval_dataset/typos_dataset.csv.xz

We should replace the old `""commits_with_typo.csv.xz""` file with a new one. ",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-16T08:58:05Z,Can you add a docstring with the same explanation you add to a PR? ,763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T14:47:26Z,"```suggestion
    Extract non-typo-ed identifiers from the dataset.
```
Someone has to write a linter rule to disable repeating the function name parts in the docstring.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T14:49:18Z,"```suggestion
    1. Filter items, where token splits of the wrong and the correct identifiers are equal (they differ in non-alpha \
```",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T14:51:43Z,"```suggestion
    chars or casing).
```",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T14:52:17Z,**test** dataset?,763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T14:52:36Z,Single quotes.,763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:05:53Z,"Don't you think that it's cool if the function name really reflects the best way you would describe it's work in a text?
Anyway I thought of the better name which gives clearer understanding of what the function does.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:17:31Z,"Totally cool, that's right. Not cool to have a docstring which does not give any additional information about the function, that's my point :)",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:21:17Z,"I particularly don't like the word ""filter"" in source code because it can mean different things:

1. Remove something and return the rest.
2. Extract something, return it, and discard the rest.

Those are two opposite actions. Many programmers all over the world keep using ""filter"" at random and it really puzzles every time when you read their code. This is why repeating ""filter"" in the docstring is so unhelpful.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:23:25Z,"Totally agree, I think I myself sometimes use it for both, and always feel confused, so i really like the new name:)",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:44:17Z,This line is 120 characters. How come that it passed the CI?,763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:45:19Z,"Ah, because we do not check `research` for formatting. We should change this.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-16T09:45:08Z,"Btw src-d/ml-core has [old TokenParser](https://github.com/src-d/ml-core/blob/master/sourced/ml/core/algorithms/token_parser.py), so right now it cannot be used.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-16T09:54:18Z,"Ok, I will update it.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-16T11:46:55Z,PR with an update: https://github.com/src-d/ml-core/pull/13,763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-16T08:57:58Z,"`commits_with_typo` already filtered from https://github.com/src-d/style-analyzer/blob/master/lookout/style/typos/research/eval_dataset/typos_dataset.csv.xz

We should replace the old `""commits_with_typo.csv.xz""` file with a new one. ",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-16T08:58:05Z,Can you add a docstring with the same explanation you add to a PR? ,763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T14:47:26Z,"```suggestion
    Extract non-typo-ed identifiers from the dataset.
```
Someone has to write a linter rule to disable repeating the function name parts in the docstring.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T14:49:18Z,"```suggestion
    1. Filter items, where token splits of the wrong and the correct identifiers are equal (they differ in non-alpha \
```",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T14:51:43Z,"```suggestion
    chars or casing).
```",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T14:52:17Z,**test** dataset?,763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T14:52:36Z,Single quotes.,763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:05:53Z,"Don't you think that it's cool if the function name really reflects the best way you would describe it's work in a text?
Anyway I thought of the better name which gives clearer understanding of what the function does.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:17:31Z,"Totally cool, that's right. Not cool to have a docstring which does not give any additional information about the function, that's my point :)",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:21:17Z,"I particularly don't like the word ""filter"" in source code because it can mean different things:

1. Remove something and return the rest.
2. Extract something, return it, and discard the rest.

Those are two opposite actions. Many programmers all over the world keep using ""filter"" at random and it really puzzles every time when you read their code. This is why repeating ""filter"" in the docstring is so unhelpful.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:23:25Z,"Totally agree, I think I myself sometimes use it for both, and always feel confused, so i really like the new name:)",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:44:17Z,This line is 120 characters. How come that it passed the CI?,763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-21T15:45:19Z,"Ah, because we do not check `research` for formatting. We should change this.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-16T09:45:08Z,"Btw src-d/ml-core has [old TokenParser](https://github.com/src-d/ml-core/blob/master/sourced/ml/core/algorithms/token_parser.py), so right now it cannot be used.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-16T09:54:18Z,"Ok, I will update it.",763
github.com/src-d/style-analyzer,lookout/style/typos/research/eval_dataset/filter_dataset.py,2019-05-16T11:46:55Z,PR with an update: https://github.com/src-d/ml-core/pull/13,763
github.com/equinor/eNLP,enlp/processing/stdtools.py,2020-04-16T21:49:35Z,Also fixed one of the Codacy issues :) the one with the reimport in `stdtools.py`.,5
github.com/equinor/eNLP,enlp/processing/stdtools.py,2020-04-17T12:58:20Z,This is great! Thank you for adding to the library 🥇 ,5
github.com/equinor/eNLP,tests/processing/test_tokenise.py,2020-04-20T08:17:51Z,"Hei, this is a great PR and I really welcome your feedback, thank you. 

I like the formatting from black however I do not wish to enforce black formatting for the moment. My understanding is at the moment it is still slightly contended within the software development community. I am conscious not to incorporate anything that may reduce accessibility to the library, so whilst it is nice to have the code formatted in that manner then I do not wish to enforce it automatically and risk causing additional conflicts to contributors.

The aim of the library is really to be easy to use and contribute back to by other data scientists. We will of course ensure that all contributions meet a minimum coding standard however as the majority of data scientists are not trained software developers then I do not wish to strictly enforce aspects of software development that may discourage some more junior contributors.

Thanks 👍 ",6
github.com/equinor/eNLP,tests/processing/test_tokenise.py,2020-04-20T13:44:53Z,"Gotcha :thumbsup:

The `black` module is still in the requirements.txt, so anyone wanting to run the formatter can still do so.",6
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-15T20:20:55Z,This line is throwing the error. If you remove it the CI tests should pass :) ,148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:54Z,"
Okay I found out why the check didn't work :)",148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:27Z,Okay I found out why the check didn't work :),148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-15T20:20:55Z,This line is throwing the error. If you remove it the CI tests should pass :) ,148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:54Z,"
Okay I found out why the check didn't work :)",148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:27Z,Okay I found out why the check didn't work :),148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-15T20:20:55Z,This line is throwing the error. If you remove it the CI tests should pass :) ,148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:54Z,"
Okay I found out why the check didn't work :)",148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:27Z,Okay I found out why the check didn't work :),148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-15T20:20:55Z,This line is throwing the error. If you remove it the CI tests should pass :) ,148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:54Z,"
Okay I found out why the check didn't work :)",148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:27Z,Okay I found out why the check didn't work :),148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-15T20:20:55Z,This line is throwing the error. If you remove it the CI tests should pass :) ,148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:54Z,"
Okay I found out why the check didn't work :)",148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:27Z,Okay I found out why the check didn't work :),148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-15T20:20:55Z,This line is throwing the error. If you remove it the CI tests should pass :) ,148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:54Z,"
Okay I found out why the check didn't work :)",148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:27Z,Okay I found out why the check didn't work :),148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-15T20:20:55Z,This line is throwing the error. If you remove it the CI tests should pass :) ,148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:54Z,"
Okay I found out why the check didn't work :)",148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:27Z,Okay I found out why the check didn't work :),148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-15T20:20:55Z,This line is throwing the error. If you remove it the CI tests should pass :) ,148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:54Z,"
Okay I found out why the check didn't work :)",148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:27Z,Okay I found out why the check didn't work :),148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-15T20:20:55Z,This line is throwing the error. If you remove it the CI tests should pass :) ,148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:54Z,"
Okay I found out why the check didn't work :)",148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:27Z,Okay I found out why the check didn't work :),148
github.com/skekre98/NBA-Search,inference/statnode.py,2020-12-02T18:16:59Z,"No need to create a new variable, let's just return stat_total",134
github.com/skekre98/NBA-Search,inference/statnode.py,2020-12-02T18:17:22Z,"No need to create a new variable, let's just return stat_adv",134
github.com/skekre98/NBA-Search,inference/statnode.py,2020-12-02T18:19:42Z,Let's also leverage a similarity threshold in case the query was misclassified and return `None` for the extracted stat if the threshold is not met.,134
github.com/skekre98/NBA-Search,inference/statnode.py,2020-12-02T19:50:34Z,"> Have you found any cases where this returns an unexpected value? Would be good to note for the future.

Nothing unexpected like the initial issue from what I can tell, but I am not totally sure how the Chat was performing, other than the rebound/3-point confusion, before I started working on it. 

There are times when the return is more specific than expected, eg:
```
Query: What is Kobe Bryan't shooting percentage?
Output: Kobe Bryant has a true shooting percentage of 0.544
```
But a completely different stat has not come up during my tests. ",134
github.com/skekre98/NBA-Search,inference/statnode.py,2020-12-02T20:58:59Z,"> > Have you found any cases where this returns an unexpected value? Would be good to note for the future.
> 
> Nothing unexpected like the initial issue from what I can tell, but I am not totally sure how the Chat was performing, other than the rebound/3-point confusion, before I started working on it.
> 
> There are times when the return is more specific than expected, eg:
> 
> ```
> Query: What is Kobe Bryan't shooting percentage?
> Output: Kobe Bryant has a true shooting percentage of 0.544
> ```
> 
> But a completely different stat has not come up during my tests.

Awesome! Not a problem, better to have a stat that it too accurate than incorrect 😄 ",134
github.com/skekre98/NBA-Search,inference/statnode.py,2020-12-02T21:43:45Z,"Ok great! Thank you for all your communication on this, it's a fun project and I will try to keep contributing as issues come up. 

> @AidanKenney great work! Out of curiosity how did you decide the similarity threshold? Was a higher similarity threshold returning `None` more often than necessary?

The lowest match ratio I saw that still gave the desired result was a 57, so I gave it a little extra cushion. Happy to change it up though!",134
github.com/skekre98/NBA-Search,inference/statnode.py,2020-12-02T22:07:31Z,"> Ok great! Thank you for all your communication on this, it's a fun project and I will try to keep contributing as issues come up.
> 
> > @AidanKenney great work! Out of curiosity how did you decide the similarity threshold? Was a higher similarity threshold returning `None` more often than necessary?
> 
> The lowest match ratio I saw that still gave the desired result was a 57, so I gave it a little extra cushion. Happy to change it up though!

Seems, like it is working fine! I'll go ahead and merge the PR.",134
github.com/skekre98/NBA-Search,inference/statnode.py,2020-12-02T22:08:22Z,Awesome! Thanks @skekre98 ,134
github.com/skekre98/NBA-Search,inference/statnode.py,2020-12-02T18:16:59Z,"No need to create a new variable, let's just return stat_total",134
github.com/skekre98/NBA-Search,inference/statnode.py,2020-12-02T18:17:22Z,"No need to create a new variable, let's just return stat_adv",134
github.com/skekre98/NBA-Search,inference/statnode.py,2020-12-02T18:19:42Z,Let's also leverage a similarity threshold in case the query was misclassified and return `None` for the extracted stat if the threshold is not met.,134
github.com/skekre98/NBA-Search,inference/statnode.py,2020-12-02T19:50:34Z,"> Have you found any cases where this returns an unexpected value? Would be good to note for the future.

Nothing unexpected like the initial issue from what I can tell, but I am not totally sure how the Chat was performing, other than the rebound/3-point confusion, before I started working on it. 

There are times when the return is more specific than expected, eg:
```
Query: What is Kobe Bryan't shooting percentage?
Output: Kobe Bryant has a true shooting percentage of 0.544
```
But a completely different stat has not come up during my tests. ",134
github.com/skekre98/NBA-Search,inference/statnode.py,2020-12-02T20:58:59Z,"> > Have you found any cases where this returns an unexpected value? Would be good to note for the future.
> 
> Nothing unexpected like the initial issue from what I can tell, but I am not totally sure how the Chat was performing, other than the rebound/3-point confusion, before I started working on it.
> 
> There are times when the return is more specific than expected, eg:
> 
> ```
> Query: What is Kobe Bryan't shooting percentage?
> Output: Kobe Bryant has a true shooting percentage of 0.544
> ```
> 
> But a completely different stat has not come up during my tests.

Awesome! Not a problem, better to have a stat that it too accurate than incorrect 😄 ",134
github.com/skekre98/NBA-Search,inference/statnode.py,2020-12-02T21:43:45Z,"Ok great! Thank you for all your communication on this, it's a fun project and I will try to keep contributing as issues come up. 

> @AidanKenney great work! Out of curiosity how did you decide the similarity threshold? Was a higher similarity threshold returning `None` more often than necessary?

The lowest match ratio I saw that still gave the desired result was a 57, so I gave it a little extra cushion. Happy to change it up though!",134
github.com/skekre98/NBA-Search,inference/statnode.py,2020-12-02T22:07:31Z,"> Ok great! Thank you for all your communication on this, it's a fun project and I will try to keep contributing as issues come up.
> 
> > @AidanKenney great work! Out of curiosity how did you decide the similarity threshold? Was a higher similarity threshold returning `None` more often than necessary?
> 
> The lowest match ratio I saw that still gave the desired result was a 57, so I gave it a little extra cushion. Happy to change it up though!

Seems, like it is working fine! I'll go ahead and merge the PR.",134
github.com/skekre98/NBA-Search,inference/statnode.py,2020-12-02T22:08:22Z,Awesome! Thanks @skekre98 ,134
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-15T20:20:55Z,This line is throwing the error. If you remove it the CI tests should pass :) ,148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:54Z,"
Okay I found out why the check didn't work :)",148
github.com/skekre98/NBA-Search,inference/statnode.py,2021-01-19T07:04:27Z,Okay I found out why the check didn't work :),148
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-30T17:54:01Z,"Let's move functions to extract name, stat, and stat_val into `response`. Just leave `generate_random_response` to actually create the string response from these values. See `ranknode.py` for an example.",106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:46:01Z,You are missing `stat` as an input parameter.,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:47:22Z,You need to move this before `get_player_stat` is called,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:48:08Z,You need to move this before `get_player_stat` is called,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-30T17:55:40Z,"@Ervin66 Looks close, the CI pipeline is complaining because `response` is being used incorrectly. Responses look good though, so just one change and we should be ready to merge 👍 ",106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:36:41Z,I don't understand the errors,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:49:38Z,@Ervin66 see comments. There are a few issues about the way you have implemented `response`,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-30T17:54:01Z,"Let's move functions to extract name, stat, and stat_val into `response`. Just leave `generate_random_response` to actually create the string response from these values. See `ranknode.py` for an example.",106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:46:01Z,You are missing `stat` as an input parameter.,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:47:22Z,You need to move this before `get_player_stat` is called,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:48:08Z,You need to move this before `get_player_stat` is called,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-30T17:55:40Z,"@Ervin66 Looks close, the CI pipeline is complaining because `response` is being used incorrectly. Responses look good though, so just one change and we should be ready to merge 👍 ",106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:36:41Z,I don't understand the errors,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:49:38Z,@Ervin66 see comments. There are a few issues about the way you have implemented `response`,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-30T17:54:01Z,"Let's move functions to extract name, stat, and stat_val into `response`. Just leave `generate_random_response` to actually create the string response from these values. See `ranknode.py` for an example.",106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:46:01Z,You are missing `stat` as an input parameter.,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:47:22Z,You need to move this before `get_player_stat` is called,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:48:08Z,You need to move this before `get_player_stat` is called,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-30T17:55:40Z,"@Ervin66 Looks close, the CI pipeline is complaining because `response` is being used incorrectly. Responses look good though, so just one change and we should be ready to merge 👍 ",106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:36:41Z,I don't understand the errors,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:49:38Z,@Ervin66 see comments. There are a few issues about the way you have implemented `response`,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-30T17:54:01Z,"Let's move functions to extract name, stat, and stat_val into `response`. Just leave `generate_random_response` to actually create the string response from these values. See `ranknode.py` for an example.",106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:46:01Z,You are missing `stat` as an input parameter.,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:47:22Z,You need to move this before `get_player_stat` is called,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:48:08Z,You need to move this before `get_player_stat` is called,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-30T17:55:40Z,"@Ervin66 Looks close, the CI pipeline is complaining because `response` is being used incorrectly. Responses look good though, so just one change and we should be ready to merge 👍 ",106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:36:41Z,I don't understand the errors,106
github.com/skekre98/NBA-Search,inference/statnode.py,2020-10-31T18:49:38Z,@Ervin66 see comments. There are a few issues about the way you have implemented `response`,106
github.com/skekre98/NBA-Search,inference/infonode.py,2020-11-10T19:51:54Z,described*,119
github.com/skekre98/NBA-Search,inference/infonode.py,2020-11-10T19:54:22Z,"Perhaps remove the ""I"" after the and to just leave it as ""and skekre98 is leading them.""",119
github.com/skekre98/NBA-Search,inference/infonode.py,2020-11-10T19:51:54Z,described*,119
github.com/skekre98/NBA-Search,inference/infonode.py,2020-11-10T19:54:22Z,"Perhaps remove the ""I"" after the and to just leave it as ""and skekre98 is leading them.""",119
github.com/skekre98/NBA-Search,inference/infonode.py,2020-10-22T16:53:22Z,"Can you convert this return to a set. Will make _in_ command in test constant time instead of linear.
```python
return({'do','be'})
```",83
github.com/skekre98/NBA-Search,inference/infonode.py,2020-10-22T16:54:15Z,"Can you convert this return to a set. Will make _in_ command in test constant time instead of linear.
```python
return({'make','build'})
```",83
github.com/skekre98/NBA-Search,inference/infonode.py,2020-10-22T17:10:56Z,All set.,83
github.com/skekre98/NBA-Search,inference/infonode.py,2020-10-22T17:11:01Z,All set.,83
github.com/skekre98/NBA-Search,inference/infonode.py,2020-10-22T17:43:01Z,Any way you can add the hacktoberfest-accepted label? I would be very grateful. ,83
github.com/skekre98/NBA-Search,inference/infonode.py,2020-10-22T16:53:22Z,"Can you convert this return to a set. Will make _in_ command in test constant time instead of linear.
```python
return({'do','be'})
```",83
github.com/skekre98/NBA-Search,inference/infonode.py,2020-10-22T16:54:15Z,"Can you convert this return to a set. Will make _in_ command in test constant time instead of linear.
```python
return({'make','build'})
```",83
github.com/skekre98/NBA-Search,inference/infonode.py,2020-10-22T17:10:56Z,All set.,83
github.com/skekre98/NBA-Search,inference/infonode.py,2020-10-22T17:11:01Z,All set.,83
github.com/skekre98/NBA-Search,inference/infonode.py,2020-10-22T17:43:01Z,Any way you can add the hacktoberfest-accepted label? I would be very grateful. ,83
github.com/skekre98/NBA-Search,inference/infonode.py,2020-10-22T16:53:22Z,"Can you convert this return to a set. Will make _in_ command in test constant time instead of linear.
```python
return({'do','be'})
```",83
github.com/skekre98/NBA-Search,inference/infonode.py,2020-10-22T16:54:15Z,"Can you convert this return to a set. Will make _in_ command in test constant time instead of linear.
```python
return({'make','build'})
```",83
github.com/skekre98/NBA-Search,inference/infonode.py,2020-10-22T17:10:56Z,All set.,83
github.com/skekre98/NBA-Search,inference/infonode.py,2020-10-22T17:11:01Z,All set.,83
github.com/skekre98/NBA-Search,inference/infonode.py,2020-10-22T17:43:01Z,Any way you can add the hacktoberfest-accepted label? I would be very grateful. ,83
github.com/skekre98/NBA-Search,inference/infonode.py,2020-10-19T15:11:35Z,"just removed the variables and imports, ready to merge",74
github.com/skekre98/NBA-Search,inference/infonode.py,2020-10-19T15:11:35Z,"just removed the variables and imports, ready to merge",74
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T19:22:54Z,You can just change this to `if not west[0] or not east[0]:` no need to create a new list for conditional.,146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T19:23:06Z,Please remove this prior to merge.,146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T23:49:56Z,"@MishalAshraf can you change the inner entries to tuples. Let's try to keep it in sync with the other entries in the `dict`. See line 131 as an example.

So `["""",""""],["""",""""]` should be `("""",""""),("""","""")` for all entries in the map",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-06T20:14:47Z,"Awesome @MishalAshraf, please also see my comment on #145 regarding the null pointer check. Can you also show me a screenshot of what the playoff bracket looks like now?",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T23:50:31Z,"Great work @MishalAshraf, one minor change and we should be good to merge 👍  ",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T23:57:01Z,"> LGTM 🎉

Awesome! Thanks for your patience, my first actual PR!",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-08T00:09:26Z," > Awesome! Thanks for your patience, my first actual PR!

Congrats on your first successful open source commit 🎉 ",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T19:22:54Z,You can just change this to `if not west[0] or not east[0]:` no need to create a new list for conditional.,146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T19:23:06Z,Please remove this prior to merge.,146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T23:49:56Z,"@MishalAshraf can you change the inner entries to tuples. Let's try to keep it in sync with the other entries in the `dict`. See line 131 as an example.

So `["""",""""],["""",""""]` should be `("""",""""),("""","""")` for all entries in the map",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-06T20:14:47Z,"Awesome @MishalAshraf, please also see my comment on #145 regarding the null pointer check. Can you also show me a screenshot of what the playoff bracket looks like now?",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T23:50:31Z,"Great work @MishalAshraf, one minor change and we should be good to merge 👍  ",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T23:57:01Z,"> LGTM 🎉

Awesome! Thanks for your patience, my first actual PR!",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-08T00:09:26Z," > Awesome! Thanks for your patience, my first actual PR!

Congrats on your first successful open source commit 🎉 ",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T19:22:54Z,You can just change this to `if not west[0] or not east[0]:` no need to create a new list for conditional.,146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T19:23:06Z,Please remove this prior to merge.,146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T23:49:56Z,"@MishalAshraf can you change the inner entries to tuples. Let's try to keep it in sync with the other entries in the `dict`. See line 131 as an example.

So `["""",""""],["""",""""]` should be `("""",""""),("""","""")` for all entries in the map",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-06T20:14:47Z,"Awesome @MishalAshraf, please also see my comment on #145 regarding the null pointer check. Can you also show me a screenshot of what the playoff bracket looks like now?",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T23:50:31Z,"Great work @MishalAshraf, one minor change and we should be good to merge 👍  ",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T23:57:01Z,"> LGTM 🎉

Awesome! Thanks for your patience, my first actual PR!",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-08T00:09:26Z," > Awesome! Thanks for your patience, my first actual PR!

Congrats on your first successful open source commit 🎉 ",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T19:22:54Z,You can just change this to `if not west[0] or not east[0]:` no need to create a new list for conditional.,146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T19:23:06Z,Please remove this prior to merge.,146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T23:49:56Z,"@MishalAshraf can you change the inner entries to tuples. Let's try to keep it in sync with the other entries in the `dict`. See line 131 as an example.

So `["""",""""],["""",""""]` should be `("""",""""),("""","""")` for all entries in the map",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-06T20:14:47Z,"Awesome @MishalAshraf, please also see my comment on #145 regarding the null pointer check. Can you also show me a screenshot of what the playoff bracket looks like now?",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T23:50:31Z,"Great work @MishalAshraf, one minor change and we should be good to merge 👍  ",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T23:57:01Z,"> LGTM 🎉

Awesome! Thanks for your patience, my first actual PR!",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-08T00:09:26Z," > Awesome! Thanks for your patience, my first actual PR!

Congrats on your first successful open source commit 🎉 ",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T19:22:54Z,You can just change this to `if not west[0] or not east[0]:` no need to create a new list for conditional.,146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T19:23:06Z,Please remove this prior to merge.,146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T23:49:56Z,"@MishalAshraf can you change the inner entries to tuples. Let's try to keep it in sync with the other entries in the `dict`. See line 131 as an example.

So `["""",""""],["""",""""]` should be `("""",""""),("""","""")` for all entries in the map",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-06T20:14:47Z,"Awesome @MishalAshraf, please also see my comment on #145 regarding the null pointer check. Can you also show me a screenshot of what the playoff bracket looks like now?",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T23:50:31Z,"Great work @MishalAshraf, one minor change and we should be good to merge 👍  ",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-07T23:57:01Z,"> LGTM 🎉

Awesome! Thanks for your patience, my first actual PR!",146
github.com/skekre98/NBA-Search,modules/transformer.py,2021-01-08T00:09:26Z," > Awesome! Thanks for your patience, my first actual PR!

Congrats on your first successful open source commit 🎉 ",146
github.com/skekre98/NBA-Search,modules/transformer.py,2020-12-16T17:06:49Z,Great work @Nahoyhp! ,139
github.com/skekre98/NBA-Search,modules/transformer.py,2020-10-01T15:57:15Z,"Cool, looks good to me!",27
github.com/skekre98/NBA-Search,modules/transformer.py,2020-10-01T15:57:15Z,"Cool, looks good to me!",27
github.com/connorjoleary/DeepCite,backend/model/tokenizer.py,2020-08-21T22:19:12Z,Quick question did you find out that `spacy` is better than Google's Vector stuff?,67
github.com/connorjoleary/DeepCite,backend/model/tokenizer.py,2020-08-21T22:46:33Z,"Not really, but I did to a ton of investigation and found out that if I want to save About $100 a month, then this is the way to do it.",67
github.com/connorjoleary/DeepCite,backend/model/tokenizer.py,2020-08-21T22:47:33Z,"I didn't post the changes, but let me know if you want db access to run them yourself",67
github.com/connorjoleary/DeepCite,backend/model/tokenizer.py,2020-08-22T21:22:47Z,"Ahh I see, makes sense",67
github.com/connorjoleary/DeepCite,lightweight_docker/main.py,2021-03-08T05:43:39Z,Update,71
github.com/connorjoleary/DeepCite,lightweight_docker/main.py,2021-03-08T05:44:10Z,Update folder names,71
github.com/connorjoleary/DeepCite,lightweight_docker/main.py,2021-03-08T05:46:10Z,Add readme for this folder,71
github.com/connorjoleary/DeepCite,lightweight_docker/main.py,2021-03-08T05:46:40Z,add issue for this hack,71
github.com/connorjoleary/DeepCite,lightweight_docker/main.py,2021-03-11T07:04:19Z,#61,71
github.com/rubra-ai/rubra,core/local_model.py,2024-02-20T23:31:43Z,why is this change necessary?,89
github.com/rubra-ai/rubra,core/local_model.py,2024-02-21T00:38:42Z,"## Deploying with &nbsp;<a href=""https://pages.dev""><img alt=""Cloudflare Pages"" src=""https://user-images.githubusercontent.com/23264/106598434-9e719e00-654f-11eb-9e59-6167043cfa01.png"" width=""16""></a> &nbsp;Cloudflare Pages

<table><tr><td><strong>Latest commit:</strong> </td><td>
<code>c1dcb29</code>
</td></tr>
<tr><td><strong>Status:</strong></td><td>&nbsp;✅&nbsp; Deploy successful!</td></tr>
<tr><td><strong>Preview URL:</strong></td><td>
<a href='https://02854f14.rubra.pages.dev'>https://02854f14.rubra.pages.dev</a>
</td></tr>
<tr><td><strong>Branch Preview URL:</strong></td><td>
<a href='https://assistant-update-fix.rubra.pages.dev'>https://assistant-update-fix.rubra.pages.dev</a>
</td></tr>
</table>

[View logs](https://dash.cloudflare.com/?to=/:account/pages/view/rubra/02854f14-97d8-43a1-8d3b-779a4ed6b729)
",89
github.com/rubra-ai/rubra,core/local_model.py,2024-02-21T17:44:28Z,"> The build context needs to be added to the build and push image target
> 
> `docker buildx build --build-context core=./core`

updated.",89
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-11-05T20:52:19Z,When would commit be false?,135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-11-05T20:58:33Z,Doing a `save()` one object at a time is painful for big datasets. Can we make this an add_objects() that takes a list of objects and goes through and does bulk operations to index them? See [this playground branch].(https://github.com/UW-COSMOS/Cosmos/blob/ians_oct20_api_changes/cosmos/retrieval/retrieval/elastic_retriever.py#L181),135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-11-05T21:00:36Z,I've never used `joins`... How is the performance?,135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-11-10T17:56:25Z,"I would expect that the performance is OK, given that the objects are denormalized and duplicated across entities. We can do perform a profile in the future.",135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-11-10T17:57:32Z,This is important. I'll make the bulk change.,135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-11-10T17:58:10Z,specifically if you want to do things like bulk inserts.,135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-11-13T04:14:18Z,not a huge deal but spelling on scheduluer,135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-12-02T21:59:43Z,Added in acda80e,135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-12-02T22:01:21Z,It actually was a big deal ;)  Fixed in 0463b8d,135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-12-02T22:17:05Z,"My big issue with this implementation is the duplication of the objects for each occurrence of an entity. It seems wasteful, but _ok_ in the table/figure caption cases, since there's a low number of entities in those. But sections ends up being pretty bloated and equations even worse. In a test of 1,000 docs with 1158 equations, I'm seeing over **500,000** objects with cls:Equation in eo-site, verified by looking at the average number of  linked entities for the equation dataframe:

```
>>> q['ents_linked'].apply(len).mean()
463.2262521588946
```

Worse, each equation is associated with its page contents (https://github.com/UW-COSMOS/Cosmos/blob/d60cfb18196052d2155562957aaf317dae62b502/cosmos/ingestion/ingest/process/aggregation/aggregate.py#L229). So we're getting both huge numbers of entities linked to each equation _and_ we're saving 463 copies of these pages' contents.. The end result is a 20GB index for a 1,000 document set. So we'd be looking at a ~2TB index for the covid set.

I'll experiment with some alternatives..",135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-12-02T22:24:26Z,"This is intentional. Having it be denormalized like this makes it faster to query (we don’t need to do joins), at the cost of space. The alternative is a normalized entity/object table, which will be really slow to join on an online setting like we have.

We have a normalized join happening between pdfs and objects, if you want to implement a normalized version.
On Dec 2, 2020, 4:17 PM -0600, Ian Ross <notifications@github.com>, wrote:
> My big issue with this implementation is the duplication of the objects for each occurrence of an entity. It seems wasteful, but ok in the table/figure caption cases, since there's a low number of entities in those. But sections ends up being pretty bloated and equations even worse. In a test of 1,000 docs with 1158 equations, I'm seeing over 500,000 objects with cls:Equation in eo-site, verified by looking at the average number of linked entities for the equation dataframe:
> >>> q['ents_linked'].apply(len).mean()
> 463.2262521588946
> Worse, each equation is associated with its page contents (https://github.com/UW-COSMOS/Cosmos/blob/d60cfb18196052d2155562957aaf317dae62b502/cosmos/ingestion/ingest/process/aggregation/aggregate.py#L229). So we're getting both huge numbers of entities linked to each equation and we're saving 463 copies of these pages' contents.. The end result is a 20GB index for a 1,000 document set. So we'd be looking at a ~2TB index for the covid set.
> I'll experiment with some alternatives..
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-11-05T20:52:19Z,When would commit be false?,135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-11-05T20:58:33Z,Doing a `save()` one object at a time is painful for big datasets. Can we make this an add_objects() that takes a list of objects and goes through and does bulk operations to index them? See [this playground branch].(https://github.com/UW-COSMOS/Cosmos/blob/ians_oct20_api_changes/cosmos/retrieval/retrieval/elastic_retriever.py#L181),135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-11-05T21:00:36Z,I've never used `joins`... How is the performance?,135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-11-10T17:56:25Z,"I would expect that the performance is OK, given that the objects are denormalized and duplicated across entities. We can do perform a profile in the future.",135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-11-10T17:57:32Z,This is important. I'll make the bulk change.,135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-11-10T17:58:10Z,specifically if you want to do things like bulk inserts.,135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-11-13T04:14:18Z,not a huge deal but spelling on scheduluer,135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-12-02T21:59:43Z,Added in acda80e,135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-12-02T22:01:21Z,It actually was a big deal ;)  Fixed in 0463b8d,135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-12-02T22:17:05Z,"My big issue with this implementation is the duplication of the objects for each occurrence of an entity. It seems wasteful, but _ok_ in the table/figure caption cases, since there's a low number of entities in those. But sections ends up being pretty bloated and equations even worse. In a test of 1,000 docs with 1158 equations, I'm seeing over **500,000** objects with cls:Equation in eo-site, verified by looking at the average number of  linked entities for the equation dataframe:

```
>>> q['ents_linked'].apply(len).mean()
463.2262521588946
```

Worse, each equation is associated with its page contents (https://github.com/UW-COSMOS/Cosmos/blob/d60cfb18196052d2155562957aaf317dae62b502/cosmos/ingestion/ingest/process/aggregation/aggregate.py#L229). So we're getting both huge numbers of entities linked to each equation _and_ we're saving 463 copies of these pages' contents.. The end result is a 20GB index for a 1,000 document set. So we'd be looking at a ~2TB index for the covid set.

I'll experiment with some alternatives..",135
github.com/UW-COSMOS/Cosmos,cosmos/ingestion/ingest/preload_plugins/linking_setup.py,2020-12-02T22:24:26Z,"This is intentional. Having it be denormalized like this makes it faster to query (we don’t need to do joins), at the cost of space. The alternative is a normalized entity/object table, which will be really slow to join on an online setting like we have.

We have a normalized join happening between pdfs and objects, if you want to implement a normalized version.
On Dec 2, 2020, 4:17 PM -0600, Ian Ross <notifications@github.com>, wrote:
> My big issue with this implementation is the duplication of the objects for each occurrence of an entity. It seems wasteful, but ok in the table/figure caption cases, since there's a low number of entities in those. But sections ends up being pretty bloated and equations even worse. In a test of 1,000 docs with 1158 equations, I'm seeing over 500,000 objects with cls:Equation in eo-site, verified by looking at the average number of linked entities for the equation dataframe:
> >>> q['ents_linked'].apply(len).mean()
> 463.2262521588946
> Worse, each equation is associated with its page contents (https://github.com/UW-COSMOS/Cosmos/blob/d60cfb18196052d2155562957aaf317dae62b502/cosmos/ingestion/ingest/process/aggregation/aggregate.py#L229). So we're getting both huge numbers of entities linked to each equation and we're saving 463 copies of these pages' contents.. The end result is a 20GB index for a 1,000 document set. So we'd be looking at a ~2TB index for the covid set.
> I'll experiment with some alternatives..
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",135
github.com/amazon-science/fact-graph,data/preprocess/utils.py,2022-04-29T04:46:32Z,README update the code upload.,2
github.com/amazon-science/fact-graph,data/preprocess/augmentation_ops.py,2022-04-29T04:46:32Z,README update the code upload.,2
github.com/amazon-science/fact-graph,data/preprocess/02.1.1_align_amrs.py,2022-04-29T04:46:32Z,README update the code upload.,2
github.com/amazon-science/fact-graph,data/preprocess/02.1.1_align_amrs.py,2022-04-29T04:46:32Z,README update the code upload.,2
github.com/amazon-science/fact-graph,data/preprocess/preprocess_evaluate.py,2022-04-29T04:46:32Z,README update the code upload.,2
github.com/bcgov/digital-journeys,forms-flow-data-analysis-api/jobs/spacy_ner_trainer.py,2022-08-15T17:28:05Z,"We added a role, ""manager"", for the supervisors. May need to update this if planned to return applications for that role in the future. Don't think have an issue at the moment.",504
github.com/bcgov/digital-journeys,forms-flow-data-analysis-api/jobs/spacy_ner_trainer.py,2022-08-15T17:48:16Z,"We may want to review this endpoint to make sure it does not have security implications. It'll be interesting to see what fields a user can update about his/her profile. Whether email/IDIR or user group/role are one of them?

We can also disable it until there is a need for it.

Oh just saw it is only for updating user locale, should be fine then.",504
github.com/bcgov/digital-journeys,forms-flow-data-analysis-api/jobs/spacy_ner_trainer.py,2022-08-15T18:44:34Z,This should help get rid of some of the security vulnerability warnings we get on the repo :),504
github.com/bcgov/digital-journeys,forms-flow-data-analysis-api/jobs/spacy_ner_trainer.py,2022-08-15T19:36:15Z,Seems like `handleChange` is duplicated. There is another instance just below.,504
github.com/bcgov/digital-journeys,forms-flow-data-analysis-api/jobs/spacy_ner_trainer.py,2022-08-16T16:00:07Z,"good catch, change is added to my current commit for fixing build issues",504
github.com/bcgov/digital-journeys,forms-flow-data-analysis-api/jobs/spacy_ner_trainer.py,2022-08-16T16:02:23Z,I'm not seeing any mention of the 'Manager' role in this file on other branches. I'll look for where to re-add it though.,504
github.com/bcgov/digital-journeys,forms-flow-data-analysis-api/jobs/spacy_ner_trainer.py,2022-08-16T16:42:42Z,@david-sabadash @iman-jamali-fw We should keep this as the `REVIEWER` group. The manager role should not have any additional permissions for now. It's currently purely a concept used in the context of hiding / displaying things on the frontend. The `REVIEWER` group is a built in part of formsflow that we should not touch as it comes with a lot of different permissions,504
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-07-27T18:45:43Z,"OK, now it works with all languages.

Results for this commit:
Testing on  english - News.
macro-F1: 0.733

Testing on  english - WikiNews.
macro-F1: 0.692

Testing on  english - Wikipedia.
macro-F1: 0.690

Testing on  german - German.
macro-F1: 0.659

Testing on  spanish - Spanish.
macro-F1: 0.645

Testing on  french - French.
macro-F1: 0.226",31
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-07-27T19:55:50Z,"Ok! I suggest we use to drive progress, as this is the obvious test case in
this, and the main comparison against previous work!
On Fri, 27 Jul 2018 at 19:47, IntoThePit <notifications@github.com> wrote:

> OK, now it works with all languages.
>
> Results for this commit:
> Testing on english - News.
> macro-F1: 0.733
>
> Testing on english - WikiNews.
> macro-F1: 0.692
>
> Testing on english - Wikipedia.
> macro-F1: 0.690
>
> Testing on german - German.
> macro-F1: 0.659
>
> Testing on spanish - Spanish.
> macro-F1: 0.645
>
> Testing on french - French.
> macro-F1: 0.226
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/31#issuecomment-408506615>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABbUhQgPvd77fSqHa1zVSwThJrd_NbW3ks5uK1_XgaJpZM4VkaZi>
> .
>
",31
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-07-02T14:53:45Z,Thank you.,8
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-06-30T11:17:15Z,"Hi Tom,

Thank you for the code. It looks good overall. There is one detail that I think we need to figure out.

What's going to be the purpose of the getter methods in the Dataset class: train_set(), dev_set(), test_set()? Originally, the idea was to read the data (if it hadn't been read before) and then return it. Now that we have the pickle objects. Is anyone who calls train_set(), for example, going to expect to have the data from the pickle objects too? If that is the case, then I think we could modify the code from those functions a little bit.  Something like this:

```
        if self._trainset is None: 
            trainset_raw = self.read_dataset(self._trainset_path)
            trainset_spacy = self.read_spacy_pickle(self._trainset_spacy_path)
            self._trainset = pd.concat([trainset_raw, trainset_spacy], axis=1)
        
        return  self._trainset
```

What do you think? ",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-06-30T11:26:02Z,"Regarding your question about the pickle objects, we could put them in the Google Drive and then each one will have to download them and put them in the right folder. We should also add a .gitignore in those folders. Is that reasonable? Any other ideas @andreasvlachos?",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-06-30T11:29:40Z,"Hi Fernando,

I agree, that looks good. Will pandas behave OK if there is no spacy set there to concatenate?

Cheers,
Tom

On 30 Jun 2018, at 12:17, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>> wrote:


Hi Tom,

Thank you for the code. It looks good overall. There is one detail that I think we need to figure out.

What's going to be the purpose of the getter methods in the Dataset class: train_set(), dev_set(), test_set()? Originally, the idea was to read the data (if it hadn't been read before) and then return it. Now that we have the pickle objects. Is anyone who calls train_set(), for example, going to expect to have the data from the pickle objects too? If that is the case, then I think we could modify the code from those functions a little bit. Something like this:

        if self._trainset is None:
            trainset_raw = self.read_dataset(self._trainset_path)
            trainset_spacy = self.read_spacy_pickle(self._trainset_spacy_path)
            self._trainset = pd.concat([trainset_raw, trainset_spacy], axis=1)

        return  self._trainset


What do you think?

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401534627>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhOIlqoh_PzZfexTZoBhInvY7km-Oks5uB148gaJpZM4U9hnK>.

",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-06-30T11:32:10Z,"Cool. I did have another idea about this, which is that by running

$ python3 src/data/build_spacy_objects.py <LANGUAGE>

For each language locally, we can each build the pickles on our own machines.

I don’t know which is more appropriate…

Cheers,
Tom

On 30 Jun 2018, at 12:26, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>> wrote:


Regarding your question about the pickle objects, we could put them in the Google Drive and then each one will have to download them and put them in the right folder. We should also add a .gitignore in those folders. Is that reasonable? Any other ideas @andreasvlachos<https://github.com/andreasvlachos>?

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401534995>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhF_kZmrhdLtIaZr59gfyOBUj5UABks5uB2BKgaJpZM4U9hnK>.

",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-06-30T11:49:27Z,"If everything going forward relies on the spacy data being loaded, then we need to make sure that the pickle object exists. Two ways that I could think of for handling this:

1. If the pickle object does not exist, we could send an error message requesting that it be created, and then terminate the program because we cannot continue.

2. If the pickle object does not exist, we could send a warning message, and then internally process the data using spacy and create the pickle object.

Remember that the idea of having the pickle objects was to avoid having to run the spacy parsers every time that we need to train and test. I personally prefer option 1.",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-07-01T11:21:59Z,"Hi guys,

Thanks for the good conversation. I think that both options Fernando
mentions will eventually be used, option 1 to quickly setup an experiment
on a new machine, option 2 to experiment with the spacy preprocessing and
ensure we can replicate our work from scratch. Let’s support both. Maybe
the easiest would be to implement option 2, and the user sees the message
and decides whether to wait for the preprocessing to finish or interrupts
it and downloads, Google drive would be the place for the large files.

Cheers,
Andreas
On Sat, 30 Jun 2018 at 12:49, Fernando Alva Manchego <
notifications@github.com> wrote:

> If everything going forward relies on the spacy data being loaded, then we
> need to make sure that the pickle object exists. Two ways that I could
> think of for handling this:
>
>    1.
>
>    If the pickle object does not exist, we could send an error message
>    requesting that it be created, and then terminate the program because we
>    cannot continue.
>    2.
>
>    If the pickle object does not exist, we could send a warning message,
>    and then internally process the data using spacy and create the pickle
>    object.
>
> Remember that the idea of having the pickle objects was to avoid having to
> run the spacy parsers every time that we need to train and test. I
> personally prefer option 1.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401536118>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABbUhaJ8xdsqKNg9Fhsvf2REBbiPKbByks5uB2XHgaJpZM4U9hnK>
> .
>
",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-07-02T07:53:14Z,"Hi,

That sounds good. Should I code this up on my fork as it is and submit a new pull request, Fernando?

Thanks,
Tom

On 1 Jul 2018, at 12:21, Andreas Vlachos <notifications@github.com<mailto:notifications@github.com>> wrote:

Hi guys,

Thanks for the good conversation. I think that both options Fernando
mentions will eventually be used, option 1 to quickly setup an experiment
on a new machine, option 2 to experiment with the spacy preprocessing and
ensure we can replicate our work from scratch. Let’s support both. Maybe
the easiest would be to implement option 2, and the user sees the message
and decides whether to wait for the preprocessing to finish or interrupts
it and downloads, Google drive would be the place for the large files.

Cheers,
Andreas
On Sat, 30 Jun 2018 at 12:49, Fernando Alva Manchego <
notifications@github.com<mailto:notifications@github.com>> wrote:

> If everything going forward relies on the spacy data being loaded, then we
> need to make sure that the pickle object exists. Two ways that I could
> think of for handling this:
>
> 1.
>
> If the pickle object does not exist, we could send an error message
> requesting that it be created, and then terminate the program because we
> cannot continue.
> 2.
>
> If the pickle object does not exist, we could send a warning message,
> and then internally process the data using spacy and create the pickle
> object.
>
> Remember that the idea of having the pickle objects was to avoid having to
> run the spacy parsers every time that we need to train and test. I
> personally prefer option 1.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401536118>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABbUhaJ8xdsqKNg9Fhsvf2REBbiPKbByks5uB2XHgaJpZM4U9hnK>
> .
>

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401600359>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhF3-PKb7TJ6MQrB6Oftelb0wkEpjks5uCLDXgaJpZM4U9hnK>.

",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-07-02T09:25:05Z,"Yes, please.

On 2 July 2018 at 08:53, tomdakin <notifications@github.com> wrote:

> Hi,
>
> That sounds good. Should I code this up on my fork as it is and submit a
> new pull request, Fernando?
>
> Thanks,
> Tom
>
> On 1 Jul 2018, at 12:21, Andreas Vlachos <notifications@github.com<mailto:
> notifications@github.com>> wrote:
>
> Hi guys,
>
> Thanks for the good conversation. I think that both options Fernando
> mentions will eventually be used, option 1 to quickly setup an experiment
> on a new machine, option 2 to experiment with the spacy preprocessing and
> ensure we can replicate our work from scratch. Let’s support both. Maybe
> the easiest would be to implement option 2, and the user sees the message
> and decides whether to wait for the preprocessing to finish or interrupts
> it and downloads, Google drive would be the place for the large files.
>
> Cheers,
> Andreas
> On Sat, 30 Jun 2018 at 12:49, Fernando Alva Manchego <
> notifications@github.com<mailto:notifications@github.com>> wrote:
>
> > If everything going forward relies on the spacy data being loaded, then
> we
> > need to make sure that the pickle object exists. Two ways that I could
> > think of for handling this:
> >
> > 1.
> >
> > If the pickle object does not exist, we could send an error message
> > requesting that it be created, and then terminate the program because we
> > cannot continue.
> > 2.
> >
> > If the pickle object does not exist, we could send a warning message,
> > and then internally process the data using spacy and create the pickle
> > object.
> >
> > Remember that the idea of having the pickle objects was to avoid having
> to
> > run the spacy parsers every time that we need to train and test. I
> > personally prefer option 1.
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401536118>, or
> mute
> > the thread
> > <https://github.com/notifications/unsubscribe-auth/
> ABbUhaJ8xdsqKNg9Fhsvf2REBbiPKbByks5uB2XHgaJpZM4U9hnK>
> > .
> >
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub<https://github.com/
> sheffieldnlp/cwi/pull/7#issuecomment-401600359>, or mute the thread<
> https://github.com/notifications/unsubscribe-auth/AfUBhF3-
> PKb7TJ6MQrB6Oftelb0wkEpjks5uCLDXgaJpZM4U9hnK>.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401701776>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ACof6KVctrZaVGlcXctEHL6Vn_aoOP45ks5uCdFrgaJpZM4U9hnK>
> .
>



-- 
Fernando Alva Manchego
",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-07-02T14:07:02Z,"Hi Fernando, 
I've updated the spacy/raw dataset structure as per your suggestion. 
Thanks,
Tom",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-07-02T14:42:06Z,P.S. Do I need to wait for you to merge the pull before I make further changes? ,7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-07-02T14:49:51Z,Merge done.,7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-07-02T14:53:45Z,Thank you.,8
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-06-30T11:17:15Z,"Hi Tom,

Thank you for the code. It looks good overall. There is one detail that I think we need to figure out.

What's going to be the purpose of the getter methods in the Dataset class: train_set(), dev_set(), test_set()? Originally, the idea was to read the data (if it hadn't been read before) and then return it. Now that we have the pickle objects. Is anyone who calls train_set(), for example, going to expect to have the data from the pickle objects too? If that is the case, then I think we could modify the code from those functions a little bit.  Something like this:

```
        if self._trainset is None: 
            trainset_raw = self.read_dataset(self._trainset_path)
            trainset_spacy = self.read_spacy_pickle(self._trainset_spacy_path)
            self._trainset = pd.concat([trainset_raw, trainset_spacy], axis=1)
        
        return  self._trainset
```

What do you think? ",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-06-30T11:26:02Z,"Regarding your question about the pickle objects, we could put them in the Google Drive and then each one will have to download them and put them in the right folder. We should also add a .gitignore in those folders. Is that reasonable? Any other ideas @andreasvlachos?",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-06-30T11:29:40Z,"Hi Fernando,

I agree, that looks good. Will pandas behave OK if there is no spacy set there to concatenate?

Cheers,
Tom

On 30 Jun 2018, at 12:17, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>> wrote:


Hi Tom,

Thank you for the code. It looks good overall. There is one detail that I think we need to figure out.

What's going to be the purpose of the getter methods in the Dataset class: train_set(), dev_set(), test_set()? Originally, the idea was to read the data (if it hadn't been read before) and then return it. Now that we have the pickle objects. Is anyone who calls train_set(), for example, going to expect to have the data from the pickle objects too? If that is the case, then I think we could modify the code from those functions a little bit. Something like this:

        if self._trainset is None:
            trainset_raw = self.read_dataset(self._trainset_path)
            trainset_spacy = self.read_spacy_pickle(self._trainset_spacy_path)
            self._trainset = pd.concat([trainset_raw, trainset_spacy], axis=1)

        return  self._trainset


What do you think?

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401534627>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhOIlqoh_PzZfexTZoBhInvY7km-Oks5uB148gaJpZM4U9hnK>.

",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-06-30T11:32:10Z,"Cool. I did have another idea about this, which is that by running

$ python3 src/data/build_spacy_objects.py <LANGUAGE>

For each language locally, we can each build the pickles on our own machines.

I don’t know which is more appropriate…

Cheers,
Tom

On 30 Jun 2018, at 12:26, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>> wrote:


Regarding your question about the pickle objects, we could put them in the Google Drive and then each one will have to download them and put them in the right folder. We should also add a .gitignore in those folders. Is that reasonable? Any other ideas @andreasvlachos<https://github.com/andreasvlachos>?

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401534995>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhF_kZmrhdLtIaZr59gfyOBUj5UABks5uB2BKgaJpZM4U9hnK>.

",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-06-30T11:49:27Z,"If everything going forward relies on the spacy data being loaded, then we need to make sure that the pickle object exists. Two ways that I could think of for handling this:

1. If the pickle object does not exist, we could send an error message requesting that it be created, and then terminate the program because we cannot continue.

2. If the pickle object does not exist, we could send a warning message, and then internally process the data using spacy and create the pickle object.

Remember that the idea of having the pickle objects was to avoid having to run the spacy parsers every time that we need to train and test. I personally prefer option 1.",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-07-01T11:21:59Z,"Hi guys,

Thanks for the good conversation. I think that both options Fernando
mentions will eventually be used, option 1 to quickly setup an experiment
on a new machine, option 2 to experiment with the spacy preprocessing and
ensure we can replicate our work from scratch. Let’s support both. Maybe
the easiest would be to implement option 2, and the user sees the message
and decides whether to wait for the preprocessing to finish or interrupts
it and downloads, Google drive would be the place for the large files.

Cheers,
Andreas
On Sat, 30 Jun 2018 at 12:49, Fernando Alva Manchego <
notifications@github.com> wrote:

> If everything going forward relies on the spacy data being loaded, then we
> need to make sure that the pickle object exists. Two ways that I could
> think of for handling this:
>
>    1.
>
>    If the pickle object does not exist, we could send an error message
>    requesting that it be created, and then terminate the program because we
>    cannot continue.
>    2.
>
>    If the pickle object does not exist, we could send a warning message,
>    and then internally process the data using spacy and create the pickle
>    object.
>
> Remember that the idea of having the pickle objects was to avoid having to
> run the spacy parsers every time that we need to train and test. I
> personally prefer option 1.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401536118>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABbUhaJ8xdsqKNg9Fhsvf2REBbiPKbByks5uB2XHgaJpZM4U9hnK>
> .
>
",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-07-02T07:53:14Z,"Hi,

That sounds good. Should I code this up on my fork as it is and submit a new pull request, Fernando?

Thanks,
Tom

On 1 Jul 2018, at 12:21, Andreas Vlachos <notifications@github.com<mailto:notifications@github.com>> wrote:

Hi guys,

Thanks for the good conversation. I think that both options Fernando
mentions will eventually be used, option 1 to quickly setup an experiment
on a new machine, option 2 to experiment with the spacy preprocessing and
ensure we can replicate our work from scratch. Let’s support both. Maybe
the easiest would be to implement option 2, and the user sees the message
and decides whether to wait for the preprocessing to finish or interrupts
it and downloads, Google drive would be the place for the large files.

Cheers,
Andreas
On Sat, 30 Jun 2018 at 12:49, Fernando Alva Manchego <
notifications@github.com<mailto:notifications@github.com>> wrote:

> If everything going forward relies on the spacy data being loaded, then we
> need to make sure that the pickle object exists. Two ways that I could
> think of for handling this:
>
> 1.
>
> If the pickle object does not exist, we could send an error message
> requesting that it be created, and then terminate the program because we
> cannot continue.
> 2.
>
> If the pickle object does not exist, we could send a warning message,
> and then internally process the data using spacy and create the pickle
> object.
>
> Remember that the idea of having the pickle objects was to avoid having to
> run the spacy parsers every time that we need to train and test. I
> personally prefer option 1.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401536118>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABbUhaJ8xdsqKNg9Fhsvf2REBbiPKbByks5uB2XHgaJpZM4U9hnK>
> .
>

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401600359>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhF3-PKb7TJ6MQrB6Oftelb0wkEpjks5uCLDXgaJpZM4U9hnK>.

",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-07-02T09:25:05Z,"Yes, please.

On 2 July 2018 at 08:53, tomdakin <notifications@github.com> wrote:

> Hi,
>
> That sounds good. Should I code this up on my fork as it is and submit a
> new pull request, Fernando?
>
> Thanks,
> Tom
>
> On 1 Jul 2018, at 12:21, Andreas Vlachos <notifications@github.com<mailto:
> notifications@github.com>> wrote:
>
> Hi guys,
>
> Thanks for the good conversation. I think that both options Fernando
> mentions will eventually be used, option 1 to quickly setup an experiment
> on a new machine, option 2 to experiment with the spacy preprocessing and
> ensure we can replicate our work from scratch. Let’s support both. Maybe
> the easiest would be to implement option 2, and the user sees the message
> and decides whether to wait for the preprocessing to finish or interrupts
> it and downloads, Google drive would be the place for the large files.
>
> Cheers,
> Andreas
> On Sat, 30 Jun 2018 at 12:49, Fernando Alva Manchego <
> notifications@github.com<mailto:notifications@github.com>> wrote:
>
> > If everything going forward relies on the spacy data being loaded, then
> we
> > need to make sure that the pickle object exists. Two ways that I could
> > think of for handling this:
> >
> > 1.
> >
> > If the pickle object does not exist, we could send an error message
> > requesting that it be created, and then terminate the program because we
> > cannot continue.
> > 2.
> >
> > If the pickle object does not exist, we could send a warning message,
> > and then internally process the data using spacy and create the pickle
> > object.
> >
> > Remember that the idea of having the pickle objects was to avoid having
> to
> > run the spacy parsers every time that we need to train and test. I
> > personally prefer option 1.
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401536118>, or
> mute
> > the thread
> > <https://github.com/notifications/unsubscribe-auth/
> ABbUhaJ8xdsqKNg9Fhsvf2REBbiPKbByks5uB2XHgaJpZM4U9hnK>
> > .
> >
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub<https://github.com/
> sheffieldnlp/cwi/pull/7#issuecomment-401600359>, or mute the thread<
> https://github.com/notifications/unsubscribe-auth/AfUBhF3-
> PKb7TJ6MQrB6Oftelb0wkEpjks5uCLDXgaJpZM4U9hnK>.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401701776>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ACof6KVctrZaVGlcXctEHL6Vn_aoOP45ks5uCdFrgaJpZM4U9hnK>
> .
>



-- 
Fernando Alva Manchego
",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-07-02T14:07:02Z,"Hi Fernando, 
I've updated the spacy/raw dataset structure as per your suggestion. 
Thanks,
Tom",7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-07-02T14:42:06Z,P.S. Do I need to wait for you to merge the pull before I make further changes? ,7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-07-02T14:49:51Z,Merge done.,7
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-07-02T14:53:45Z,Thank you.,8
github.com/sheffieldnlp/cwi,src/data/dataset.py,2018-06-27T14:57:02Z,"If this is necessary, I have no problem with it. Thank you.",5
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-24T13:47:45Z,"Hi Tom,

Thank you for this. I have just tested the model and, indeed, the code is back at running at a very reasonable speed. Nice work!

What you mention is very odd. I would suggest to first perform a sort of sanity check, and make sure that even by moving code between extractors, we are obtaining the same number and values for all features. 
All of our features are deterministic, so we should always get the same feature table. This may not seem meaningful, but I would just like to make sure we are not making a silly mistake in the code.

If we indeed get the same feature table but still different predictions, then I currently have no other ideas. Any thoughts @andreasvlachos ?

Best,
Fernando
",27
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-24T17:07:27Z,"Hi Fernando,

Thanks for the debug tip - it worked. For some reason the features are coming back differently when they are in different extractor classes. This is obviously bad, but I will fix it. It is much easier to fix than the case where the algorithm is giving different predictions for the same features!

I’ll work on it and hopefully get the bug ironed out tonight.

Cheers
Tom

On 24 Jul 2018, at 14:47, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>> wrote:


Hi Tom,

Thank you for this. I have just tested the model and, indeed, the code is back at running at a very reasonable speed. Nice work!

What you mention is very odd. I would suggest to first perform a sort of sanity check, and make sure that even by moving code between extractors, we are obtaining the same number and values for all features.
All of our features are deterministic, so we should always get the same feature table. This may not seem meaningful, but I would just like to make sure we are not making a silly mistake in the code.

If we indeed get the same feature table but still different predictions, then I currently have no other ideas. Any thoughts @andreasvlachos<https://github.com/andreasvlachos> ?

Best,
Fernando

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407412711>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhEmK3-FMbJv1RDmMKHrPirQH75iuks5uJyWBgaJpZM4VcuGr>.

",27
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-24T17:13:45Z,"I spoke too soon - I misread my output. The feature is in fact being extracted the same in both classes!
T

On 24 Jul 2018, at 18:07, Tom Dakin <tom.a.dakin@hotmail.co.uk<mailto:tom.a.dakin@hotmail.co.uk>> wrote:

Hi Fernando,

Thanks for the debug tip - it worked. For some reason the features are coming back differently when they are in different extractor classes. This is obviously bad, but I will fix it. It is much easier to fix than the case where the algorithm is giving different predictions for the same features!

I’ll work on it and hopefully get the bug ironed out tonight.

Cheers
Tom

On 24 Jul 2018, at 14:47, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>> wrote:


Hi Tom,

Thank you for this. I have just tested the model and, indeed, the code is back at running at a very reasonable speed. Nice work!

What you mention is very odd. I would suggest to first perform a sort of sanity check, and make sure that even by moving code between extractors, we are obtaining the same number and values for all features.
All of our features are deterministic, so we should always get the same feature table. This may not seem meaningful, but I would just like to make sure we are not making a silly mistake in the code.

If we indeed get the same feature table but still different predictions, then I currently have no other ideas. Any thoughts @andreasvlachos<https://github.com/andreasvlachos> ?

Best,
Fernando

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407412711>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhEmK3-FMbJv1RDmMKHrPirQH75iuks5uJyWBgaJpZM4VcuGr>.


",27
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-24T18:51:06Z,"Does this happen with any feature that you change or with one feature in
particular?

On Tue, 24 Jul 2018 at 18:13, tomdakin <notifications@github.com> wrote:

> I spoke too soon - I misread my output. The feature is in fact being
> extracted the same in both classes!
> T
>
> On 24 Jul 2018, at 18:07, Tom Dakin <tom.a.dakin@hotmail.co.uk<mailto:
> tom.a.dakin@hotmail.co.uk>> wrote:
>
> Hi Fernando,
>
> Thanks for the debug tip - it worked. For some reason the features are
> coming back differently when they are in different extractor classes. This
> is obviously bad, but I will fix it. It is much easier to fix than the case
> where the algorithm is giving different predictions for the same features!
>
> I’ll work on it and hopefully get the bug ironed out tonight.
>
> Cheers
> Tom
>
> On 24 Jul 2018, at 14:47, Fernando Alva Manchego <notifications@github.com
> <mailto:notifications@github.com>> wrote:
>
>
> Hi Tom,
>
> Thank you for this. I have just tested the model and, indeed, the code is
> back at running at a very reasonable speed. Nice work!
>
> What you mention is very odd. I would suggest to first perform a sort of
> sanity check, and make sure that even by moving code between extractors, we
> are obtaining the same number and values for all features.
> All of our features are deterministic, so we should always get the same
> feature table. This may not seem meaningful, but I would just like to make
> sure we are not making a silly mistake in the code.
>
> If we indeed get the same feature table but still different predictions,
> then I currently have no other ideas. Any thoughts @andreasvlachos<
> https://github.com/andreasvlachos> ?
>
> Best,
> Fernando
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub<
> https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407412711>, or
> mute the thread<
> https://github.com/notifications/unsubscribe-auth/AfUBhEmK3-FMbJv1RDmMKHrPirQH75iuks5uJyWBgaJpZM4VcuGr>.
>
>
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407482321>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ACof6Nf-64WBS_jUoybsXsCVG_5aYI7Bks5uJ1XKgaJpZM4VcuGr>
> .
>


-- 
Fernando Alva Manchego
",27
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-24T20:00:33Z,"It seems to happen with every feature I’ve tried so far.
T

On 24 Jul 2018, at 19:51, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>> wrote:

Does this happen with any feature that you change or with one feature in
particular?

On Tue, 24 Jul 2018 at 18:13, tomdakin <notifications@github.com<mailto:notifications@github.com>> wrote:

> I spoke too soon - I misread my output. The feature is in fact being
> extracted the same in both classes!
> T
>
> On 24 Jul 2018, at 18:07, Tom Dakin <tom.a.dakin@hotmail.co.uk<mailto:tom.a.dakin@hotmail.co.uk><mailto:
> tom.a.dakin@hotmail.co.uk<mailto:tom.a.dakin@hotmail.co.uk>>> wrote:
>
> Hi Fernando,
>
> Thanks for the debug tip - it worked. For some reason the features are
> coming back differently when they are in different extractor classes. This
> is obviously bad, but I will fix it. It is much easier to fix than the case
> where the algorithm is giving different predictions for the same features!
>
> I’ll work on it and hopefully get the bug ironed out tonight.
>
> Cheers
> Tom
>
> On 24 Jul 2018, at 14:47, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>
> <mailto:notifications@github.com>> wrote:
>
>
> Hi Tom,
>
> Thank you for this. I have just tested the model and, indeed, the code is
> back at running at a very reasonable speed. Nice work!
>
> What you mention is very odd. I would suggest to first perform a sort of
> sanity check, and make sure that even by moving code between extractors, we
> are obtaining the same number and values for all features.
> All of our features are deterministic, so we should always get the same
> feature table. This may not seem meaningful, but I would just like to make
> sure we are not making a silly mistake in the code.
>
> If we indeed get the same feature table but still different predictions,
> then I currently have no other ideas. Any thoughts @andreasvlachos<
> https://github.com/andreasvlachos> ?
>
> Best,
> Fernando
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub<
> https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407412711>, or
> mute the thread<
> https://github.com/notifications/unsubscribe-auth/AfUBhEmK3-FMbJv1RDmMKHrPirQH75iuks5uJyWBgaJpZM4VcuGr>.
>
>
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407482321>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ACof6Nf-64WBS_jUoybsXsCVG_5aYI7Bks5uJ1XKgaJpZM4VcuGr>
> .
>


--
Fernando Alva Manchego

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407513586>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhPJaiBUvmZbmPTsiV27gq8iDwDTwks5uJ2ycgaJpZM4VcuGr>.

",27
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-24T20:15:34Z,"Hi all,

Sorry, was travelling today, haven't been able to take a look at the code
yet. A guess: could the order/names of the features matter?

Cheers,
Andreas

On Tue, 24 Jul 2018 at 21:00 tomdakin <notifications@github.com> wrote:

> It seems to happen with every feature I’ve tried so far.
> T
>
> On 24 Jul 2018, at 19:51, Fernando Alva Manchego <notifications@github.com
> <mailto:notifications@github.com>> wrote:
>
> Does this happen with any feature that you change or with one feature in
> particular?
>
> On Tue, 24 Jul 2018 at 18:13, tomdakin <notifications@github.com<mailto:
> notifications@github.com>> wrote:
>
> > I spoke too soon - I misread my output. The feature is in fact being
> > extracted the same in both classes!
> > T
> >
> > On 24 Jul 2018, at 18:07, Tom Dakin <tom.a.dakin@hotmail.co.uk<mailto:
> tom.a.dakin@hotmail.co.uk><mailto:
> > tom.a.dakin@hotmail.co.uk<mailto:tom.a.dakin@hotmail.co.uk>>> wrote:
> >
> > Hi Fernando,
> >
> > Thanks for the debug tip - it worked. For some reason the features are
> > coming back differently when they are in different extractor classes.
> This
> > is obviously bad, but I will fix it. It is much easier to fix than the
> case
> > where the algorithm is giving different predictions for the same
> features!
> >
> > I’ll work on it and hopefully get the bug ironed out tonight.
> >
> > Cheers
> > Tom
> >
> > On 24 Jul 2018, at 14:47, Fernando Alva Manchego <
> notifications@github.com<mailto:notifications@github.com>
> > <mailto:notifications@github.com>> wrote:
> >
> >
> > Hi Tom,
> >
> > Thank you for this. I have just tested the model and, indeed, the code
> is
> > back at running at a very reasonable speed. Nice work!
> >
> > What you mention is very odd. I would suggest to first perform a sort of
> > sanity check, and make sure that even by moving code between extractors,
> we
> > are obtaining the same number and values for all features.
> > All of our features are deterministic, so we should always get the same
> > feature table. This may not seem meaningful, but I would just like to
> make
> > sure we are not making a silly mistake in the code.
> >
> > If we indeed get the same feature table but still different predictions,
> > then I currently have no other ideas. Any thoughts @andreasvlachos<
> > https://github.com/andreasvlachos> ?
> >
> > Best,
> > Fernando
> >
> > —
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub<
> > https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407412711>, or
> > mute the thread<
> >
> https://github.com/notifications/unsubscribe-auth/AfUBhEmK3-FMbJv1RDmMKHrPirQH75iuks5uJyWBgaJpZM4VcuGr>.
>
> >
> >
> >
> > —
> > You are receiving this because you modified the open/close state.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407482321>,
> or mute
> > the thread
> > <
> https://github.com/notifications/unsubscribe-auth/ACof6Nf-64WBS_jUoybsXsCVG_5aYI7Bks5uJ1XKgaJpZM4VcuGr>
>
> > .
> >
>
>
> --
> Fernando Alva Manchego
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub<
> https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407513586>, or
> mute the thread<
> https://github.com/notifications/unsubscribe-auth/AfUBhPJaiBUvmZbmPTsiV27gq8iDwDTwks5uJ2ycgaJpZM4VcuGr>.
>
>
> —
> You are receiving this because you were mentioned.
>
>
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407532941>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABbUhT5Wd9gv0yXSzqb6vUiQmec-QqAHks5uJ3zigaJpZM4VcuGr>
> .
>
",27
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-24T20:45:32Z,"Hi Andreas & All,

That’s the only thing we could think of when Aneeq and I were looking at this earlier - that the order of the features somehow matters. I figure that there could be some randomness in the solver for the logistic regression, and giving it the features in a different order could lead to a different solution. It is pretty high dimensional data. I’m experimenting with different solvers now for LR to see if I can find a setup that is consistent under changing feature order.

Cheers,
Tom

On 24 Jul 2018, at 21:15, Andreas Vlachos <notifications@github.com<mailto:notifications@github.com>> wrote:

Hi all,

Sorry, was travelling today, haven't been able to take a look at the code
yet. A guess: could the order/names of the features matter?

Cheers,
Andreas

On Tue, 24 Jul 2018 at 21:00 tomdakin <notifications@github.com<mailto:notifications@github.com>> wrote:

> It seems to happen with every feature I’ve tried so far.
> T
>
> On 24 Jul 2018, at 19:51, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>
> <mailto:notifications@github.com>> wrote:
>
> Does this happen with any feature that you change or with one feature in
> particular?
>
> On Tue, 24 Jul 2018 at 18:13, tomdakin <notifications@github.com<mailto:notifications@github.com><mailto:
> notifications@github.com<mailto:notifications@github.com>>> wrote:
>
> > I spoke too soon - I misread my output. The feature is in fact being
> > extracted the same in both classes!
> > T
> >
> > On 24 Jul 2018, at 18:07, Tom Dakin <tom.a.dakin@hotmail.co.uk<mailto:tom.a.dakin@hotmail.co.uk><mailto:
> tom.a.dakin@hotmail.co.uk<mailto:tom.a.dakin@hotmail.co.uk>><mailto:
> > tom.a.dakin@hotmail.co.uk<mailto:tom.a.dakin@hotmail.co.uk><mailto:tom.a.dakin@hotmail.co.uk>>> wrote:
> >
> > Hi Fernando,
> >
> > Thanks for the debug tip - it worked. For some reason the features are
> > coming back differently when they are in different extractor classes.
> This
> > is obviously bad, but I will fix it. It is much easier to fix than the
> case
> > where the algorithm is giving different predictions for the same
> features!
> >
> > I’ll work on it and hopefully get the bug ironed out tonight.
> >
> > Cheers
> > Tom
> >
> > On 24 Jul 2018, at 14:47, Fernando Alva Manchego <
> notifications@github.com<mailto:notifications@github.com><mailto:notifications@github.com>
> > <mailto:notifications@github.com>> wrote:
> >
> >
> > Hi Tom,
> >
> > Thank you for this. I have just tested the model and, indeed, the code
> is
> > back at running at a very reasonable speed. Nice work!
> >
> > What you mention is very odd. I would suggest to first perform a sort of
> > sanity check, and make sure that even by moving code between extractors,
> we
> > are obtaining the same number and values for all features.
> > All of our features are deterministic, so we should always get the same
> > feature table. This may not seem meaningful, but I would just like to
> make
> > sure we are not making a silly mistake in the code.
> >
> > If we indeed get the same feature table but still different predictions,
> > then I currently have no other ideas. Any thoughts @andreasvlachos<
> > https://github.com/andreasvlachos> ?
> >
> > Best,
> > Fernando
> >
> > —
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub<
> > https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407412711>, or
> > mute the thread<
> >
> https://github.com/notifications/unsubscribe-auth/AfUBhEmK3-FMbJv1RDmMKHrPirQH75iuks5uJyWBgaJpZM4VcuGr>.
>
> >
> >
> >
> > —
> > You are receiving this because you modified the open/close state.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407482321>,
> or mute
> > the thread
> > <
> https://github.com/notifications/unsubscribe-auth/ACof6Nf-64WBS_jUoybsXsCVG_5aYI7Bks5uJ1XKgaJpZM4VcuGr>
>
> > .
> >
>
>
> --
> Fernando Alva Manchego
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub<
> https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407513586>, or
> mute the thread<
> https://github.com/notifications/unsubscribe-auth/AfUBhPJaiBUvmZbmPTsiV27gq8iDwDTwks5uJ2ycgaJpZM4VcuGr>.
>
>
> —
> You are receiving this because you were mentioned.
>
>
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407532941>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABbUhT5Wd9gv0yXSzqb6vUiQmec-QqAHks5uJ3zigaJpZM4VcuGr>
> .
>

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407537371>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhNDIa4CN_mtkBUPyxPOdbjTLVoxGks5uJ4BngaJpZM4VcuGr>.

",27
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-06-30T11:17:15Z,"Hi Tom,

Thank you for the code. It looks good overall. There is one detail that I think we need to figure out.

What's going to be the purpose of the getter methods in the Dataset class: train_set(), dev_set(), test_set()? Originally, the idea was to read the data (if it hadn't been read before) and then return it. Now that we have the pickle objects. Is anyone who calls train_set(), for example, going to expect to have the data from the pickle objects too? If that is the case, then I think we could modify the code from those functions a little bit.  Something like this:

```
        if self._trainset is None: 
            trainset_raw = self.read_dataset(self._trainset_path)
            trainset_spacy = self.read_spacy_pickle(self._trainset_spacy_path)
            self._trainset = pd.concat([trainset_raw, trainset_spacy], axis=1)
        
        return  self._trainset
```

What do you think? ",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-06-30T11:26:02Z,"Regarding your question about the pickle objects, we could put them in the Google Drive and then each one will have to download them and put them in the right folder. We should also add a .gitignore in those folders. Is that reasonable? Any other ideas @andreasvlachos?",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-06-30T11:29:40Z,"Hi Fernando,

I agree, that looks good. Will pandas behave OK if there is no spacy set there to concatenate?

Cheers,
Tom

On 30 Jun 2018, at 12:17, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>> wrote:


Hi Tom,

Thank you for the code. It looks good overall. There is one detail that I think we need to figure out.

What's going to be the purpose of the getter methods in the Dataset class: train_set(), dev_set(), test_set()? Originally, the idea was to read the data (if it hadn't been read before) and then return it. Now that we have the pickle objects. Is anyone who calls train_set(), for example, going to expect to have the data from the pickle objects too? If that is the case, then I think we could modify the code from those functions a little bit. Something like this:

        if self._trainset is None:
            trainset_raw = self.read_dataset(self._trainset_path)
            trainset_spacy = self.read_spacy_pickle(self._trainset_spacy_path)
            self._trainset = pd.concat([trainset_raw, trainset_spacy], axis=1)

        return  self._trainset


What do you think?

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401534627>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhOIlqoh_PzZfexTZoBhInvY7km-Oks5uB148gaJpZM4U9hnK>.

",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-06-30T11:32:10Z,"Cool. I did have another idea about this, which is that by running

$ python3 src/data/build_spacy_objects.py <LANGUAGE>

For each language locally, we can each build the pickles on our own machines.

I don’t know which is more appropriate…

Cheers,
Tom

On 30 Jun 2018, at 12:26, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>> wrote:


Regarding your question about the pickle objects, we could put them in the Google Drive and then each one will have to download them and put them in the right folder. We should also add a .gitignore in those folders. Is that reasonable? Any other ideas @andreasvlachos<https://github.com/andreasvlachos>?

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401534995>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhF_kZmrhdLtIaZr59gfyOBUj5UABks5uB2BKgaJpZM4U9hnK>.

",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-06-30T11:49:27Z,"If everything going forward relies on the spacy data being loaded, then we need to make sure that the pickle object exists. Two ways that I could think of for handling this:

1. If the pickle object does not exist, we could send an error message requesting that it be created, and then terminate the program because we cannot continue.

2. If the pickle object does not exist, we could send a warning message, and then internally process the data using spacy and create the pickle object.

Remember that the idea of having the pickle objects was to avoid having to run the spacy parsers every time that we need to train and test. I personally prefer option 1.",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-01T11:21:59Z,"Hi guys,

Thanks for the good conversation. I think that both options Fernando
mentions will eventually be used, option 1 to quickly setup an experiment
on a new machine, option 2 to experiment with the spacy preprocessing and
ensure we can replicate our work from scratch. Let’s support both. Maybe
the easiest would be to implement option 2, and the user sees the message
and decides whether to wait for the preprocessing to finish or interrupts
it and downloads, Google drive would be the place for the large files.

Cheers,
Andreas
On Sat, 30 Jun 2018 at 12:49, Fernando Alva Manchego <
notifications@github.com> wrote:

> If everything going forward relies on the spacy data being loaded, then we
> need to make sure that the pickle object exists. Two ways that I could
> think of for handling this:
>
>    1.
>
>    If the pickle object does not exist, we could send an error message
>    requesting that it be created, and then terminate the program because we
>    cannot continue.
>    2.
>
>    If the pickle object does not exist, we could send a warning message,
>    and then internally process the data using spacy and create the pickle
>    object.
>
> Remember that the idea of having the pickle objects was to avoid having to
> run the spacy parsers every time that we need to train and test. I
> personally prefer option 1.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401536118>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABbUhaJ8xdsqKNg9Fhsvf2REBbiPKbByks5uB2XHgaJpZM4U9hnK>
> .
>
",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-02T07:53:14Z,"Hi,

That sounds good. Should I code this up on my fork as it is and submit a new pull request, Fernando?

Thanks,
Tom

On 1 Jul 2018, at 12:21, Andreas Vlachos <notifications@github.com<mailto:notifications@github.com>> wrote:

Hi guys,

Thanks for the good conversation. I think that both options Fernando
mentions will eventually be used, option 1 to quickly setup an experiment
on a new machine, option 2 to experiment with the spacy preprocessing and
ensure we can replicate our work from scratch. Let’s support both. Maybe
the easiest would be to implement option 2, and the user sees the message
and decides whether to wait for the preprocessing to finish or interrupts
it and downloads, Google drive would be the place for the large files.

Cheers,
Andreas
On Sat, 30 Jun 2018 at 12:49, Fernando Alva Manchego <
notifications@github.com<mailto:notifications@github.com>> wrote:

> If everything going forward relies on the spacy data being loaded, then we
> need to make sure that the pickle object exists. Two ways that I could
> think of for handling this:
>
> 1.
>
> If the pickle object does not exist, we could send an error message
> requesting that it be created, and then terminate the program because we
> cannot continue.
> 2.
>
> If the pickle object does not exist, we could send a warning message,
> and then internally process the data using spacy and create the pickle
> object.
>
> Remember that the idea of having the pickle objects was to avoid having to
> run the spacy parsers every time that we need to train and test. I
> personally prefer option 1.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401536118>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABbUhaJ8xdsqKNg9Fhsvf2REBbiPKbByks5uB2XHgaJpZM4U9hnK>
> .
>

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401600359>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhF3-PKb7TJ6MQrB6Oftelb0wkEpjks5uCLDXgaJpZM4U9hnK>.

",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-02T09:25:05Z,"Yes, please.

On 2 July 2018 at 08:53, tomdakin <notifications@github.com> wrote:

> Hi,
>
> That sounds good. Should I code this up on my fork as it is and submit a
> new pull request, Fernando?
>
> Thanks,
> Tom
>
> On 1 Jul 2018, at 12:21, Andreas Vlachos <notifications@github.com<mailto:
> notifications@github.com>> wrote:
>
> Hi guys,
>
> Thanks for the good conversation. I think that both options Fernando
> mentions will eventually be used, option 1 to quickly setup an experiment
> on a new machine, option 2 to experiment with the spacy preprocessing and
> ensure we can replicate our work from scratch. Let’s support both. Maybe
> the easiest would be to implement option 2, and the user sees the message
> and decides whether to wait for the preprocessing to finish or interrupts
> it and downloads, Google drive would be the place for the large files.
>
> Cheers,
> Andreas
> On Sat, 30 Jun 2018 at 12:49, Fernando Alva Manchego <
> notifications@github.com<mailto:notifications@github.com>> wrote:
>
> > If everything going forward relies on the spacy data being loaded, then
> we
> > need to make sure that the pickle object exists. Two ways that I could
> > think of for handling this:
> >
> > 1.
> >
> > If the pickle object does not exist, we could send an error message
> > requesting that it be created, and then terminate the program because we
> > cannot continue.
> > 2.
> >
> > If the pickle object does not exist, we could send a warning message,
> > and then internally process the data using spacy and create the pickle
> > object.
> >
> > Remember that the idea of having the pickle objects was to avoid having
> to
> > run the spacy parsers every time that we need to train and test. I
> > personally prefer option 1.
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401536118>, or
> mute
> > the thread
> > <https://github.com/notifications/unsubscribe-auth/
> ABbUhaJ8xdsqKNg9Fhsvf2REBbiPKbByks5uB2XHgaJpZM4U9hnK>
> > .
> >
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub<https://github.com/
> sheffieldnlp/cwi/pull/7#issuecomment-401600359>, or mute the thread<
> https://github.com/notifications/unsubscribe-auth/AfUBhF3-
> PKb7TJ6MQrB6Oftelb0wkEpjks5uCLDXgaJpZM4U9hnK>.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401701776>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ACof6KVctrZaVGlcXctEHL6Vn_aoOP45ks5uCdFrgaJpZM4U9hnK>
> .
>



-- 
Fernando Alva Manchego
",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-02T14:07:02Z,"Hi Fernando, 
I've updated the spacy/raw dataset structure as per your suggestion. 
Thanks,
Tom",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-02T14:42:06Z,P.S. Do I need to wait for you to merge the pull before I make further changes? ,7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-02T14:49:51Z,Merge done.,7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-06-30T11:17:15Z,"Hi Tom,

Thank you for the code. It looks good overall. There is one detail that I think we need to figure out.

What's going to be the purpose of the getter methods in the Dataset class: train_set(), dev_set(), test_set()? Originally, the idea was to read the data (if it hadn't been read before) and then return it. Now that we have the pickle objects. Is anyone who calls train_set(), for example, going to expect to have the data from the pickle objects too? If that is the case, then I think we could modify the code from those functions a little bit.  Something like this:

```
        if self._trainset is None: 
            trainset_raw = self.read_dataset(self._trainset_path)
            trainset_spacy = self.read_spacy_pickle(self._trainset_spacy_path)
            self._trainset = pd.concat([trainset_raw, trainset_spacy], axis=1)
        
        return  self._trainset
```

What do you think? ",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-06-30T11:26:02Z,"Regarding your question about the pickle objects, we could put them in the Google Drive and then each one will have to download them and put them in the right folder. We should also add a .gitignore in those folders. Is that reasonable? Any other ideas @andreasvlachos?",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-06-30T11:29:40Z,"Hi Fernando,

I agree, that looks good. Will pandas behave OK if there is no spacy set there to concatenate?

Cheers,
Tom

On 30 Jun 2018, at 12:17, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>> wrote:


Hi Tom,

Thank you for the code. It looks good overall. There is one detail that I think we need to figure out.

What's going to be the purpose of the getter methods in the Dataset class: train_set(), dev_set(), test_set()? Originally, the idea was to read the data (if it hadn't been read before) and then return it. Now that we have the pickle objects. Is anyone who calls train_set(), for example, going to expect to have the data from the pickle objects too? If that is the case, then I think we could modify the code from those functions a little bit. Something like this:

        if self._trainset is None:
            trainset_raw = self.read_dataset(self._trainset_path)
            trainset_spacy = self.read_spacy_pickle(self._trainset_spacy_path)
            self._trainset = pd.concat([trainset_raw, trainset_spacy], axis=1)

        return  self._trainset


What do you think?

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401534627>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhOIlqoh_PzZfexTZoBhInvY7km-Oks5uB148gaJpZM4U9hnK>.

",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-06-30T11:32:10Z,"Cool. I did have another idea about this, which is that by running

$ python3 src/data/build_spacy_objects.py <LANGUAGE>

For each language locally, we can each build the pickles on our own machines.

I don’t know which is more appropriate…

Cheers,
Tom

On 30 Jun 2018, at 12:26, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>> wrote:


Regarding your question about the pickle objects, we could put them in the Google Drive and then each one will have to download them and put them in the right folder. We should also add a .gitignore in those folders. Is that reasonable? Any other ideas @andreasvlachos<https://github.com/andreasvlachos>?

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401534995>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhF_kZmrhdLtIaZr59gfyOBUj5UABks5uB2BKgaJpZM4U9hnK>.

",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-06-30T11:49:27Z,"If everything going forward relies on the spacy data being loaded, then we need to make sure that the pickle object exists. Two ways that I could think of for handling this:

1. If the pickle object does not exist, we could send an error message requesting that it be created, and then terminate the program because we cannot continue.

2. If the pickle object does not exist, we could send a warning message, and then internally process the data using spacy and create the pickle object.

Remember that the idea of having the pickle objects was to avoid having to run the spacy parsers every time that we need to train and test. I personally prefer option 1.",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-01T11:21:59Z,"Hi guys,

Thanks for the good conversation. I think that both options Fernando
mentions will eventually be used, option 1 to quickly setup an experiment
on a new machine, option 2 to experiment with the spacy preprocessing and
ensure we can replicate our work from scratch. Let’s support both. Maybe
the easiest would be to implement option 2, and the user sees the message
and decides whether to wait for the preprocessing to finish or interrupts
it and downloads, Google drive would be the place for the large files.

Cheers,
Andreas
On Sat, 30 Jun 2018 at 12:49, Fernando Alva Manchego <
notifications@github.com> wrote:

> If everything going forward relies on the spacy data being loaded, then we
> need to make sure that the pickle object exists. Two ways that I could
> think of for handling this:
>
>    1.
>
>    If the pickle object does not exist, we could send an error message
>    requesting that it be created, and then terminate the program because we
>    cannot continue.
>    2.
>
>    If the pickle object does not exist, we could send a warning message,
>    and then internally process the data using spacy and create the pickle
>    object.
>
> Remember that the idea of having the pickle objects was to avoid having to
> run the spacy parsers every time that we need to train and test. I
> personally prefer option 1.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401536118>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABbUhaJ8xdsqKNg9Fhsvf2REBbiPKbByks5uB2XHgaJpZM4U9hnK>
> .
>
",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-02T07:53:14Z,"Hi,

That sounds good. Should I code this up on my fork as it is and submit a new pull request, Fernando?

Thanks,
Tom

On 1 Jul 2018, at 12:21, Andreas Vlachos <notifications@github.com<mailto:notifications@github.com>> wrote:

Hi guys,

Thanks for the good conversation. I think that both options Fernando
mentions will eventually be used, option 1 to quickly setup an experiment
on a new machine, option 2 to experiment with the spacy preprocessing and
ensure we can replicate our work from scratch. Let’s support both. Maybe
the easiest would be to implement option 2, and the user sees the message
and decides whether to wait for the preprocessing to finish or interrupts
it and downloads, Google drive would be the place for the large files.

Cheers,
Andreas
On Sat, 30 Jun 2018 at 12:49, Fernando Alva Manchego <
notifications@github.com<mailto:notifications@github.com>> wrote:

> If everything going forward relies on the spacy data being loaded, then we
> need to make sure that the pickle object exists. Two ways that I could
> think of for handling this:
>
> 1.
>
> If the pickle object does not exist, we could send an error message
> requesting that it be created, and then terminate the program because we
> cannot continue.
> 2.
>
> If the pickle object does not exist, we could send a warning message,
> and then internally process the data using spacy and create the pickle
> object.
>
> Remember that the idea of having the pickle objects was to avoid having to
> run the spacy parsers every time that we need to train and test. I
> personally prefer option 1.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401536118>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABbUhaJ8xdsqKNg9Fhsvf2REBbiPKbByks5uB2XHgaJpZM4U9hnK>
> .
>

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401600359>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhF3-PKb7TJ6MQrB6Oftelb0wkEpjks5uCLDXgaJpZM4U9hnK>.

",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-02T09:25:05Z,"Yes, please.

On 2 July 2018 at 08:53, tomdakin <notifications@github.com> wrote:

> Hi,
>
> That sounds good. Should I code this up on my fork as it is and submit a
> new pull request, Fernando?
>
> Thanks,
> Tom
>
> On 1 Jul 2018, at 12:21, Andreas Vlachos <notifications@github.com<mailto:
> notifications@github.com>> wrote:
>
> Hi guys,
>
> Thanks for the good conversation. I think that both options Fernando
> mentions will eventually be used, option 1 to quickly setup an experiment
> on a new machine, option 2 to experiment with the spacy preprocessing and
> ensure we can replicate our work from scratch. Let’s support both. Maybe
> the easiest would be to implement option 2, and the user sees the message
> and decides whether to wait for the preprocessing to finish or interrupts
> it and downloads, Google drive would be the place for the large files.
>
> Cheers,
> Andreas
> On Sat, 30 Jun 2018 at 12:49, Fernando Alva Manchego <
> notifications@github.com<mailto:notifications@github.com>> wrote:
>
> > If everything going forward relies on the spacy data being loaded, then
> we
> > need to make sure that the pickle object exists. Two ways that I could
> > think of for handling this:
> >
> > 1.
> >
> > If the pickle object does not exist, we could send an error message
> > requesting that it be created, and then terminate the program because we
> > cannot continue.
> > 2.
> >
> > If the pickle object does not exist, we could send a warning message,
> > and then internally process the data using spacy and create the pickle
> > object.
> >
> > Remember that the idea of having the pickle objects was to avoid having
> to
> > run the spacy parsers every time that we need to train and test. I
> > personally prefer option 1.
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401536118>, or
> mute
> > the thread
> > <https://github.com/notifications/unsubscribe-auth/
> ABbUhaJ8xdsqKNg9Fhsvf2REBbiPKbByks5uB2XHgaJpZM4U9hnK>
> > .
> >
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub<https://github.com/
> sheffieldnlp/cwi/pull/7#issuecomment-401600359>, or mute the thread<
> https://github.com/notifications/unsubscribe-auth/AfUBhF3-
> PKb7TJ6MQrB6Oftelb0wkEpjks5uCLDXgaJpZM4U9hnK>.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/7#issuecomment-401701776>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ACof6KVctrZaVGlcXctEHL6Vn_aoOP45ks5uCdFrgaJpZM4U9hnK>
> .
>



-- 
Fernando Alva Manchego
",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-02T14:07:02Z,"Hi Fernando, 
I've updated the spacy/raw dataset structure as per your suggestion. 
Thanks,
Tom",7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-02T14:42:06Z,P.S. Do I need to wait for you to merge the pull before I make further changes? ,7
github.com/sheffieldnlp/cwi,src/data/build_spacy_objects.py,2018-07-02T14:49:51Z,Merge done.,7
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-10-26T19:28:49Z,"I also did some tests with a Random Forest Classifier. Average performance dropped, but some languages were a reasonable amount better-off.
```
Crosslingual Model
Lang	LogReg	RandFor
Fr	0.643	0.691
EnN	0.729	0.653
EnWN	0.675	0.591
EnW	0.685	0.591
Es	0.689	0.712
De	0.703	0.626
---------------------
Avg	0.687	0.644
```",34
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-10-27T16:59:46Z,Thanks Pierre. Interesting results.,34
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-10-26T19:28:49Z,"I also did some tests with a Random Forest Classifier. Average performance dropped, but some languages were a reasonable amount better-off.
```
Crosslingual Model
Lang	LogReg	RandFor
Fr	0.643	0.691
EnN	0.729	0.653
EnWN	0.675	0.591
EnW	0.685	0.591
Es	0.689	0.712
De	0.703	0.626
---------------------
Avg	0.687	0.644
```",34
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-10-27T16:59:46Z,Thanks Pierre. Interesting results.,34
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-27T18:45:43Z,"OK, now it works with all languages.

Results for this commit:
Testing on  english - News.
macro-F1: 0.733

Testing on  english - WikiNews.
macro-F1: 0.692

Testing on  english - Wikipedia.
macro-F1: 0.690

Testing on  german - German.
macro-F1: 0.659

Testing on  spanish - Spanish.
macro-F1: 0.645

Testing on  french - French.
macro-F1: 0.226",31
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-27T19:55:50Z,"Ok! I suggest we use to drive progress, as this is the obvious test case in
this, and the main comparison against previous work!
On Fri, 27 Jul 2018 at 19:47, IntoThePit <notifications@github.com> wrote:

> OK, now it works with all languages.
>
> Results for this commit:
> Testing on english - News.
> macro-F1: 0.733
>
> Testing on english - WikiNews.
> macro-F1: 0.692
>
> Testing on english - Wikipedia.
> macro-F1: 0.690
>
> Testing on german - German.
> macro-F1: 0.659
>
> Testing on spanish - Spanish.
> macro-F1: 0.645
>
> Testing on french - French.
> macro-F1: 0.226
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/31#issuecomment-408506615>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABbUhQgPvd77fSqHa1zVSwThJrd_NbW3ks5uK1_XgaJpZM4VkaZi>
> .
>
",31
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-26T16:28:15Z,"""run_monolingual **should** still work.""

Could you make sure that they indeed work?",30
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-26T17:22:15Z,"Whoops, yeah I meant it did still work as far as I can test on my Windows machine.

Though, looking at it now, it only produces results for English? Is this a more recent change that I'm unaware of? It doesn't error or anything, it just completes having tested on English. As far as I'm aware, this isn't a change I've introduced.

Model for english - News.

Results on Test Data
macro-F1: 0.864


Model for english - WikiNews.

Results on Test Data
macro-F1: 0.818


Model for english - Wikipedia.

Results on Test Data
macro-F1: 0.789",30
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-26T17:25:07Z,"Hi Pierre,

Are you using the -l flag and specifying language when running
run_monolingual? The default (no flag) shows results only for English.

Kind regards,
Sanjana

On 26 July 2018 at 18:22, IntoThePit <notifications@github.com> wrote:

> Whoops, yeah I meant it did still work as far as I can test on my Windows
> machine.
>
> Though, looking at it now, it only produces results for English? Is this a
> more recent change that I'm unaware of? It doesn't error or anything, it
> just completes having tested on English. As far as I'm aware, this isn't a
> change I've introduced.
>
> Model for english - News.
>
> Results on Test Data
> macro-F1: 0.864
>
> Model for english - WikiNews.
>
> Results on Test Data
> macro-F1: 0.818
>
> Model for english - Wikipedia.
>
> Results on Test Data
> macro-F1: 0.789
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/30#issuecomment-408171386>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/APaUw3Kx19Ond7q1JDbbkUcTrpqvcPKcks5uKfrHgaJpZM4ViHuL>
> .
>
",30
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-26T17:39:00Z,"Thanks Sanjana, I just found it, and there was another unrelated error relating to Spanish encoding, which I just fixed by adding the usual encoding='utf-8' to the file open.

It'd be quite nice to have an ability to select ""all languages"" option for testing",30
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-26T16:28:15Z,"""run_monolingual **should** still work.""

Could you make sure that they indeed work?",30
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-26T17:22:15Z,"Whoops, yeah I meant it did still work as far as I can test on my Windows machine.

Though, looking at it now, it only produces results for English? Is this a more recent change that I'm unaware of? It doesn't error or anything, it just completes having tested on English. As far as I'm aware, this isn't a change I've introduced.

Model for english - News.

Results on Test Data
macro-F1: 0.864


Model for english - WikiNews.

Results on Test Data
macro-F1: 0.818


Model for english - Wikipedia.

Results on Test Data
macro-F1: 0.789",30
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-26T17:25:07Z,"Hi Pierre,

Are you using the -l flag and specifying language when running
run_monolingual? The default (no flag) shows results only for English.

Kind regards,
Sanjana

On 26 July 2018 at 18:22, IntoThePit <notifications@github.com> wrote:

> Whoops, yeah I meant it did still work as far as I can test on my Windows
> machine.
>
> Though, looking at it now, it only produces results for English? Is this a
> more recent change that I'm unaware of? It doesn't error or anything, it
> just completes having tested on English. As far as I'm aware, this isn't a
> change I've introduced.
>
> Model for english - News.
>
> Results on Test Data
> macro-F1: 0.864
>
> Model for english - WikiNews.
>
> Results on Test Data
> macro-F1: 0.818
>
> Model for english - Wikipedia.
>
> Results on Test Data
> macro-F1: 0.789
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/30#issuecomment-408171386>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/APaUw3Kx19Ond7q1JDbbkUcTrpqvcPKcks5uKfrHgaJpZM4ViHuL>
> .
>
",30
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-26T17:39:00Z,"Thanks Sanjana, I just found it, and there was another unrelated error relating to Spanish encoding, which I just fixed by adding the usual encoding='utf-8' to the file open.

It'd be quite nice to have an ability to select ""all languages"" option for testing",30
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-25T09:48:33Z,"Thanks Tom. I would try to take a look at it, and will encourage everyone else to try it to.",28
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-24T13:47:45Z,"Hi Tom,

Thank you for this. I have just tested the model and, indeed, the code is back at running at a very reasonable speed. Nice work!

What you mention is very odd. I would suggest to first perform a sort of sanity check, and make sure that even by moving code between extractors, we are obtaining the same number and values for all features. 
All of our features are deterministic, so we should always get the same feature table. This may not seem meaningful, but I would just like to make sure we are not making a silly mistake in the code.

If we indeed get the same feature table but still different predictions, then I currently have no other ideas. Any thoughts @andreasvlachos ?

Best,
Fernando
",27
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-24T17:07:27Z,"Hi Fernando,

Thanks for the debug tip - it worked. For some reason the features are coming back differently when they are in different extractor classes. This is obviously bad, but I will fix it. It is much easier to fix than the case where the algorithm is giving different predictions for the same features!

I’ll work on it and hopefully get the bug ironed out tonight.

Cheers
Tom

On 24 Jul 2018, at 14:47, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>> wrote:


Hi Tom,

Thank you for this. I have just tested the model and, indeed, the code is back at running at a very reasonable speed. Nice work!

What you mention is very odd. I would suggest to first perform a sort of sanity check, and make sure that even by moving code between extractors, we are obtaining the same number and values for all features.
All of our features are deterministic, so we should always get the same feature table. This may not seem meaningful, but I would just like to make sure we are not making a silly mistake in the code.

If we indeed get the same feature table but still different predictions, then I currently have no other ideas. Any thoughts @andreasvlachos<https://github.com/andreasvlachos> ?

Best,
Fernando

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407412711>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhEmK3-FMbJv1RDmMKHrPirQH75iuks5uJyWBgaJpZM4VcuGr>.

",27
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-24T17:13:45Z,"I spoke too soon - I misread my output. The feature is in fact being extracted the same in both classes!
T

On 24 Jul 2018, at 18:07, Tom Dakin <tom.a.dakin@hotmail.co.uk<mailto:tom.a.dakin@hotmail.co.uk>> wrote:

Hi Fernando,

Thanks for the debug tip - it worked. For some reason the features are coming back differently when they are in different extractor classes. This is obviously bad, but I will fix it. It is much easier to fix than the case where the algorithm is giving different predictions for the same features!

I’ll work on it and hopefully get the bug ironed out tonight.

Cheers
Tom

On 24 Jul 2018, at 14:47, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>> wrote:


Hi Tom,

Thank you for this. I have just tested the model and, indeed, the code is back at running at a very reasonable speed. Nice work!

What you mention is very odd. I would suggest to first perform a sort of sanity check, and make sure that even by moving code between extractors, we are obtaining the same number and values for all features.
All of our features are deterministic, so we should always get the same feature table. This may not seem meaningful, but I would just like to make sure we are not making a silly mistake in the code.

If we indeed get the same feature table but still different predictions, then I currently have no other ideas. Any thoughts @andreasvlachos<https://github.com/andreasvlachos> ?

Best,
Fernando

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407412711>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhEmK3-FMbJv1RDmMKHrPirQH75iuks5uJyWBgaJpZM4VcuGr>.


",27
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-24T18:51:06Z,"Does this happen with any feature that you change or with one feature in
particular?

On Tue, 24 Jul 2018 at 18:13, tomdakin <notifications@github.com> wrote:

> I spoke too soon - I misread my output. The feature is in fact being
> extracted the same in both classes!
> T
>
> On 24 Jul 2018, at 18:07, Tom Dakin <tom.a.dakin@hotmail.co.uk<mailto:
> tom.a.dakin@hotmail.co.uk>> wrote:
>
> Hi Fernando,
>
> Thanks for the debug tip - it worked. For some reason the features are
> coming back differently when they are in different extractor classes. This
> is obviously bad, but I will fix it. It is much easier to fix than the case
> where the algorithm is giving different predictions for the same features!
>
> I’ll work on it and hopefully get the bug ironed out tonight.
>
> Cheers
> Tom
>
> On 24 Jul 2018, at 14:47, Fernando Alva Manchego <notifications@github.com
> <mailto:notifications@github.com>> wrote:
>
>
> Hi Tom,
>
> Thank you for this. I have just tested the model and, indeed, the code is
> back at running at a very reasonable speed. Nice work!
>
> What you mention is very odd. I would suggest to first perform a sort of
> sanity check, and make sure that even by moving code between extractors, we
> are obtaining the same number and values for all features.
> All of our features are deterministic, so we should always get the same
> feature table. This may not seem meaningful, but I would just like to make
> sure we are not making a silly mistake in the code.
>
> If we indeed get the same feature table but still different predictions,
> then I currently have no other ideas. Any thoughts @andreasvlachos<
> https://github.com/andreasvlachos> ?
>
> Best,
> Fernando
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub<
> https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407412711>, or
> mute the thread<
> https://github.com/notifications/unsubscribe-auth/AfUBhEmK3-FMbJv1RDmMKHrPirQH75iuks5uJyWBgaJpZM4VcuGr>.
>
>
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407482321>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ACof6Nf-64WBS_jUoybsXsCVG_5aYI7Bks5uJ1XKgaJpZM4VcuGr>
> .
>


-- 
Fernando Alva Manchego
",27
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-24T20:00:33Z,"It seems to happen with every feature I’ve tried so far.
T

On 24 Jul 2018, at 19:51, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>> wrote:

Does this happen with any feature that you change or with one feature in
particular?

On Tue, 24 Jul 2018 at 18:13, tomdakin <notifications@github.com<mailto:notifications@github.com>> wrote:

> I spoke too soon - I misread my output. The feature is in fact being
> extracted the same in both classes!
> T
>
> On 24 Jul 2018, at 18:07, Tom Dakin <tom.a.dakin@hotmail.co.uk<mailto:tom.a.dakin@hotmail.co.uk><mailto:
> tom.a.dakin@hotmail.co.uk<mailto:tom.a.dakin@hotmail.co.uk>>> wrote:
>
> Hi Fernando,
>
> Thanks for the debug tip - it worked. For some reason the features are
> coming back differently when they are in different extractor classes. This
> is obviously bad, but I will fix it. It is much easier to fix than the case
> where the algorithm is giving different predictions for the same features!
>
> I’ll work on it and hopefully get the bug ironed out tonight.
>
> Cheers
> Tom
>
> On 24 Jul 2018, at 14:47, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>
> <mailto:notifications@github.com>> wrote:
>
>
> Hi Tom,
>
> Thank you for this. I have just tested the model and, indeed, the code is
> back at running at a very reasonable speed. Nice work!
>
> What you mention is very odd. I would suggest to first perform a sort of
> sanity check, and make sure that even by moving code between extractors, we
> are obtaining the same number and values for all features.
> All of our features are deterministic, so we should always get the same
> feature table. This may not seem meaningful, but I would just like to make
> sure we are not making a silly mistake in the code.
>
> If we indeed get the same feature table but still different predictions,
> then I currently have no other ideas. Any thoughts @andreasvlachos<
> https://github.com/andreasvlachos> ?
>
> Best,
> Fernando
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub<
> https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407412711>, or
> mute the thread<
> https://github.com/notifications/unsubscribe-auth/AfUBhEmK3-FMbJv1RDmMKHrPirQH75iuks5uJyWBgaJpZM4VcuGr>.
>
>
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407482321>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ACof6Nf-64WBS_jUoybsXsCVG_5aYI7Bks5uJ1XKgaJpZM4VcuGr>
> .
>


--
Fernando Alva Manchego

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407513586>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhPJaiBUvmZbmPTsiV27gq8iDwDTwks5uJ2ycgaJpZM4VcuGr>.

",27
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-24T20:15:34Z,"Hi all,

Sorry, was travelling today, haven't been able to take a look at the code
yet. A guess: could the order/names of the features matter?

Cheers,
Andreas

On Tue, 24 Jul 2018 at 21:00 tomdakin <notifications@github.com> wrote:

> It seems to happen with every feature I’ve tried so far.
> T
>
> On 24 Jul 2018, at 19:51, Fernando Alva Manchego <notifications@github.com
> <mailto:notifications@github.com>> wrote:
>
> Does this happen with any feature that you change or with one feature in
> particular?
>
> On Tue, 24 Jul 2018 at 18:13, tomdakin <notifications@github.com<mailto:
> notifications@github.com>> wrote:
>
> > I spoke too soon - I misread my output. The feature is in fact being
> > extracted the same in both classes!
> > T
> >
> > On 24 Jul 2018, at 18:07, Tom Dakin <tom.a.dakin@hotmail.co.uk<mailto:
> tom.a.dakin@hotmail.co.uk><mailto:
> > tom.a.dakin@hotmail.co.uk<mailto:tom.a.dakin@hotmail.co.uk>>> wrote:
> >
> > Hi Fernando,
> >
> > Thanks for the debug tip - it worked. For some reason the features are
> > coming back differently when they are in different extractor classes.
> This
> > is obviously bad, but I will fix it. It is much easier to fix than the
> case
> > where the algorithm is giving different predictions for the same
> features!
> >
> > I’ll work on it and hopefully get the bug ironed out tonight.
> >
> > Cheers
> > Tom
> >
> > On 24 Jul 2018, at 14:47, Fernando Alva Manchego <
> notifications@github.com<mailto:notifications@github.com>
> > <mailto:notifications@github.com>> wrote:
> >
> >
> > Hi Tom,
> >
> > Thank you for this. I have just tested the model and, indeed, the code
> is
> > back at running at a very reasonable speed. Nice work!
> >
> > What you mention is very odd. I would suggest to first perform a sort of
> > sanity check, and make sure that even by moving code between extractors,
> we
> > are obtaining the same number and values for all features.
> > All of our features are deterministic, so we should always get the same
> > feature table. This may not seem meaningful, but I would just like to
> make
> > sure we are not making a silly mistake in the code.
> >
> > If we indeed get the same feature table but still different predictions,
> > then I currently have no other ideas. Any thoughts @andreasvlachos<
> > https://github.com/andreasvlachos> ?
> >
> > Best,
> > Fernando
> >
> > —
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub<
> > https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407412711>, or
> > mute the thread<
> >
> https://github.com/notifications/unsubscribe-auth/AfUBhEmK3-FMbJv1RDmMKHrPirQH75iuks5uJyWBgaJpZM4VcuGr>.
>
> >
> >
> >
> > —
> > You are receiving this because you modified the open/close state.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407482321>,
> or mute
> > the thread
> > <
> https://github.com/notifications/unsubscribe-auth/ACof6Nf-64WBS_jUoybsXsCVG_5aYI7Bks5uJ1XKgaJpZM4VcuGr>
>
> > .
> >
>
>
> --
> Fernando Alva Manchego
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub<
> https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407513586>, or
> mute the thread<
> https://github.com/notifications/unsubscribe-auth/AfUBhPJaiBUvmZbmPTsiV27gq8iDwDTwks5uJ2ycgaJpZM4VcuGr>.
>
>
> —
> You are receiving this because you were mentioned.
>
>
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407532941>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABbUhT5Wd9gv0yXSzqb6vUiQmec-QqAHks5uJ3zigaJpZM4VcuGr>
> .
>
",27
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-24T20:45:32Z,"Hi Andreas & All,

That’s the only thing we could think of when Aneeq and I were looking at this earlier - that the order of the features somehow matters. I figure that there could be some randomness in the solver for the logistic regression, and giving it the features in a different order could lead to a different solution. It is pretty high dimensional data. I’m experimenting with different solvers now for LR to see if I can find a setup that is consistent under changing feature order.

Cheers,
Tom

On 24 Jul 2018, at 21:15, Andreas Vlachos <notifications@github.com<mailto:notifications@github.com>> wrote:

Hi all,

Sorry, was travelling today, haven't been able to take a look at the code
yet. A guess: could the order/names of the features matter?

Cheers,
Andreas

On Tue, 24 Jul 2018 at 21:00 tomdakin <notifications@github.com<mailto:notifications@github.com>> wrote:

> It seems to happen with every feature I’ve tried so far.
> T
>
> On 24 Jul 2018, at 19:51, Fernando Alva Manchego <notifications@github.com<mailto:notifications@github.com>
> <mailto:notifications@github.com>> wrote:
>
> Does this happen with any feature that you change or with one feature in
> particular?
>
> On Tue, 24 Jul 2018 at 18:13, tomdakin <notifications@github.com<mailto:notifications@github.com><mailto:
> notifications@github.com<mailto:notifications@github.com>>> wrote:
>
> > I spoke too soon - I misread my output. The feature is in fact being
> > extracted the same in both classes!
> > T
> >
> > On 24 Jul 2018, at 18:07, Tom Dakin <tom.a.dakin@hotmail.co.uk<mailto:tom.a.dakin@hotmail.co.uk><mailto:
> tom.a.dakin@hotmail.co.uk<mailto:tom.a.dakin@hotmail.co.uk>><mailto:
> > tom.a.dakin@hotmail.co.uk<mailto:tom.a.dakin@hotmail.co.uk><mailto:tom.a.dakin@hotmail.co.uk>>> wrote:
> >
> > Hi Fernando,
> >
> > Thanks for the debug tip - it worked. For some reason the features are
> > coming back differently when they are in different extractor classes.
> This
> > is obviously bad, but I will fix it. It is much easier to fix than the
> case
> > where the algorithm is giving different predictions for the same
> features!
> >
> > I’ll work on it and hopefully get the bug ironed out tonight.
> >
> > Cheers
> > Tom
> >
> > On 24 Jul 2018, at 14:47, Fernando Alva Manchego <
> notifications@github.com<mailto:notifications@github.com><mailto:notifications@github.com>
> > <mailto:notifications@github.com>> wrote:
> >
> >
> > Hi Tom,
> >
> > Thank you for this. I have just tested the model and, indeed, the code
> is
> > back at running at a very reasonable speed. Nice work!
> >
> > What you mention is very odd. I would suggest to first perform a sort of
> > sanity check, and make sure that even by moving code between extractors,
> we
> > are obtaining the same number and values for all features.
> > All of our features are deterministic, so we should always get the same
> > feature table. This may not seem meaningful, but I would just like to
> make
> > sure we are not making a silly mistake in the code.
> >
> > If we indeed get the same feature table but still different predictions,
> > then I currently have no other ideas. Any thoughts @andreasvlachos<
> > https://github.com/andreasvlachos> ?
> >
> > Best,
> > Fernando
> >
> > —
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub<
> > https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407412711>, or
> > mute the thread<
> >
> https://github.com/notifications/unsubscribe-auth/AfUBhEmK3-FMbJv1RDmMKHrPirQH75iuks5uJyWBgaJpZM4VcuGr>.
>
> >
> >
> >
> > —
> > You are receiving this because you modified the open/close state.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407482321>,
> or mute
> > the thread
> > <
> https://github.com/notifications/unsubscribe-auth/ACof6Nf-64WBS_jUoybsXsCVG_5aYI7Bks5uJ1XKgaJpZM4VcuGr>
>
> > .
> >
>
>
> --
> Fernando Alva Manchego
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub<
> https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407513586>, or
> mute the thread<
> https://github.com/notifications/unsubscribe-auth/AfUBhPJaiBUvmZbmPTsiV27gq8iDwDTwks5uJ2ycgaJpZM4VcuGr>.
>
>
> —
> You are receiving this because you were mentioned.
>
>
> Reply to this email directly, view it on GitHub
> <https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407532941>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABbUhT5Wd9gv0yXSzqb6vUiQmec-QqAHks5uJ3zigaJpZM4VcuGr>
> .
>

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/sheffieldnlp/cwi/pull/27#issuecomment-407537371>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AfUBhNDIa4CN_mtkBUPyxPOdbjTLVoxGks5uJ4BngaJpZM4VcuGr>.

",27
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-11T10:05:55Z,"Hi Sanjana,
Thanks for the code. I have checked the Google Drive and found the spacy objects you are mentioning. Could you check that again please?

Also, it appears that there are some conflicts in the file `src/features/feature_transfomers.py`. Would you mind fixing that? Probably they were caused by the merge I did a few minutes ago of Tom's code. Apologies for that.",17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-22T11:36:02Z,"Hi Fernando, 

Can this be merged now? I have fixed conflicts and incorporated all spacy objects.

Kind regards,
Sanjana",17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-22T12:02:58Z,There are some errors originating from I think Advanced Extractor for Spanish at the moment. Something related to 'noun chunks'.,17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-11T10:05:55Z,"Hi Sanjana,
Thanks for the code. I have checked the Google Drive and found the spacy objects you are mentioning. Could you check that again please?

Also, it appears that there are some conflicts in the file `src/features/feature_transfomers.py`. Would you mind fixing that? Probably they were caused by the merge I did a few minutes ago of Tom's code. Apologies for that.",17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-22T11:36:02Z,"Hi Fernando, 

Can this be merged now? I have fixed conflicts and incorporated all spacy objects.

Kind regards,
Sanjana",17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-22T12:02:58Z,There are some errors originating from I think Advanced Extractor for Spanish at the moment. Something related to 'noun chunks'.,17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-11T10:05:55Z,"Hi Sanjana,
Thanks for the code. I have checked the Google Drive and found the spacy objects you are mentioning. Could you check that again please?

Also, it appears that there are some conflicts in the file `src/features/feature_transfomers.py`. Would you mind fixing that? Probably they were caused by the merge I did a few minutes ago of Tom's code. Apologies for that.",17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-22T11:36:02Z,"Hi Fernando, 

Can this be merged now? I have fixed conflicts and incorporated all spacy objects.

Kind regards,
Sanjana",17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-22T12:02:58Z,There are some errors originating from I think Advanced Extractor for Spanish at the moment. Something related to 'noun chunks'.,17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-11T10:05:55Z,"Hi Sanjana,
Thanks for the code. I have checked the Google Drive and found the spacy objects you are mentioning. Could you check that again please?

Also, it appears that there are some conflicts in the file `src/features/feature_transfomers.py`. Would you mind fixing that? Probably they were caused by the merge I did a few minutes ago of Tom's code. Apologies for that.",17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-22T11:36:02Z,"Hi Fernando, 

Can this be merged now? I have fixed conflicts and incorporated all spacy objects.

Kind regards,
Sanjana",17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-22T12:02:58Z,There are some errors originating from I think Advanced Extractor for Spanish at the moment. Something related to 'noun chunks'.,17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-11T10:05:55Z,"Hi Sanjana,
Thanks for the code. I have checked the Google Drive and found the spacy objects you are mentioning. Could you check that again please?

Also, it appears that there are some conflicts in the file `src/features/feature_transfomers.py`. Would you mind fixing that? Probably they were caused by the merge I did a few minutes ago of Tom's code. Apologies for that.",17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-22T11:36:02Z,"Hi Fernando, 

Can this be merged now? I have fixed conflicts and incorporated all spacy objects.

Kind regards,
Sanjana",17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-22T12:02:58Z,There are some errors originating from I think Advanced Extractor for Spanish at the moment. Something related to 'noun chunks'.,17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-11T10:05:55Z,"Hi Sanjana,
Thanks for the code. I have checked the Google Drive and found the spacy objects you are mentioning. Could you check that again please?

Also, it appears that there are some conflicts in the file `src/features/feature_transfomers.py`. Would you mind fixing that? Probably they were caused by the merge I did a few minutes ago of Tom's code. Apologies for that.",17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-22T11:36:02Z,"Hi Fernando, 

Can this be merged now? I have fixed conflicts and incorporated all spacy objects.

Kind regards,
Sanjana",17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-22T12:02:58Z,There are some errors originating from I think Advanced Extractor for Spanish at the moment. Something related to 'noun chunks'.,17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-11T10:05:55Z,"Hi Sanjana,
Thanks for the code. I have checked the Google Drive and found the spacy objects you are mentioning. Could you check that again please?

Also, it appears that there are some conflicts in the file `src/features/feature_transfomers.py`. Would you mind fixing that? Probably they were caused by the merge I did a few minutes ago of Tom's code. Apologies for that.",17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-22T11:36:02Z,"Hi Fernando, 

Can this be merged now? I have fixed conflicts and incorporated all spacy objects.

Kind regards,
Sanjana",17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-22T12:02:58Z,There are some errors originating from I think Advanced Extractor for Spanish at the moment. Something related to 'noun chunks'.,17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-11T10:05:55Z,"Hi Sanjana,
Thanks for the code. I have checked the Google Drive and found the spacy objects you are mentioning. Could you check that again please?

Also, it appears that there are some conflicts in the file `src/features/feature_transfomers.py`. Would you mind fixing that? Probably they were caused by the merge I did a few minutes ago of Tom's code. Apologies for that.",17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-22T11:36:02Z,"Hi Fernando, 

Can this be merged now? I have fixed conflicts and incorporated all spacy objects.

Kind regards,
Sanjana",17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-22T12:02:58Z,There are some errors originating from I think Advanced Extractor for Spanish at the moment. Something related to 'noun chunks'.,17
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-06T15:12:06Z,Thank you.,14
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-03T19:48:08Z,"Now this also includes unigrams, bigrams and trigrams, though these seemed to harm performance in non-English languages (maybe just because there's less training data in those languages):

Old --> New:
News: 0.81 --> 0.83(+0.02)
Wikinews: 0.73 --> 0.79(+0.06)
Wikipedia:  0.71 --> 0.73(+0.02)
Spanish: 0.77 --> 0.75(-0.02)
German: 0.75 --> 0.74 (-0.01)",13
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-04T09:21:49Z,Nice work! :),13
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-03T19:48:08Z,"Now this also includes unigrams, bigrams and trigrams, though these seemed to harm performance in non-English languages (maybe just because there's less training data in those languages):

Old --> New:
News: 0.81 --> 0.83(+0.02)
Wikinews: 0.73 --> 0.79(+0.06)
Wikipedia:  0.71 --> 0.73(+0.02)
Spanish: 0.77 --> 0.75(-0.02)
German: 0.75 --> 0.74 (-0.01)",13
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-04T09:21:49Z,Nice work! :),13
github.com/sheffieldnlp/cwi,src/features/feature_transfomers.py,2018-07-02T14:53:45Z,Thank you.,8
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-04-07T03:58:19Z,"Is there a better way to test if a ```date string``` specifies a particular date (e.g. '16th December' vs 'a week ago')? I don't really want to use another library just for this test...

If we are going to stick with this, should we move this somewhere else? (in case we need to handle non-english articles)",135
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-04-05T00:29:47Z,"Based on a couple of tests, I don't think its working quite as expected.

For example, using a publication date of 30th October 2016
````
publication_date = datetime.datetime(2016, 10, 30)
````
Example: ""Friday evening""
Expected result: `datetime.datetime(2016, 10, 28, 0, 0)`
Actual result: `datetime.datetime(2016, 10, 24, 6, 0)`

Example: ""'28th October'""
Expected result: `datetime.datetime(2016, 10, 28, 0, 0)`
Actual result: `datetime.datetime(2015, 11, 2, 0, 0)`




",135
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-04-09T19:34:07Z,"Hey, so that I can merge can I ask you to make one small change:
On line 152 change `return datetime.datetime(`  to `return datetime(` ",135
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-04-10T00:03:03Z,Done :),135
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-04-07T03:58:19Z,"Is there a better way to test if a ```date string``` specifies a particular date (e.g. '16th December' vs 'a week ago')? I don't really want to use another library just for this test...

If we are going to stick with this, should we move this somewhere else? (in case we need to handle non-english articles)",135
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-04-05T00:29:47Z,"Based on a couple of tests, I don't think its working quite as expected.

For example, using a publication date of 30th October 2016
````
publication_date = datetime.datetime(2016, 10, 30)
````
Example: ""Friday evening""
Expected result: `datetime.datetime(2016, 10, 28, 0, 0)`
Actual result: `datetime.datetime(2016, 10, 24, 6, 0)`

Example: ""'28th October'""
Expected result: `datetime.datetime(2016, 10, 28, 0, 0)`
Actual result: `datetime.datetime(2015, 11, 2, 0, 0)`




",135
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-04-09T19:34:07Z,"Hey, so that I can merge can I ask you to make one small change:
On line 152 change `return datetime.datetime(`  to `return datetime(` ",135
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-04-10T00:03:03Z,Done :),135
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-04-07T03:58:19Z,"Is there a better way to test if a ```date string``` specifies a particular date (e.g. '16th December' vs 'a week ago')? I don't really want to use another library just for this test...

If we are going to stick with this, should we move this somewhere else? (in case we need to handle non-english articles)",135
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-04-05T00:29:47Z,"Based on a couple of tests, I don't think its working quite as expected.

For example, using a publication date of 30th October 2016
````
publication_date = datetime.datetime(2016, 10, 30)
````
Example: ""Friday evening""
Expected result: `datetime.datetime(2016, 10, 28, 0, 0)`
Actual result: `datetime.datetime(2016, 10, 24, 6, 0)`

Example: ""'28th October'""
Expected result: `datetime.datetime(2016, 10, 28, 0, 0)`
Actual result: `datetime.datetime(2015, 11, 2, 0, 0)`




",135
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-04-09T19:34:07Z,"Hey, so that I can merge can I ask you to make one small change:
On line 152 change `return datetime.datetime(`  to `return datetime(` ",135
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-04-10T00:03:03Z,Done :),135
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-03-28T15:42:26Z,"By the way, having the docker container set up with everything on the Master branch is awesome and makes it easy for a new person to jump into the project. It would be great to have that pulled into the Interpreter branch as well!",125
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-03-27T15:21:57Z,"Hey....I think I see what happened here....I merged a subsequent PR without checking it properly and it turned out that it was based on an earlier version of the repo.
I will try and clean this up a bit later on today.",113
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-03-28T00:20:15Z,"Hi @alexanderrich you were correct the first time and I had forgotten to include the file.
I think this is fixed now with PR #124 but let me know any other issues you have! Thanks.",113
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-03-28T12:54:15Z,"Everything works now, thanks!",113
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-03-27T15:21:57Z,"Hey....I think I see what happened here....I merged a subsequent PR without checking it properly and it turned out that it was based on an earlier version of the repo.
I will try and clean this up a bit later on today.",113
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-03-28T00:20:15Z,"Hi @alexanderrich you were correct the first time and I had forgotten to include the file.
I think this is fixed now with PR #124 but let me know any other issues you have! Thanks.",113
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-03-28T12:54:15Z,"Everything works now, thanks!",113
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-03-09T17:23:58Z,"Hey, it's looking good.  I think it would be good to take a step back and just think about the processing workflow a second.

The main thing that concerns me is loading `Interpreter()` as this requires loading a 2GB language model, so just want to make sure we are loading at the right point, rather than having to reload it in various places.

In theory, I think the flow for a single URL is / should be:

1. Receive URL
2. Attempt to parse (and save content, title, domain etc. to database?)
3. Load Interpreter
4. Use Interpreter to extract:
  - Language
  - Reports
  - Locations etc.
5. Update article attributes based on output from Interpreter

In my mind I think we should manage this workflow in `pipeline.py` and therefore only initialize `Interpreter()` in the pipeline rather than also in the Article class.

Any thoughts?",101
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-03-09T18:32:23Z,"I was debating if I should use interpreter in ```article.py``` or ```pipeline.py``` too.  Now that I look at the updated schema, it makes sense to have it in pipeline since article is just a data model. ",101
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-02-28T11:33:08Z,"The code looks good. I'm not up to speed on what the purpose is though. Is this to allow for displacy integration? 

e: I'm a moron - forgot to read your pull request description.",88
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-02-25T03:27:14Z,Looks good to me.,87
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-02-18T22:24:23Z,"So, still a lot of work to be done in terms of refactoring, cleaning things up, dealing with some special cases, and then probably lots of testing to see where we're missing things, however here is a start at filling out the interpreter with lots of functions (mostly James' work) for processing articles.

I added a few extra fields to the Article class....I haven't yet updated any of the SQL stuff for these fields, because I thought it would be good to review / discuss how these should be saved.
In particular, what are your thoughts on saving extracted Reports? Creating some sort of separate table with a `belongs to` relationship and foreign key?

In the meantime, I have also included an example notebook of how these functions work in practice.

Let me know any suggestions, modifications or improvements you think I should include at this stage.",74
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-02-19T05:38:15Z,"I've just had another look through the refactored notebook. There are actually several cases of reports that were previously being generated that are now absent. I also noticed some cases that were missed in my DependencyTreeExperiments3 notebook.

 We will need to carefully examine the content of the reports that are generated to check that all relevent information is being extracted from the article (ie merely generating a report for an article is not a guarantee that it has been properly processed). I've made a start at trying to fix some of these issues, but I've run out of time. I've uploaded this work (DependencyTreeExperiments5.ipynb). Apologies; the code in this notebook is a bit of a mess, I plan to come back to this later but I thought I'd give you a heads up on what I've found so far.

e: I still think we should merge this; we will just need to change it later.",74
github.com/Data4Democracy/internal-displacement,internal_displacement/interpreter.py,2017-02-09T04:00:55Z,Looks good and agree with the move from filter to interpreter.,44
github.com/Data4Democracy/internal-displacement,internal_displacement/tests/test_Pipeline.py,2017-03-27T15:21:57Z,"Hey....I think I see what happened here....I merged a subsequent PR without checking it properly and it turned out that it was based on an earlier version of the repo.
I will try and clean this up a bit later on today.",113
github.com/Data4Democracy/internal-displacement,internal_displacement/tests/test_Pipeline.py,2017-03-28T00:20:15Z,"Hi @alexanderrich you were correct the first time and I had forgotten to include the file.
I think this is fixed now with PR #124 but let me know any other issues you have! Thanks.",113
github.com/Data4Democracy/internal-displacement,internal_displacement/tests/test_Pipeline.py,2017-03-28T12:54:15Z,"Everything works now, thanks!",113
github.com/Data4Democracy/internal-displacement,internal_displacement/tests/test_Interpreter.py,2017-02-10T03:28:11Z,Looks good to me,52
github.com/Data4Democracy/internal-displacement,internal_displacement/tests/test_fact_extraction.py,2017-02-25T03:27:14Z,Looks good to me.,87
github.com/Data4Democracy/internal-displacement,internal_displacement/tests/test_fact_extraction.py,2017-02-25T03:27:14Z,Looks good to me.,87
github.com/sloev/spacy-syllables,tests/test_all.py,2021-03-04T11:20:01Z,"lets use the pyphen.language_fallback function to get a short or localized lang code from the given one instead:
https://github.com/Kozea/Pyphen/blob/4e3cac0c90d80ceb2d6209575a1b46cb812fe4b1/pyphen/__init__.py#L53",1
github.com/sloev/spacy-syllables,tests/test_all.py,2021-03-04T11:20:30Z,"pyphen supports a ton of languages, locking ourselves to this shortlist is unnecesary",1
github.com/sloev/spacy-syllables,tests/test_all.py,2021-03-04T11:21:47Z,"lang should be before name, its more common to set the language than the name i think
and name: str should propably be name: Optional[str] = ""syllables""",1
github.com/sloev/spacy-syllables,tests/test_all.py,2021-03-04T18:00:37Z,"The way you add Spacy 3.0 pipeline components means that this init will never be called by the user; custom configuration information gets set in the add_pipe, i.e. `nlp.add_pipe(""syllables"", after=""tagger"", config={""lang"": ""en_US""})`. The way the parameters are laid out here seems to be the convention for spacy 3.0 pipeline components, but I don't think it matters too much, if you still want me to change it, I will.",1
github.com/sloev/spacy-syllables,tests/test_all.py,2021-03-04T18:06:16Z,"I originally did exactly this. The problem is that this resulted in changed behavior. For example, `hyph_en.dic` used to be a soft-link to `en_US`, but it was removed in Pyphen 0.10.0, and the fallback now defaults to `en_GB`. This resulted in failed tests, with certain words having changed numbers of syllables.",1
github.com/sloev/spacy-syllables,tests/test_all.py,2021-03-04T18:07:52Z,"This is only a workaround for the removal of the symlinked defaults in pyphen for the listed languages here, to avoid changing our default behavior. If there's a country code, or if it's not one of these languages, this section won't get called.",1
github.com/sloev/spacy-syllables,tests/test_all.py,2021-03-04T18:51:17Z,"Just so you can see what I'm talking about, `ls` from pyphen-0.9.5:

```
hyph_de.dic -> hyph_de_DE.dic         
hyph_de_AT.dic                        
hyph_de_CH.dic                        
hyph_de_DE.dic                        
hyph_el.dic -> hyph_el_GR.dic         
hyph_el_GR.dic                        
hyph_en.dic -> hyph_en_US.dic         
hyph_en_GB.dic                        
hyph_en_Latn_GB.dic -> hyph_en_GB.dic 
hyph_en_Latn_US.dic -> hyph_en_US.dic 
hyph_en_US.dic                        
[...]
hyph_pt.dic -> hyph_pt_PT.dic         
hyph_pt_BR.dic                        
hyph_pt_Latn_BR.dic -> hyph_pt_BR.dic 
hyph_pt_Latn_PT.dic -> hyph_pt_PT.dic 
hyph_pt_PT.dic                        
```

The defaults for `de`, `en`, and `pt` changed as a result of dropping the symlinks, because `pyphen.language_fallback()` just looks up alphabetically. So, `de` defaults to `de_AT` instead of `de_DE`, `en` defaults to `en_GB` instead of `en_US`, and `pt` defaults to `pt_BR` instead of `pt_PT`.

While other languages had their symlinked defaults dropped (like `hyph_el.dic -> hyph_el_GR.dic`), these only had one country variation, so it was not necessary to add those to the workaround.",1
github.com/sloev/spacy-syllables,tests/test_all.py,2021-03-04T18:34:48Z,"I've just added a section to the readme with information on how to migrate the module spacy 2.x to 3.0, to head off any confusion here. If you don't think it's necessary, I'll remove it.",1
github.com/sloev/spacy-syllables,tests/test_all.py,2021-03-05T08:48:26Z,"@nikitalita spacy-syllables 3.0.1 has been released
thanks for the great work!",1
github.com/libratom/libratom,libratom/lib/core.py,2022-11-29T06:16:04Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/194?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom) Report
> Merging [#194](https://codecov.io/gh/libratom/libratom/pull/194?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom) (f554b11) into [main](https://codecov.io/gh/libratom/libratom/commit/79dcf5b99633e0737e270d319730d244f9e66708?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom) (79dcf5b) will **decrease** coverage by `0.02%`.
> The diff coverage is `100.00%`.

<details><summary>Additional details and impacted files</summary>


[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/194/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom)](https://codecov.io/gh/libratom/libratom/pull/194?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom)

```diff
@@            Coverage Diff             @@
##             main     #194      +/-   ##
==========================================
- Coverage   95.84%   95.81%   -0.03%     
==========================================
  Files          28       28              
  Lines        1132     1148      +16     
==========================================
+ Hits         1085     1100      +15     
- Misses         47       48       +1     
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/194?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom) | Coverage Δ | |
|---|---|---|
| [libratom/lib/mbox.py](https://codecov.io/gh/libratom/libratom/pull/194/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom#diff-bGlicmF0b20vbGliL21ib3gucHk=) | `100.00% <ø> (ø)` | |
| [libratom/lib/base.py](https://codecov.io/gh/libratom/libratom/pull/194/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom#diff-bGlicmF0b20vbGliL2Jhc2UucHk=) | `100.00% <100.00%> (ø)` | |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/194/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.79% <100.00%> (+0.55%)` | :arrow_up: |
| [libratom/lib/entities.py](https://codecov.io/gh/libratom/libratom/pull/194/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom#diff-bGlicmF0b20vbGliL2VudGl0aWVzLnB5) | `89.79% <100.00%> (+0.10%)` | :arrow_up: |
| [libratom/lib/pff.py](https://codecov.io/gh/libratom/libratom/pull/194/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom#diff-bGlicmF0b20vbGliL3BmZi5weQ==) | `98.69% <100.00%> (ø)` | |
| [libratom/lib/report.py](https://codecov.io/gh/libratom/libratom/pull/194/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom#diff-bGlicmF0b20vbGliL3JlcG9ydC5weQ==) | `90.00% <100.00%> (+0.10%)` | :arrow_up: |
| [libratom/models/attachment.py](https://codecov.io/gh/libratom/libratom/pull/194/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom#diff-bGlicmF0b20vbW9kZWxzL2F0dGFjaG1lbnQucHk=) | `100.00% <100.00%> (ø)` | |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/194/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `92.63% <0.00%> (-1.06%)` | :arrow_down: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/194?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/194?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom). Last update [79dcf5b...f554b11](https://codecov.io/gh/libratom/libratom/pull/194?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom).

</details>",194
github.com/libratom/libratom,libratom/lib/core.py,2022-10-19T21:59:19Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/193?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom) Report
> Merging [#193](https://codecov.io/gh/libratom/libratom/pull/193?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom) (f874cfe) into [main](https://codecov.io/gh/libratom/libratom/commit/f1e0df46403c0e406c79e2aee9e29c1e8ecd263d?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom) (f1e0df4) will **decrease** coverage by `0.53%`.
> The diff coverage is `100.00%`.

<details><summary>Additional details and impacted files</summary>


[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/193/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom)](https://codecov.io/gh/libratom/libratom/pull/193?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom)

```diff
@@            Coverage Diff             @@
##             main     #193      +/-   ##
==========================================
- Coverage   96.46%   95.93%   -0.54%     
==========================================
  Files          28       28              
  Lines        1132     1132              
==========================================
- Hits         1092     1086       -6     
- Misses         40       46       +6     
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/193?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom) | Coverage Δ | |
|---|---|---|
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/193/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.23% <100.00%> (-3.89%)` | :arrow_down: |
| [libratom/lib/entities.py](https://codecov.io/gh/libratom/libratom/pull/193/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom#diff-bGlicmF0b20vbGliL2VudGl0aWVzLnB5) | `89.69% <0.00%> (-2.07%)` | :arrow_down: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/193?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/193?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom). Last update [f1e0df4...f874cfe](https://codecov.io/gh/libratom/libratom/pull/193?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=libratom).

</details>",193
github.com/libratom/libratom,libratom/lib/core.py,2021-02-23T21:50:53Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=h1) Report
> Merging [#160](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=desc) (6b244e3) into [master](https://codecov.io/gh/libratom/libratom/commit/1ccc7d02cff9dbfd09e0e29d2b44e4d5c9d08e53?el=desc) (1ccc7d0) will **increase** coverage by `0.05%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/160/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #160      +/-   ##
==========================================
+ Coverage   96.07%   96.12%   +0.05%     
==========================================
  Files          26       26              
  Lines        1044     1059      +15     
==========================================
+ Hits         1003     1018      +15     
  Misses         41       41              
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/160/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `92.63% <ø> (ø)` | |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/160/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `95.00% <100.00%> (+0.61%)` | :arrow_up: |
| [libratom/lib/entities.py](https://codecov.io/gh/libratom/libratom/pull/160/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2VudGl0aWVzLnB5) | `92.94% <100.00%> (+0.34%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=footer). Last update [1ccc7d0...6b244e3](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",160
github.com/libratom/libratom,libratom/lib/core.py,2021-02-23T21:50:53Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=h1) Report
> Merging [#160](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=desc) (6b244e3) into [master](https://codecov.io/gh/libratom/libratom/commit/1ccc7d02cff9dbfd09e0e29d2b44e4d5c9d08e53?el=desc) (1ccc7d0) will **increase** coverage by `0.05%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/160/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #160      +/-   ##
==========================================
+ Coverage   96.07%   96.12%   +0.05%     
==========================================
  Files          26       26              
  Lines        1044     1059      +15     
==========================================
+ Hits         1003     1018      +15     
  Misses         41       41              
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/160/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `92.63% <ø> (ø)` | |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/160/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `95.00% <100.00%> (+0.61%)` | :arrow_up: |
| [libratom/lib/entities.py](https://codecov.io/gh/libratom/libratom/pull/160/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2VudGl0aWVzLnB5) | `92.94% <100.00%> (+0.34%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=footer). Last update [1ccc7d0...6b244e3](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",160
github.com/libratom/libratom,libratom/lib/core.py,2021-02-23T21:50:53Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=h1) Report
> Merging [#160](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=desc) (6b244e3) into [master](https://codecov.io/gh/libratom/libratom/commit/1ccc7d02cff9dbfd09e0e29d2b44e4d5c9d08e53?el=desc) (1ccc7d0) will **increase** coverage by `0.05%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/160/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #160      +/-   ##
==========================================
+ Coverage   96.07%   96.12%   +0.05%     
==========================================
  Files          26       26              
  Lines        1044     1059      +15     
==========================================
+ Hits         1003     1018      +15     
  Misses         41       41              
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/160/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `92.63% <ø> (ø)` | |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/160/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `95.00% <100.00%> (+0.61%)` | :arrow_up: |
| [libratom/lib/entities.py](https://codecov.io/gh/libratom/libratom/pull/160/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2VudGl0aWVzLnB5) | `92.94% <100.00%> (+0.34%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=footer). Last update [1ccc7d0...6b244e3](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",160
github.com/libratom/libratom,libratom/lib/core.py,2021-02-23T21:50:53Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=h1) Report
> Merging [#160](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=desc) (6b244e3) into [master](https://codecov.io/gh/libratom/libratom/commit/1ccc7d02cff9dbfd09e0e29d2b44e4d5c9d08e53?el=desc) (1ccc7d0) will **increase** coverage by `0.05%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/160/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #160      +/-   ##
==========================================
+ Coverage   96.07%   96.12%   +0.05%     
==========================================
  Files          26       26              
  Lines        1044     1059      +15     
==========================================
+ Hits         1003     1018      +15     
  Misses         41       41              
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/160/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `92.63% <ø> (ø)` | |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/160/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `95.00% <100.00%> (+0.61%)` | :arrow_up: |
| [libratom/lib/entities.py](https://codecov.io/gh/libratom/libratom/pull/160/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2VudGl0aWVzLnB5) | `92.94% <100.00%> (+0.34%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=footer). Last update [1ccc7d0...6b244e3](https://codecov.io/gh/libratom/libratom/pull/160?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",160
github.com/libratom/libratom,libratom/lib/core.py,2021-02-08T23:28:03Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/157?src=pr&el=h1) Report
> Merging [#157](https://codecov.io/gh/libratom/libratom/pull/157?src=pr&el=desc) (87b07f5) into [master](https://codecov.io/gh/libratom/libratom/commit/6dd5c49cbefe8db135987a8b5cca5ace97d8391c?el=desc) (6dd5c49) will **increase** coverage by `0.54%`.
> The diff coverage is `85.71%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/157/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/157?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #157      +/-   ##
==========================================
+ Coverage   95.52%   96.07%   +0.54%     
==========================================
  Files          26       26              
  Lines        1051     1044       -7     
==========================================
- Hits         1004     1003       -1     
+ Misses         47       41       -6     
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/157?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/157/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `94.38% <ø> (+3.37%)` | :arrow_up: |
| [libratom/lib/constants.py](https://codecov.io/gh/libratom/libratom/pull/157/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvbnN0YW50cy5weQ==) | `100.00% <ø> (ø)` | |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/157/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `94.38% <75.00%> (+2.89%)` | :arrow_up: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/157/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `92.63% <100.00%> (+0.07%)` | :arrow_up: |
| [libratom/data/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/157/diff?src=pr&el=tree#diff-bGlicmF0b20vZGF0YS9fX2luaXRfXy5weQ==) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/157?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/157?src=pr&el=footer). Last update [6dd5c49...87b07f5](https://codecov.io/gh/libratom/libratom/pull/157?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",157
github.com/libratom/libratom,libratom/lib/core.py,2020-11-04T20:29:02Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/149?src=pr&el=h1) Report
> Merging [#149](https://codecov.io/gh/libratom/libratom/pull/149?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/7ec0db796825ffccef50c34ffdd77b254785cda8?el=desc) will **increase** coverage by `0.05%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/149/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/149?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #149      +/-   ##
==========================================
+ Coverage   95.47%   95.52%   +0.05%     
==========================================
  Files          26       26              
  Lines        1039     1051      +12     
==========================================
+ Hits          992     1004      +12     
  Misses         47       47              
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/149?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/149/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `100.00% <100.00%> (ø)` | |
| [libratom/lib/constants.py](https://codecov.io/gh/libratom/libratom/pull/149/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvbnN0YW50cy5weQ==) | `100.00% <100.00%> (ø)` | |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/149/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `91.48% <100.00%> (ø)` | |
| [libratom/lib/pff.py](https://codecov.io/gh/libratom/libratom/pull/149/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3BmZi5weQ==) | `98.69% <100.00%> (+0.08%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/149?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/149?src=pr&el=footer). Last update [7ec0db7...0b09c32](https://codecov.io/gh/libratom/libratom/pull/149?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",149
github.com/libratom/libratom,libratom/lib/core.py,2020-11-04T20:29:02Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/149?src=pr&el=h1) Report
> Merging [#149](https://codecov.io/gh/libratom/libratom/pull/149?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/7ec0db796825ffccef50c34ffdd77b254785cda8?el=desc) will **increase** coverage by `0.05%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/149/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/149?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #149      +/-   ##
==========================================
+ Coverage   95.47%   95.52%   +0.05%     
==========================================
  Files          26       26              
  Lines        1039     1051      +12     
==========================================
+ Hits          992     1004      +12     
  Misses         47       47              
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/149?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/149/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `100.00% <100.00%> (ø)` | |
| [libratom/lib/constants.py](https://codecov.io/gh/libratom/libratom/pull/149/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvbnN0YW50cy5weQ==) | `100.00% <100.00%> (ø)` | |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/149/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `91.48% <100.00%> (ø)` | |
| [libratom/lib/pff.py](https://codecov.io/gh/libratom/libratom/pull/149/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3BmZi5weQ==) | `98.69% <100.00%> (+0.08%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/149?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/149?src=pr&el=footer). Last update [7ec0db7...0b09c32](https://codecov.io/gh/libratom/libratom/pull/149?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",149
github.com/libratom/libratom,libratom/lib/core.py,2020-10-27T06:28:41Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/148?src=pr&el=h1) Report
> Merging [#148](https://codecov.io/gh/libratom/libratom/pull/148?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/d088238efa4a938c14bee1ca5587e00c541088d8?el=desc) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/148/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/148?src=pr&el=tree)

```diff
@@           Coverage Diff           @@
##           master     #148   +/-   ##
=======================================
  Coverage   95.47%   95.47%           
=======================================
  Files          26       26           
  Lines        1039     1039           
=======================================
  Hits          992      992           
  Misses         47       47           
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/148?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/148/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `100.00% <ø> (ø)` | |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/148/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `92.55% <ø> (ø)` | |
| [libratom/lib/mbox.py](https://codecov.io/gh/libratom/libratom/pull/148/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL21ib3gucHk=) | `100.00% <ø> (ø)` | |
| [libratom/lib/pff.py](https://codecov.io/gh/libratom/libratom/pull/148/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3BmZi5weQ==) | `98.61% <ø> (ø)` | |
| [libratom/scripts/get\_media\_type\_list.py](https://codecov.io/gh/libratom/libratom/pull/148/diff?src=pr&el=tree#diff-bGlicmF0b20vc2NyaXB0cy9nZXRfbWVkaWFfdHlwZV9saXN0LnB5) | `96.96% <ø> (ø)` | |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/148/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `91.48% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/148?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/148?src=pr&el=footer). Last update [d088238...8a0a71c](https://codecov.io/gh/libratom/libratom/pull/148?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",148
github.com/libratom/libratom,libratom/lib/core.py,2020-09-18T18:57:42Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/143?src=pr&el=h1) Report
> Merging [#143](https://codecov.io/gh/libratom/libratom/pull/143?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/3a2521c361d81cf96cdc35b220996e54daccefb6?el=desc) will **not change** coverage.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/143/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/143?src=pr&el=tree)

```diff
@@           Coverage Diff           @@
##           master     #143   +/-   ##
=======================================
  Coverage   95.47%   95.47%           
=======================================
  Files          26       26           
  Lines        1039     1039           
=======================================
  Hits          992      992           
  Misses         47       47           
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/143?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/143/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `91.48% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/143?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/143?src=pr&el=footer). Last update [3a2521c...ba44aad](https://codecov.io/gh/libratom/libratom/pull/143?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",143
github.com/libratom/libratom,libratom/lib/core.py,2020-09-18T20:32:26Z,Also update list of known mime types,143
github.com/libratom/libratom,libratom/lib/core.py,2020-07-15T06:43:12Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/138?src=pr&el=h1) Report
> Merging [#138](https://codecov.io/gh/libratom/libratom/pull/138?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/ae0403364f3c4f1880d6d44532f752651e775237&el=desc) will **increase** coverage by `0.69%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/138/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/138?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #138      +/-   ##
==========================================
+ Coverage   94.78%   95.47%   +0.69%     
==========================================
  Files          24       26       +2     
  Lines         959     1039      +80     
==========================================
+ Hits          909      992      +83     
+ Misses         50       47       -3     
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/138?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/138/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `100.00% <100.00%> (ø)` | |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/138/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `92.55% <100.00%> (ø)` | |
| [libratom/lib/base.py](https://codecov.io/gh/libratom/libratom/pull/138/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2Jhc2UucHk=) | `100.00% <100.00%> (ø)` | |
| [libratom/lib/concurrency.py](https://codecov.io/gh/libratom/libratom/pull/138/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvbmN1cnJlbmN5LnB5) | `92.00% <100.00%> (+3.11%)` | :arrow_up: |
| [libratom/lib/constants.py](https://codecov.io/gh/libratom/libratom/pull/138/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvbnN0YW50cy5weQ==) | `100.00% <100.00%> (ø)` | |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/138/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `91.48% <100.00%> (-0.59%)` | :arrow_down: |
| [libratom/lib/database.py](https://codecov.io/gh/libratom/libratom/pull/138/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2RhdGFiYXNlLnB5) | `92.10% <100.00%> (+2.81%)` | :arrow_up: |
| [libratom/lib/entities.py](https://codecov.io/gh/libratom/libratom/pull/138/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2VudGl0aWVzLnB5) | `92.59% <100.00%> (-3.47%)` | :arrow_down: |
| [libratom/lib/mbox.py](https://codecov.io/gh/libratom/libratom/pull/138/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL21ib3gucHk=) | `100.00% <100.00%> (+1.78%)` | :arrow_up: |
| [libratom/lib/pff.py](https://codecov.io/gh/libratom/libratom/pull/138/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3BmZi5weQ==) | `98.61% <100.00%> (+0.12%)` | :arrow_up: |
| ... and [9 more](https://codecov.io/gh/libratom/libratom/pull/138/diff?src=pr&el=tree-more) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/138?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/138?src=pr&el=footer). Last update [ae04033...d4b9b4e](https://codecov.io/gh/libratom/libratom/pull/138?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",138
github.com/libratom/libratom,libratom/lib/core.py,2020-03-26T21:43:05Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=h1) Report
> Merging [#127](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/85e0e2ebac28f95e4e80b5c6c959bcee7c680eb5&el=desc) will **decrease** coverage by `0.05%`.
> The diff coverage is `94.28%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/127/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #127      +/-   ##
==========================================
- Coverage   94.67%   94.61%   -0.06%     
==========================================
  Files          23       23              
  Lines         826      892      +66     
==========================================
+ Hits          782      844      +62     
- Misses         44       48       +4     
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `92.55% <84.61%> (-1.35%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.00% <90.90%> (-0.41%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `100.00% <100.00%> (ø)` | |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `91.39% <100.00%> (+2.20%)` | :arrow_up: |
| [libratom/lib/base.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2Jhc2UucHk=) | `100.00% <100.00%> (ø)` | |
| [libratom/lib/pff.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3BmZi5weQ==) | `97.59% <100.00%> (+0.18%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=footer). Last update [85e0e2e...6f78225](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",127
github.com/libratom/libratom,libratom/lib/core.py,2020-03-26T21:43:05Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=h1) Report
> Merging [#127](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/85e0e2ebac28f95e4e80b5c6c959bcee7c680eb5&el=desc) will **decrease** coverage by `0.05%`.
> The diff coverage is `94.28%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/127/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #127      +/-   ##
==========================================
- Coverage   94.67%   94.61%   -0.06%     
==========================================
  Files          23       23              
  Lines         826      892      +66     
==========================================
+ Hits          782      844      +62     
- Misses         44       48       +4     
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `92.55% <84.61%> (-1.35%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.00% <90.90%> (-0.41%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `100.00% <100.00%> (ø)` | |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `91.39% <100.00%> (+2.20%)` | :arrow_up: |
| [libratom/lib/base.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2Jhc2UucHk=) | `100.00% <100.00%> (ø)` | |
| [libratom/lib/pff.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3BmZi5weQ==) | `97.59% <100.00%> (+0.18%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=footer). Last update [85e0e2e...6f78225](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",127
github.com/libratom/libratom,libratom/lib/core.py,2020-03-26T21:43:05Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=h1) Report
> Merging [#127](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/85e0e2ebac28f95e4e80b5c6c959bcee7c680eb5&el=desc) will **decrease** coverage by `0.05%`.
> The diff coverage is `94.28%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/127/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #127      +/-   ##
==========================================
- Coverage   94.67%   94.61%   -0.06%     
==========================================
  Files          23       23              
  Lines         826      892      +66     
==========================================
+ Hits          782      844      +62     
- Misses         44       48       +4     
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `92.55% <84.61%> (-1.35%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.00% <90.90%> (-0.41%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `100.00% <100.00%> (ø)` | |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `91.39% <100.00%> (+2.20%)` | :arrow_up: |
| [libratom/lib/base.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2Jhc2UucHk=) | `100.00% <100.00%> (ø)` | |
| [libratom/lib/pff.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3BmZi5weQ==) | `97.59% <100.00%> (+0.18%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=footer). Last update [85e0e2e...6f78225](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",127
github.com/libratom/libratom,libratom/lib/core.py,2020-02-26T15:00:15Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=h1) Report
> Merging [#119](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/3d6fd61d889af4723e38ebbb4dc43cc548f2fa63?src=pr&el=desc) will **decrease** coverage by `1.2%`.
> The diff coverage is `86.84%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/119/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #119      +/-   ##
==========================================
- Coverage   95.27%   94.06%   -1.21%     
==========================================
  Files          23       23              
  Lines         719      826     +107     
==========================================
+ Hits          685      777      +92     
- Misses         34       49      +15
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL19faW5pdF9fLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `83.78% <77.77%> (-16.22%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `93.9% <93.75%> (-0.31%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `98.33% <94.11%> (-1.67%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.4% <96%> (+1.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=footer). Last update [3d6fd61...15e4988](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",119
github.com/libratom/libratom,libratom/lib/core.py,2020-02-26T15:00:15Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=h1) Report
> Merging [#119](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/3d6fd61d889af4723e38ebbb4dc43cc548f2fa63?src=pr&el=desc) will **decrease** coverage by `1.2%`.
> The diff coverage is `86.84%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/119/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #119      +/-   ##
==========================================
- Coverage   95.27%   94.06%   -1.21%     
==========================================
  Files          23       23              
  Lines         719      826     +107     
==========================================
+ Hits          685      777      +92     
- Misses         34       49      +15
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL19faW5pdF9fLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `83.78% <77.77%> (-16.22%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `93.9% <93.75%> (-0.31%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `98.33% <94.11%> (-1.67%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.4% <96%> (+1.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=footer). Last update [3d6fd61...15e4988](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",119
github.com/libratom/libratom,libratom/lib/core.py,2020-02-26T15:00:15Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=h1) Report
> Merging [#119](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/3d6fd61d889af4723e38ebbb4dc43cc548f2fa63?src=pr&el=desc) will **decrease** coverage by `1.2%`.
> The diff coverage is `86.84%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/119/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #119      +/-   ##
==========================================
- Coverage   95.27%   94.06%   -1.21%     
==========================================
  Files          23       23              
  Lines         719      826     +107     
==========================================
+ Hits          685      777      +92     
- Misses         34       49      +15
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL19faW5pdF9fLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `83.78% <77.77%> (-16.22%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `93.9% <93.75%> (-0.31%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `98.33% <94.11%> (-1.67%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.4% <96%> (+1.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=footer). Last update [3d6fd61...15e4988](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",119
github.com/libratom/libratom,libratom/lib/core.py,2020-01-31T22:13:40Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/112?src=pr&el=h1) Report
> Merging [#112](https://codecov.io/gh/libratom/libratom/pull/112?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/2c1364b124e57e575ce28b7b2302fb67917796eb?src=pr&el=desc) will **increase** coverage by `0.15%`.
> The diff coverage is `100%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/112/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/112?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #112      +/-   ##
==========================================
+ Coverage   94.98%   95.14%   +0.15%     
==========================================
  Files          23       23              
  Lines         698      700       +2     
==========================================
+ Hits          663      666       +3     
+ Misses         35       34       -1
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/112?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/lib/report.py](https://codecov.io/gh/libratom/libratom/pull/112/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3JlcG9ydC5weQ==) | `86.04% <100%> (+1.16%)` | :arrow_up: |
| [libratom/lib/concurrency.py](https://codecov.io/gh/libratom/libratom/pull/112/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvbmN1cnJlbmN5LnB5) | `91.89% <100%> (ø)` | :arrow_up: |
| [libratom/lib/entities.py](https://codecov.io/gh/libratom/libratom/pull/112/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2VudGl0aWVzLnB5) | `96.05% <100%> (ø)` | :arrow_up: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/112/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `91.07% <100%> (+0.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/112?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/112?src=pr&el=footer). Last update [2c1364b...2717fb7](https://codecov.io/gh/libratom/libratom/pull/112?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",112
github.com/libratom/libratom,libratom/lib/core.py,2020-01-31T22:13:40Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/112?src=pr&el=h1) Report
> Merging [#112](https://codecov.io/gh/libratom/libratom/pull/112?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/2c1364b124e57e575ce28b7b2302fb67917796eb?src=pr&el=desc) will **increase** coverage by `0.15%`.
> The diff coverage is `100%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/112/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/112?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #112      +/-   ##
==========================================
+ Coverage   94.98%   95.14%   +0.15%     
==========================================
  Files          23       23              
  Lines         698      700       +2     
==========================================
+ Hits          663      666       +3     
+ Misses         35       34       -1
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/112?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/lib/report.py](https://codecov.io/gh/libratom/libratom/pull/112/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3JlcG9ydC5weQ==) | `86.04% <100%> (+1.16%)` | :arrow_up: |
| [libratom/lib/concurrency.py](https://codecov.io/gh/libratom/libratom/pull/112/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvbmN1cnJlbmN5LnB5) | `91.89% <100%> (ø)` | :arrow_up: |
| [libratom/lib/entities.py](https://codecov.io/gh/libratom/libratom/pull/112/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2VudGl0aWVzLnB5) | `96.05% <100%> (ø)` | :arrow_up: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/112/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `91.07% <100%> (+0.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/112?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/112?src=pr&el=footer). Last update [2c1364b...2717fb7](https://codecov.io/gh/libratom/libratom/pull/112?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",112
github.com/libratom/libratom,libratom/lib/core.py,2020-01-31T20:00:14Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/111?src=pr&el=h1) Report
> Merging [#111](https://codecov.io/gh/libratom/libratom/pull/111?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/080c814466df1a55aba548fab7cf9516729427d3?src=pr&el=desc) will **decrease** coverage by `0.14%`.
> The diff coverage is `n/a`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/111/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/111?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #111      +/-   ##
==========================================
- Coverage   95.12%   94.98%   -0.15%     
==========================================
  Files          23       23              
  Lines         698      698              
==========================================
- Hits          664      663       -1     
- Misses         34       35       +1
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/111?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/111/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `90.74% <ø> (ø)` | :arrow_up: |
| [libratom/lib/mbox.py](https://codecov.io/gh/libratom/libratom/pull/111/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL21ib3gucHk=) | `96.87% <0%> (-3.13%)` | :arrow_down: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/111?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/111?src=pr&el=footer). Last update [080c814...e8a4c4d](https://codecov.io/gh/libratom/libratom/pull/111?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",111
github.com/libratom/libratom,libratom/lib/core.py,2020-01-29T23:38:59Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/108?src=pr&el=h1) Report
> Merging [#108](https://codecov.io/gh/libratom/libratom/pull/108?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/b1f2cfb8a38ab7aa2a1d019773190c4fe7a308c7?src=pr&el=desc) will **decrease** coverage by `1.55%`.
> The diff coverage is `86.36%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/108/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/108?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #108      +/-   ##
==========================================
- Coverage   96.11%   94.56%   -1.56%     
==========================================
  Files          23       23              
  Lines         618      699      +81     
==========================================
+ Hits          594      661      +67     
- Misses         24       38      +14
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/108?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/lib/entities.py](https://codecov.io/gh/libratom/libratom/pull/108/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2VudGl0aWVzLnB5) | `96.05% <100%> (+3.25%)` | :arrow_up: |
| [libratom/lib/concurrency.py](https://codecov.io/gh/libratom/libratom/pull/108/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvbmN1cnJlbmN5LnB5) | `91.89% <100%> (-1.45%)` | :arrow_down: |
| [libratom/lib/database.py](https://codecov.io/gh/libratom/libratom/pull/108/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2RhdGFiYXNlLnB5) | `89.28% <100%> (+0.39%)` | :arrow_up: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/108/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/lib/report.py](https://codecov.io/gh/libratom/libratom/pull/108/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3JlcG9ydC5weQ==) | `84.7% <75%> (-6.21%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/108/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `90.14% <83.33%> (-5.32%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/108/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `90.74% <87.5%> (-9.26%)` | :arrow_down: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/108?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/108?src=pr&el=footer). Last update [b1f2cfb...7725c9d](https://codecov.io/gh/libratom/libratom/pull/108?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",108
github.com/libratom/libratom,libratom/lib/core.py,2020-01-29T23:38:59Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/108?src=pr&el=h1) Report
> Merging [#108](https://codecov.io/gh/libratom/libratom/pull/108?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/b1f2cfb8a38ab7aa2a1d019773190c4fe7a308c7?src=pr&el=desc) will **decrease** coverage by `1.55%`.
> The diff coverage is `86.36%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/108/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/108?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #108      +/-   ##
==========================================
- Coverage   96.11%   94.56%   -1.56%     
==========================================
  Files          23       23              
  Lines         618      699      +81     
==========================================
+ Hits          594      661      +67     
- Misses         24       38      +14
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/108?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/lib/entities.py](https://codecov.io/gh/libratom/libratom/pull/108/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2VudGl0aWVzLnB5) | `96.05% <100%> (+3.25%)` | :arrow_up: |
| [libratom/lib/concurrency.py](https://codecov.io/gh/libratom/libratom/pull/108/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvbmN1cnJlbmN5LnB5) | `91.89% <100%> (-1.45%)` | :arrow_down: |
| [libratom/lib/database.py](https://codecov.io/gh/libratom/libratom/pull/108/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2RhdGFiYXNlLnB5) | `89.28% <100%> (+0.39%)` | :arrow_up: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/108/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/lib/report.py](https://codecov.io/gh/libratom/libratom/pull/108/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3JlcG9ydC5weQ==) | `84.7% <75%> (-6.21%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/108/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `90.14% <83.33%> (-5.32%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/108/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `90.74% <87.5%> (-9.26%)` | :arrow_down: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/108?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/108?src=pr&el=footer). Last update [b1f2cfb...7725c9d](https://codecov.io/gh/libratom/libratom/pull/108?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",108
github.com/libratom/libratom,libratom/lib/core.py,2019-10-21T21:50:42Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/72?src=pr&el=h1) Report
> Merging [#72](https://codecov.io/gh/libratom/libratom/pull/72?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/60afe79495fc7b916c3e23d3764937fa902845f1?src=pr&el=desc) will **decrease** coverage by `0.58%`.
> The diff coverage is `85%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/72/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/72?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master      #72      +/-   ##
==========================================
- Coverage   95.48%   94.89%   -0.59%     
==========================================
  Files          19       19              
  Lines         531      529       -2     
==========================================
- Hits          507      502       -5     
- Misses         24       27       +3
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/72?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/lib/report.py](https://codecov.io/gh/libratom/libratom/pull/72/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3JlcG9ydC5weQ==) | `84.09% <ø> (ø)` | :arrow_up: |
| [libratom/lib/concurrency.py](https://codecov.io/gh/libratom/libratom/pull/72/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvbmN1cnJlbmN5LnB5) | `94.44% <ø> (ø)` | :arrow_up: |
| [libratom/lib/entities.py](https://codecov.io/gh/libratom/libratom/pull/72/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2VudGl0aWVzLnB5) | `89.28% <ø> (ø)` | :arrow_up: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/72/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `100% <ø> (ø)` | :arrow_up: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/72/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `100% <ø> (ø)` | :arrow_up: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/72/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/lib/pff.py](https://codecov.io/gh/libratom/libratom/pull/72/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3BmZi5weQ==) | `95.71% <83.33%> (-4.29%)` | :arrow_down: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/72?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/72?src=pr&el=footer). Last update [60afe79...ca42e4b](https://codecov.io/gh/libratom/libratom/pull/72?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",72
github.com/libratom/libratom,libratom/lib/core.py,2019-10-06T15:51:22Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/64?src=pr&el=h1) Report
> Merging [#64](https://codecov.io/gh/libratom/libratom/pull/64?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/fc9dfabb38a9c1809b43b49f4c3941245bf0fd0c?src=pr&el=desc) will **increase** coverage by `1.26%`.
> The diff coverage is `100%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/64/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/64?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master      #64      +/-   ##
==========================================
+ Coverage    93.8%   95.06%   +1.26%     
==========================================
  Files          17       18       +1     
  Lines         484      486       +2     
==========================================
+ Hits          454      462       +8     
+ Misses         30       24       -6
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/64?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/lib/exceptions.py](https://codecov.io/gh/libratom/libratom/pull/64/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2V4Y2VwdGlvbnMucHk=) | `100% <100%> (ø)` | |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/64/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `100% <100%> (+6.66%)` | :arrow_up: |
| [libratom/lib/entities.py](https://codecov.io/gh/libratom/libratom/pull/64/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2VudGl0aWVzLnB5) | `89.28% <0%> (+2.67%)` | :arrow_up: |
| [libratom/lib/concurrency.py](https://codecov.io/gh/libratom/libratom/pull/64/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvbmN1cnJlbmN5LnB5) | `94.44% <0%> (+5.55%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/64?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/64?src=pr&el=footer). Last update [fc9dfab...86256e8](https://codecov.io/gh/libratom/libratom/pull/64?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",64
github.com/libratom/libratom,libratom/lib/core.py,2019-10-01T05:10:06Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/62?src=pr&el=h1) Report
> Merging [#62](https://codecov.io/gh/libratom/libratom/pull/62?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/c50d27c01dad4cb1647e514cb3579244c2222e71?src=pr&el=desc) will **decrease** coverage by `1.4%`.
> The diff coverage is `96.55%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/62/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/62?src=pr&el=tree)

```diff
@@            Coverage Diff            @@
##           master     #62      +/-   ##
=========================================
- Coverage    95.2%   93.8%   -1.41%     
=========================================
  Files          13      17       +4     
  Lines         438     484      +46     
=========================================
+ Hits          417     454      +37     
- Misses         21      30       +9
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/62?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/lib/entities.py](https://codecov.io/gh/libratom/libratom/pull/62/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2VudGl0aWVzLnB5) | `86.6% <100%> (-2.68%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/62/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/lib/mbox.py](https://codecov.io/gh/libratom/libratom/pull/62/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL21ib3gucHk=) | `100% <100%> (ø)` | |
| [libratom/lib/pff.py](https://codecov.io/gh/libratom/libratom/pull/62/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3BmZi5weQ==) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/lib/base.py](https://codecov.io/gh/libratom/libratom/pull/62/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2Jhc2UucHk=) | `100% <100%> (ø)` | |
| [libratom/lib/concurrency.py](https://codecov.io/gh/libratom/libratom/pull/62/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvbmN1cnJlbmN5LnB5) | `88.88% <100%> (-5.56%)` | :arrow_down: |
| [libratom/lib/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/62/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL19faW5pdF9fLnB5) | `100% <100%> (ø)` | |
| [libratom/lib/database.py](https://codecov.io/gh/libratom/libratom/pull/62/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2RhdGFiYXNlLnB5) | `88.88% <50%> (-11.12%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/62/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `93.33% <93.33%> (ø)` | |
| ... and [5 more](https://codecov.io/gh/libratom/libratom/pull/62/diff?src=pr&el=tree-more) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/62?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/62?src=pr&el=footer). Last update [c50d27c...604d80b](https://codecov.io/gh/libratom/libratom/pull/62?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",62
github.com/libratom/libratom,libratom/cli/utils.py,2021-02-08T23:28:03Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/157?src=pr&el=h1) Report
> Merging [#157](https://codecov.io/gh/libratom/libratom/pull/157?src=pr&el=desc) (87b07f5) into [master](https://codecov.io/gh/libratom/libratom/commit/6dd5c49cbefe8db135987a8b5cca5ace97d8391c?el=desc) (6dd5c49) will **increase** coverage by `0.54%`.
> The diff coverage is `85.71%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/157/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/157?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #157      +/-   ##
==========================================
+ Coverage   95.52%   96.07%   +0.54%     
==========================================
  Files          26       26              
  Lines        1051     1044       -7     
==========================================
- Hits         1004     1003       -1     
+ Misses         47       41       -6     
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/157?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/157/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `94.38% <ø> (+3.37%)` | :arrow_up: |
| [libratom/lib/constants.py](https://codecov.io/gh/libratom/libratom/pull/157/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvbnN0YW50cy5weQ==) | `100.00% <ø> (ø)` | |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/157/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `94.38% <75.00%> (+2.89%)` | :arrow_up: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/157/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `92.63% <100.00%> (+0.07%)` | :arrow_up: |
| [libratom/data/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/157/diff?src=pr&el=tree#diff-bGlicmF0b20vZGF0YS9fX2luaXRfXy5weQ==) | `100.00% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/157?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/157?src=pr&el=footer). Last update [6dd5c49...87b07f5](https://codecov.io/gh/libratom/libratom/pull/157?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",157
github.com/libratom/libratom,libratom/cli/utils.py,2020-03-27T16:46:13Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/128?src=pr&el=h1) Report
> Merging [#128](https://codecov.io/gh/libratom/libratom/pull/128?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/31902fef573d4bc23260439a3a40543de7381c4c&el=desc) will **increase** coverage by `0.28%`.
> The diff coverage is `100.00%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/128/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/128?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #128      +/-   ##
==========================================
+ Coverage   94.61%   94.90%   +0.28%     
==========================================
  Files          23       24       +1     
  Lines         892      903      +11     
==========================================
+ Hits          844      857      +13     
+ Misses         48       46       -2     
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/128?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/128/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `91.01% <100.00%> (-0.39%)` | :arrow_down: |
| [libratom/data/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/128/diff?src=pr&el=tree#diff-bGlicmF0b20vZGF0YS9fX2luaXRfXy5weQ==) | `100.00% <100.00%> (ø)` | |
| [libratom/lib/pff.py](https://codecov.io/gh/libratom/libratom/pull/128/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3BmZi5weQ==) | `100.00% <100.00%> (+2.40%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/128?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/128?src=pr&el=footer). Last update [31902fe...cec681e](https://codecov.io/gh/libratom/libratom/pull/128?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",128
github.com/libratom/libratom,libratom/cli/utils.py,2020-03-26T21:43:05Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=h1) Report
> Merging [#127](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/85e0e2ebac28f95e4e80b5c6c959bcee7c680eb5&el=desc) will **decrease** coverage by `0.05%`.
> The diff coverage is `94.28%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/127/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #127      +/-   ##
==========================================
- Coverage   94.67%   94.61%   -0.06%     
==========================================
  Files          23       23              
  Lines         826      892      +66     
==========================================
+ Hits          782      844      +62     
- Misses         44       48       +4     
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `92.55% <84.61%> (-1.35%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.00% <90.90%> (-0.41%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `100.00% <100.00%> (ø)` | |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `91.39% <100.00%> (+2.20%)` | :arrow_up: |
| [libratom/lib/base.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2Jhc2UucHk=) | `100.00% <100.00%> (ø)` | |
| [libratom/lib/pff.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3BmZi5weQ==) | `97.59% <100.00%> (+0.18%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=footer). Last update [85e0e2e...6f78225](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",127
github.com/libratom/libratom,libratom/cli/utils.py,2020-03-26T21:43:05Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=h1) Report
> Merging [#127](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/85e0e2ebac28f95e4e80b5c6c959bcee7c680eb5&el=desc) will **decrease** coverage by `0.05%`.
> The diff coverage is `94.28%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/127/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #127      +/-   ##
==========================================
- Coverage   94.67%   94.61%   -0.06%     
==========================================
  Files          23       23              
  Lines         826      892      +66     
==========================================
+ Hits          782      844      +62     
- Misses         44       48       +4     
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `92.55% <84.61%> (-1.35%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.00% <90.90%> (-0.41%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `100.00% <100.00%> (ø)` | |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `91.39% <100.00%> (+2.20%)` | :arrow_up: |
| [libratom/lib/base.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2Jhc2UucHk=) | `100.00% <100.00%> (ø)` | |
| [libratom/lib/pff.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3BmZi5weQ==) | `97.59% <100.00%> (+0.18%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=footer). Last update [85e0e2e...6f78225](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",127
github.com/libratom/libratom,libratom/cli/utils.py,2020-03-26T21:43:05Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=h1) Report
> Merging [#127](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/85e0e2ebac28f95e4e80b5c6c959bcee7c680eb5&el=desc) will **decrease** coverage by `0.05%`.
> The diff coverage is `94.28%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/127/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #127      +/-   ##
==========================================
- Coverage   94.67%   94.61%   -0.06%     
==========================================
  Files          23       23              
  Lines         826      892      +66     
==========================================
+ Hits          782      844      +62     
- Misses         44       48       +4     
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `92.55% <84.61%> (-1.35%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.00% <90.90%> (-0.41%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `100.00% <100.00%> (ø)` | |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `91.39% <100.00%> (+2.20%)` | :arrow_up: |
| [libratom/lib/base.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2Jhc2UucHk=) | `100.00% <100.00%> (ø)` | |
| [libratom/lib/pff.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3BmZi5weQ==) | `97.59% <100.00%> (+0.18%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=footer). Last update [85e0e2e...6f78225](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",127
github.com/libratom/libratom,libratom/cli/utils.py,2020-03-26T21:43:05Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=h1) Report
> Merging [#127](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/85e0e2ebac28f95e4e80b5c6c959bcee7c680eb5&el=desc) will **decrease** coverage by `0.05%`.
> The diff coverage is `94.28%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/127/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #127      +/-   ##
==========================================
- Coverage   94.67%   94.61%   -0.06%     
==========================================
  Files          23       23              
  Lines         826      892      +66     
==========================================
+ Hits          782      844      +62     
- Misses         44       48       +4     
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `92.55% <84.61%> (-1.35%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.00% <90.90%> (-0.41%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `100.00% <100.00%> (ø)` | |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `91.39% <100.00%> (+2.20%)` | :arrow_up: |
| [libratom/lib/base.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2Jhc2UucHk=) | `100.00% <100.00%> (ø)` | |
| [libratom/lib/pff.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3BmZi5weQ==) | `97.59% <100.00%> (+0.18%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=footer). Last update [85e0e2e...6f78225](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",127
github.com/libratom/libratom,libratom/cli/utils.py,2020-03-26T21:43:05Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=h1) Report
> Merging [#127](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/85e0e2ebac28f95e4e80b5c6c959bcee7c680eb5&el=desc) will **decrease** coverage by `0.05%`.
> The diff coverage is `94.28%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/127/graphs/tree.svg?width=650&height=150&src=pr&token=pLv2qHIbMn)](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #127      +/-   ##
==========================================
- Coverage   94.67%   94.61%   -0.06%     
==========================================
  Files          23       23              
  Lines         826      892      +66     
==========================================
+ Hits          782      844      +62     
- Misses         44       48       +4     
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `92.55% <84.61%> (-1.35%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.00% <90.90%> (-0.41%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `100.00% <100.00%> (ø)` | |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `91.39% <100.00%> (+2.20%)` | :arrow_up: |
| [libratom/lib/base.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2Jhc2UucHk=) | `100.00% <100.00%> (ø)` | |
| [libratom/lib/pff.py](https://codecov.io/gh/libratom/libratom/pull/127/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3BmZi5weQ==) | `97.59% <100.00%> (+0.18%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=footer). Last update [85e0e2e...6f78225](https://codecov.io/gh/libratom/libratom/pull/127?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",127
github.com/libratom/libratom,libratom/cli/utils.py,2020-02-26T15:00:15Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=h1) Report
> Merging [#119](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/3d6fd61d889af4723e38ebbb4dc43cc548f2fa63?src=pr&el=desc) will **decrease** coverage by `1.2%`.
> The diff coverage is `86.84%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/119/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #119      +/-   ##
==========================================
- Coverage   95.27%   94.06%   -1.21%     
==========================================
  Files          23       23              
  Lines         719      826     +107     
==========================================
+ Hits          685      777      +92     
- Misses         34       49      +15
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL19faW5pdF9fLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `83.78% <77.77%> (-16.22%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `93.9% <93.75%> (-0.31%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `98.33% <94.11%> (-1.67%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.4% <96%> (+1.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=footer). Last update [3d6fd61...15e4988](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",119
github.com/libratom/libratom,libratom/cli/utils.py,2020-02-26T15:00:15Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=h1) Report
> Merging [#119](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/3d6fd61d889af4723e38ebbb4dc43cc548f2fa63?src=pr&el=desc) will **decrease** coverage by `1.2%`.
> The diff coverage is `86.84%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/119/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #119      +/-   ##
==========================================
- Coverage   95.27%   94.06%   -1.21%     
==========================================
  Files          23       23              
  Lines         719      826     +107     
==========================================
+ Hits          685      777      +92     
- Misses         34       49      +15
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL19faW5pdF9fLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `83.78% <77.77%> (-16.22%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `93.9% <93.75%> (-0.31%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `98.33% <94.11%> (-1.67%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.4% <96%> (+1.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=footer). Last update [3d6fd61...15e4988](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",119
github.com/libratom/libratom,libratom/cli/utils.py,2020-02-26T15:00:15Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=h1) Report
> Merging [#119](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/3d6fd61d889af4723e38ebbb4dc43cc548f2fa63?src=pr&el=desc) will **decrease** coverage by `1.2%`.
> The diff coverage is `86.84%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/119/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #119      +/-   ##
==========================================
- Coverage   95.27%   94.06%   -1.21%     
==========================================
  Files          23       23              
  Lines         719      826     +107     
==========================================
+ Hits          685      777      +92     
- Misses         34       49      +15
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL19faW5pdF9fLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `83.78% <77.77%> (-16.22%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `93.9% <93.75%> (-0.31%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `98.33% <94.11%> (-1.67%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.4% <96%> (+1.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=footer). Last update [3d6fd61...15e4988](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",119
github.com/libratom/libratom,libratom/cli/utils.py,2020-02-26T15:00:15Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=h1) Report
> Merging [#119](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/3d6fd61d889af4723e38ebbb4dc43cc548f2fa63?src=pr&el=desc) will **decrease** coverage by `1.2%`.
> The diff coverage is `86.84%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/119/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #119      +/-   ##
==========================================
- Coverage   95.27%   94.06%   -1.21%     
==========================================
  Files          23       23              
  Lines         719      826     +107     
==========================================
+ Hits          685      777      +92     
- Misses         34       49      +15
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL19faW5pdF9fLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `83.78% <77.77%> (-16.22%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `93.9% <93.75%> (-0.31%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `98.33% <94.11%> (-1.67%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.4% <96%> (+1.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=footer). Last update [3d6fd61...15e4988](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",119
github.com/libratom/libratom,libratom/cli/utils.py,2020-02-26T15:00:15Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=h1) Report
> Merging [#119](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/3d6fd61d889af4723e38ebbb4dc43cc548f2fa63?src=pr&el=desc) will **decrease** coverage by `1.2%`.
> The diff coverage is `86.84%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/119/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #119      +/-   ##
==========================================
- Coverage   95.27%   94.06%   -1.21%     
==========================================
  Files          23       23              
  Lines         719      826     +107     
==========================================
+ Hits          685      777      +92     
- Misses         34       49      +15
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL19faW5pdF9fLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `83.78% <77.77%> (-16.22%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `93.9% <93.75%> (-0.31%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `98.33% <94.11%> (-1.67%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.4% <96%> (+1.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=footer). Last update [3d6fd61...15e4988](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",119
github.com/libratom/libratom,libratom/cli/utils.py,2020-02-26T15:00:15Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=h1) Report
> Merging [#119](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/3d6fd61d889af4723e38ebbb4dc43cc548f2fa63?src=pr&el=desc) will **decrease** coverage by `1.2%`.
> The diff coverage is `86.84%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/119/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #119      +/-   ##
==========================================
- Coverage   95.27%   94.06%   -1.21%     
==========================================
  Files          23       23              
  Lines         719      826     +107     
==========================================
+ Hits          685      777      +92     
- Misses         34       49      +15
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL19faW5pdF9fLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `83.78% <77.77%> (-16.22%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `93.9% <93.75%> (-0.31%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `98.33% <94.11%> (-1.67%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.4% <96%> (+1.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=footer). Last update [3d6fd61...15e4988](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",119
github.com/libratom/libratom,libratom/cli/utils.py,2020-02-26T15:00:15Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=h1) Report
> Merging [#119](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/3d6fd61d889af4723e38ebbb4dc43cc548f2fa63?src=pr&el=desc) will **decrease** coverage by `1.2%`.
> The diff coverage is `86.84%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/119/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #119      +/-   ##
==========================================
- Coverage   95.27%   94.06%   -1.21%     
==========================================
  Files          23       23              
  Lines         719      826     +107     
==========================================
+ Hits          685      777      +92     
- Misses         34       49      +15
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL19faW5pdF9fLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `83.78% <77.77%> (-16.22%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `93.9% <93.75%> (-0.31%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `98.33% <94.11%> (-1.67%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.4% <96%> (+1.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=footer). Last update [3d6fd61...15e4988](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",119
github.com/libratom/libratom,libratom/cli/utils.py,2020-02-26T15:00:15Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=h1) Report
> Merging [#119](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/3d6fd61d889af4723e38ebbb4dc43cc548f2fa63?src=pr&el=desc) will **decrease** coverage by `1.2%`.
> The diff coverage is `86.84%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/119/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #119      +/-   ##
==========================================
- Coverage   95.27%   94.06%   -1.21%     
==========================================
  Files          23       23              
  Lines         719      826     +107     
==========================================
+ Hits          685      777      +92     
- Misses         34       49      +15
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL19faW5pdF9fLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `83.78% <77.77%> (-16.22%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `93.9% <93.75%> (-0.31%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `98.33% <94.11%> (-1.67%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.4% <96%> (+1.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=footer). Last update [3d6fd61...15e4988](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",119
github.com/libratom/libratom,libratom/cli/utils.py,2020-02-26T15:00:15Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=h1) Report
> Merging [#119](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/3d6fd61d889af4723e38ebbb4dc43cc548f2fa63?src=pr&el=desc) will **decrease** coverage by `1.2%`.
> The diff coverage is `86.84%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/119/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #119      +/-   ##
==========================================
- Coverage   95.27%   94.06%   -1.21%     
==========================================
  Files          23       23              
  Lines         719      826     +107     
==========================================
+ Hits          685      777      +92     
- Misses         34       49      +15
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL19faW5pdF9fLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `83.78% <77.77%> (-16.22%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `93.9% <93.75%> (-0.31%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `98.33% <94.11%> (-1.67%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.4% <96%> (+1.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=footer). Last update [3d6fd61...15e4988](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",119
github.com/libratom/libratom,libratom/cli/utils.py,2020-02-26T15:00:15Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=h1) Report
> Merging [#119](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/3d6fd61d889af4723e38ebbb4dc43cc548f2fa63?src=pr&el=desc) will **decrease** coverage by `1.2%`.
> The diff coverage is `86.84%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/119/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #119      +/-   ##
==========================================
- Coverage   95.27%   94.06%   -1.21%     
==========================================
  Files          23       23              
  Lines         719      826     +107     
==========================================
+ Hits          685      777      +92     
- Misses         34       49      +15
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL19faW5pdF9fLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `83.78% <77.77%> (-16.22%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `93.9% <93.75%> (-0.31%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `98.33% <94.11%> (-1.67%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.4% <96%> (+1.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=footer). Last update [3d6fd61...15e4988](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",119
github.com/libratom/libratom,libratom/cli/utils.py,2020-02-26T15:00:15Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=h1) Report
> Merging [#119](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/3d6fd61d889af4723e38ebbb4dc43cc548f2fa63?src=pr&el=desc) will **decrease** coverage by `1.2%`.
> The diff coverage is `86.84%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/119/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #119      +/-   ##
==========================================
- Coverage   95.27%   94.06%   -1.21%     
==========================================
  Files          23       23              
  Lines         719      826     +107     
==========================================
+ Hits          685      777      +92     
- Misses         34       49      +15
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL19faW5pdF9fLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `83.78% <77.77%> (-16.22%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `93.9% <93.75%> (-0.31%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `98.33% <94.11%> (-1.67%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.4% <96%> (+1.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=footer). Last update [3d6fd61...15e4988](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",119
github.com/libratom/libratom,libratom/cli/utils.py,2020-02-26T15:00:15Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=h1) Report
> Merging [#119](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/3d6fd61d889af4723e38ebbb4dc43cc548f2fa63?src=pr&el=desc) will **decrease** coverage by `1.2%`.
> The diff coverage is `86.84%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/119/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #119      +/-   ##
==========================================
- Coverage   95.27%   94.06%   -1.21%     
==========================================
  Files          23       23              
  Lines         719      826     +107     
==========================================
+ Hits          685      777      +92     
- Misses         34       49      +15
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL19faW5pdF9fLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `83.78% <77.77%> (-16.22%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `93.9% <93.75%> (-0.31%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `98.33% <94.11%> (-1.67%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.4% <96%> (+1.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=footer). Last update [3d6fd61...15e4988](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",119
github.com/libratom/libratom,libratom/cli/utils.py,2020-02-26T15:00:15Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=h1) Report
> Merging [#119](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/3d6fd61d889af4723e38ebbb4dc43cc548f2fa63?src=pr&el=desc) will **decrease** coverage by `1.2%`.
> The diff coverage is `86.84%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/119/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master     #119      +/-   ##
==========================================
- Coverage   95.27%   94.06%   -1.21%     
==========================================
  Files          23       23              
  Lines         719      826     +107     
==========================================
+ Hits          685      777      +92     
- Misses         34       49      +15
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL19faW5pdF9fLnB5) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `83.78% <77.77%> (-16.22%)` | :arrow_down: |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `93.9% <93.75%> (-0.31%)` | :arrow_down: |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `98.33% <94.11%> (-1.67%)` | :arrow_down: |
| [libratom/lib/core.py](https://codecov.io/gh/libratom/libratom/pull/119/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvcmUucHk=) | `92.4% <96%> (+1.33%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=footer). Last update [3d6fd61...15e4988](https://codecov.io/gh/libratom/libratom/pull/119?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",119
github.com/libratom/libratom,libratom/cli/utils.py,2019-08-01T13:06:29Z,"# [Codecov](https://codecov.io/gh/libratom/libratom/pull/37?src=pr&el=h1) Report
> Merging [#37](https://codecov.io/gh/libratom/libratom/pull/37?src=pr&el=desc) into [master](https://codecov.io/gh/libratom/libratom/commit/5c3ca12995ac0109debb7e65e703d8d62ae66918?src=pr&el=desc) will **increase** coverage by `1.88%`.
> The diff coverage is `98.61%`.

[![Impacted file tree graph](https://codecov.io/gh/libratom/libratom/pull/37/graphs/tree.svg?width=650&token=pLv2qHIbMn&height=150&src=pr)](https://codecov.io/gh/libratom/libratom/pull/37?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master      #37      +/-   ##
==========================================
+ Coverage   92.57%   94.46%   +1.88%     
==========================================
  Files           8       10       +2     
  Lines         283      307      +24     
==========================================
+ Hits          262      290      +28     
+ Misses         21       17       -4
```


| [Impacted Files](https://codecov.io/gh/libratom/libratom/pull/37?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [libratom/cli/\_\_init\_\_.py](https://codecov.io/gh/libratom/libratom/pull/37/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL19faW5pdF9fLnB5) | `100% <ø> (ø)` | :arrow_up: |
| [libratom/lib/pff.py](https://codecov.io/gh/libratom/libratom/pull/37/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL3BmZi5weQ==) | `100% <ø> (ø)` | |
| [libratom/lib/database.py](https://codecov.io/gh/libratom/libratom/pull/37/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2RhdGFiYXNlLnB5) | `78.57% <ø> (ø)` | |
| [libratom/cli/subcommands.py](https://codecov.io/gh/libratom/libratom/pull/37/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3N1YmNvbW1hbmRzLnB5) | `100% <100%> (ø)` | |
| [libratom/lib/concurrency.py](https://codecov.io/gh/libratom/libratom/pull/37/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2NvbmN1cnJlbmN5LnB5) | `94.44% <100%> (ø)` | |
| [libratom/cli/cli.py](https://codecov.io/gh/libratom/libratom/pull/37/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL2NsaS5weQ==) | `100% <100%> (ø)` | :arrow_up: |
| [libratom/cli/utils.py](https://codecov.io/gh/libratom/libratom/pull/37/diff?src=pr&el=tree#diff-bGlicmF0b20vY2xpL3V0aWxzLnB5) | `100% <100%> (ø)` | |
| [libratom/lib/entities.py](https://codecov.io/gh/libratom/libratom/pull/37/diff?src=pr&el=tree#diff-bGlicmF0b20vbGliL2VudGl0aWVzLnB5) | `87.62% <92.3%> (ø)` | |
| ... and [2 more](https://codecov.io/gh/libratom/libratom/pull/37/diff?src=pr&el=tree-more) | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/libratom/libratom/pull/37?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/libratom/libratom/pull/37?src=pr&el=footer). Last update [5c3ca12...ec55ee8](https://codecov.io/gh/libratom/libratom/pull/37?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",37
github.com/lrank/Robust_and_Privacy_preserving_Text_Representations,Pytorch/sentiment/adv_model.py,2019-12-20T05:28:46Z,"> Hi Yitong,
> 
> I have repeated both the POS-Tagging and Sentiment Classification experiments in the paper using Pytorch.
> Could you please take a look at the code?
> 
> Thank you.

Looks amazing! Thank you! Y",3
github.com/lrank/Robust_and_Privacy_preserving_Text_Representations,Pytorch/sentiment/baseline_model.py,2019-12-20T05:28:46Z,"> Hi Yitong,
> 
> I have repeated both the POS-Tagging and Sentiment Classification experiments in the paper using Pytorch.
> Could you please take a look at the code?
> 
> Thank you.

Looks amazing! Thank you! Y",3
github.com/lrank/Robust_and_Privacy_preserving_Text_Representations,Pytorch/sentiment/baseline_model.py,2019-12-20T05:28:46Z,"> Hi Yitong,
> 
> I have repeated both the POS-Tagging and Sentiment Classification experiments in the paper using Pytorch.
> Could you please take a look at the code?
> 
> Thank you.

Looks amazing! Thank you! Y",3
github.com/spacy-pl/utils,NER-wroc-analysis/get_analysis.py,2019-05-08T19:03:51Z,"Napisz mi proszę co się dzieje w tej funkcji, bo nie wiem czy dobrze rozumiem.",61
github.com/spacy-pl/utils,NER-wroc-analysis/get_analysis.py,2019-05-08T19:05:12Z,Po co tutaj nkjp? Czy może nazwa jest po prostu obsolete?,61
github.com/spacy-pl/utils,NER-wroc-analysis/get_analysis.py,2019-05-08T19:07:30Z,"Na przyszłość komentuj więcej, albo operacje na konkretnych poziomach tekstu wydzielaj po prostu do osobnych funkcji, latwiej wtedy zrozumieć co się dzieje. (np. tutaj jest parę operacji na poziomie zdania, i ciężko sprawdzić czy są sensowne, bez informacji co mają robić) ",61
github.com/spacy-pl/utils,NER-wroc-analysis/get_analysis.py,2019-04-25T07:09:18Z,"closes #50, closes #41 ",61
github.com/spacy-pl/utils,deployment/combine_and_package.py,2019-04-17T20:01:14Z,"Dobrze rozumiem, to jest spakowany tagger? I nie jest stepem, bo pakujemy ręcznie? Spakowane modele umieszczałbym raczej w release, models zostawiłbym na modele będące outputem treningu.",59
github.com/spacy-pl/utils,deployment/combine_and_package.py,2019-04-17T20:01:52Z,Czy teraz nkjp2us to jest mapa konwersji samych posów?,59
github.com/spacy-pl/utils,deployment/combine_and_package.py,2019-04-17T20:03:01Z,Tutaj przydałyby się jeszcze strategie w dependencjach,59
github.com/spacy-pl/utils,deployment/combine_and_package.py,2019-04-17T20:06:16Z,"Wywaliłbym domyślną strategię - dzięki temu że zawsze trzeba ją podać, to stepy dvc będą lepiej dokumentować to co dzieje się po kolei",59
github.com/spacy-pl/utils,deployment/combine_and_package.py,2019-04-17T20:09:25Z,"Tak
",59
github.com/marinapts/ttds_movie_search,ir_eval/indexing/quotes.py,2020-02-20T18:04:38Z,Should we maybe move all indexing related files to a subfolder ir_eval/indexing for a better organised project folder structure? ,10
github.com/marinapts/ttds_movie_search,ir_eval/indexing/quotes.py,2020-02-20T18:30:35Z,I think the latest commit breaks other modules that use preprocessing.py,10
github.com/LAION-AI/riverbed,src/utils.py,2023-03-12T16:30:49Z,looks good to me! thank  you!,1
github.com/LAION-AI/riverbed,src/searcher_indexer.py,2023-03-12T16:30:49Z,looks good to me! thank  you!,1
github.com/IndicoDataSolutions/Indico-Solutions-Toolkit,indico_toolkit/staggered_loop/metrics.py,2022-06-09T14:32:14Z,"@Scott771 tests passing now, think this is ready for review. 
",140
github.com/IndicoDataSolutions/Indico-Solutions-Toolkit,indico_toolkit/staggered_loop/metrics.py,2022-06-21T14:25:43Z,@Scott771 going to merge this EOD tomorrow unless you have objections,140
github.com/IndicoDataSolutions/Indico-Solutions-Toolkit,indico_toolkit/staggered_loop/metrics.py,2022-06-09T14:32:14Z,"@Scott771 tests passing now, think this is ready for review. 
",140
github.com/IndicoDataSolutions/Indico-Solutions-Toolkit,indico_toolkit/staggered_loop/metrics.py,2022-06-21T14:25:43Z,@Scott771 going to merge this EOD tomorrow unless you have objections,140
github.com/IndicoDataSolutions/Indico-Solutions-Toolkit,indico_toolkit/staggered_loop/metrics.py,2022-06-09T14:32:14Z,"@Scott771 tests passing now, think this is ready for review. 
",140
github.com/IndicoDataSolutions/Indico-Solutions-Toolkit,indico_toolkit/staggered_loop/metrics.py,2022-06-21T14:25:43Z,@Scott771 going to merge this EOD tomorrow unless you have objections,140
github.com/accraze/python-ia-markov,src/ia_markov/markov.py,2018-10-01T18:31:07Z,"I think there is a problem with the build...
as described https://bitbucket.org/ned/coveragepy/issues/548/dont-fail-with-coverage-combine-aka-43",22
github.com/accraze/python-ia-markov,src/ia_markov/markov.py,2018-10-06T05:17:09Z,"@ex00 thanks for the PR! happy hacktoberfest 🎃 🖥 
you can ignore the `coverage` issue in travisCI",24
github.com/accraze/python-ia-markov,src/ia_markov/markov.py,2018-10-01T18:31:07Z,"I think there is a problem with the build...
as described https://bitbucket.org/ned/coveragepy/issues/548/dont-fail-with-coverage-combine-aka-43",22
github.com/accraze/python-ia-markov,src/ia_markov/markov.py,2018-07-29T15:41:58Z,"# [Codecov](https://codecov.io/gh/accraze/python-ia-markov/pull/14?src=pr&el=h1) Report
> Merging [#14](https://codecov.io/gh/accraze/python-ia-markov/pull/14?src=pr&el=desc) into [master](https://codecov.io/gh/accraze/python-ia-markov/commit/8228dd6922a91e68e93dbc6f8416c5c49edf9009?src=pr&el=desc) will **increase** coverage by `0.23%`.
> The diff coverage is `75%`.

[![Impacted file tree graph](https://codecov.io/gh/accraze/python-ia-markov/pull/14/graphs/tree.svg?token=tPMjeyMpjD&width=650&height=150&src=pr)](https://codecov.io/gh/accraze/python-ia-markov/pull/14?src=pr&el=tree)

```diff
@@            Coverage Diff             @@
##           master      #14      +/-   ##
==========================================
+ Coverage   74.31%   74.54%   +0.23%     
==========================================
  Files           4        4              
  Lines         109      110       +1     
  Branches       12       12              
==========================================
+ Hits           81       82       +1     
  Misses         26       26              
  Partials        2        2
```


| [Impacted Files](https://codecov.io/gh/accraze/python-ia-markov/pull/14?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [src/ia\_markov/markov.py](https://codecov.io/gh/accraze/python-ia-markov/pull/14/diff?src=pr&el=tree#diff-c3JjL2lhX21hcmtvdi9tYXJrb3YucHk=) | `73.68% <75%> (+0.46%)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/accraze/python-ia-markov/pull/14?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/accraze/python-ia-markov/pull/14?src=pr&el=footer). Last update [8228dd6...60e35b3](https://codecov.io/gh/accraze/python-ia-markov/pull/14?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",14
github.com/accraze/python-ia-markov,src/ia_markov/markov.py,2018-07-14T16:08:27Z,"# [Codecov](https://codecov.io/gh/accraze/python-ia-markov/pull/5?src=pr&el=h1) Report
> Merging [#5](https://codecov.io/gh/accraze/python-ia-markov/pull/5?src=pr&el=desc) into [master](https://codecov.io/gh/accraze/python-ia-markov/commit/99fa27c0af1f3df5fb6eef4604f7b96f7f4fe240?src=pr&el=desc) will **decrease** coverage by `13.02%`.
> The diff coverage is `50%`.

[![Impacted file tree graph](https://codecov.io/gh/accraze/python-ia-markov/pull/5/graphs/tree.svg?height=150&width=650&token=tPMjeyMpjD&src=pr)](https://codecov.io/gh/accraze/python-ia-markov/pull/5?src=pr&el=tree)

```diff
@@             Coverage Diff             @@
##           master       #5       +/-   ##
===========================================
- Coverage   81.91%   68.88%   -13.03%     
===========================================
  Files           4        4               
  Lines          94       90        -4     
  Branches       10       10               
===========================================
- Hits           77       62       -15     
- Misses         15       26       +11     
  Partials        2        2
```


| [Impacted Files](https://codecov.io/gh/accraze/python-ia-markov/pull/5?src=pr&el=tree) | Coverage Δ | |
|---|---|---|
| [tests/test\_markov.py](https://codecov.io/gh/accraze/python-ia-markov/pull/5/diff?src=pr&el=tree#diff-dGVzdHMvdGVzdF9tYXJrb3YucHk=) | `92.85% <ø> (-0.9%)` | :arrow_down: |
| [src/ia\_markov/markov.py](https://codecov.io/gh/accraze/python-ia-markov/pull/5/diff?src=pr&el=tree#diff-c3JjL2lhX21hcmtvdi9tYXJrb3YucHk=) | `53.57% <0%> (-19.65%)` | :arrow_down: |
| [src/ia\_markov/\_\_init\_\_.py](https://codecov.io/gh/accraze/python-ia-markov/pull/5/diff?src=pr&el=tree#diff-c3JjL2lhX21hcmtvdi9fX2luaXRfXy5weQ==) | `100% <100%> (ø)` | :arrow_up: |

------

[Continue to review full report at Codecov](https://codecov.io/gh/accraze/python-ia-markov/pull/5?src=pr&el=continue).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/accraze/python-ia-markov/pull/5?src=pr&el=footer). Last update [99fa27c...c76884d](https://codecov.io/gh/accraze/python-ia-markov/pull/5?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).
",5
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-06-09T19:25:45Z,"If we only need tokenization from space, we need not add other pipes to the processors' list. ",35
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-06-09T19:26:05Z,We can remove configs that's not being used anywhere.,35
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-06-10T23:42:11Z,Thanks. I will fix those.,35
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-06-15T05:03:31Z,"These import comments seem superfluous, since the name itself implies what's being imported.",35
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-06-15T05:05:05Z,"I don't think we need comments for each line in the code, some lines are self explanatory. Maybe we can reduce the clutter by deleting unnecessary comments?",35
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-06-16T03:06:05Z,"Following the python convention, we should use `show_data`",35
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-06-16T03:09:15Z,"This config loading is correct. But as an example, it isn't really necessary. The config file is quite brief, we should probably directly initialize the config here, so that one can actually see what happens in one file.",35
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-06-16T03:11:41Z,"The model is actually configurable via [this parameter](https://github.com/KiaLAN/ForteHealth/blob/60bb3919d4f96f246f328f5f8a86bc771f6bba04/fortex/health/processors/icd_coding_processor.py#L106). So this description is not exactly accurate. In addition, it might be helpful to show how to configure this.",35
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-06-16T03:12:24Z,Why are we installing `forte.elastic` when it is not used in the example?,35
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-06-16T06:54:48Z,I copied that from `examples/mimic_iii/medical_pipeline.py`. I guess both this and that file need to change.,35
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-06-16T06:57:20Z,"I copied that from `examples/mimic_iii/medical_pipeline.py`.

When I uninstall that package, the code works fine. I will remove that dependency.",35
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-06-12T23:45:45Z,@Piyush13y I've cleaned those configs.,35
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-06-15T05:06:38Z,"Other than the unnecessary comments, everything seems fine. I can merge the PR as soon as you can resolve the small suggestions",35
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-06-15T09:35:31Z,"I've removed those comments.

And I fixed a mistake in config, where I accidentally removed the language model. Since we don't have POS in the pipeline, I also removed its printing.",35
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-05-31T19:57:09Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/29?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#29](https://codecov.io/gh/asyml/ForteHealth/pull/29?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (d306fe2) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/2b80d30c69422118963755fe61732894b2a3bcf3?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (2b80d30) will **not change** coverage.
> The diff coverage is `100.00%`.

```diff
@@           Coverage Diff           @@
##           master      #29   +/-   ##
=======================================
  Coverage   84.44%   84.44%           
=======================================
  Files           9        9           
  Lines         508      508           
=======================================
  Hits          429      429           
  Misses         79       79           
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/29?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/\_\_init\_\_.py](https://codecov.io/gh/asyml/ForteHealth/pull/29/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9fX2luaXRfXy5weQ==) | `100.00% <ø> (ø)` | |
| [...tex/health/processors/negation\_context\_analyzer.py](https://codecov.io/gh/asyml/ForteHealth/pull/29/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL25lZ2F0aW9uX2NvbnRleHRfYW5hbHl6ZXIucHk=) | `97.16% <ø> (ø)` | |
| [fortex/health/readers/mimic3\_note\_reader.py](https://codecov.io/gh/asyml/ForteHealth/pull/29/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9yZWFkZXJzL21pbWljM19ub3RlX3JlYWRlci5weQ==) | `97.87% <ø> (ø)` | |
| [fortex/health/processors/icd\_coding\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/29/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL2ljZF9jb2RpbmdfcHJvY2Vzc29yLnB5) | `97.43% <100.00%> (ø)` | |
| [fortex/health/readers/\_\_init\_\_.py](https://codecov.io/gh/asyml/ForteHealth/pull/29/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9yZWFkZXJzL19faW5pdF9fLnB5) | `100.00% <100.00%> (ø)` | |
| [...te\_medical/processors/icd\_coding\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/29/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGVfbWVkaWNhbC9wcm9jZXNzb3JzL2ljZF9jb2RpbmdfcHJvY2Vzc29yX3Rlc3QucHk=) | `100.00% <100.00%> (ø)` | |
| [...dical/processors/negation\_context\_analysis\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/29/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGVfbWVkaWNhbC9wcm9jZXNzb3JzL25lZ2F0aW9uX2NvbnRleHRfYW5hbHlzaXNfdGVzdC5weQ==) | `100.00% <100.00%> (ø)` | |
| [...s/forte\_medical/readers/mimic3\_note\_reader\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/29/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGVfbWVkaWNhbC9yZWFkZXJzL21pbWljM19ub3RlX3JlYWRlcl90ZXN0LnB5) | `96.29% <100.00%> (ø)` | |

------

[Continue to review full report at Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/29?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml).
> **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
> `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`
> Powered by [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/29?src=pr&el=footer&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml). Last update [2b80d30...d306fe2](https://codecov.io/gh/asyml/ForteHealth/pull/29?src=pr&el=lastupdated&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml).
",29
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:05:09Z,"1. shouldn't use camel case for argument/variables `singlePack`.
2. It is indeed weird to use `True` as string, why not using bool?

",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:06:47Z,maybe use a text reader and load a sample file from disk?,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:07:04Z,no camel case,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:12:44Z,2022,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:35:25Z,The variable name `singlePack` is a bit weird since it is controlling the reader source.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:36:00Z,no camel case or we simply inline the configs here.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:37:46Z,shall we provide these negex triggers as part of the repo? ,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:39:49Z,"A question, did we adopt the code from Ctakes? If so, we probably want to make a reference here.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:40:58Z,I find that the processor also [expects `Sentence`](https://github.com/asyml/forte-medical/pull/7/files#diff-ca80a2b79a235631494ffd7a9f32b1291e606dc773cfe08e1a3176f6264d0d68R111).,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:41:39Z,"one thing we could do is that we provide a default rule set, and let the users provide theirs if they know how to",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:41:34Z,"Not from Ctakes, that uses Finite State Machines to implement Negex. Instead, we adopted it from [here.](https://github.com/chapmanbe/negex) I can add a reference to this repo in our code?",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:43:29Z,"I was initially planning to do that. Something like this:

```
{
""negation_rules_path"": """",
""pre_negation_rules"": [],
""post_negation_rules"": []
}
```

We basically add all `pre_negation_rules` and `post_negaion_rules` to the rules picked from the sample rules file, which will be shipped with the repo. 
However, I thought I will add these improvements after this gets pushed.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:44:34Z,"Yes, I think we should ship it with the repo, as default set of rules for the processor. I think we should put this file to a different folder if that's the case, but not sure where. Maybe within /processors/ instead of /examples/mimic_iii/ ? ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:48:32Z,"boolean type was misbehaving for some reason. I will retry though, string didn't seem ideal to me either.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T18:05:10Z,"yes, let's acknowledge them",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T18:19:31Z,"So we need to make sure it gets automatically picked up when people download and use the code. So if it is part of the code, it needs should be picked up by `setup.py`, or it is a file URL, then you can consider downloading it somewhere.

It could be your decision on where it will be placed. ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T23:20:30Z,"> 1. I guess we want to lint the project with `mypy`, `pylint` and `black` to make it more standard before we merge this.
> 2. We will also need to set up test cases (and write test cases), like [here](https://github.com/asyml/forte/blob/master/.github/workflows/main.yml#L97).

Sure. I'll update the workflow with more linting tools.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T11:33:13Z,@hunterhector Still unable to add @tanyuqian as a reviewer. It says I can add **atmost** 1 reviewer.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T17:30:53Z,"> @hunterhector Still unable to add @tanyuqian as a reviewer. It says I can add **almost** 1 reviewer.

Add bowen in the future. I will get notified for the PRs anyway",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-04T05:00:53Z,"> 1. I guess we want to lint the project with `mypy`, `pylint` and `black` to make it more standard before we merge this.
> 2. We will also need to set up test cases (and write test cases), like [here](https://github.com/asyml/forte/blob/master/.github/workflows/main.yml#L97).

Pytest and documentation has been updated. 
@Piyush13y Could you write unit tests for the components you developed? ([mimic_reader](https://github.com/asyml/forte-medical/blob/master/tests/readers/mimic3_note_reader_test.py#L12) and this negation analyzer)",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-04T12:06:41Z,"@tanyuqian I had already added test cases for `NegationContextAnalyzer`, and now I have added a test case for Mimic3 reader as well. However, there seems to be something broken with respect to pytest in the workflow I think, which gives errors in the CI pipeline. I am able to run these tests successfully on my local machine.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-06T22:02:25Z,"> @tanyuqian I had already added test cases for `NegationContextAnalyzer`, and now I have added a test case for Mimic3 reader as well. However, there seems to be something broken with respect to pytest in the workflow I think, which gives errors in the CI pipeline. I am able to run these tests successfully on my local machine.

@Piyush13y Could you double-check it is working from your end? like re-install forte/forte-wrapper/forte-medical and re-run? I got the same error message as the workflow here https://github.com/asyml/forte-medical/runs/5435388860?check_suite_focus=true#step:13:23 
(```ImportError: cannot import name 'MedicalEntityMention' from 'ftx.medical' (/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/ftx/medical/__init__.py)```)",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-06T22:10:32Z,"@tanyuqian There were 2 issues raised in the CI pipeline initially, one was due to a stray test folder which, on deletion, fixed that problem.
The other one related to import statement is because [this](https://github.com/asyml/forte-wrappers/pull/96) Forte-wrapper's PR is yet to be merged, which completes the namespace consistency story. I have run these tests with that PR and it works fine. There's some other issue which is failing a test on that PR which has blocked its merge for now. @hunterhector mentioned someone will be working on that but might take some time. ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:05:09Z,"1. shouldn't use camel case for argument/variables `singlePack`.
2. It is indeed weird to use `True` as string, why not using bool?

",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:06:47Z,maybe use a text reader and load a sample file from disk?,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:07:04Z,no camel case,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:12:44Z,2022,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:35:25Z,The variable name `singlePack` is a bit weird since it is controlling the reader source.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:36:00Z,no camel case or we simply inline the configs here.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:37:46Z,shall we provide these negex triggers as part of the repo? ,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:39:49Z,"A question, did we adopt the code from Ctakes? If so, we probably want to make a reference here.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:40:58Z,I find that the processor also [expects `Sentence`](https://github.com/asyml/forte-medical/pull/7/files#diff-ca80a2b79a235631494ffd7a9f32b1291e606dc773cfe08e1a3176f6264d0d68R111).,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:41:39Z,"one thing we could do is that we provide a default rule set, and let the users provide theirs if they know how to",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:41:34Z,"Not from Ctakes, that uses Finite State Machines to implement Negex. Instead, we adopted it from [here.](https://github.com/chapmanbe/negex) I can add a reference to this repo in our code?",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:43:29Z,"I was initially planning to do that. Something like this:

```
{
""negation_rules_path"": """",
""pre_negation_rules"": [],
""post_negation_rules"": []
}
```

We basically add all `pre_negation_rules` and `post_negaion_rules` to the rules picked from the sample rules file, which will be shipped with the repo. 
However, I thought I will add these improvements after this gets pushed.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:44:34Z,"Yes, I think we should ship it with the repo, as default set of rules for the processor. I think we should put this file to a different folder if that's the case, but not sure where. Maybe within /processors/ instead of /examples/mimic_iii/ ? ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:48:32Z,"boolean type was misbehaving for some reason. I will retry though, string didn't seem ideal to me either.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T18:05:10Z,"yes, let's acknowledge them",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T18:19:31Z,"So we need to make sure it gets automatically picked up when people download and use the code. So if it is part of the code, it needs should be picked up by `setup.py`, or it is a file URL, then you can consider downloading it somewhere.

It could be your decision on where it will be placed. ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T23:20:30Z,"> 1. I guess we want to lint the project with `mypy`, `pylint` and `black` to make it more standard before we merge this.
> 2. We will also need to set up test cases (and write test cases), like [here](https://github.com/asyml/forte/blob/master/.github/workflows/main.yml#L97).

Sure. I'll update the workflow with more linting tools.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T11:33:13Z,@hunterhector Still unable to add @tanyuqian as a reviewer. It says I can add **atmost** 1 reviewer.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T17:30:53Z,"> @hunterhector Still unable to add @tanyuqian as a reviewer. It says I can add **almost** 1 reviewer.

Add bowen in the future. I will get notified for the PRs anyway",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-04T05:00:53Z,"> 1. I guess we want to lint the project with `mypy`, `pylint` and `black` to make it more standard before we merge this.
> 2. We will also need to set up test cases (and write test cases), like [here](https://github.com/asyml/forte/blob/master/.github/workflows/main.yml#L97).

Pytest and documentation has been updated. 
@Piyush13y Could you write unit tests for the components you developed? ([mimic_reader](https://github.com/asyml/forte-medical/blob/master/tests/readers/mimic3_note_reader_test.py#L12) and this negation analyzer)",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-04T12:06:41Z,"@tanyuqian I had already added test cases for `NegationContextAnalyzer`, and now I have added a test case for Mimic3 reader as well. However, there seems to be something broken with respect to pytest in the workflow I think, which gives errors in the CI pipeline. I am able to run these tests successfully on my local machine.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-06T22:02:25Z,"> @tanyuqian I had already added test cases for `NegationContextAnalyzer`, and now I have added a test case for Mimic3 reader as well. However, there seems to be something broken with respect to pytest in the workflow I think, which gives errors in the CI pipeline. I am able to run these tests successfully on my local machine.

@Piyush13y Could you double-check it is working from your end? like re-install forte/forte-wrapper/forte-medical and re-run? I got the same error message as the workflow here https://github.com/asyml/forte-medical/runs/5435388860?check_suite_focus=true#step:13:23 
(```ImportError: cannot import name 'MedicalEntityMention' from 'ftx.medical' (/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/ftx/medical/__init__.py)```)",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-06T22:10:32Z,"@tanyuqian There were 2 issues raised in the CI pipeline initially, one was due to a stray test folder which, on deletion, fixed that problem.
The other one related to import statement is because [this](https://github.com/asyml/forte-wrappers/pull/96) Forte-wrapper's PR is yet to be merged, which completes the namespace consistency story. I have run these tests with that PR and it works fine. There's some other issue which is failing a test on that PR which has blocked its merge for now. @hunterhector mentioned someone will be working on that but might take some time. ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:05:09Z,"1. shouldn't use camel case for argument/variables `singlePack`.
2. It is indeed weird to use `True` as string, why not using bool?

",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:06:47Z,maybe use a text reader and load a sample file from disk?,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:07:04Z,no camel case,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:12:44Z,2022,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:35:25Z,The variable name `singlePack` is a bit weird since it is controlling the reader source.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:36:00Z,no camel case or we simply inline the configs here.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:37:46Z,shall we provide these negex triggers as part of the repo? ,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:39:49Z,"A question, did we adopt the code from Ctakes? If so, we probably want to make a reference here.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:40:58Z,I find that the processor also [expects `Sentence`](https://github.com/asyml/forte-medical/pull/7/files#diff-ca80a2b79a235631494ffd7a9f32b1291e606dc773cfe08e1a3176f6264d0d68R111).,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:41:39Z,"one thing we could do is that we provide a default rule set, and let the users provide theirs if they know how to",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:41:34Z,"Not from Ctakes, that uses Finite State Machines to implement Negex. Instead, we adopted it from [here.](https://github.com/chapmanbe/negex) I can add a reference to this repo in our code?",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:43:29Z,"I was initially planning to do that. Something like this:

```
{
""negation_rules_path"": """",
""pre_negation_rules"": [],
""post_negation_rules"": []
}
```

We basically add all `pre_negation_rules` and `post_negaion_rules` to the rules picked from the sample rules file, which will be shipped with the repo. 
However, I thought I will add these improvements after this gets pushed.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:44:34Z,"Yes, I think we should ship it with the repo, as default set of rules for the processor. I think we should put this file to a different folder if that's the case, but not sure where. Maybe within /processors/ instead of /examples/mimic_iii/ ? ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:48:32Z,"boolean type was misbehaving for some reason. I will retry though, string didn't seem ideal to me either.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T18:05:10Z,"yes, let's acknowledge them",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T18:19:31Z,"So we need to make sure it gets automatically picked up when people download and use the code. So if it is part of the code, it needs should be picked up by `setup.py`, or it is a file URL, then you can consider downloading it somewhere.

It could be your decision on where it will be placed. ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T23:20:30Z,"> 1. I guess we want to lint the project with `mypy`, `pylint` and `black` to make it more standard before we merge this.
> 2. We will also need to set up test cases (and write test cases), like [here](https://github.com/asyml/forte/blob/master/.github/workflows/main.yml#L97).

Sure. I'll update the workflow with more linting tools.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T11:33:13Z,@hunterhector Still unable to add @tanyuqian as a reviewer. It says I can add **atmost** 1 reviewer.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T17:30:53Z,"> @hunterhector Still unable to add @tanyuqian as a reviewer. It says I can add **almost** 1 reviewer.

Add bowen in the future. I will get notified for the PRs anyway",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-04T05:00:53Z,"> 1. I guess we want to lint the project with `mypy`, `pylint` and `black` to make it more standard before we merge this.
> 2. We will also need to set up test cases (and write test cases), like [here](https://github.com/asyml/forte/blob/master/.github/workflows/main.yml#L97).

Pytest and documentation has been updated. 
@Piyush13y Could you write unit tests for the components you developed? ([mimic_reader](https://github.com/asyml/forte-medical/blob/master/tests/readers/mimic3_note_reader_test.py#L12) and this negation analyzer)",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-04T12:06:41Z,"@tanyuqian I had already added test cases for `NegationContextAnalyzer`, and now I have added a test case for Mimic3 reader as well. However, there seems to be something broken with respect to pytest in the workflow I think, which gives errors in the CI pipeline. I am able to run these tests successfully on my local machine.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-06T22:02:25Z,"> @tanyuqian I had already added test cases for `NegationContextAnalyzer`, and now I have added a test case for Mimic3 reader as well. However, there seems to be something broken with respect to pytest in the workflow I think, which gives errors in the CI pipeline. I am able to run these tests successfully on my local machine.

@Piyush13y Could you double-check it is working from your end? like re-install forte/forte-wrapper/forte-medical and re-run? I got the same error message as the workflow here https://github.com/asyml/forte-medical/runs/5435388860?check_suite_focus=true#step:13:23 
(```ImportError: cannot import name 'MedicalEntityMention' from 'ftx.medical' (/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/ftx/medical/__init__.py)```)",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-06T22:10:32Z,"@tanyuqian There were 2 issues raised in the CI pipeline initially, one was due to a stray test folder which, on deletion, fixed that problem.
The other one related to import statement is because [this](https://github.com/asyml/forte-wrappers/pull/96) Forte-wrapper's PR is yet to be merged, which completes the namespace consistency story. I have run these tests with that PR and it works fine. There's some other issue which is failing a test on that PR which has blocked its merge for now. @hunterhector mentioned someone will be working on that but might take some time. ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:05:09Z,"1. shouldn't use camel case for argument/variables `singlePack`.
2. It is indeed weird to use `True` as string, why not using bool?

",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:06:47Z,maybe use a text reader and load a sample file from disk?,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:07:04Z,no camel case,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:12:44Z,2022,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:35:25Z,The variable name `singlePack` is a bit weird since it is controlling the reader source.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:36:00Z,no camel case or we simply inline the configs here.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:37:46Z,shall we provide these negex triggers as part of the repo? ,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:39:49Z,"A question, did we adopt the code from Ctakes? If so, we probably want to make a reference here.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:40:58Z,I find that the processor also [expects `Sentence`](https://github.com/asyml/forte-medical/pull/7/files#diff-ca80a2b79a235631494ffd7a9f32b1291e606dc773cfe08e1a3176f6264d0d68R111).,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:41:39Z,"one thing we could do is that we provide a default rule set, and let the users provide theirs if they know how to",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:41:34Z,"Not from Ctakes, that uses Finite State Machines to implement Negex. Instead, we adopted it from [here.](https://github.com/chapmanbe/negex) I can add a reference to this repo in our code?",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:43:29Z,"I was initially planning to do that. Something like this:

```
{
""negation_rules_path"": """",
""pre_negation_rules"": [],
""post_negation_rules"": []
}
```

We basically add all `pre_negation_rules` and `post_negaion_rules` to the rules picked from the sample rules file, which will be shipped with the repo. 
However, I thought I will add these improvements after this gets pushed.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:44:34Z,"Yes, I think we should ship it with the repo, as default set of rules for the processor. I think we should put this file to a different folder if that's the case, but not sure where. Maybe within /processors/ instead of /examples/mimic_iii/ ? ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:48:32Z,"boolean type was misbehaving for some reason. I will retry though, string didn't seem ideal to me either.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T18:05:10Z,"yes, let's acknowledge them",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T18:19:31Z,"So we need to make sure it gets automatically picked up when people download and use the code. So if it is part of the code, it needs should be picked up by `setup.py`, or it is a file URL, then you can consider downloading it somewhere.

It could be your decision on where it will be placed. ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T23:20:30Z,"> 1. I guess we want to lint the project with `mypy`, `pylint` and `black` to make it more standard before we merge this.
> 2. We will also need to set up test cases (and write test cases), like [here](https://github.com/asyml/forte/blob/master/.github/workflows/main.yml#L97).

Sure. I'll update the workflow with more linting tools.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T11:33:13Z,@hunterhector Still unable to add @tanyuqian as a reviewer. It says I can add **atmost** 1 reviewer.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T17:30:53Z,"> @hunterhector Still unable to add @tanyuqian as a reviewer. It says I can add **almost** 1 reviewer.

Add bowen in the future. I will get notified for the PRs anyway",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-04T05:00:53Z,"> 1. I guess we want to lint the project with `mypy`, `pylint` and `black` to make it more standard before we merge this.
> 2. We will also need to set up test cases (and write test cases), like [here](https://github.com/asyml/forte/blob/master/.github/workflows/main.yml#L97).

Pytest and documentation has been updated. 
@Piyush13y Could you write unit tests for the components you developed? ([mimic_reader](https://github.com/asyml/forte-medical/blob/master/tests/readers/mimic3_note_reader_test.py#L12) and this negation analyzer)",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-04T12:06:41Z,"@tanyuqian I had already added test cases for `NegationContextAnalyzer`, and now I have added a test case for Mimic3 reader as well. However, there seems to be something broken with respect to pytest in the workflow I think, which gives errors in the CI pipeline. I am able to run these tests successfully on my local machine.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-06T22:02:25Z,"> @tanyuqian I had already added test cases for `NegationContextAnalyzer`, and now I have added a test case for Mimic3 reader as well. However, there seems to be something broken with respect to pytest in the workflow I think, which gives errors in the CI pipeline. I am able to run these tests successfully on my local machine.

@Piyush13y Could you double-check it is working from your end? like re-install forte/forte-wrapper/forte-medical and re-run? I got the same error message as the workflow here https://github.com/asyml/forte-medical/runs/5435388860?check_suite_focus=true#step:13:23 
(```ImportError: cannot import name 'MedicalEntityMention' from 'ftx.medical' (/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/ftx/medical/__init__.py)```)",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-06T22:10:32Z,"@tanyuqian There were 2 issues raised in the CI pipeline initially, one was due to a stray test folder which, on deletion, fixed that problem.
The other one related to import statement is because [this](https://github.com/asyml/forte-wrappers/pull/96) Forte-wrapper's PR is yet to be merged, which completes the namespace consistency story. I have run these tests with that PR and it works fine. There's some other issue which is failing a test on that PR which has blocked its merge for now. @hunterhector mentioned someone will be working on that but might take some time. ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:05:09Z,"1. shouldn't use camel case for argument/variables `singlePack`.
2. It is indeed weird to use `True` as string, why not using bool?

",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:06:47Z,maybe use a text reader and load a sample file from disk?,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:07:04Z,no camel case,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:12:44Z,2022,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:35:25Z,The variable name `singlePack` is a bit weird since it is controlling the reader source.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:36:00Z,no camel case or we simply inline the configs here.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:37:46Z,shall we provide these negex triggers as part of the repo? ,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:39:49Z,"A question, did we adopt the code from Ctakes? If so, we probably want to make a reference here.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:40:58Z,I find that the processor also [expects `Sentence`](https://github.com/asyml/forte-medical/pull/7/files#diff-ca80a2b79a235631494ffd7a9f32b1291e606dc773cfe08e1a3176f6264d0d68R111).,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:41:39Z,"one thing we could do is that we provide a default rule set, and let the users provide theirs if they know how to",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:41:34Z,"Not from Ctakes, that uses Finite State Machines to implement Negex. Instead, we adopted it from [here.](https://github.com/chapmanbe/negex) I can add a reference to this repo in our code?",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:43:29Z,"I was initially planning to do that. Something like this:

```
{
""negation_rules_path"": """",
""pre_negation_rules"": [],
""post_negation_rules"": []
}
```

We basically add all `pre_negation_rules` and `post_negaion_rules` to the rules picked from the sample rules file, which will be shipped with the repo. 
However, I thought I will add these improvements after this gets pushed.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:44:34Z,"Yes, I think we should ship it with the repo, as default set of rules for the processor. I think we should put this file to a different folder if that's the case, but not sure where. Maybe within /processors/ instead of /examples/mimic_iii/ ? ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:48:32Z,"boolean type was misbehaving for some reason. I will retry though, string didn't seem ideal to me either.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T18:05:10Z,"yes, let's acknowledge them",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T18:19:31Z,"So we need to make sure it gets automatically picked up when people download and use the code. So if it is part of the code, it needs should be picked up by `setup.py`, or it is a file URL, then you can consider downloading it somewhere.

It could be your decision on where it will be placed. ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T23:20:30Z,"> 1. I guess we want to lint the project with `mypy`, `pylint` and `black` to make it more standard before we merge this.
> 2. We will also need to set up test cases (and write test cases), like [here](https://github.com/asyml/forte/blob/master/.github/workflows/main.yml#L97).

Sure. I'll update the workflow with more linting tools.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T11:33:13Z,@hunterhector Still unable to add @tanyuqian as a reviewer. It says I can add **atmost** 1 reviewer.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T17:30:53Z,"> @hunterhector Still unable to add @tanyuqian as a reviewer. It says I can add **almost** 1 reviewer.

Add bowen in the future. I will get notified for the PRs anyway",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-04T05:00:53Z,"> 1. I guess we want to lint the project with `mypy`, `pylint` and `black` to make it more standard before we merge this.
> 2. We will also need to set up test cases (and write test cases), like [here](https://github.com/asyml/forte/blob/master/.github/workflows/main.yml#L97).

Pytest and documentation has been updated. 
@Piyush13y Could you write unit tests for the components you developed? ([mimic_reader](https://github.com/asyml/forte-medical/blob/master/tests/readers/mimic3_note_reader_test.py#L12) and this negation analyzer)",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-04T12:06:41Z,"@tanyuqian I had already added test cases for `NegationContextAnalyzer`, and now I have added a test case for Mimic3 reader as well. However, there seems to be something broken with respect to pytest in the workflow I think, which gives errors in the CI pipeline. I am able to run these tests successfully on my local machine.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-06T22:02:25Z,"> @tanyuqian I had already added test cases for `NegationContextAnalyzer`, and now I have added a test case for Mimic3 reader as well. However, there seems to be something broken with respect to pytest in the workflow I think, which gives errors in the CI pipeline. I am able to run these tests successfully on my local machine.

@Piyush13y Could you double-check it is working from your end? like re-install forte/forte-wrapper/forte-medical and re-run? I got the same error message as the workflow here https://github.com/asyml/forte-medical/runs/5435388860?check_suite_focus=true#step:13:23 
(```ImportError: cannot import name 'MedicalEntityMention' from 'ftx.medical' (/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/ftx/medical/__init__.py)```)",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-06T22:10:32Z,"@tanyuqian There were 2 issues raised in the CI pipeline initially, one was due to a stray test folder which, on deletion, fixed that problem.
The other one related to import statement is because [this](https://github.com/asyml/forte-wrappers/pull/96) Forte-wrapper's PR is yet to be merged, which completes the namespace consistency story. I have run these tests with that PR and it works fine. There's some other issue which is failing a test on that PR which has blocked its merge for now. @hunterhector mentioned someone will be working on that but might take some time. ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:05:09Z,"1. shouldn't use camel case for argument/variables `singlePack`.
2. It is indeed weird to use `True` as string, why not using bool?

",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:06:47Z,maybe use a text reader and load a sample file from disk?,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:07:04Z,no camel case,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:12:44Z,2022,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:35:25Z,The variable name `singlePack` is a bit weird since it is controlling the reader source.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:36:00Z,no camel case or we simply inline the configs here.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:37:46Z,shall we provide these negex triggers as part of the repo? ,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:39:49Z,"A question, did we adopt the code from Ctakes? If so, we probably want to make a reference here.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:40:58Z,I find that the processor also [expects `Sentence`](https://github.com/asyml/forte-medical/pull/7/files#diff-ca80a2b79a235631494ffd7a9f32b1291e606dc773cfe08e1a3176f6264d0d68R111).,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:41:39Z,"one thing we could do is that we provide a default rule set, and let the users provide theirs if they know how to",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:41:34Z,"Not from Ctakes, that uses Finite State Machines to implement Negex. Instead, we adopted it from [here.](https://github.com/chapmanbe/negex) I can add a reference to this repo in our code?",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:43:29Z,"I was initially planning to do that. Something like this:

```
{
""negation_rules_path"": """",
""pre_negation_rules"": [],
""post_negation_rules"": []
}
```

We basically add all `pre_negation_rules` and `post_negaion_rules` to the rules picked from the sample rules file, which will be shipped with the repo. 
However, I thought I will add these improvements after this gets pushed.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:44:34Z,"Yes, I think we should ship it with the repo, as default set of rules for the processor. I think we should put this file to a different folder if that's the case, but not sure where. Maybe within /processors/ instead of /examples/mimic_iii/ ? ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:48:32Z,"boolean type was misbehaving for some reason. I will retry though, string didn't seem ideal to me either.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T18:05:10Z,"yes, let's acknowledge them",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T18:19:31Z,"So we need to make sure it gets automatically picked up when people download and use the code. So if it is part of the code, it needs should be picked up by `setup.py`, or it is a file URL, then you can consider downloading it somewhere.

It could be your decision on where it will be placed. ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T23:20:30Z,"> 1. I guess we want to lint the project with `mypy`, `pylint` and `black` to make it more standard before we merge this.
> 2. We will also need to set up test cases (and write test cases), like [here](https://github.com/asyml/forte/blob/master/.github/workflows/main.yml#L97).

Sure. I'll update the workflow with more linting tools.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T11:33:13Z,@hunterhector Still unable to add @tanyuqian as a reviewer. It says I can add **atmost** 1 reviewer.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T17:30:53Z,"> @hunterhector Still unable to add @tanyuqian as a reviewer. It says I can add **almost** 1 reviewer.

Add bowen in the future. I will get notified for the PRs anyway",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-04T05:00:53Z,"> 1. I guess we want to lint the project with `mypy`, `pylint` and `black` to make it more standard before we merge this.
> 2. We will also need to set up test cases (and write test cases), like [here](https://github.com/asyml/forte/blob/master/.github/workflows/main.yml#L97).

Pytest and documentation has been updated. 
@Piyush13y Could you write unit tests for the components you developed? ([mimic_reader](https://github.com/asyml/forte-medical/blob/master/tests/readers/mimic3_note_reader_test.py#L12) and this negation analyzer)",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-04T12:06:41Z,"@tanyuqian I had already added test cases for `NegationContextAnalyzer`, and now I have added a test case for Mimic3 reader as well. However, there seems to be something broken with respect to pytest in the workflow I think, which gives errors in the CI pipeline. I am able to run these tests successfully on my local machine.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-06T22:02:25Z,"> @tanyuqian I had already added test cases for `NegationContextAnalyzer`, and now I have added a test case for Mimic3 reader as well. However, there seems to be something broken with respect to pytest in the workflow I think, which gives errors in the CI pipeline. I am able to run these tests successfully on my local machine.

@Piyush13y Could you double-check it is working from your end? like re-install forte/forte-wrapper/forte-medical and re-run? I got the same error message as the workflow here https://github.com/asyml/forte-medical/runs/5435388860?check_suite_focus=true#step:13:23 
(```ImportError: cannot import name 'MedicalEntityMention' from 'ftx.medical' (/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/ftx/medical/__init__.py)```)",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-06T22:10:32Z,"@tanyuqian There were 2 issues raised in the CI pipeline initially, one was due to a stray test folder which, on deletion, fixed that problem.
The other one related to import statement is because [this](https://github.com/asyml/forte-wrappers/pull/96) Forte-wrapper's PR is yet to be merged, which completes the namespace consistency story. I have run these tests with that PR and it works fine. There's some other issue which is failing a test on that PR which has blocked its merge for now. @hunterhector mentioned someone will be working on that but might take some time. ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:05:09Z,"1. shouldn't use camel case for argument/variables `singlePack`.
2. It is indeed weird to use `True` as string, why not using bool?

",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:06:47Z,maybe use a text reader and load a sample file from disk?,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:07:04Z,no camel case,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:12:44Z,2022,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:35:25Z,The variable name `singlePack` is a bit weird since it is controlling the reader source.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:36:00Z,no camel case or we simply inline the configs here.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:37:46Z,shall we provide these negex triggers as part of the repo? ,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:39:49Z,"A question, did we adopt the code from Ctakes? If so, we probably want to make a reference here.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:40:58Z,I find that the processor also [expects `Sentence`](https://github.com/asyml/forte-medical/pull/7/files#diff-ca80a2b79a235631494ffd7a9f32b1291e606dc773cfe08e1a3176f6264d0d68R111).,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:41:39Z,"one thing we could do is that we provide a default rule set, and let the users provide theirs if they know how to",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:41:34Z,"Not from Ctakes, that uses Finite State Machines to implement Negex. Instead, we adopted it from [here.](https://github.com/chapmanbe/negex) I can add a reference to this repo in our code?",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:43:29Z,"I was initially planning to do that. Something like this:

```
{
""negation_rules_path"": """",
""pre_negation_rules"": [],
""post_negation_rules"": []
}
```

We basically add all `pre_negation_rules` and `post_negaion_rules` to the rules picked from the sample rules file, which will be shipped with the repo. 
However, I thought I will add these improvements after this gets pushed.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:44:34Z,"Yes, I think we should ship it with the repo, as default set of rules for the processor. I think we should put this file to a different folder if that's the case, but not sure where. Maybe within /processors/ instead of /examples/mimic_iii/ ? ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:48:32Z,"boolean type was misbehaving for some reason. I will retry though, string didn't seem ideal to me either.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T18:05:10Z,"yes, let's acknowledge them",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T18:19:31Z,"So we need to make sure it gets automatically picked up when people download and use the code. So if it is part of the code, it needs should be picked up by `setup.py`, or it is a file URL, then you can consider downloading it somewhere.

It could be your decision on where it will be placed. ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T23:20:30Z,"> 1. I guess we want to lint the project with `mypy`, `pylint` and `black` to make it more standard before we merge this.
> 2. We will also need to set up test cases (and write test cases), like [here](https://github.com/asyml/forte/blob/master/.github/workflows/main.yml#L97).

Sure. I'll update the workflow with more linting tools.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T11:33:13Z,@hunterhector Still unable to add @tanyuqian as a reviewer. It says I can add **atmost** 1 reviewer.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T17:30:53Z,"> @hunterhector Still unable to add @tanyuqian as a reviewer. It says I can add **almost** 1 reviewer.

Add bowen in the future. I will get notified for the PRs anyway",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-04T05:00:53Z,"> 1. I guess we want to lint the project with `mypy`, `pylint` and `black` to make it more standard before we merge this.
> 2. We will also need to set up test cases (and write test cases), like [here](https://github.com/asyml/forte/blob/master/.github/workflows/main.yml#L97).

Pytest and documentation has been updated. 
@Piyush13y Could you write unit tests for the components you developed? ([mimic_reader](https://github.com/asyml/forte-medical/blob/master/tests/readers/mimic3_note_reader_test.py#L12) and this negation analyzer)",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-04T12:06:41Z,"@tanyuqian I had already added test cases for `NegationContextAnalyzer`, and now I have added a test case for Mimic3 reader as well. However, there seems to be something broken with respect to pytest in the workflow I think, which gives errors in the CI pipeline. I am able to run these tests successfully on my local machine.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-06T22:02:25Z,"> @tanyuqian I had already added test cases for `NegationContextAnalyzer`, and now I have added a test case for Mimic3 reader as well. However, there seems to be something broken with respect to pytest in the workflow I think, which gives errors in the CI pipeline. I am able to run these tests successfully on my local machine.

@Piyush13y Could you double-check it is working from your end? like re-install forte/forte-wrapper/forte-medical and re-run? I got the same error message as the workflow here https://github.com/asyml/forte-medical/runs/5435388860?check_suite_focus=true#step:13:23 
(```ImportError: cannot import name 'MedicalEntityMention' from 'ftx.medical' (/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/ftx/medical/__init__.py)```)",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-06T22:10:32Z,"@tanyuqian There were 2 issues raised in the CI pipeline initially, one was due to a stray test folder which, on deletion, fixed that problem.
The other one related to import statement is because [this](https://github.com/asyml/forte-wrappers/pull/96) Forte-wrapper's PR is yet to be merged, which completes the namespace consistency story. I have run these tests with that PR and it works fine. There's some other issue which is failing a test on that PR which has blocked its merge for now. @hunterhector mentioned someone will be working on that but might take some time. ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:05:09Z,"1. shouldn't use camel case for argument/variables `singlePack`.
2. It is indeed weird to use `True` as string, why not using bool?

",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:06:47Z,maybe use a text reader and load a sample file from disk?,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:07:04Z,no camel case,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:12:44Z,2022,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:35:25Z,The variable name `singlePack` is a bit weird since it is controlling the reader source.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:36:00Z,no camel case or we simply inline the configs here.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:37:46Z,shall we provide these negex triggers as part of the repo? ,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:39:49Z,"A question, did we adopt the code from Ctakes? If so, we probably want to make a reference here.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:40:58Z,I find that the processor also [expects `Sentence`](https://github.com/asyml/forte-medical/pull/7/files#diff-ca80a2b79a235631494ffd7a9f32b1291e606dc773cfe08e1a3176f6264d0d68R111).,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T22:41:39Z,"one thing we could do is that we provide a default rule set, and let the users provide theirs if they know how to",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:41:34Z,"Not from Ctakes, that uses Finite State Machines to implement Negex. Instead, we adopted it from [here.](https://github.com/chapmanbe/negex) I can add a reference to this repo in our code?",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:43:29Z,"I was initially planning to do that. Something like this:

```
{
""negation_rules_path"": """",
""pre_negation_rules"": [],
""post_negation_rules"": []
}
```

We basically add all `pre_negation_rules` and `post_negaion_rules` to the rules picked from the sample rules file, which will be shipped with the repo. 
However, I thought I will add these improvements after this gets pushed.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:44:34Z,"Yes, I think we should ship it with the repo, as default set of rules for the processor. I think we should put this file to a different folder if that's the case, but not sure where. Maybe within /processors/ instead of /examples/mimic_iii/ ? ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-01T05:48:32Z,"boolean type was misbehaving for some reason. I will retry though, string didn't seem ideal to me either.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T18:05:10Z,"yes, let's acknowledge them",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T18:19:31Z,"So we need to make sure it gets automatically picked up when people download and use the code. So if it is part of the code, it needs should be picked up by `setup.py`, or it is a file URL, then you can consider downloading it somewhere.

It could be your decision on where it will be placed. ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-28T23:20:30Z,"> 1. I guess we want to lint the project with `mypy`, `pylint` and `black` to make it more standard before we merge this.
> 2. We will also need to set up test cases (and write test cases), like [here](https://github.com/asyml/forte/blob/master/.github/workflows/main.yml#L97).

Sure. I'll update the workflow with more linting tools.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T11:33:13Z,@hunterhector Still unable to add @tanyuqian as a reviewer. It says I can add **atmost** 1 reviewer.,7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-02T17:30:53Z,"> @hunterhector Still unable to add @tanyuqian as a reviewer. It says I can add **almost** 1 reviewer.

Add bowen in the future. I will get notified for the PRs anyway",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-04T05:00:53Z,"> 1. I guess we want to lint the project with `mypy`, `pylint` and `black` to make it more standard before we merge this.
> 2. We will also need to set up test cases (and write test cases), like [here](https://github.com/asyml/forte/blob/master/.github/workflows/main.yml#L97).

Pytest and documentation has been updated. 
@Piyush13y Could you write unit tests for the components you developed? ([mimic_reader](https://github.com/asyml/forte-medical/blob/master/tests/readers/mimic3_note_reader_test.py#L12) and this negation analyzer)",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-04T12:06:41Z,"@tanyuqian I had already added test cases for `NegationContextAnalyzer`, and now I have added a test case for Mimic3 reader as well. However, there seems to be something broken with respect to pytest in the workflow I think, which gives errors in the CI pipeline. I am able to run these tests successfully on my local machine.",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-06T22:02:25Z,"> @tanyuqian I had already added test cases for `NegationContextAnalyzer`, and now I have added a test case for Mimic3 reader as well. However, there seems to be something broken with respect to pytest in the workflow I think, which gives errors in the CI pipeline. I am able to run these tests successfully on my local machine.

@Piyush13y Could you double-check it is working from your end? like re-install forte/forte-wrapper/forte-medical and re-run? I got the same error message as the workflow here https://github.com/asyml/forte-medical/runs/5435388860?check_suite_focus=true#step:13:23 
(```ImportError: cannot import name 'MedicalEntityMention' from 'ftx.medical' (/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/ftx/medical/__init__.py)```)",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-03-06T22:10:32Z,"@tanyuqian There were 2 issues raised in the CI pipeline initially, one was due to a stray test folder which, on deletion, fixed that problem.
The other one related to import statement is because [this](https://github.com/asyml/forte-wrappers/pull/96) Forte-wrapper's PR is yet to be merged, which completes the namespace consistency story. I have run these tests with that PR and it works fine. There's some other issue which is failing a test on that PR which has blocked its merge for now. @hunterhector mentioned someone will be working on that but might take some time. ",7
github.com/asyml/ForteHealth,examples/mimic_iii/medical_pipeline.py,2022-02-19T20:50:10Z,"Thanks for the fix. One thing missing is how the `setup.py` work (https://packaging.python.org/en/latest/guides/packaging-namespace-packages/#native-namespace-packages), we need to let it know that we use certain namespaces.

Btw, to enforce this convention and make everything consistent in the future, we probably should also adopt the same convention in Forte main repo (this should be an issue on Forte):

this includes several small steps:
1. update https://github.com/asyml/forte/blob/master/forte/ontology_specs/medical.json which in turn that package path, to make them not in the ""ftx"" package directly. Need to also update the usage of this (in the examples you try before, but we should search for the usage more carefully).
2. after generating the code, we remove the init file here: https://github.com/asyml/forte/tree/master/ftx 
3. update setup.py according to this: https://packaging.python.org/en/latest/guides/packaging-namespace-packages/#native-namespace-packages
    - `packages=find_namespace_packages(include=['ftx.*'])`

The reason is that namespace packaging requires us to use the same convention everywhere, otherwise weird things would happen during import.

",4
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-12-29T12:15:07Z,"we should have a check for self.configs.pipe_name == ""hyponym_detector"" too.
and through an error message if its not from the options in config.",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2023-01-12T21:35:29Z,"Shouldn't it be the other way around, like it was before these changes?",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2023-01-13T08:03:50Z,"general is hypernym and specific is hyponym
![image](https://user-images.githubusercontent.com/16308156/212269147-8dff8ad5-ed80-4072-a432-c09c08297c55.png)
",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2023-01-13T17:20:46Z,"That's fine, however, what I meant to say was ""Keystone plant species"" is the general concept while ""fig trees"" is the specific concept and not the other way around. You can refer https://pythonlang.dev/repo/allenai-scispacy/ to check the ordering on concepts in the returned tuple in Hearst patterns. item[1] should be the general concept and item[2] should be the specific concept, and we should label accordingly. Currently, we are doing the exact opposite I think. Let me know if I have misunderstood.",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-12-26T09:05:25Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/84?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#84](https://codecov.io/gh/asyml/ForteHealth/pull/84?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (c5765d5) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/3963a7b8e6c3ed23ee5123c65a9030e33ab1b7d4?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (3963a7b) will **decrease** coverage by `0.21%`.
> The diff coverage is `100.00%`.

```diff
@@            Coverage Diff             @@
##           master      #84      +/-   ##
==========================================
- Coverage   88.25%   88.05%   -0.21%     
==========================================
  Files          14       14              
  Lines         758      745      -13     
==========================================
- Hits          669      656      -13     
  Misses         89       89              
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/84?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/84?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.33% <100.00%> (-0.30%)` | :arrow_down: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2023-01-20T18:05:11Z,"I was wondering how the scispacy test case passed when you had swapped the general and specific concepts in the backend initially (with the 1st commit). Could you check that out, since if the tests are running properly, it should have failed when we swapped both the concepts, right?",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-12-29T12:15:07Z,"we should have a check for self.configs.pipe_name == ""hyponym_detector"" too.
and through an error message if its not from the options in config.",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2023-01-12T21:35:29Z,"Shouldn't it be the other way around, like it was before these changes?",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2023-01-13T08:03:50Z,"general is hypernym and specific is hyponym
![image](https://user-images.githubusercontent.com/16308156/212269147-8dff8ad5-ed80-4072-a432-c09c08297c55.png)
",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2023-01-13T17:20:46Z,"That's fine, however, what I meant to say was ""Keystone plant species"" is the general concept while ""fig trees"" is the specific concept and not the other way around. You can refer https://pythonlang.dev/repo/allenai-scispacy/ to check the ordering on concepts in the returned tuple in Hearst patterns. item[1] should be the general concept and item[2] should be the specific concept, and we should label accordingly. Currently, we are doing the exact opposite I think. Let me know if I have misunderstood.",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-12-26T09:05:25Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/84?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#84](https://codecov.io/gh/asyml/ForteHealth/pull/84?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (c5765d5) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/3963a7b8e6c3ed23ee5123c65a9030e33ab1b7d4?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (3963a7b) will **decrease** coverage by `0.21%`.
> The diff coverage is `100.00%`.

```diff
@@            Coverage Diff             @@
##           master      #84      +/-   ##
==========================================
- Coverage   88.25%   88.05%   -0.21%     
==========================================
  Files          14       14              
  Lines         758      745      -13     
==========================================
- Hits          669      656      -13     
  Misses         89       89              
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/84?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/84?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.33% <100.00%> (-0.30%)` | :arrow_down: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2023-01-20T18:05:11Z,"I was wondering how the scispacy test case passed when you had swapped the general and specific concepts in the backend initially (with the 1st commit). Could you check that out, since if the tests are running properly, it should have failed when we swapped both the concepts, right?",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-12-29T12:15:07Z,"we should have a check for self.configs.pipe_name == ""hyponym_detector"" too.
and through an error message if its not from the options in config.",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2023-01-12T21:35:29Z,"Shouldn't it be the other way around, like it was before these changes?",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2023-01-13T08:03:50Z,"general is hypernym and specific is hyponym
![image](https://user-images.githubusercontent.com/16308156/212269147-8dff8ad5-ed80-4072-a432-c09c08297c55.png)
",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2023-01-13T17:20:46Z,"That's fine, however, what I meant to say was ""Keystone plant species"" is the general concept while ""fig trees"" is the specific concept and not the other way around. You can refer https://pythonlang.dev/repo/allenai-scispacy/ to check the ordering on concepts in the returned tuple in Hearst patterns. item[1] should be the general concept and item[2] should be the specific concept, and we should label accordingly. Currently, we are doing the exact opposite I think. Let me know if I have misunderstood.",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-12-26T09:05:25Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/84?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#84](https://codecov.io/gh/asyml/ForteHealth/pull/84?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (c5765d5) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/3963a7b8e6c3ed23ee5123c65a9030e33ab1b7d4?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (3963a7b) will **decrease** coverage by `0.21%`.
> The diff coverage is `100.00%`.

```diff
@@            Coverage Diff             @@
##           master      #84      +/-   ##
==========================================
- Coverage   88.25%   88.05%   -0.21%     
==========================================
  Files          14       14              
  Lines         758      745      -13     
==========================================
- Hits          669      656      -13     
  Misses         89       89              
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/84?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/84?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.33% <100.00%> (-0.30%)` | :arrow_down: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2023-01-20T18:05:11Z,"I was wondering how the scispacy test case passed when you had swapped the general and specific concepts in the backend initially (with the 1st commit). Could you check that out, since if the tests are running properly, it should have failed when we swapped both the concepts, right?",84
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-12-05T11:39:54Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/77?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#77](https://codecov.io/gh/asyml/ForteHealth/pull/77?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (d40e783) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/5ba59890ce72c826c3c7e4930da4f20f2d53d0e1?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (5ba5989) will **increase** coverage by `0.01%`.
> The diff coverage is `100.00%`.

```diff
@@            Coverage Diff             @@
##           master      #77      +/-   ##
==========================================
+ Coverage   88.24%   88.25%   +0.01%     
==========================================
  Files          14       14              
  Lines         757      758       +1     
==========================================
+ Hits          668      669       +1     
  Misses         89       89              
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/77?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/77/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.63% <ø> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/77/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",77
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-12-05T11:39:54Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/77?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#77](https://codecov.io/gh/asyml/ForteHealth/pull/77?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (d40e783) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/5ba59890ce72c826c3c7e4930da4f20f2d53d0e1?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (5ba5989) will **increase** coverage by `0.01%`.
> The diff coverage is `100.00%`.

```diff
@@            Coverage Diff             @@
##           master      #77      +/-   ##
==========================================
+ Coverage   88.24%   88.25%   +0.01%     
==========================================
  Files          14       14              
  Lines         757      758       +1     
==========================================
+ Hits          668      669       +1     
  Misses         89       89              
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/77?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/77/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.63% <ø> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/77/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",77
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-11-27T06:40:15Z,"For consistency 
```suggestion
            self.assertEqual(detected.hyponym_link, expected_value[""hyponym_link""])
```",75
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-11-27T06:45:21Z,"Just a minor suggestion, upto if you want to make that change. I think we can skip these parenthesis (here and in the return statement), since it just complicates the readability in this case, and doesn't add to functionality. 
Also, maybe we can do the index finding more elegantly. Since, in a scenario with multiple hyponyms for a bigger text chunk, we traverse the whole text chunk for each detected hyponym, which may not be performant. We can do that in the next iteration/PR too. ",75
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-11-28T10:08:55Z,this is done by black actually,75
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-11-24T12:15:58Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/75?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#75](https://codecov.io/gh/asyml/ForteHealth/pull/75?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (f911bd1) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/c787ed64424cb22d0a33b0df44e5e9471604e5c0?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (c787ed6) will **increase** coverage by `0.28%`.
> The diff coverage is `100.00%`.

```diff
@@            Coverage Diff             @@
##           master      #75      +/-   ##
==========================================
+ Coverage   87.95%   88.24%   +0.28%     
==========================================
  Files          14       14              
  Lines         739      757      +18     
==========================================
+ Hits          650      668      +18     
  Misses         89       89              
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/75?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/75/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.63% <100.00%> (+0.38%)` | :arrow_up: |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/75/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",75
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-11-27T06:40:15Z,"For consistency 
```suggestion
            self.assertEqual(detected.hyponym_link, expected_value[""hyponym_link""])
```",75
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-11-27T06:45:21Z,"Just a minor suggestion, upto if you want to make that change. I think we can skip these parenthesis (here and in the return statement), since it just complicates the readability in this case, and doesn't add to functionality. 
Also, maybe we can do the index finding more elegantly. Since, in a scenario with multiple hyponyms for a bigger text chunk, we traverse the whole text chunk for each detected hyponym, which may not be performant. We can do that in the next iteration/PR too. ",75
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-11-28T10:08:55Z,this is done by black actually,75
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-11-24T12:15:58Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/75?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#75](https://codecov.io/gh/asyml/ForteHealth/pull/75?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (f911bd1) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/c787ed64424cb22d0a33b0df44e5e9471604e5c0?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (c787ed6) will **increase** coverage by `0.28%`.
> The diff coverage is `100.00%`.

```diff
@@            Coverage Diff             @@
##           master      #75      +/-   ##
==========================================
+ Coverage   87.95%   88.24%   +0.28%     
==========================================
  Files          14       14              
  Lines         739      757      +18     
==========================================
+ Hits          650      668      +18     
  Misses         89       89              
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/75?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/75/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.63% <100.00%> (+0.38%)` | :arrow_up: |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/75/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",75
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-11-27T06:40:15Z,"For consistency 
```suggestion
            self.assertEqual(detected.hyponym_link, expected_value[""hyponym_link""])
```",75
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-11-27T06:45:21Z,"Just a minor suggestion, upto if you want to make that change. I think we can skip these parenthesis (here and in the return statement), since it just complicates the readability in this case, and doesn't add to functionality. 
Also, maybe we can do the index finding more elegantly. Since, in a scenario with multiple hyponyms for a bigger text chunk, we traverse the whole text chunk for each detected hyponym, which may not be performant. We can do that in the next iteration/PR too. ",75
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-11-28T10:08:55Z,this is done by black actually,75
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-11-24T12:15:58Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/75?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#75](https://codecov.io/gh/asyml/ForteHealth/pull/75?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (f911bd1) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/c787ed64424cb22d0a33b0df44e5e9471604e5c0?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (c787ed6) will **increase** coverage by `0.28%`.
> The diff coverage is `100.00%`.

```diff
@@            Coverage Diff             @@
##           master      #75      +/-   ##
==========================================
+ Coverage   87.95%   88.24%   +0.28%     
==========================================
  Files          14       14              
  Lines         739      757      +18     
==========================================
+ Hits          650      668      +18     
  Misses         89       89              
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/75?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/75/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.63% <100.00%> (+0.38%)` | :arrow_up: |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/75/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",75
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:25:01Z,"I don't think the class variables (ParentType, ChildType) need to be added here. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:27:41Z,"`SciSpacy` is also wrapped here: https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L405, can we have the implementation in one place not two?",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:30:34Z,"This `set_up` is a bit hard-coded to me. Can we do 

````
{
   spacy_pipe_config: {
       {
            ""pipe_name"": ""abbreviation_detector"",
            ""pipe_configs"": {
                  // Based on the content here, decide what pipeline to run.
             }
       }  
   }
}
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:18Z,icd?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:31:27Z,the key definitions are all wrong,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:18Z,"expected type is not `ft.onto.base_ontology.Document`, but should be `self.configs.entry_type`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:32:44Z,where did we expect any `Annotation`?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:33:58Z,"name is wrong, `Hyponym`.

We also have `Phrase`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T19:34:32Z,Is this a manual change of ontology class? We should avoid this and change through json config.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:28:50Z,Fixed this comment issue caused by copy-paste. Changed to SciSpacyProcessor related comments.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:29:28Z,The ParentType and ChildType is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-05T00:33:57Z,No this is restored to the current version checked into master to be able to compile correctly so the change to Phrase is correct and will merge with no problem (now after changed a comment line 2 it is identical with master) ,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:23:14Z,The key definitions in comments is fixed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:24:41Z,This line is now removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T12:49:40Z,Ok changed to upper case. Also added Phrase (parent and child),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:01:01Z,"Ok this line is changed to : self.configs.entry_type: set(),   instead",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T13:09:46Z,"Previously we did have a less-hard-coded version of this trying with coding with Dynamic configurations but unfortunately it does not work as the ""self.extractor.add_pipe"" require 2 distinctively different  hard-coded form for sciSpacy, and can not be united in one form (will creates all kinds of weird problems elsewhere) so this although not ideal looking, it is the best/most robust way to implement . ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T14:29:21Z,Suggest turning this into a new bug/new feature as this will be more complicated to implement and need more considerations other than the original bug/requirements.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:46:11Z,These should be done in the processor: the `initialize` method. Or these two lines are probably not used.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:49:54Z,Consider used utilities [here](https://github.com/asyml/forte/blob/master/forte/utils/utils.py#L80),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:50:24Z,We should remove `print` statement in the final PR.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:52:11Z,We should write the possible options here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:16Z,We didn't use the attribute name `classification` in `process` (this should be removed),36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T15:54:39Z,"This should be removed, we don't have anything related to `mutli_class`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-12T17:39:00Z,"This is also not used in the system, maybe you can follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235) for GPU setups.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T10:57:31Z,Ok these 2 lines are now merged to initialized methods and removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:25:59Z,"Unfortunately substitute line 77 and 78 to using ""get_class"" in forte utils like the following: 
        path_str, module_str = self.configs.entry_type.rsplit(""."", 1)
        # mod = importlib.import_module(path_str)
        # entry = getattr(mod, module_str)
        entry = get_class(class_name=module_str, module_paths=path_str)
Failed,  error message is:
  File ""/Users/../fortex/health/processors/scispacy_processor.py"", line 79, in _process
    entry = get_class(class_name=module_str, module_paths=path_str)
  File ""/Users/.../Documents/GitHub/forte-medical/venv/lib/python3.6/site-packages/forte/utils/utils.py"", line 107, in get_class
    ""Class not found in {}: {}"".format(module_paths, class_name)
ValueError: Class not found in ft.onto.base_ontology: Document

While using the original code of importlib.import_module can load successfully, so currently keeping the old code until late this get fixed somewhere about get_class",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:28:43Z,print removed,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:34:39Z,"added the 2 options for pipe_name. model_name is more complicated and out of scope for this current one so can not list in detail, just default to en_core_sci_sm ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:35:35Z,ok removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:36:20Z,ok this line also removed.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:39:53Z,removed and tested ok.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T11:42:31Z,The 2 lines are merged into initialize method and removed here.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:52:05Z,What's the reason of `model_name` being to complicated? If we support models from scispacy we can add URL to their documentation,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:53:25Z,"gpu is not enabled now, can we follow [here](https://github.com/asyml/forte-wrappers/blob/main/src/spacy/fortex/spacy/spacy_processors.py#L235)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:54:58Z,"documentation too brief and incorrect. 
1. Please make it clear for users are not familiar with our jargons. What is an entry? 
2. The purpose of this processor is also not `classification`.
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-13T16:56:21Z,"The following lines are problematic, we don't even have `self.configs.attribute_name`",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:12:36Z,Yes URL hyper link to available model names are now added accordingly in the new commit,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:13:10Z,Yes added the 3 parameters for gpu in the new code.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-19T13:14:02Z,Corrected to let user to use the document type in the new comment.,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-07-28T16:57:51Z,"Ok this is now fixed (after referencing to style/example of negation_context_analyzer) and also ""Phrase"" is added as suggested.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-19T19:05:58Z,"we can't just test one or two test cases, let's use a matrix strategy to test different processors separately.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:10Z,we should remove these unused comments,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:35:59Z,"don't disable this, remove the unused-import",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T16:39:29Z,"the content of the record should depend on the config, when the pipeline is `abbreviation_detector` we have `Abbreviation`, otherwise we have the other two types.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:08Z,"We can add an elif instead of else, so we don't enter this condition incorrectlly in case of typos and future pipe_names. Also, lets add comments on new lines instead of just appending to code on the same line, just for better readability. ",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:45:52Z,"If its an unused comment, we can remove it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:01Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:11Z,Unused comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-24T22:50:28Z,Stray comment,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-25T08:37:18Z,"I found out that, James actually used this because ""HyponymDetector"" and ""AbbreviationDetector"" are used by pipelines in test otherwise same error as earlier. 

```
config = {
            ""entry_type"": ""ft.onto.base_ontology.Document"",
            ""model_name"": ""en_core_sci_sm"",
            ""pipe_name"": ""abbreviation_detector"",
        }
```",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-01T07:58:16Z,@J007X Did you discuss about this with Hector ?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T14:26:35Z,"I believe these dependencies are needed when using the newly created processor. So we shouldn't name this `test_scispacy`. In addition, we should have some documentation (such as in Readme.md), to talk about how to setup the environment for certain processors if you want to use it.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-14T04:36:04Z,"Please remove all comments and extra import statements (if any). Also, add the child and parent attributes to the `hyponym` object, you can keep the PR as draft until its ready for review. Let me know once its ready:)",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-06-29T04:59:03Z,"There are still some extra comments in the code, make sure you remove those. Also, the build is still failing.",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-08-18T08:54:18Z,"# [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#36](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (97d0725) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/867b854391973b9cf1c1a1fe67fbfb8ff8566059?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (867b854) will **increase** coverage by `1.63%`.
> The diff coverage is `98.91%`.

```diff
@@            Coverage Diff             @@
##           master      #36      +/-   ##
==========================================
+ Coverage   84.17%   85.81%   +1.63%     
==========================================
  Files           9       10       +1     
  Lines         512      726     +214     
==========================================
+ Hits          431      623     +192     
- Misses         81      103      +22     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/36?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [fortex/health/processors/scispacy\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvci5weQ==) | `98.24% <98.24%> (ø)` | |
| [...ortex/health/processors/scispacy\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3NjaXNwYWN5X3Byb2Nlc3Nvcl90ZXN0LnB5) | `100.00% <100.00%> (ø)` | |
| [ftx/medical/clinical\_ontology.py](https://codecov.io/gh/asyml/ForteHealth/pull/36/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-ZnR4L21lZGljYWwvY2xpbmljYWxfb250b2xvZ3kucHk=) | `73.21% <0.00%> (+5.23%)` | :arrow_up: |

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-08T09:31:12Z,@hunterhector can you review this pull request?,36
github.com/asyml/ForteHealth,fortex/health/processors/scispacy_processor.py,2022-09-09T01:45:58Z,"> @Piyush13y any more suggestions from you

I had added a few comments a couple weeks back, other than that I feel the setup file could be a little more polished but I think you have already added a comment pertaining to that. ",36
github.com/asyml/ForteHealth,fortex/health/processors/temporal_mention_normalizing_processor.py,2023-03-02T08:50:45Z,Format issue,91
github.com/asyml/ForteHealth,fortex/health/processors/temporal_mention_normalizing_processor.py,2023-03-02T08:51:21Z,"This just adds 2 tests for the processor, while I see 3 different test files for this processor. Are we missing on here?",91
github.com/asyml/ForteHealth,fortex/health/processors/temporal_mention_normalizing_processor.py,2023-03-02T08:53:55Z,"Should be ""Tagging and Normalising Processor""* ?",91
github.com/asyml/ForteHealth,fortex/health/processors/temporal_mention_normalizing_processor.py,2023-03-02T08:57:15Z,"Minor suggestion: The entry type is a document and we are processing a list of sentences here, we can maybe make it consistent like the other test cases for this processor by joining the sentences. ",91
github.com/asyml/ForteHealth,fortex/health/processors/temporal_mention_normalizing_processor.py,2023-03-08T09:37:08Z,"this follow the same format as scispacy and forte-wrapper, I have fixed xray_image_processor format",91
github.com/asyml/ForteHealth,fortex/health/processors/temporal_mention_normalizing_processor.py,2023-03-08T09:40:26Z,Done,91
github.com/asyml/ForteHealth,fortex/health/processors/temporal_mention_normalizing_processor.py,2023-03-08T09:40:44Z,Updated with more description as it is using two processors,91
github.com/asyml/ForteHealth,fortex/health/processors/temporal_mention_normalizing_processor.py,2023-03-08T11:34:46Z,Done,91
github.com/asyml/ForteHealth,fortex/health/processors/temporal_mention_normalizing_processor.py,2023-02-21T11:13:50Z,"## [Codecov](https://codecov.io/gh/asyml/ForteHealth/pull/91?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) Report
> Merging [#91](https://codecov.io/gh/asyml/ForteHealth/pull/91?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (b3b82a7) into [master](https://codecov.io/gh/asyml/ForteHealth/commit/a0615315c1186d51be8118f3846d37f988465716?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) (a061531) will **increase** coverage by `2.42%`.
> The diff coverage is `98.19%`.

```diff
@@            Coverage Diff             @@
##           master      #91      +/-   ##
==========================================
+ Coverage   87.85%   90.27%   +2.42%     
==========================================
  Files          14       19       +5     
  Lines         749      915     +166     
==========================================
+ Hits          658      826     +168     
+ Misses         91       89       -2     
```


| [Impacted Files](https://codecov.io/gh/asyml/ForteHealth/pull/91?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml) | Coverage Δ | |
|---|---|---|
| [...h/processors/temporal\_mention\_tagging\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/91?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3RlbXBvcmFsX21lbnRpb25fdGFnZ2luZ19wcm9jZXNzb3IucHk=) | `95.45% <95.45%> (ø)` | |
| [...ocessors/temporal\_mention\_normalizing\_processor.py](https://codecov.io/gh/asyml/ForteHealth/pull/91?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-Zm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3RlbXBvcmFsX21lbnRpb25fbm9ybWFsaXppbmdfcHJvY2Vzc29yLnB5) | `97.95% <97.95%> (ø)` | |
| [...ors/temporal\_mention\_normalizing\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/91?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3RlbXBvcmFsX21lbnRpb25fbm9ybWFsaXppbmdfcHJvY2Vzc29yX3Rlc3QucHk=) | `100.00% <100.00%> (ø)` | |
| [...alth/processors/temporal\_mention\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/91?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3RlbXBvcmFsX21lbnRpb25fcHJvY2Vzc29yX3Rlc3QucHk=) | `100.00% <100.00%> (ø)` | |
| [...cessors/temporal\_mention\_tagging\_processor\_test.py](https://codecov.io/gh/asyml/ForteHealth/pull/91?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml#diff-dGVzdHMvZm9ydGV4L2hlYWx0aC9wcm9jZXNzb3JzL3RlbXBvcmFsX21lbnRpb25fdGFnZ2luZ19wcm9jZXNzb3JfdGVzdC5weQ==) | `100.00% <100.00%> (ø)` | |

... and [1 file with indirect coverage changes](https://codecov.io/gh/asyml/ForteHealth/pull/91/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)

:mega: We’re building smart automated test selection to slash your CI/CD build times. [Learn more](https://about.codecov.io/iterative-testing/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=asyml)
",91
github.com/wkvong/multimodal-baby,multimodal/multimodal_lit.py,2022-01-11T21:20:05Z,add drop_last for validation data loader too (for contrastive part only),6
github.com/wkvong/multimodal-baby,multimodal/multimodal_lit.py,2022-01-11T21:20:05Z,add drop_last for validation data loader too (for contrastive part only),6
github.com/wkvong/multimodal-baby,multimodal/multimodal_lit.py,2022-01-11T21:20:05Z,add drop_last for validation data loader too (for contrastive part only),6
github.com/wkvong/multimodal-baby,multimodal/multimodal_lit.py,2022-01-11T21:20:05Z,add drop_last for validation data loader too (for contrastive part only),6
github.com/wkvong/multimodal-baby,multimodal/multimodal_lit.py,2022-01-11T21:20:05Z,add drop_last for validation data loader too (for contrastive part only),6
github.com/wkvong/multimodal-baby,multimodal/multimodal_lit.py,2022-01-11T21:20:05Z,add drop_last for validation data loader too (for contrastive part only),6
github.com/wkvong/multimodal-baby,multimodal/multimodal_lit.py,2022-01-11T21:20:05Z,add drop_last for validation data loader too (for contrastive part only),6
github.com/wkvong/multimodal-baby,multimodal/multimodal_lit.py,2022-01-11T21:20:05Z,add drop_last for validation data loader too (for contrastive part only),6
github.com/wkvong/multimodal-baby,multimodal/multimodal_lit.py,2022-01-11T21:20:05Z,add drop_last for validation data loader too (for contrastive part only),6
github.com/wkvong/multimodal-baby,multimodal/multimodal_lit.py,2022-01-11T21:20:05Z,add drop_last for validation data loader too (for contrastive part only),6
github.com/wkvong/multimodal-baby,multimodal/multimodal_lit.py,2022-01-11T21:20:05Z,add drop_last for validation data loader too (for contrastive part only),6
github.com/wkvong/multimodal-baby,multimodal/multimodal_lit.py,2022-01-11T21:20:05Z,add drop_last for validation data loader too (for contrastive part only),6
github.com/wkvong/multimodal-baby,multimodal/multimodal_lit.py,2022-01-11T21:20:05Z,add drop_last for validation data loader too (for contrastive part only),6
github.com/wkvong/multimodal-baby,multimodal/multimodal_lit.py,2022-01-11T21:20:05Z,add drop_last for validation data loader too (for contrastive part only),6
github.com/wkvong/multimodal-baby,multimodal/multimodal_lit.py,2022-01-11T21:20:05Z,add drop_last for validation data loader too (for contrastive part only),6
github.com/wkvong/multimodal-baby,multimodal/multimodal_lit.py,2022-01-11T21:20:05Z,add drop_last for validation data loader too (for contrastive part only),6
github.com/wkvong/multimodal-baby,multimodal/multimodal_saycam_data_module.py,2022-01-11T21:20:05Z,add drop_last for validation data loader too (for contrastive part only),6
github.com/writerai/replaCy,replacy/scorer.py,2021-05-04T16:52:12Z,"Based on this comment it seems like we shouldn't actually write this fix :sob: https://github.com/explosion/spaCy/issues/7972#issuecomment-831072036

If they think the behavior is a bug, they will revert it, which means the ""fix"" is DO NOT USE spaCy 2.3.5",91
github.com/writerai/replaCy,replacy/scorer.py,2021-05-04T17:16:53Z,"Ok, I retract my previous comment. It seems like all the changes we made are reasonable bounds-checking and that this PR is an improvement regardless of spaCy behavior",91
github.com/writerai/replaCy,replacy/scorer.py,2020-09-21T23:42:38Z,"""times before the spellcheck in vscode"" :grimacing: ",81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-21T23:43:08Z,what does it do? :thinking: ,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-21T23:48:14Z,oh! :exploding_head: ,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-21T23:50:39Z,:heart: ,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-21T23:51:09Z,and return a list of spans (after recent changes),81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T00:07:20Z,liked the previous lines more :( ,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T00:07:45Z,:chefkiss:,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T00:09:02Z,:exploding_head: ,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T00:09:42Z,oh glad it is moved here!,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T00:11:44Z,"I wonder ... we allow replacy to use any nlp, but we require en_core_web_sm in tests? :grimacing: 
It is ok?",81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T00:12:04Z,:grimacing: ,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T18:48:38Z,"my editor complained, and I thought... yeah, you are right editor, inflector is not defined!",81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T18:49:45Z,I moved it out into `utils` but some projects using replacy call it via `ReplaceMatcher.validate_match_dict` so I wanted to attach it to the class here (which makes it a static method),81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T18:51:34Z,"this wasn't a bug, it was just, I wanted to make the components have inputs and outputs, instead of using class properties",81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T18:52:07Z,We should add tests with other languages!,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T18:52:20Z,gotta have my dumb IDs,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-21T23:34:20Z,"@melisa-qordoba Here is how this would be used for #80 

https://github.com/Qordobacode/replaCy/issues/80#issuecomment-696434960",81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T18:52:47Z,I installed this version of replaCy in a downstream project (Clarity) and the test suite still passes 💪 ,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-21T23:42:38Z,"""times before the spellcheck in vscode"" :grimacing: ",81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-21T23:43:08Z,what does it do? :thinking: ,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-21T23:48:14Z,oh! :exploding_head: ,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-21T23:50:39Z,:heart: ,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-21T23:51:09Z,and return a list of spans (after recent changes),81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T00:07:20Z,liked the previous lines more :( ,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T00:07:45Z,:chefkiss:,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T00:09:02Z,:exploding_head: ,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T00:09:42Z,oh glad it is moved here!,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T00:11:44Z,"I wonder ... we allow replacy to use any nlp, but we require en_core_web_sm in tests? :grimacing: 
It is ok?",81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T00:12:04Z,:grimacing: ,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T18:48:38Z,"my editor complained, and I thought... yeah, you are right editor, inflector is not defined!",81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T18:49:45Z,I moved it out into `utils` but some projects using replacy call it via `ReplaceMatcher.validate_match_dict` so I wanted to attach it to the class here (which makes it a static method),81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T18:51:34Z,"this wasn't a bug, it was just, I wanted to make the components have inputs and outputs, instead of using class properties",81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T18:52:07Z,We should add tests with other languages!,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T18:52:20Z,gotta have my dumb IDs,81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-21T23:34:20Z,"@melisa-qordoba Here is how this would be used for #80 

https://github.com/Qordobacode/replaCy/issues/80#issuecomment-696434960",81
github.com/writerai/replaCy,replacy/scorer.py,2020-09-22T18:52:47Z,I installed this version of replaCy in a downstream project (Clarity) and the test suite still passes 💪 ,81
github.com/writerai/replaCy,replacy/scorer.py,2020-06-26T15:54:13Z,"can we put this import in `get_default_lm`? If they don't want to use the LM, we shouldn't die if it isn't installed",63
github.com/writerai/replaCy,replacy/scorer.py,2020-06-26T17:14:03Z,"These 2 parameters are so we can build the LM stuff,
```python
self.scorer = KenLMScorer(nlp=self.nlp, model=get_default_lm(testing=testing)) if use_lm else None
```

Now that I see that, it seems like directly passing in a `scorer` is cleaner (""Dependency Injection"")",63
github.com/writerai/replaCy,replacy/scorer.py,2020-06-26T17:16:20Z,"that is outdated, but same idea: can we put this in `load_lm` ?",63
github.com/writerai/replaCy,replacy/scorer.py,2020-06-29T12:36:49Z,done :ok_hand: ,63
github.com/writerai/replaCy,replacy/scorer.py,2020-06-29T12:37:30Z,Yes! Bonus: using lm is optional now.,63
github.com/writerai/replaCy,replacy/scorer.py,2020-06-29T17:31:07Z,:yay:,63
github.com/writerai/replaCy,replacy/scorer.py,2020-06-29T17:31:21Z,more :yay:,63
github.com/writerai/replaCy,replacy/scorer.py,2020-06-29T17:32:00Z,"```suggestion
Speed and accuracy benchmark (copied from the Lemminflect repo):
```",63
github.com/writerai/replaCy,replacy/scorer.py,2020-06-29T17:32:31Z,even more :yay:!,63
github.com/writerai/replaCy,replacy/scorer.py,2020-06-29T22:43:08Z,"Sorry, I don't really know if my code samples are right, since I don't know the type signatures

`self.scorer` is `None` if there is no `KenLM`... Should we have the line that sets it be :

```python
self.scorer = (
            KenLMScorer(nlp=self.nlp, model=load_lm(lm_path)) if lm_path else lambda x: 1
        )
```

e.g. set it to the constant function?

Or, if there is more than 1 suggestion, maybe `sort_suggestions` should have behavior that depends on `self.scorer`... meaning ""if it's None, either don't change the order, or randomize it""",63
github.com/writerai/replaCy,replacy/scorer.py,2020-06-30T07:56:03Z,"Can you reproduce the bug?

Sorting and scoring happens only if there is the scorer, otherwise this step is completely skipped:
https://github.com/Qordobacode/replaCy/blob/c6eb41fba0b430c95b1feee5261807df716b3151/replacy/__init__.py#L392

I think I disagree with randomizing suggestions since this doesn't look like a desired behavior before adding `kenlm` - what if users want to manually set the order of suggestions (because they feel some options will be better)?",63
github.com/writerai/replaCy,replacy/scorer.py,2020-06-30T08:00:22Z,Take a look at `tests/test_suggestions.py`. This is the case when there is no `lm_path`.,63
github.com/writerai/replaCy,replacy/scorer.py,2020-06-30T16:07:46Z,I see,63
github.com/writerai/replaCy,replacy/scorer.py,2020-06-26T22:36:51Z,"I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)
",63
github.com/writerai/replaCy,replacy/scorer.py,2020-06-29T12:39:03Z,"> I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
> ![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)

Changed :ok_hand: 
Also did one update (after rethinking json schema). Backward compatible.

`INFLECTION` is always a string. You can set `POS`, `TAG` or `ALL`. ",63
github.com/writerai/replaCy,replacy/__init__.py,2021-11-30T16:07:18Z,why do we want this?,117
github.com/writerai/replaCy,replacy/__init__.py,2021-11-30T19:38:34Z,"ok from the ticket I guess the way things currently are set, we don't need to filter spans, because we already filter by longest. So making this change means that from now on, filtering needs to be done in the pipeline? ",117
github.com/writerai/replaCy,replacy/__init__.py,2021-12-05T06:55:37Z,"@sam-writer Yes
merging this code means: filtering will be on each service when needed through pipeline ",117
github.com/writerai/replaCy,replacy/__init__.py,2021-05-18T22:06:18Z,"these just don't need to be here

```python
>>> from replacy.db import load_json
>>> import spacy
>>> nlp = spacy.load(""en_core_web_sm"")
>>> match_dict = load_json('./replacy/resources/match_dict.json')
>>> ematcher = ReplaceMatcher.with_espan(nlp, match_dict=match_dict)
>>> spans = ematcher(""I'll have to make due."")
>>> spans[0].comment
'This is a bad match, it is here to demonstrate overlap behavior'
```",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-18T21:59:54Z,"Added a factory method so you don't have to import ESpan, not sure which I like more:

```python
from replacy import ReplaceMatcher
from replacy.db import load_json
import spacy
nlp = spacy.load(""en_core_web_sm"")
match_dict = load_json('./replacy/resources/match_dict.json')
ematcher = ReplaceMatcher.with_espan(nlp, match_dict=match_dict)
s = ematcher(""She extracts revenge."")[0]
```

thoughts?",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-19T05:02:24Z,"The match dict in your test doesn't represent the overlap problem we are trying to solve, this one does:
STILL WORKS with this one
```
{
    ""make-1"": {
        ""patterns"": [
            {
                ""LEMMA"": ""make""
            }
        ],
        ""suggestions"": [
            [
                {
                    ""TEXT"": ""MAKE""
                }
            ]
        ],
        ""subcategory"": ""MAKE_CAPS""
    },
    ""make-2"": {
        ""patterns"": [
            {
                ""LEMMA"": ""make""
            }
        ],
        ""suggestions"": [
            [
                {
                    ""TEXT"": ""MaKe""
                }
            ]
        ],
        ""subcategory"": ""MAKE_STYLE"",
        ""comment"": ""This is a bad match, it is here to demonstrate overlap behavior"",
    }
}
```


> Tested this in the REPL:
> 
> ```python
> >>> from replacy import ESpan
> >>> from replacy import ReplaceMatcher
> >>> from replacy.db import load_json
> >>> import spacy
> >>> nlp = spacy.load(""en_core_web_sm"")
> >>> match_dict = load_json('./replacy/resources/match_dict.json')
> >>> ematcher = ReplaceMatcher(nlp, match_dict=match_dict, SpanClass=ESpan)
> >>> s = ematcher(""She extracts revenge."")[0]
> >>> s
> extracts
> >>> s.suggestions
> ['exacts']
> >>> s.match_name
> 'extract-revenge'
> >>> doc = nlp(""She extracts revenge."")
> >>> e = ESpan(doc, 1, 2)
> >>> e
> extracts
> >>> e.suggestions
> []
> >>> e.match_name
> ''
> >>> e.comment
> ''
> >>> e.vector
> array([ 3.7579389 , 390608 ,  ... , 0.37205344], dtype=float32)
> >>> e.kb_id
> 0
> >>> e.vector_norm
> 25.310467
> >>> e._.comment = ""yo metaprogramming""
> >>> e.comment
> 'yo metaprogramming'
> >>> e == e._
> True
> ```
> 
> I added the following to the match_dict to check for overlap behavior
> 
> ```json
> {
>   ""make-due"": {
>     ""patterns"": [
>       {
>         ""LEMMA"": ""make"",
>         ""TEMPLATE_ID"": 1
>       },
>       {
>         ""LOWER"": ""due""
>       }
>     ],
>     ""suggestions"": [
>       [
>         {
>           ""TEXT"": ""make"",
>           ""FROM_TEMPLATE_ID"": 1
>         },
>         {
>           ""TEXT"": ""do""
>         }
>       ]
>     ]
>   },
>   ""dupe-test"": {
>     ""patterns"": [
>       {
>         ""LEMMA"": ""make"",
>         ""TEMPLATE_ID"": 1
>       }
>     ],
>     ""suggestions"": [
>       [
>         {
>           ""TEXT"": ""build"",
>           ""FROM_TEMPLATE_ID"": 1
>         }
>       ]
>     ],
>     ""comment"": ""This is a bad match, it is here to demonstrate overlap behavior"",
>     ""test"": {
>       ""positive"": [""I will make something""],
>       ""negative"": []
>     }
>   }
> ```
> 
> this gives
> 
> ```python
> >>> spans = ematcher(""I will make due"")
> >>> spans
> [make, make due]
> >>> spans[0].match_name
> 'dupe-test'
> >>> spans[1].match_name
> 'make-due'
> >>> spans[1].suggestions
> ['make do']
> >>> spans[0].suggestions
> ['build']
> ```
",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-19T05:32:26Z,"@sam-qordoba all good, just one change: added `has_extension` implementation",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-18T22:06:18Z,"these just don't need to be here

```python
>>> from replacy.db import load_json
>>> import spacy
>>> nlp = spacy.load(""en_core_web_sm"")
>>> match_dict = load_json('./replacy/resources/match_dict.json')
>>> ematcher = ReplaceMatcher.with_espan(nlp, match_dict=match_dict)
>>> spans = ematcher(""I'll have to make due."")
>>> spans[0].comment
'This is a bad match, it is here to demonstrate overlap behavior'
```",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-18T21:59:54Z,"Added a factory method so you don't have to import ESpan, not sure which I like more:

```python
from replacy import ReplaceMatcher
from replacy.db import load_json
import spacy
nlp = spacy.load(""en_core_web_sm"")
match_dict = load_json('./replacy/resources/match_dict.json')
ematcher = ReplaceMatcher.with_espan(nlp, match_dict=match_dict)
s = ematcher(""She extracts revenge."")[0]
```

thoughts?",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-19T05:02:24Z,"The match dict in your test doesn't represent the overlap problem we are trying to solve, this one does:
STILL WORKS with this one
```
{
    ""make-1"": {
        ""patterns"": [
            {
                ""LEMMA"": ""make""
            }
        ],
        ""suggestions"": [
            [
                {
                    ""TEXT"": ""MAKE""
                }
            ]
        ],
        ""subcategory"": ""MAKE_CAPS""
    },
    ""make-2"": {
        ""patterns"": [
            {
                ""LEMMA"": ""make""
            }
        ],
        ""suggestions"": [
            [
                {
                    ""TEXT"": ""MaKe""
                }
            ]
        ],
        ""subcategory"": ""MAKE_STYLE"",
        ""comment"": ""This is a bad match, it is here to demonstrate overlap behavior"",
    }
}
```


> Tested this in the REPL:
> 
> ```python
> >>> from replacy import ESpan
> >>> from replacy import ReplaceMatcher
> >>> from replacy.db import load_json
> >>> import spacy
> >>> nlp = spacy.load(""en_core_web_sm"")
> >>> match_dict = load_json('./replacy/resources/match_dict.json')
> >>> ematcher = ReplaceMatcher(nlp, match_dict=match_dict, SpanClass=ESpan)
> >>> s = ematcher(""She extracts revenge."")[0]
> >>> s
> extracts
> >>> s.suggestions
> ['exacts']
> >>> s.match_name
> 'extract-revenge'
> >>> doc = nlp(""She extracts revenge."")
> >>> e = ESpan(doc, 1, 2)
> >>> e
> extracts
> >>> e.suggestions
> []
> >>> e.match_name
> ''
> >>> e.comment
> ''
> >>> e.vector
> array([ 3.7579389 , 390608 ,  ... , 0.37205344], dtype=float32)
> >>> e.kb_id
> 0
> >>> e.vector_norm
> 25.310467
> >>> e._.comment = ""yo metaprogramming""
> >>> e.comment
> 'yo metaprogramming'
> >>> e == e._
> True
> ```
> 
> I added the following to the match_dict to check for overlap behavior
> 
> ```json
> {
>   ""make-due"": {
>     ""patterns"": [
>       {
>         ""LEMMA"": ""make"",
>         ""TEMPLATE_ID"": 1
>       },
>       {
>         ""LOWER"": ""due""
>       }
>     ],
>     ""suggestions"": [
>       [
>         {
>           ""TEXT"": ""make"",
>           ""FROM_TEMPLATE_ID"": 1
>         },
>         {
>           ""TEXT"": ""do""
>         }
>       ]
>     ]
>   },
>   ""dupe-test"": {
>     ""patterns"": [
>       {
>         ""LEMMA"": ""make"",
>         ""TEMPLATE_ID"": 1
>       }
>     ],
>     ""suggestions"": [
>       [
>         {
>           ""TEXT"": ""build"",
>           ""FROM_TEMPLATE_ID"": 1
>         }
>       ]
>     ],
>     ""comment"": ""This is a bad match, it is here to demonstrate overlap behavior"",
>     ""test"": {
>       ""positive"": [""I will make something""],
>       ""negative"": []
>     }
>   }
> ```
> 
> this gives
> 
> ```python
> >>> spans = ematcher(""I will make due"")
> >>> spans
> [make, make due]
> >>> spans[0].match_name
> 'dupe-test'
> >>> spans[1].match_name
> 'make-due'
> >>> spans[1].suggestions
> ['make do']
> >>> spans[0].suggestions
> ['build']
> ```
",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-19T05:32:26Z,"@sam-qordoba all good, just one change: added `has_extension` implementation",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-18T22:06:18Z,"these just don't need to be here

```python
>>> from replacy.db import load_json
>>> import spacy
>>> nlp = spacy.load(""en_core_web_sm"")
>>> match_dict = load_json('./replacy/resources/match_dict.json')
>>> ematcher = ReplaceMatcher.with_espan(nlp, match_dict=match_dict)
>>> spans = ematcher(""I'll have to make due."")
>>> spans[0].comment
'This is a bad match, it is here to demonstrate overlap behavior'
```",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-18T21:59:54Z,"Added a factory method so you don't have to import ESpan, not sure which I like more:

```python
from replacy import ReplaceMatcher
from replacy.db import load_json
import spacy
nlp = spacy.load(""en_core_web_sm"")
match_dict = load_json('./replacy/resources/match_dict.json')
ematcher = ReplaceMatcher.with_espan(nlp, match_dict=match_dict)
s = ematcher(""She extracts revenge."")[0]
```

thoughts?",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-19T05:02:24Z,"The match dict in your test doesn't represent the overlap problem we are trying to solve, this one does:
STILL WORKS with this one
```
{
    ""make-1"": {
        ""patterns"": [
            {
                ""LEMMA"": ""make""
            }
        ],
        ""suggestions"": [
            [
                {
                    ""TEXT"": ""MAKE""
                }
            ]
        ],
        ""subcategory"": ""MAKE_CAPS""
    },
    ""make-2"": {
        ""patterns"": [
            {
                ""LEMMA"": ""make""
            }
        ],
        ""suggestions"": [
            [
                {
                    ""TEXT"": ""MaKe""
                }
            ]
        ],
        ""subcategory"": ""MAKE_STYLE"",
        ""comment"": ""This is a bad match, it is here to demonstrate overlap behavior"",
    }
}
```


> Tested this in the REPL:
> 
> ```python
> >>> from replacy import ESpan
> >>> from replacy import ReplaceMatcher
> >>> from replacy.db import load_json
> >>> import spacy
> >>> nlp = spacy.load(""en_core_web_sm"")
> >>> match_dict = load_json('./replacy/resources/match_dict.json')
> >>> ematcher = ReplaceMatcher(nlp, match_dict=match_dict, SpanClass=ESpan)
> >>> s = ematcher(""She extracts revenge."")[0]
> >>> s
> extracts
> >>> s.suggestions
> ['exacts']
> >>> s.match_name
> 'extract-revenge'
> >>> doc = nlp(""She extracts revenge."")
> >>> e = ESpan(doc, 1, 2)
> >>> e
> extracts
> >>> e.suggestions
> []
> >>> e.match_name
> ''
> >>> e.comment
> ''
> >>> e.vector
> array([ 3.7579389 , 390608 ,  ... , 0.37205344], dtype=float32)
> >>> e.kb_id
> 0
> >>> e.vector_norm
> 25.310467
> >>> e._.comment = ""yo metaprogramming""
> >>> e.comment
> 'yo metaprogramming'
> >>> e == e._
> True
> ```
> 
> I added the following to the match_dict to check for overlap behavior
> 
> ```json
> {
>   ""make-due"": {
>     ""patterns"": [
>       {
>         ""LEMMA"": ""make"",
>         ""TEMPLATE_ID"": 1
>       },
>       {
>         ""LOWER"": ""due""
>       }
>     ],
>     ""suggestions"": [
>       [
>         {
>           ""TEXT"": ""make"",
>           ""FROM_TEMPLATE_ID"": 1
>         },
>         {
>           ""TEXT"": ""do""
>         }
>       ]
>     ]
>   },
>   ""dupe-test"": {
>     ""patterns"": [
>       {
>         ""LEMMA"": ""make"",
>         ""TEMPLATE_ID"": 1
>       }
>     ],
>     ""suggestions"": [
>       [
>         {
>           ""TEXT"": ""build"",
>           ""FROM_TEMPLATE_ID"": 1
>         }
>       ]
>     ],
>     ""comment"": ""This is a bad match, it is here to demonstrate overlap behavior"",
>     ""test"": {
>       ""positive"": [""I will make something""],
>       ""negative"": []
>     }
>   }
> ```
> 
> this gives
> 
> ```python
> >>> spans = ematcher(""I will make due"")
> >>> spans
> [make, make due]
> >>> spans[0].match_name
> 'dupe-test'
> >>> spans[1].match_name
> 'make-due'
> >>> spans[1].suggestions
> ['make do']
> >>> spans[0].suggestions
> ['build']
> ```
",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-19T05:32:26Z,"@sam-qordoba all good, just one change: added `has_extension` implementation",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-18T22:06:18Z,"these just don't need to be here

```python
>>> from replacy.db import load_json
>>> import spacy
>>> nlp = spacy.load(""en_core_web_sm"")
>>> match_dict = load_json('./replacy/resources/match_dict.json')
>>> ematcher = ReplaceMatcher.with_espan(nlp, match_dict=match_dict)
>>> spans = ematcher(""I'll have to make due."")
>>> spans[0].comment
'This is a bad match, it is here to demonstrate overlap behavior'
```",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-18T21:59:54Z,"Added a factory method so you don't have to import ESpan, not sure which I like more:

```python
from replacy import ReplaceMatcher
from replacy.db import load_json
import spacy
nlp = spacy.load(""en_core_web_sm"")
match_dict = load_json('./replacy/resources/match_dict.json')
ematcher = ReplaceMatcher.with_espan(nlp, match_dict=match_dict)
s = ematcher(""She extracts revenge."")[0]
```

thoughts?",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-19T05:02:24Z,"The match dict in your test doesn't represent the overlap problem we are trying to solve, this one does:
STILL WORKS with this one
```
{
    ""make-1"": {
        ""patterns"": [
            {
                ""LEMMA"": ""make""
            }
        ],
        ""suggestions"": [
            [
                {
                    ""TEXT"": ""MAKE""
                }
            ]
        ],
        ""subcategory"": ""MAKE_CAPS""
    },
    ""make-2"": {
        ""patterns"": [
            {
                ""LEMMA"": ""make""
            }
        ],
        ""suggestions"": [
            [
                {
                    ""TEXT"": ""MaKe""
                }
            ]
        ],
        ""subcategory"": ""MAKE_STYLE"",
        ""comment"": ""This is a bad match, it is here to demonstrate overlap behavior"",
    }
}
```


> Tested this in the REPL:
> 
> ```python
> >>> from replacy import ESpan
> >>> from replacy import ReplaceMatcher
> >>> from replacy.db import load_json
> >>> import spacy
> >>> nlp = spacy.load(""en_core_web_sm"")
> >>> match_dict = load_json('./replacy/resources/match_dict.json')
> >>> ematcher = ReplaceMatcher(nlp, match_dict=match_dict, SpanClass=ESpan)
> >>> s = ematcher(""She extracts revenge."")[0]
> >>> s
> extracts
> >>> s.suggestions
> ['exacts']
> >>> s.match_name
> 'extract-revenge'
> >>> doc = nlp(""She extracts revenge."")
> >>> e = ESpan(doc, 1, 2)
> >>> e
> extracts
> >>> e.suggestions
> []
> >>> e.match_name
> ''
> >>> e.comment
> ''
> >>> e.vector
> array([ 3.7579389 , 390608 ,  ... , 0.37205344], dtype=float32)
> >>> e.kb_id
> 0
> >>> e.vector_norm
> 25.310467
> >>> e._.comment = ""yo metaprogramming""
> >>> e.comment
> 'yo metaprogramming'
> >>> e == e._
> True
> ```
> 
> I added the following to the match_dict to check for overlap behavior
> 
> ```json
> {
>   ""make-due"": {
>     ""patterns"": [
>       {
>         ""LEMMA"": ""make"",
>         ""TEMPLATE_ID"": 1
>       },
>       {
>         ""LOWER"": ""due""
>       }
>     ],
>     ""suggestions"": [
>       [
>         {
>           ""TEXT"": ""make"",
>           ""FROM_TEMPLATE_ID"": 1
>         },
>         {
>           ""TEXT"": ""do""
>         }
>       ]
>     ]
>   },
>   ""dupe-test"": {
>     ""patterns"": [
>       {
>         ""LEMMA"": ""make"",
>         ""TEMPLATE_ID"": 1
>       }
>     ],
>     ""suggestions"": [
>       [
>         {
>           ""TEXT"": ""build"",
>           ""FROM_TEMPLATE_ID"": 1
>         }
>       ]
>     ],
>     ""comment"": ""This is a bad match, it is here to demonstrate overlap behavior"",
>     ""test"": {
>       ""positive"": [""I will make something""],
>       ""negative"": []
>     }
>   }
> ```
> 
> this gives
> 
> ```python
> >>> spans = ematcher(""I will make due"")
> >>> spans
> [make, make due]
> >>> spans[0].match_name
> 'dupe-test'
> >>> spans[1].match_name
> 'make-due'
> >>> spans[1].suggestions
> ['make do']
> >>> spans[0].suggestions
> ['build']
> ```
",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-19T05:32:26Z,"@sam-qordoba all good, just one change: added `has_extension` implementation",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-18T22:06:18Z,"these just don't need to be here

```python
>>> from replacy.db import load_json
>>> import spacy
>>> nlp = spacy.load(""en_core_web_sm"")
>>> match_dict = load_json('./replacy/resources/match_dict.json')
>>> ematcher = ReplaceMatcher.with_espan(nlp, match_dict=match_dict)
>>> spans = ematcher(""I'll have to make due."")
>>> spans[0].comment
'This is a bad match, it is here to demonstrate overlap behavior'
```",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-18T21:59:54Z,"Added a factory method so you don't have to import ESpan, not sure which I like more:

```python
from replacy import ReplaceMatcher
from replacy.db import load_json
import spacy
nlp = spacy.load(""en_core_web_sm"")
match_dict = load_json('./replacy/resources/match_dict.json')
ematcher = ReplaceMatcher.with_espan(nlp, match_dict=match_dict)
s = ematcher(""She extracts revenge."")[0]
```

thoughts?",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-19T05:02:24Z,"The match dict in your test doesn't represent the overlap problem we are trying to solve, this one does:
STILL WORKS with this one
```
{
    ""make-1"": {
        ""patterns"": [
            {
                ""LEMMA"": ""make""
            }
        ],
        ""suggestions"": [
            [
                {
                    ""TEXT"": ""MAKE""
                }
            ]
        ],
        ""subcategory"": ""MAKE_CAPS""
    },
    ""make-2"": {
        ""patterns"": [
            {
                ""LEMMA"": ""make""
            }
        ],
        ""suggestions"": [
            [
                {
                    ""TEXT"": ""MaKe""
                }
            ]
        ],
        ""subcategory"": ""MAKE_STYLE"",
        ""comment"": ""This is a bad match, it is here to demonstrate overlap behavior"",
    }
}
```


> Tested this in the REPL:
> 
> ```python
> >>> from replacy import ESpan
> >>> from replacy import ReplaceMatcher
> >>> from replacy.db import load_json
> >>> import spacy
> >>> nlp = spacy.load(""en_core_web_sm"")
> >>> match_dict = load_json('./replacy/resources/match_dict.json')
> >>> ematcher = ReplaceMatcher(nlp, match_dict=match_dict, SpanClass=ESpan)
> >>> s = ematcher(""She extracts revenge."")[0]
> >>> s
> extracts
> >>> s.suggestions
> ['exacts']
> >>> s.match_name
> 'extract-revenge'
> >>> doc = nlp(""She extracts revenge."")
> >>> e = ESpan(doc, 1, 2)
> >>> e
> extracts
> >>> e.suggestions
> []
> >>> e.match_name
> ''
> >>> e.comment
> ''
> >>> e.vector
> array([ 3.7579389 , 390608 ,  ... , 0.37205344], dtype=float32)
> >>> e.kb_id
> 0
> >>> e.vector_norm
> 25.310467
> >>> e._.comment = ""yo metaprogramming""
> >>> e.comment
> 'yo metaprogramming'
> >>> e == e._
> True
> ```
> 
> I added the following to the match_dict to check for overlap behavior
> 
> ```json
> {
>   ""make-due"": {
>     ""patterns"": [
>       {
>         ""LEMMA"": ""make"",
>         ""TEMPLATE_ID"": 1
>       },
>       {
>         ""LOWER"": ""due""
>       }
>     ],
>     ""suggestions"": [
>       [
>         {
>           ""TEXT"": ""make"",
>           ""FROM_TEMPLATE_ID"": 1
>         },
>         {
>           ""TEXT"": ""do""
>         }
>       ]
>     ]
>   },
>   ""dupe-test"": {
>     ""patterns"": [
>       {
>         ""LEMMA"": ""make"",
>         ""TEMPLATE_ID"": 1
>       }
>     ],
>     ""suggestions"": [
>       [
>         {
>           ""TEXT"": ""build"",
>           ""FROM_TEMPLATE_ID"": 1
>         }
>       ]
>     ],
>     ""comment"": ""This is a bad match, it is here to demonstrate overlap behavior"",
>     ""test"": {
>       ""positive"": [""I will make something""],
>       ""negative"": []
>     }
>   }
> ```
> 
> this gives
> 
> ```python
> >>> spans = ematcher(""I will make due"")
> >>> spans
> [make, make due]
> >>> spans[0].match_name
> 'dupe-test'
> >>> spans[1].match_name
> 'make-due'
> >>> spans[1].suggestions
> ['make do']
> >>> spans[0].suggestions
> ['build']
> ```
",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-19T05:32:26Z,"@sam-qordoba all good, just one change: added `has_extension` implementation",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-18T22:06:18Z,"these just don't need to be here

```python
>>> from replacy.db import load_json
>>> import spacy
>>> nlp = spacy.load(""en_core_web_sm"")
>>> match_dict = load_json('./replacy/resources/match_dict.json')
>>> ematcher = ReplaceMatcher.with_espan(nlp, match_dict=match_dict)
>>> spans = ematcher(""I'll have to make due."")
>>> spans[0].comment
'This is a bad match, it is here to demonstrate overlap behavior'
```",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-18T21:59:54Z,"Added a factory method so you don't have to import ESpan, not sure which I like more:

```python
from replacy import ReplaceMatcher
from replacy.db import load_json
import spacy
nlp = spacy.load(""en_core_web_sm"")
match_dict = load_json('./replacy/resources/match_dict.json')
ematcher = ReplaceMatcher.with_espan(nlp, match_dict=match_dict)
s = ematcher(""She extracts revenge."")[0]
```

thoughts?",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-19T05:02:24Z,"The match dict in your test doesn't represent the overlap problem we are trying to solve, this one does:
STILL WORKS with this one
```
{
    ""make-1"": {
        ""patterns"": [
            {
                ""LEMMA"": ""make""
            }
        ],
        ""suggestions"": [
            [
                {
                    ""TEXT"": ""MAKE""
                }
            ]
        ],
        ""subcategory"": ""MAKE_CAPS""
    },
    ""make-2"": {
        ""patterns"": [
            {
                ""LEMMA"": ""make""
            }
        ],
        ""suggestions"": [
            [
                {
                    ""TEXT"": ""MaKe""
                }
            ]
        ],
        ""subcategory"": ""MAKE_STYLE"",
        ""comment"": ""This is a bad match, it is here to demonstrate overlap behavior"",
    }
}
```


> Tested this in the REPL:
> 
> ```python
> >>> from replacy import ESpan
> >>> from replacy import ReplaceMatcher
> >>> from replacy.db import load_json
> >>> import spacy
> >>> nlp = spacy.load(""en_core_web_sm"")
> >>> match_dict = load_json('./replacy/resources/match_dict.json')
> >>> ematcher = ReplaceMatcher(nlp, match_dict=match_dict, SpanClass=ESpan)
> >>> s = ematcher(""She extracts revenge."")[0]
> >>> s
> extracts
> >>> s.suggestions
> ['exacts']
> >>> s.match_name
> 'extract-revenge'
> >>> doc = nlp(""She extracts revenge."")
> >>> e = ESpan(doc, 1, 2)
> >>> e
> extracts
> >>> e.suggestions
> []
> >>> e.match_name
> ''
> >>> e.comment
> ''
> >>> e.vector
> array([ 3.7579389 , 390608 ,  ... , 0.37205344], dtype=float32)
> >>> e.kb_id
> 0
> >>> e.vector_norm
> 25.310467
> >>> e._.comment = ""yo metaprogramming""
> >>> e.comment
> 'yo metaprogramming'
> >>> e == e._
> True
> ```
> 
> I added the following to the match_dict to check for overlap behavior
> 
> ```json
> {
>   ""make-due"": {
>     ""patterns"": [
>       {
>         ""LEMMA"": ""make"",
>         ""TEMPLATE_ID"": 1
>       },
>       {
>         ""LOWER"": ""due""
>       }
>     ],
>     ""suggestions"": [
>       [
>         {
>           ""TEXT"": ""make"",
>           ""FROM_TEMPLATE_ID"": 1
>         },
>         {
>           ""TEXT"": ""do""
>         }
>       ]
>     ]
>   },
>   ""dupe-test"": {
>     ""patterns"": [
>       {
>         ""LEMMA"": ""make"",
>         ""TEMPLATE_ID"": 1
>       }
>     ],
>     ""suggestions"": [
>       [
>         {
>           ""TEXT"": ""build"",
>           ""FROM_TEMPLATE_ID"": 1
>         }
>       ]
>     ],
>     ""comment"": ""This is a bad match, it is here to demonstrate overlap behavior"",
>     ""test"": {
>       ""positive"": [""I will make something""],
>       ""negative"": []
>     }
>   }
> ```
> 
> this gives
> 
> ```python
> >>> spans = ematcher(""I will make due"")
> >>> spans
> [make, make due]
> >>> spans[0].match_name
> 'dupe-test'
> >>> spans[1].match_name
> 'make-due'
> >>> spans[1].suggestions
> ['make do']
> >>> spans[0].suggestions
> ['build']
> ```
",96
github.com/writerai/replaCy,replacy/__init__.py,2021-05-19T05:32:26Z,"@sam-qordoba all good, just one change: added `has_extension` implementation",96
github.com/writerai/replaCy,replacy/__init__.py,2020-09-21T23:42:38Z,"""times before the spellcheck in vscode"" :grimacing: ",81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-21T23:43:08Z,what does it do? :thinking: ,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-21T23:48:14Z,oh! :exploding_head: ,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-21T23:50:39Z,:heart: ,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-21T23:51:09Z,and return a list of spans (after recent changes),81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T00:07:20Z,liked the previous lines more :( ,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T00:07:45Z,:chefkiss:,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T00:09:02Z,:exploding_head: ,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T00:09:42Z,oh glad it is moved here!,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T00:11:44Z,"I wonder ... we allow replacy to use any nlp, but we require en_core_web_sm in tests? :grimacing: 
It is ok?",81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T00:12:04Z,:grimacing: ,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T18:48:38Z,"my editor complained, and I thought... yeah, you are right editor, inflector is not defined!",81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T18:49:45Z,I moved it out into `utils` but some projects using replacy call it via `ReplaceMatcher.validate_match_dict` so I wanted to attach it to the class here (which makes it a static method),81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T18:51:34Z,"this wasn't a bug, it was just, I wanted to make the components have inputs and outputs, instead of using class properties",81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T18:52:07Z,We should add tests with other languages!,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T18:52:20Z,gotta have my dumb IDs,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-21T23:34:20Z,"@melisa-qordoba Here is how this would be used for #80 

https://github.com/Qordobacode/replaCy/issues/80#issuecomment-696434960",81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T18:52:47Z,I installed this version of replaCy in a downstream project (Clarity) and the test suite still passes 💪 ,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-21T23:42:38Z,"""times before the spellcheck in vscode"" :grimacing: ",81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-21T23:43:08Z,what does it do? :thinking: ,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-21T23:48:14Z,oh! :exploding_head: ,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-21T23:50:39Z,:heart: ,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-21T23:51:09Z,and return a list of spans (after recent changes),81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T00:07:20Z,liked the previous lines more :( ,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T00:07:45Z,:chefkiss:,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T00:09:02Z,:exploding_head: ,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T00:09:42Z,oh glad it is moved here!,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T00:11:44Z,"I wonder ... we allow replacy to use any nlp, but we require en_core_web_sm in tests? :grimacing: 
It is ok?",81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T00:12:04Z,:grimacing: ,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T18:48:38Z,"my editor complained, and I thought... yeah, you are right editor, inflector is not defined!",81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T18:49:45Z,I moved it out into `utils` but some projects using replacy call it via `ReplaceMatcher.validate_match_dict` so I wanted to attach it to the class here (which makes it a static method),81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T18:51:34Z,"this wasn't a bug, it was just, I wanted to make the components have inputs and outputs, instead of using class properties",81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T18:52:07Z,We should add tests with other languages!,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T18:52:20Z,gotta have my dumb IDs,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-21T23:34:20Z,"@melisa-qordoba Here is how this would be used for #80 

https://github.com/Qordobacode/replaCy/issues/80#issuecomment-696434960",81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-22T18:52:47Z,I installed this version of replaCy in a downstream project (Clarity) and the test suite still passes 💪 ,81
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T19:18:52Z,"not sure this is a reasonable criteria, I guess I have to look at a bigger match dict...",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T19:23:59Z,"this isn't blocking. It seems like you had to do a lot of list-membership checking, and used sets, when there are ways that are more :snek:

This one, for example, feels less-pythonic than

```suggestion
            if any([article in item_options for article in [""a"", ""an"", ""the""]]):
```",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:05:17Z,"again, non-blocking style thing. I think this is the same as:

```suggestion
            if all([el in item_options for el in [""person"", ""people""]]) or all([el in item_options for el in [""ox"", ""oxen""]]):
                return 1
```

Since I am mathy, set operations make sense (and I know the Python syntax for intersection with `&`) but it may be more obvious to use `all`?",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:18:11Z,wait the lemmas are different? are we testing this just to document the weirdness?,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:18:49Z,"`plural` and `singular` switched for all of these, not that it matters (but since it's open thought you'd want to know)",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:19:16Z,Can we have a test case that uses `MAX_COUNT`?,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:19:39Z,I like little classes like this,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:59:39Z,"Here is an example where multi-token does not imply max count one:
https://github.com/Qordobacode/service.inclusivity/blob/master/service_inclusivity/resources/match_dicts/age_matches.json#L934-L935

But I thought I would find more... ",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:00:18Z,"I think I would err on the side of having replaCy assume less, and us having to do more work in the match_dicts to upgrade",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:02:20Z,"not a recommendation, but fun fact: this can be written `lemmas |= option_lemmas`",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:47:57Z,:chefkiss:,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:55:07Z,Good catch! :+1: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:56:11Z,"This is different for people / person and on / oxen.
But you are right - added xfail cases to the test.
Now, whenever we upgrade lemminflect, we can check whether lemmatization of irregular words is the same.",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:56:29Z,:smiley: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:34:30Z,done :+1: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:39:43Z,"Hmm I would rewrite that match to:
```
{""TEXT"": ""who is""},
{""TEXT"": [""single"", ""unmarried""]}
```
Then those rules would be ok :smile: 
But yeah, I agree suppression might be confusing, and some matches will need rewrites.
I promise to:
- add suppression warnings
- check `match_dicts` in dependent services
- rethink how to make those criteria better.

In other words... let's :shipit: , then fix the reality :rofl: ",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:42:35Z,Same applies here. Done for fast :shipit: Let's make it better ... later :sweat_smile: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T23:32:12Z,added simple logging :sweat_smile: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T19:18:52Z,"not sure this is a reasonable criteria, I guess I have to look at a bigger match dict...",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T19:23:59Z,"this isn't blocking. It seems like you had to do a lot of list-membership checking, and used sets, when there are ways that are more :snek:

This one, for example, feels less-pythonic than

```suggestion
            if any([article in item_options for article in [""a"", ""an"", ""the""]]):
```",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:05:17Z,"again, non-blocking style thing. I think this is the same as:

```suggestion
            if all([el in item_options for el in [""person"", ""people""]]) or all([el in item_options for el in [""ox"", ""oxen""]]):
                return 1
```

Since I am mathy, set operations make sense (and I know the Python syntax for intersection with `&`) but it may be more obvious to use `all`?",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:18:11Z,wait the lemmas are different? are we testing this just to document the weirdness?,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:18:49Z,"`plural` and `singular` switched for all of these, not that it matters (but since it's open thought you'd want to know)",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:19:16Z,Can we have a test case that uses `MAX_COUNT`?,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:19:39Z,I like little classes like this,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:59:39Z,"Here is an example where multi-token does not imply max count one:
https://github.com/Qordobacode/service.inclusivity/blob/master/service_inclusivity/resources/match_dicts/age_matches.json#L934-L935

But I thought I would find more... ",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:00:18Z,"I think I would err on the side of having replaCy assume less, and us having to do more work in the match_dicts to upgrade",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:02:20Z,"not a recommendation, but fun fact: this can be written `lemmas |= option_lemmas`",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:47:57Z,:chefkiss:,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:55:07Z,Good catch! :+1: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:56:11Z,"This is different for people / person and on / oxen.
But you are right - added xfail cases to the test.
Now, whenever we upgrade lemminflect, we can check whether lemmatization of irregular words is the same.",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:56:29Z,:smiley: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:34:30Z,done :+1: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:39:43Z,"Hmm I would rewrite that match to:
```
{""TEXT"": ""who is""},
{""TEXT"": [""single"", ""unmarried""]}
```
Then those rules would be ok :smile: 
But yeah, I agree suppression might be confusing, and some matches will need rewrites.
I promise to:
- add suppression warnings
- check `match_dicts` in dependent services
- rethink how to make those criteria better.

In other words... let's :shipit: , then fix the reality :rofl: ",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:42:35Z,Same applies here. Done for fast :shipit: Let's make it better ... later :sweat_smile: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T23:32:12Z,added simple logging :sweat_smile: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T19:18:52Z,"not sure this is a reasonable criteria, I guess I have to look at a bigger match dict...",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T19:23:59Z,"this isn't blocking. It seems like you had to do a lot of list-membership checking, and used sets, when there are ways that are more :snek:

This one, for example, feels less-pythonic than

```suggestion
            if any([article in item_options for article in [""a"", ""an"", ""the""]]):
```",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:05:17Z,"again, non-blocking style thing. I think this is the same as:

```suggestion
            if all([el in item_options for el in [""person"", ""people""]]) or all([el in item_options for el in [""ox"", ""oxen""]]):
                return 1
```

Since I am mathy, set operations make sense (and I know the Python syntax for intersection with `&`) but it may be more obvious to use `all`?",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:18:11Z,wait the lemmas are different? are we testing this just to document the weirdness?,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:18:49Z,"`plural` and `singular` switched for all of these, not that it matters (but since it's open thought you'd want to know)",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:19:16Z,Can we have a test case that uses `MAX_COUNT`?,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:19:39Z,I like little classes like this,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:59:39Z,"Here is an example where multi-token does not imply max count one:
https://github.com/Qordobacode/service.inclusivity/blob/master/service_inclusivity/resources/match_dicts/age_matches.json#L934-L935

But I thought I would find more... ",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:00:18Z,"I think I would err on the side of having replaCy assume less, and us having to do more work in the match_dicts to upgrade",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:02:20Z,"not a recommendation, but fun fact: this can be written `lemmas |= option_lemmas`",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:47:57Z,:chefkiss:,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:55:07Z,Good catch! :+1: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:56:11Z,"This is different for people / person and on / oxen.
But you are right - added xfail cases to the test.
Now, whenever we upgrade lemminflect, we can check whether lemmatization of irregular words is the same.",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:56:29Z,:smiley: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:34:30Z,done :+1: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:39:43Z,"Hmm I would rewrite that match to:
```
{""TEXT"": ""who is""},
{""TEXT"": [""single"", ""unmarried""]}
```
Then those rules would be ok :smile: 
But yeah, I agree suppression might be confusing, and some matches will need rewrites.
I promise to:
- add suppression warnings
- check `match_dicts` in dependent services
- rethink how to make those criteria better.

In other words... let's :shipit: , then fix the reality :rofl: ",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:42:35Z,Same applies here. Done for fast :shipit: Let's make it better ... later :sweat_smile: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T23:32:12Z,added simple logging :sweat_smile: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T19:18:52Z,"not sure this is a reasonable criteria, I guess I have to look at a bigger match dict...",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T19:23:59Z,"this isn't blocking. It seems like you had to do a lot of list-membership checking, and used sets, when there are ways that are more :snek:

This one, for example, feels less-pythonic than

```suggestion
            if any([article in item_options for article in [""a"", ""an"", ""the""]]):
```",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:05:17Z,"again, non-blocking style thing. I think this is the same as:

```suggestion
            if all([el in item_options for el in [""person"", ""people""]]) or all([el in item_options for el in [""ox"", ""oxen""]]):
                return 1
```

Since I am mathy, set operations make sense (and I know the Python syntax for intersection with `&`) but it may be more obvious to use `all`?",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:18:11Z,wait the lemmas are different? are we testing this just to document the weirdness?,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:18:49Z,"`plural` and `singular` switched for all of these, not that it matters (but since it's open thought you'd want to know)",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:19:16Z,Can we have a test case that uses `MAX_COUNT`?,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:19:39Z,I like little classes like this,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:59:39Z,"Here is an example where multi-token does not imply max count one:
https://github.com/Qordobacode/service.inclusivity/blob/master/service_inclusivity/resources/match_dicts/age_matches.json#L934-L935

But I thought I would find more... ",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:00:18Z,"I think I would err on the side of having replaCy assume less, and us having to do more work in the match_dicts to upgrade",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:02:20Z,"not a recommendation, but fun fact: this can be written `lemmas |= option_lemmas`",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:47:57Z,:chefkiss:,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:55:07Z,Good catch! :+1: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:56:11Z,"This is different for people / person and on / oxen.
But you are right - added xfail cases to the test.
Now, whenever we upgrade lemminflect, we can check whether lemmatization of irregular words is the same.",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:56:29Z,:smiley: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:34:30Z,done :+1: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:39:43Z,"Hmm I would rewrite that match to:
```
{""TEXT"": ""who is""},
{""TEXT"": [""single"", ""unmarried""]}
```
Then those rules would be ok :smile: 
But yeah, I agree suppression might be confusing, and some matches will need rewrites.
I promise to:
- add suppression warnings
- check `match_dicts` in dependent services
- rethink how to make those criteria better.

In other words... let's :shipit: , then fix the reality :rofl: ",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:42:35Z,Same applies here. Done for fast :shipit: Let's make it better ... later :sweat_smile: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T23:32:12Z,added simple logging :sweat_smile: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T19:18:52Z,"not sure this is a reasonable criteria, I guess I have to look at a bigger match dict...",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T19:23:59Z,"this isn't blocking. It seems like you had to do a lot of list-membership checking, and used sets, when there are ways that are more :snek:

This one, for example, feels less-pythonic than

```suggestion
            if any([article in item_options for article in [""a"", ""an"", ""the""]]):
```",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:05:17Z,"again, non-blocking style thing. I think this is the same as:

```suggestion
            if all([el in item_options for el in [""person"", ""people""]]) or all([el in item_options for el in [""ox"", ""oxen""]]):
                return 1
```

Since I am mathy, set operations make sense (and I know the Python syntax for intersection with `&`) but it may be more obvious to use `all`?",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:18:11Z,wait the lemmas are different? are we testing this just to document the weirdness?,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:18:49Z,"`plural` and `singular` switched for all of these, not that it matters (but since it's open thought you'd want to know)",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:19:16Z,Can we have a test case that uses `MAX_COUNT`?,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:19:39Z,I like little classes like this,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:59:39Z,"Here is an example where multi-token does not imply max count one:
https://github.com/Qordobacode/service.inclusivity/blob/master/service_inclusivity/resources/match_dicts/age_matches.json#L934-L935

But I thought I would find more... ",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:00:18Z,"I think I would err on the side of having replaCy assume less, and us having to do more work in the match_dicts to upgrade",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:02:20Z,"not a recommendation, but fun fact: this can be written `lemmas |= option_lemmas`",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:47:57Z,:chefkiss:,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:55:07Z,Good catch! :+1: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:56:11Z,"This is different for people / person and on / oxen.
But you are right - added xfail cases to the test.
Now, whenever we upgrade lemminflect, we can check whether lemmatization of irregular words is the same.",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:56:29Z,:smiley: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:34:30Z,done :+1: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:39:43Z,"Hmm I would rewrite that match to:
```
{""TEXT"": ""who is""},
{""TEXT"": [""single"", ""unmarried""]}
```
Then those rules would be ok :smile: 
But yeah, I agree suppression might be confusing, and some matches will need rewrites.
I promise to:
- add suppression warnings
- check `match_dicts` in dependent services
- rethink how to make those criteria better.

In other words... let's :shipit: , then fix the reality :rofl: ",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:42:35Z,Same applies here. Done for fast :shipit: Let's make it better ... later :sweat_smile: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T23:32:12Z,added simple logging :sweat_smile: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T19:18:52Z,"not sure this is a reasonable criteria, I guess I have to look at a bigger match dict...",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T19:23:59Z,"this isn't blocking. It seems like you had to do a lot of list-membership checking, and used sets, when there are ways that are more :snek:

This one, for example, feels less-pythonic than

```suggestion
            if any([article in item_options for article in [""a"", ""an"", ""the""]]):
```",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:05:17Z,"again, non-blocking style thing. I think this is the same as:

```suggestion
            if all([el in item_options for el in [""person"", ""people""]]) or all([el in item_options for el in [""ox"", ""oxen""]]):
                return 1
```

Since I am mathy, set operations make sense (and I know the Python syntax for intersection with `&`) but it may be more obvious to use `all`?",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:18:11Z,wait the lemmas are different? are we testing this just to document the weirdness?,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:18:49Z,"`plural` and `singular` switched for all of these, not that it matters (but since it's open thought you'd want to know)",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:19:16Z,Can we have a test case that uses `MAX_COUNT`?,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:19:39Z,I like little classes like this,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T20:59:39Z,"Here is an example where multi-token does not imply max count one:
https://github.com/Qordobacode/service.inclusivity/blob/master/service_inclusivity/resources/match_dicts/age_matches.json#L934-L935

But I thought I would find more... ",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:00:18Z,"I think I would err on the side of having replaCy assume less, and us having to do more work in the match_dicts to upgrade",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:02:20Z,"not a recommendation, but fun fact: this can be written `lemmas |= option_lemmas`",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:47:57Z,:chefkiss:,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:55:07Z,Good catch! :+1: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:56:11Z,"This is different for people / person and on / oxen.
But you are right - added xfail cases to the test.
Now, whenever we upgrade lemminflect, we can check whether lemmatization of irregular words is the same.",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T21:56:29Z,:smiley: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:34:30Z,done :+1: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:39:43Z,"Hmm I would rewrite that match to:
```
{""TEXT"": ""who is""},
{""TEXT"": [""single"", ""unmarried""]}
```
Then those rules would be ok :smile: 
But yeah, I agree suppression might be confusing, and some matches will need rewrites.
I promise to:
- add suppression warnings
- check `match_dicts` in dependent services
- rethink how to make those criteria better.

In other words... let's :shipit: , then fix the reality :rofl: ",78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T22:42:35Z,Same applies here. Done for fast :shipit: Let's make it better ... later :sweat_smile: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-09-09T23:32:12Z,added simple logging :sweat_smile: ,78
github.com/writerai/replaCy,replacy/__init__.py,2020-07-02T07:37:01Z,just noticed that packaging is also pumping version!,70
github.com/writerai/replaCy,replacy/__init__.py,2020-07-02T17:54:22Z,">
> >just noticed that packaging is also pumping version!
>
Isn’t it great?? I love me a good CI/CD setup

> --

Sam Havens
Director of Data Science

818.590.0484

sam.havens@qordoba.com
",70
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T15:54:13Z,"can we put this import in `get_default_lm`? If they don't want to use the LM, we shouldn't die if it isn't installed",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T17:14:03Z,"These 2 parameters are so we can build the LM stuff,
```python
self.scorer = KenLMScorer(nlp=self.nlp, model=get_default_lm(testing=testing)) if use_lm else None
```

Now that I see that, it seems like directly passing in a `scorer` is cleaner (""Dependency Injection"")",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T17:16:20Z,"that is outdated, but same idea: can we put this in `load_lm` ?",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T12:36:49Z,done :ok_hand: ,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T12:37:30Z,Yes! Bonus: using lm is optional now.,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:31:07Z,:yay:,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:31:21Z,more :yay:,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:32:00Z,"```suggestion
Speed and accuracy benchmark (copied from the Lemminflect repo):
```",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:32:31Z,even more :yay:!,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T22:43:08Z,"Sorry, I don't really know if my code samples are right, since I don't know the type signatures

`self.scorer` is `None` if there is no `KenLM`... Should we have the line that sets it be :

```python
self.scorer = (
            KenLMScorer(nlp=self.nlp, model=load_lm(lm_path)) if lm_path else lambda x: 1
        )
```

e.g. set it to the constant function?

Or, if there is more than 1 suggestion, maybe `sort_suggestions` should have behavior that depends on `self.scorer`... meaning ""if it's None, either don't change the order, or randomize it""",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-30T07:56:03Z,"Can you reproduce the bug?

Sorting and scoring happens only if there is the scorer, otherwise this step is completely skipped:
https://github.com/Qordobacode/replaCy/blob/c6eb41fba0b430c95b1feee5261807df716b3151/replacy/__init__.py#L392

I think I disagree with randomizing suggestions since this doesn't look like a desired behavior before adding `kenlm` - what if users want to manually set the order of suggestions (because they feel some options will be better)?",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-30T08:00:22Z,Take a look at `tests/test_suggestions.py`. This is the case when there is no `lm_path`.,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-30T16:07:46Z,I see,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T22:36:51Z,"I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)
",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T12:39:03Z,"> I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
> ![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)

Changed :ok_hand: 
Also did one update (after rethinking json schema). Backward compatible.

`INFLECTION` is always a string. You can set `POS`, `TAG` or `ALL`. ",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T15:54:13Z,"can we put this import in `get_default_lm`? If they don't want to use the LM, we shouldn't die if it isn't installed",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T17:14:03Z,"These 2 parameters are so we can build the LM stuff,
```python
self.scorer = KenLMScorer(nlp=self.nlp, model=get_default_lm(testing=testing)) if use_lm else None
```

Now that I see that, it seems like directly passing in a `scorer` is cleaner (""Dependency Injection"")",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T17:16:20Z,"that is outdated, but same idea: can we put this in `load_lm` ?",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T12:36:49Z,done :ok_hand: ,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T12:37:30Z,Yes! Bonus: using lm is optional now.,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:31:07Z,:yay:,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:31:21Z,more :yay:,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:32:00Z,"```suggestion
Speed and accuracy benchmark (copied from the Lemminflect repo):
```",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:32:31Z,even more :yay:!,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T22:43:08Z,"Sorry, I don't really know if my code samples are right, since I don't know the type signatures

`self.scorer` is `None` if there is no `KenLM`... Should we have the line that sets it be :

```python
self.scorer = (
            KenLMScorer(nlp=self.nlp, model=load_lm(lm_path)) if lm_path else lambda x: 1
        )
```

e.g. set it to the constant function?

Or, if there is more than 1 suggestion, maybe `sort_suggestions` should have behavior that depends on `self.scorer`... meaning ""if it's None, either don't change the order, or randomize it""",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-30T07:56:03Z,"Can you reproduce the bug?

Sorting and scoring happens only if there is the scorer, otherwise this step is completely skipped:
https://github.com/Qordobacode/replaCy/blob/c6eb41fba0b430c95b1feee5261807df716b3151/replacy/__init__.py#L392

I think I disagree with randomizing suggestions since this doesn't look like a desired behavior before adding `kenlm` - what if users want to manually set the order of suggestions (because they feel some options will be better)?",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-30T08:00:22Z,Take a look at `tests/test_suggestions.py`. This is the case when there is no `lm_path`.,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-30T16:07:46Z,I see,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T22:36:51Z,"I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)
",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T12:39:03Z,"> I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
> ![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)

Changed :ok_hand: 
Also did one update (after rethinking json schema). Backward compatible.

`INFLECTION` is always a string. You can set `POS`, `TAG` or `ALL`. ",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T15:54:13Z,"can we put this import in `get_default_lm`? If they don't want to use the LM, we shouldn't die if it isn't installed",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T17:14:03Z,"These 2 parameters are so we can build the LM stuff,
```python
self.scorer = KenLMScorer(nlp=self.nlp, model=get_default_lm(testing=testing)) if use_lm else None
```

Now that I see that, it seems like directly passing in a `scorer` is cleaner (""Dependency Injection"")",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T17:16:20Z,"that is outdated, but same idea: can we put this in `load_lm` ?",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T12:36:49Z,done :ok_hand: ,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T12:37:30Z,Yes! Bonus: using lm is optional now.,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:31:07Z,:yay:,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:31:21Z,more :yay:,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:32:00Z,"```suggestion
Speed and accuracy benchmark (copied from the Lemminflect repo):
```",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:32:31Z,even more :yay:!,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T22:43:08Z,"Sorry, I don't really know if my code samples are right, since I don't know the type signatures

`self.scorer` is `None` if there is no `KenLM`... Should we have the line that sets it be :

```python
self.scorer = (
            KenLMScorer(nlp=self.nlp, model=load_lm(lm_path)) if lm_path else lambda x: 1
        )
```

e.g. set it to the constant function?

Or, if there is more than 1 suggestion, maybe `sort_suggestions` should have behavior that depends on `self.scorer`... meaning ""if it's None, either don't change the order, or randomize it""",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-30T07:56:03Z,"Can you reproduce the bug?

Sorting and scoring happens only if there is the scorer, otherwise this step is completely skipped:
https://github.com/Qordobacode/replaCy/blob/c6eb41fba0b430c95b1feee5261807df716b3151/replacy/__init__.py#L392

I think I disagree with randomizing suggestions since this doesn't look like a desired behavior before adding `kenlm` - what if users want to manually set the order of suggestions (because they feel some options will be better)?",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-30T08:00:22Z,Take a look at `tests/test_suggestions.py`. This is the case when there is no `lm_path`.,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-30T16:07:46Z,I see,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T22:36:51Z,"I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)
",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T12:39:03Z,"> I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
> ![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)

Changed :ok_hand: 
Also did one update (after rethinking json schema). Backward compatible.

`INFLECTION` is always a string. You can set `POS`, `TAG` or `ALL`. ",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T15:54:13Z,"can we put this import in `get_default_lm`? If they don't want to use the LM, we shouldn't die if it isn't installed",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T17:14:03Z,"These 2 parameters are so we can build the LM stuff,
```python
self.scorer = KenLMScorer(nlp=self.nlp, model=get_default_lm(testing=testing)) if use_lm else None
```

Now that I see that, it seems like directly passing in a `scorer` is cleaner (""Dependency Injection"")",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T17:16:20Z,"that is outdated, but same idea: can we put this in `load_lm` ?",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T12:36:49Z,done :ok_hand: ,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T12:37:30Z,Yes! Bonus: using lm is optional now.,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:31:07Z,:yay:,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:31:21Z,more :yay:,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:32:00Z,"```suggestion
Speed and accuracy benchmark (copied from the Lemminflect repo):
```",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:32:31Z,even more :yay:!,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T22:43:08Z,"Sorry, I don't really know if my code samples are right, since I don't know the type signatures

`self.scorer` is `None` if there is no `KenLM`... Should we have the line that sets it be :

```python
self.scorer = (
            KenLMScorer(nlp=self.nlp, model=load_lm(lm_path)) if lm_path else lambda x: 1
        )
```

e.g. set it to the constant function?

Or, if there is more than 1 suggestion, maybe `sort_suggestions` should have behavior that depends on `self.scorer`... meaning ""if it's None, either don't change the order, or randomize it""",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-30T07:56:03Z,"Can you reproduce the bug?

Sorting and scoring happens only if there is the scorer, otherwise this step is completely skipped:
https://github.com/Qordobacode/replaCy/blob/c6eb41fba0b430c95b1feee5261807df716b3151/replacy/__init__.py#L392

I think I disagree with randomizing suggestions since this doesn't look like a desired behavior before adding `kenlm` - what if users want to manually set the order of suggestions (because they feel some options will be better)?",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-30T08:00:22Z,Take a look at `tests/test_suggestions.py`. This is the case when there is no `lm_path`.,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-30T16:07:46Z,I see,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T22:36:51Z,"I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)
",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T12:39:03Z,"> I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
> ![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)

Changed :ok_hand: 
Also did one update (after rethinking json schema). Backward compatible.

`INFLECTION` is always a string. You can set `POS`, `TAG` or `ALL`. ",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T15:54:13Z,"can we put this import in `get_default_lm`? If they don't want to use the LM, we shouldn't die if it isn't installed",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T17:14:03Z,"These 2 parameters are so we can build the LM stuff,
```python
self.scorer = KenLMScorer(nlp=self.nlp, model=get_default_lm(testing=testing)) if use_lm else None
```

Now that I see that, it seems like directly passing in a `scorer` is cleaner (""Dependency Injection"")",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T17:16:20Z,"that is outdated, but same idea: can we put this in `load_lm` ?",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T12:36:49Z,done :ok_hand: ,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T12:37:30Z,Yes! Bonus: using lm is optional now.,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:31:07Z,:yay:,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:31:21Z,more :yay:,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:32:00Z,"```suggestion
Speed and accuracy benchmark (copied from the Lemminflect repo):
```",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T17:32:31Z,even more :yay:!,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T22:43:08Z,"Sorry, I don't really know if my code samples are right, since I don't know the type signatures

`self.scorer` is `None` if there is no `KenLM`... Should we have the line that sets it be :

```python
self.scorer = (
            KenLMScorer(nlp=self.nlp, model=load_lm(lm_path)) if lm_path else lambda x: 1
        )
```

e.g. set it to the constant function?

Or, if there is more than 1 suggestion, maybe `sort_suggestions` should have behavior that depends on `self.scorer`... meaning ""if it's None, either don't change the order, or randomize it""",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-30T07:56:03Z,"Can you reproduce the bug?

Sorting and scoring happens only if there is the scorer, otherwise this step is completely skipped:
https://github.com/Qordobacode/replaCy/blob/c6eb41fba0b430c95b1feee5261807df716b3151/replacy/__init__.py#L392

I think I disagree with randomizing suggestions since this doesn't look like a desired behavior before adding `kenlm` - what if users want to manually set the order of suggestions (because they feel some options will be better)?",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-30T08:00:22Z,Take a look at `tests/test_suggestions.py`. This is the case when there is no `lm_path`.,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-30T16:07:46Z,I see,63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-26T22:36:51Z,"I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)
",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-29T12:39:03Z,"> I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
> ![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)

Changed :ok_hand: 
Also did one update (after rethinking json schema). Backward compatible.

`INFLECTION` is always a string. You can set `POS`, `TAG` or `ALL`. ",63
github.com/writerai/replaCy,replacy/__init__.py,2020-06-24T19:59:18Z,"This also adds `REPLACY_OP` key for use like

```json
""suggestions"": [
            [
                {
                    ""PATTERN_REF"": -1
                },
                {
                    ""TEXT"": ""with""
                },
                {
                    ""PATTERN_REF"": -2,
                    ""REPLACY_OP"": ""LOWER""
                }
            ]
        ],
```

so far, options are `LOWER/TITLE/UPPER`",62
github.com/writerai/replaCy,replacy/__init__.py,2020-06-24T19:59:18Z,"This also adds `REPLACY_OP` key for use like

```json
""suggestions"": [
            [
                {
                    ""PATTERN_REF"": -1
                },
                {
                    ""TEXT"": ""with""
                },
                {
                    ""PATTERN_REF"": -2,
                    ""REPLACY_OP"": ""LOWER""
                }
            ]
        ],
```

so far, options are `LOWER/TITLE/UPPER`",62
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T11:09:00Z,"The code grows and I am getting confused lol
What does this function return if not `v == value` ? ",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T11:19:28Z,"We could display a warning? 
Although - if this works - I would leave it. The less user need to know - the better (imo).",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T11:21:47Z,:+1: ,44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T11:27:57Z,"Seeing in line 212 `any()` so `True, False, None` are all ok.
Line 209 should be fine too.
But still would be awesome to return bool here. :grimacing: :pray: 
",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T16:50:00Z,"Yeah part of me wants to get rid of `kwargs`, but part of me now hates `args`. So I guess I will leave for now",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T16:50:47Z,"yeah, `_relatives_x_is_y` is like, a partial implementation of a DependencyMatcher :lol-sob: sorry",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T16:51:51Z,"when I pulled the logic out into the `_helper` function, I dropped that case, sorry. adding back",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T16:57:13Z,should be fixed now,44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T16:59:44Z,"Ok I changed this behavior and added a warning. Now if you want to call a function with a single dict as an argument, you can, by passing it to args (though it will warn you). If you want instead to call a function with many named args (a polyary? function? is that a word? multiary? I've only seen n-ary but that's dumb), you use `kwargs`",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T17:47:55Z,:hard-approve!,44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T11:09:00Z,"The code grows and I am getting confused lol
What does this function return if not `v == value` ? ",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T11:19:28Z,"We could display a warning? 
Although - if this works - I would leave it. The less user need to know - the better (imo).",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T11:21:47Z,:+1: ,44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T11:27:57Z,"Seeing in line 212 `any()` so `True, False, None` are all ok.
Line 209 should be fine too.
But still would be awesome to return bool here. :grimacing: :pray: 
",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T16:50:00Z,"Yeah part of me wants to get rid of `kwargs`, but part of me now hates `args`. So I guess I will leave for now",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T16:50:47Z,"yeah, `_relatives_x_is_y` is like, a partial implementation of a DependencyMatcher :lol-sob: sorry",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T16:51:51Z,"when I pulled the logic out into the `_helper` function, I dropped that case, sorry. adding back",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T16:57:13Z,should be fixed now,44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T16:59:44Z,"Ok I changed this behavior and added a warning. Now if you want to call a function with a single dict as an argument, you can, by passing it to args (though it will warn you). If you want instead to call a function with many named args (a polyary? function? is that a word? multiary? I've only seen n-ary but that's dumb), you use `kwargs`",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T17:47:55Z,:hard-approve!,44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T11:09:00Z,"The code grows and I am getting confused lol
What does this function return if not `v == value` ? ",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T11:19:28Z,"We could display a warning? 
Although - if this works - I would leave it. The less user need to know - the better (imo).",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T11:21:47Z,:+1: ,44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T11:27:57Z,"Seeing in line 212 `any()` so `True, False, None` are all ok.
Line 209 should be fine too.
But still would be awesome to return bool here. :grimacing: :pray: 
",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T16:50:00Z,"Yeah part of me wants to get rid of `kwargs`, but part of me now hates `args`. So I guess I will leave for now",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T16:50:47Z,"yeah, `_relatives_x_is_y` is like, a partial implementation of a DependencyMatcher :lol-sob: sorry",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T16:51:51Z,"when I pulled the logic out into the `_helper` function, I dropped that case, sorry. adding back",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T16:57:13Z,should be fixed now,44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T16:59:44Z,"Ok I changed this behavior and added a warning. Now if you want to call a function with a single dict as an argument, you can, by passing it to args (though it will warn you). If you want instead to call a function with many named args (a polyary? function? is that a word? multiary? I've only seen n-ary but that's dumb), you use `kwargs`",44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-18T17:47:55Z,:hard-approve!,44
github.com/writerai/replaCy,replacy/__init__.py,2020-06-15T16:18:55Z,"Wondering whether we should use `text_with_ws` instead. Token text can drop ws, unlike `TEXT`.
Fix in `inflect_or_lookup` would be needed too.",39
github.com/writerai/replaCy,replacy/__init__.py,2020-06-15T16:27:08Z,"This assumes `PATTERN REF` is always disjoint from `FROM TEMPLATE_ID`.
What if I want to copy a token from a pattern with inflection copied from another token? Or insert TEXT with `INFLECTION`?
ie would be nice to extend functionality of previous patterns instead of adding new types of patterns which lack functionality of the first.
Otherwise `lt-patterns` can only change inflections.
",39
github.com/writerai/replaCy,replacy/__init__.py,2020-06-15T16:28:46Z,"After this point we have `refd_token` (spacy token) OR `text` (string). Can we have one object with the same type? (See next comment. Maybe
```
text = refd_token.text_with_ws
```",39
github.com/writerai/replaCy,replacy/__init__.py,2020-06-15T17:07:28Z,"So, I think if they want to do `TEXT + INFLECTION` they can just do that lookup before writing the pattern (`run + VBN` is `ran`, just look that up), but you're right about `PATTERN_REF` and `FROM_TEMPLATE_ID`. I did consider this.

The reason I thought this was okay is that `PATTERN_REF` can hit any token you want, as in, there is no functionality that you can't build with this implementation (though it's not as clean as I'd like) that you could build if the combo of `PATTERN_REF` and `FROM_TEMPLATE_ID` were supported",39
github.com/writerai/replaCy,replacy/__init__.py,2020-06-15T17:18:36Z,"> Would be nice to extend replaCy functionality instead of adding new.

does this comment mean you think we shouldn't be able to change the replaCy syntax?",39
github.com/writerai/replaCy,replacy/__init__.py,2020-06-15T18:44:19Z,"It means I prefer adding new features to tokens that can be used jointly instead of adding a separate case. There is no `should/shouldn't`. Just aesthetics.

Comparison:
- copy token or inflection from any token from the pattern
- vs. error. no, you can just set inflection if you are copying a token, you can't copy inflection

I imagine an interface when you can freely point arrows to construct suggestions from patterns. Case 2 would be a strange restriction.

Current state is already cool though, so I am fine with considering extensions later.",39
github.com/writerai/replaCy,replacy/__init__.py,2020-06-17T16:45:04Z,agreed this is sub-par.,39
github.com/writerai/replaCy,replacy/__init__.py,2020-06-14T01:31:53Z,"*sigh* just realized my personal computer has the max line length set to 80, and different rules for Markdown and JSON formatting, so there are extra formatting diffs... Let me know if I need to change that.

Maybe we can check the correct `.vscode/settings.json` into git so it overrides local settings?

Sorry",39
github.com/writerai/replaCy,replacy/__init__.py,2020-05-01T01:10:13Z,:yay:,24
github.com/writerai/replaCy,replacy/__init__.py,2020-05-01T01:12:40Z,I am a fan of your READMEs :rofl: :heart: ,24
github.com/writerai/replaCy,replacy/__init__.py,2020-05-01T14:42:56Z,I am finding it quite confusing that `self.replacy_patterns` and `self.custom_match_hooks` are actually of the same type. Just the naming convention ...,24
github.com/writerai/replaCy,replacy/__init__.py,2020-05-01T16:04:21Z,I totally agree. Maybe `self.default_match_hooks` and `self.custom_match_hooks`?,24
github.com/writerai/replaCy,replacy/__init__.py,2020-05-01T16:24:34Z,I wrote a bit more in the README about how replaCy creates custom span extensions based on unexpected keys in match_dict.json. I also made the naming convention around match_hooks more reasonable!,24
github.com/writerai/replaCy,replacy/__init__.py,2020-05-01T01:10:13Z,:yay:,24
github.com/writerai/replaCy,replacy/__init__.py,2020-05-01T01:12:40Z,I am a fan of your READMEs :rofl: :heart: ,24
github.com/writerai/replaCy,replacy/__init__.py,2020-05-01T14:42:56Z,I am finding it quite confusing that `self.replacy_patterns` and `self.custom_match_hooks` are actually of the same type. Just the naming convention ...,24
github.com/writerai/replaCy,replacy/__init__.py,2020-05-01T16:04:21Z,I totally agree. Maybe `self.default_match_hooks` and `self.custom_match_hooks`?,24
github.com/writerai/replaCy,replacy/__init__.py,2020-05-01T16:24:34Z,I wrote a bit more in the README about how replaCy creates custom span extensions based on unexpected keys in match_dict.json. I also made the naming convention around match_hooks more reasonable!,24
github.com/writerai/replaCy,replacy/__init__.py,2020-03-09T23:16:33Z,"This is built and on [PyPi](https://pypi.org/project/replacy/0.11.0/) - we can take it down if this PR isn't okay, but I wanted to use it ASAP",15
github.com/writerai/replaCy,replacy/__init__.py,2020-03-09T23:16:48Z,"BTW, this closes #14 ",15
github.com/writerai/replaCy,replacy/__init__.py,2020-03-10T00:53:40Z,"@melisa-qordoba sorry for merging without review, but tests pass, and this works in a downstream app...",15
github.com/writerai/replaCy,replacy/__init__.py,2020-02-28T23:58:17Z,:laughing: ,11
github.com/writerai/replaCy,replacy/__init__.py,2020-02-28T23:59:35Z,"oh, I must: `flat_map` ? ",11
github.com/writerai/replaCy,replacy/__init__.py,2020-02-29T00:08:18Z,:laughing: ,11
github.com/writerai/replaCy,replacy/__init__.py,2020-02-28T23:40:20Z,oh my god the part I thought would be easy is impossible :sob:,11
github.com/writerai/replaCy,replacy/__init__.py,2020-03-01T20:20:17Z,"Good point about flatmap! I built that iteratively, but didn’t optimize it",11
github.com/writerai/replaCy,replacy/__init__.py,2020-02-28T23:58:17Z,:laughing: ,11
github.com/writerai/replaCy,replacy/__init__.py,2020-02-28T23:59:35Z,"oh, I must: `flat_map` ? ",11
github.com/writerai/replaCy,replacy/__init__.py,2020-02-29T00:08:18Z,:laughing: ,11
github.com/writerai/replaCy,replacy/__init__.py,2020-02-28T23:40:20Z,oh my god the part I thought would be easy is impossible :sob:,11
github.com/writerai/replaCy,replacy/__init__.py,2020-03-01T20:20:17Z,"Good point about flatmap! I built that iteratively, but didn’t optimize it",11
github.com/writerai/replaCy,replacy/__init__.py,2020-02-28T23:58:17Z,:laughing: ,11
github.com/writerai/replaCy,replacy/__init__.py,2020-02-28T23:59:35Z,"oh, I must: `flat_map` ? ",11
github.com/writerai/replaCy,replacy/__init__.py,2020-02-29T00:08:18Z,:laughing: ,11
github.com/writerai/replaCy,replacy/__init__.py,2020-02-28T23:40:20Z,oh my god the part I thought would be easy is impossible :sob:,11
github.com/writerai/replaCy,replacy/__init__.py,2020-03-01T20:20:17Z,"Good point about flatmap! I built that iteratively, but didn’t optimize it",11
github.com/writerai/replaCy,replacy/__init__.py,2020-02-07T23:14:40Z,:sob: another gone,9
github.com/writerai/replaCy,replacy/__init__.py,2020-02-07T23:41:35Z,hopefully I convinced you this was OK,9
github.com/writerai/replaCy,replacy/__init__.py,2020-02-07T23:35:09Z,"Copying what I Slacked Melisa, in case @q-biljana is curious:

I want to convince you that what I did in replacy/__init__.py  is okay...

specifically, I removed a try/catch , and you might think that violates your rule of ""never fail at runtime""... but! I don't think it does. Because I made a small code change, so that get_predicates is only ever run when you init the matcher. So this way, if you have a bad match hook, it will fail, but right away

before, `predicates = self.get_predicates(match_hooks)` was in the callback passed to the matcher, so it was run every time it checked for a match

so I moved it out of the callback (but still in `get_callback`), so it gets run once when you init the matcher... and then the callback you return is in a closure that has the value of predicates

I haven't had to think about closures in a while...",9
github.com/writerai/replaCy,replacy/__init__.py,2020-01-17T21:33:08Z,"On PyPi it says we're already on 0.5.0 ... sorry, I don't know how that happened.",6
github.com/writerai/replaCy,replacy/__init__.py,2020-01-17T21:33:15Z,https://pypi.org/project/replacy/,6
github.com/writerai/replaCy,replacy/__init__.py,2020-01-17T21:39:10Z,bumped,6
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T19:18:52Z,"not sure this is a reasonable criteria, I guess I have to look at a bigger match dict...",78
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T19:23:59Z,"this isn't blocking. It seems like you had to do a lot of list-membership checking, and used sets, when there are ways that are more :snek:

This one, for example, feels less-pythonic than

```suggestion
            if any([article in item_options for article in [""a"", ""an"", ""the""]]):
```",78
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T20:05:17Z,"again, non-blocking style thing. I think this is the same as:

```suggestion
            if all([el in item_options for el in [""person"", ""people""]]) or all([el in item_options for el in [""ox"", ""oxen""]]):
                return 1
```

Since I am mathy, set operations make sense (and I know the Python syntax for intersection with `&`) but it may be more obvious to use `all`?",78
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T20:18:11Z,wait the lemmas are different? are we testing this just to document the weirdness?,78
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T20:18:49Z,"`plural` and `singular` switched for all of these, not that it matters (but since it's open thought you'd want to know)",78
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T20:19:16Z,Can we have a test case that uses `MAX_COUNT`?,78
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T20:19:39Z,I like little classes like this,78
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T20:59:39Z,"Here is an example where multi-token does not imply max count one:
https://github.com/Qordobacode/service.inclusivity/blob/master/service_inclusivity/resources/match_dicts/age_matches.json#L934-L935

But I thought I would find more... ",78
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T21:00:18Z,"I think I would err on the side of having replaCy assume less, and us having to do more work in the match_dicts to upgrade",78
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T21:02:20Z,"not a recommendation, but fun fact: this can be written `lemmas |= option_lemmas`",78
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T21:47:57Z,:chefkiss:,78
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T21:55:07Z,Good catch! :+1: ,78
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T21:56:11Z,"This is different for people / person and on / oxen.
But you are right - added xfail cases to the test.
Now, whenever we upgrade lemminflect, we can check whether lemmatization of irregular words is the same.",78
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T21:56:29Z,:smiley: ,78
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T22:34:30Z,done :+1: ,78
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T22:39:43Z,"Hmm I would rewrite that match to:
```
{""TEXT"": ""who is""},
{""TEXT"": [""single"", ""unmarried""]}
```
Then those rules would be ok :smile: 
But yeah, I agree suppression might be confusing, and some matches will need rewrites.
I promise to:
- add suppression warnings
- check `match_dicts` in dependent services
- rethink how to make those criteria better.

In other words... let's :shipit: , then fix the reality :rofl: ",78
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T22:42:35Z,Same applies here. Done for fast :shipit: Let's make it better ... later :sweat_smile: ,78
github.com/writerai/replaCy,replacy/inflector.py,2020-09-09T23:32:12Z,added simple logging :sweat_smile: ,78
github.com/writerai/replaCy,replacy/inflector.py,2020-06-26T15:54:13Z,"can we put this import in `get_default_lm`? If they don't want to use the LM, we shouldn't die if it isn't installed",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-26T17:14:03Z,"These 2 parameters are so we can build the LM stuff,
```python
self.scorer = KenLMScorer(nlp=self.nlp, model=get_default_lm(testing=testing)) if use_lm else None
```

Now that I see that, it seems like directly passing in a `scorer` is cleaner (""Dependency Injection"")",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-26T17:16:20Z,"that is outdated, but same idea: can we put this in `load_lm` ?",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T12:36:49Z,done :ok_hand: ,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T12:37:30Z,Yes! Bonus: using lm is optional now.,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T17:31:07Z,:yay:,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T17:31:21Z,more :yay:,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T17:32:00Z,"```suggestion
Speed and accuracy benchmark (copied from the Lemminflect repo):
```",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T17:32:31Z,even more :yay:!,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T22:43:08Z,"Sorry, I don't really know if my code samples are right, since I don't know the type signatures

`self.scorer` is `None` if there is no `KenLM`... Should we have the line that sets it be :

```python
self.scorer = (
            KenLMScorer(nlp=self.nlp, model=load_lm(lm_path)) if lm_path else lambda x: 1
        )
```

e.g. set it to the constant function?

Or, if there is more than 1 suggestion, maybe `sort_suggestions` should have behavior that depends on `self.scorer`... meaning ""if it's None, either don't change the order, or randomize it""",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-30T07:56:03Z,"Can you reproduce the bug?

Sorting and scoring happens only if there is the scorer, otherwise this step is completely skipped:
https://github.com/Qordobacode/replaCy/blob/c6eb41fba0b430c95b1feee5261807df716b3151/replacy/__init__.py#L392

I think I disagree with randomizing suggestions since this doesn't look like a desired behavior before adding `kenlm` - what if users want to manually set the order of suggestions (because they feel some options will be better)?",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-30T08:00:22Z,Take a look at `tests/test_suggestions.py`. This is the case when there is no `lm_path`.,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-30T16:07:46Z,I see,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-26T22:36:51Z,"I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)
",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T12:39:03Z,"> I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
> ![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)

Changed :ok_hand: 
Also did one update (after rethinking json schema). Backward compatible.

`INFLECTION` is always a string. You can set `POS`, `TAG` or `ALL`. ",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-26T15:54:13Z,"can we put this import in `get_default_lm`? If they don't want to use the LM, we shouldn't die if it isn't installed",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-26T17:14:03Z,"These 2 parameters are so we can build the LM stuff,
```python
self.scorer = KenLMScorer(nlp=self.nlp, model=get_default_lm(testing=testing)) if use_lm else None
```

Now that I see that, it seems like directly passing in a `scorer` is cleaner (""Dependency Injection"")",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-26T17:16:20Z,"that is outdated, but same idea: can we put this in `load_lm` ?",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T12:36:49Z,done :ok_hand: ,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T12:37:30Z,Yes! Bonus: using lm is optional now.,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T17:31:07Z,:yay:,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T17:31:21Z,more :yay:,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T17:32:00Z,"```suggestion
Speed and accuracy benchmark (copied from the Lemminflect repo):
```",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T17:32:31Z,even more :yay:!,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T22:43:08Z,"Sorry, I don't really know if my code samples are right, since I don't know the type signatures

`self.scorer` is `None` if there is no `KenLM`... Should we have the line that sets it be :

```python
self.scorer = (
            KenLMScorer(nlp=self.nlp, model=load_lm(lm_path)) if lm_path else lambda x: 1
        )
```

e.g. set it to the constant function?

Or, if there is more than 1 suggestion, maybe `sort_suggestions` should have behavior that depends on `self.scorer`... meaning ""if it's None, either don't change the order, or randomize it""",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-30T07:56:03Z,"Can you reproduce the bug?

Sorting and scoring happens only if there is the scorer, otherwise this step is completely skipped:
https://github.com/Qordobacode/replaCy/blob/c6eb41fba0b430c95b1feee5261807df716b3151/replacy/__init__.py#L392

I think I disagree with randomizing suggestions since this doesn't look like a desired behavior before adding `kenlm` - what if users want to manually set the order of suggestions (because they feel some options will be better)?",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-30T08:00:22Z,Take a look at `tests/test_suggestions.py`. This is the case when there is no `lm_path`.,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-30T16:07:46Z,I see,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-26T22:36:51Z,"I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)
",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T12:39:03Z,"> I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
> ![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)

Changed :ok_hand: 
Also did one update (after rethinking json schema). Backward compatible.

`INFLECTION` is always a string. You can set `POS`, `TAG` or `ALL`. ",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-26T15:54:13Z,"can we put this import in `get_default_lm`? If they don't want to use the LM, we shouldn't die if it isn't installed",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-26T17:14:03Z,"These 2 parameters are so we can build the LM stuff,
```python
self.scorer = KenLMScorer(nlp=self.nlp, model=get_default_lm(testing=testing)) if use_lm else None
```

Now that I see that, it seems like directly passing in a `scorer` is cleaner (""Dependency Injection"")",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-26T17:16:20Z,"that is outdated, but same idea: can we put this in `load_lm` ?",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T12:36:49Z,done :ok_hand: ,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T12:37:30Z,Yes! Bonus: using lm is optional now.,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T17:31:07Z,:yay:,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T17:31:21Z,more :yay:,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T17:32:00Z,"```suggestion
Speed and accuracy benchmark (copied from the Lemminflect repo):
```",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T17:32:31Z,even more :yay:!,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T22:43:08Z,"Sorry, I don't really know if my code samples are right, since I don't know the type signatures

`self.scorer` is `None` if there is no `KenLM`... Should we have the line that sets it be :

```python
self.scorer = (
            KenLMScorer(nlp=self.nlp, model=load_lm(lm_path)) if lm_path else lambda x: 1
        )
```

e.g. set it to the constant function?

Or, if there is more than 1 suggestion, maybe `sort_suggestions` should have behavior that depends on `self.scorer`... meaning ""if it's None, either don't change the order, or randomize it""",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-30T07:56:03Z,"Can you reproduce the bug?

Sorting and scoring happens only if there is the scorer, otherwise this step is completely skipped:
https://github.com/Qordobacode/replaCy/blob/c6eb41fba0b430c95b1feee5261807df716b3151/replacy/__init__.py#L392

I think I disagree with randomizing suggestions since this doesn't look like a desired behavior before adding `kenlm` - what if users want to manually set the order of suggestions (because they feel some options will be better)?",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-30T08:00:22Z,Take a look at `tests/test_suggestions.py`. This is the case when there is no `lm_path`.,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-30T16:07:46Z,I see,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-26T22:36:51Z,"I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)
",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T12:39:03Z,"> I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
> ![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)

Changed :ok_hand: 
Also did one update (after rethinking json schema). Backward compatible.

`INFLECTION` is always a string. You can set `POS`, `TAG` or `ALL`. ",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-26T15:54:13Z,"can we put this import in `get_default_lm`? If they don't want to use the LM, we shouldn't die if it isn't installed",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-26T17:14:03Z,"These 2 parameters are so we can build the LM stuff,
```python
self.scorer = KenLMScorer(nlp=self.nlp, model=get_default_lm(testing=testing)) if use_lm else None
```

Now that I see that, it seems like directly passing in a `scorer` is cleaner (""Dependency Injection"")",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-26T17:16:20Z,"that is outdated, but same idea: can we put this in `load_lm` ?",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T12:36:49Z,done :ok_hand: ,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T12:37:30Z,Yes! Bonus: using lm is optional now.,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T17:31:07Z,:yay:,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T17:31:21Z,more :yay:,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T17:32:00Z,"```suggestion
Speed and accuracy benchmark (copied from the Lemminflect repo):
```",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T17:32:31Z,even more :yay:!,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T22:43:08Z,"Sorry, I don't really know if my code samples are right, since I don't know the type signatures

`self.scorer` is `None` if there is no `KenLM`... Should we have the line that sets it be :

```python
self.scorer = (
            KenLMScorer(nlp=self.nlp, model=load_lm(lm_path)) if lm_path else lambda x: 1
        )
```

e.g. set it to the constant function?

Or, if there is more than 1 suggestion, maybe `sort_suggestions` should have behavior that depends on `self.scorer`... meaning ""if it's None, either don't change the order, or randomize it""",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-30T07:56:03Z,"Can you reproduce the bug?

Sorting and scoring happens only if there is the scorer, otherwise this step is completely skipped:
https://github.com/Qordobacode/replaCy/blob/c6eb41fba0b430c95b1feee5261807df716b3151/replacy/__init__.py#L392

I think I disagree with randomizing suggestions since this doesn't look like a desired behavior before adding `kenlm` - what if users want to manually set the order of suggestions (because they feel some options will be better)?",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-30T08:00:22Z,Take a look at `tests/test_suggestions.py`. This is the case when there is no `lm_path`.,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-30T16:07:46Z,I see,63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-26T22:36:51Z,"I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)
",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-29T12:39:03Z,"> I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
> ![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)

Changed :ok_hand: 
Also did one update (after rethinking json schema). Backward compatible.

`INFLECTION` is always a string. You can set `POS`, `TAG` or `ALL`. ",63
github.com/writerai/replaCy,replacy/inflector.py,2020-06-15T16:18:55Z,"Wondering whether we should use `text_with_ws` instead. Token text can drop ws, unlike `TEXT`.
Fix in `inflect_or_lookup` would be needed too.",39
github.com/writerai/replaCy,replacy/inflector.py,2020-06-15T16:27:08Z,"This assumes `PATTERN REF` is always disjoint from `FROM TEMPLATE_ID`.
What if I want to copy a token from a pattern with inflection copied from another token? Or insert TEXT with `INFLECTION`?
ie would be nice to extend functionality of previous patterns instead of adding new types of patterns which lack functionality of the first.
Otherwise `lt-patterns` can only change inflections.
",39
github.com/writerai/replaCy,replacy/inflector.py,2020-06-15T16:28:46Z,"After this point we have `refd_token` (spacy token) OR `text` (string). Can we have one object with the same type? (See next comment. Maybe
```
text = refd_token.text_with_ws
```",39
github.com/writerai/replaCy,replacy/inflector.py,2020-06-15T17:07:28Z,"So, I think if they want to do `TEXT + INFLECTION` they can just do that lookup before writing the pattern (`run + VBN` is `ran`, just look that up), but you're right about `PATTERN_REF` and `FROM_TEMPLATE_ID`. I did consider this.

The reason I thought this was okay is that `PATTERN_REF` can hit any token you want, as in, there is no functionality that you can't build with this implementation (though it's not as clean as I'd like) that you could build if the combo of `PATTERN_REF` and `FROM_TEMPLATE_ID` were supported",39
github.com/writerai/replaCy,replacy/inflector.py,2020-06-15T17:18:36Z,"> Would be nice to extend replaCy functionality instead of adding new.

does this comment mean you think we shouldn't be able to change the replaCy syntax?",39
github.com/writerai/replaCy,replacy/inflector.py,2020-06-15T18:44:19Z,"It means I prefer adding new features to tokens that can be used jointly instead of adding a separate case. There is no `should/shouldn't`. Just aesthetics.

Comparison:
- copy token or inflection from any token from the pattern
- vs. error. no, you can just set inflection if you are copying a token, you can't copy inflection

I imagine an interface when you can freely point arrows to construct suggestions from patterns. Case 2 would be a strange restriction.

Current state is already cool though, so I am fine with considering extensions later.",39
github.com/writerai/replaCy,replacy/inflector.py,2020-06-17T16:45:04Z,agreed this is sub-par.,39
github.com/writerai/replaCy,replacy/inflector.py,2020-06-14T01:31:53Z,"*sigh* just realized my personal computer has the max line length set to 80, and different rules for Markdown and JSON formatting, so there are extra formatting diffs... Let me know if I need to change that.

Maybe we can check the correct `.vscode/settings.json` into git so it overrides local settings?

Sorry",39
github.com/writerai/replaCy,tests/test_hooks.py,2020-06-18T11:09:00Z,"The code grows and I am getting confused lol
What does this function return if not `v == value` ? ",44
github.com/writerai/replaCy,tests/test_hooks.py,2020-06-18T11:19:28Z,"We could display a warning? 
Although - if this works - I would leave it. The less user need to know - the better (imo).",44
github.com/writerai/replaCy,tests/test_hooks.py,2020-06-18T11:21:47Z,:+1: ,44
github.com/writerai/replaCy,tests/test_hooks.py,2020-06-18T11:27:57Z,"Seeing in line 212 `any()` so `True, False, None` are all ok.
Line 209 should be fine too.
But still would be awesome to return bool here. :grimacing: :pray: 
",44
github.com/writerai/replaCy,tests/test_hooks.py,2020-06-18T16:50:00Z,"Yeah part of me wants to get rid of `kwargs`, but part of me now hates `args`. So I guess I will leave for now",44
github.com/writerai/replaCy,tests/test_hooks.py,2020-06-18T16:50:47Z,"yeah, `_relatives_x_is_y` is like, a partial implementation of a DependencyMatcher :lol-sob: sorry",44
github.com/writerai/replaCy,tests/test_hooks.py,2020-06-18T16:51:51Z,"when I pulled the logic out into the `_helper` function, I dropped that case, sorry. adding back",44
github.com/writerai/replaCy,tests/test_hooks.py,2020-06-18T16:57:13Z,should be fixed now,44
github.com/writerai/replaCy,tests/test_hooks.py,2020-06-18T16:59:44Z,"Ok I changed this behavior and added a warning. Now if you want to call a function with a single dict as an argument, you can, by passing it to args (though it will warn you). If you want instead to call a function with many named args (a polyary? function? is that a word? multiary? I've only seen n-ary but that's dumb), you use `kwargs`",44
github.com/writerai/replaCy,tests/test_hooks.py,2020-06-18T17:47:55Z,:hard-approve!,44
github.com/writerai/replaCy,tests/test_hooks.py,2020-05-01T01:10:13Z,:yay:,24
github.com/writerai/replaCy,tests/test_hooks.py,2020-05-01T01:12:40Z,I am a fan of your READMEs :rofl: :heart: ,24
github.com/writerai/replaCy,tests/test_hooks.py,2020-05-01T14:42:56Z,I am finding it quite confusing that `self.replacy_patterns` and `self.custom_match_hooks` are actually of the same type. Just the naming convention ...,24
github.com/writerai/replaCy,tests/test_hooks.py,2020-05-01T16:04:21Z,I totally agree. Maybe `self.default_match_hooks` and `self.custom_match_hooks`?,24
github.com/writerai/replaCy,tests/test_hooks.py,2020-05-01T16:24:34Z,I wrote a bit more in the README about how replaCy creates custom span extensions based on unexpected keys in match_dict.json. I also made the naming convention around match_hooks more reasonable!,24
github.com/writerai/replaCy,tests/test_hooks.py,2020-03-09T23:16:33Z,"This is built and on [PyPi](https://pypi.org/project/replacy/0.11.0/) - we can take it down if this PR isn't okay, but I wanted to use it ASAP",15
github.com/writerai/replaCy,tests/test_hooks.py,2020-03-09T23:16:48Z,"BTW, this closes #14 ",15
github.com/writerai/replaCy,tests/test_hooks.py,2020-03-10T00:53:40Z,"@melisa-qordoba sorry for merging without review, but tests pass, and this works in a downstream app...",15
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-21T23:42:38Z,"""times before the spellcheck in vscode"" :grimacing: ",81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-21T23:43:08Z,what does it do? :thinking: ,81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-21T23:48:14Z,oh! :exploding_head: ,81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-21T23:50:39Z,:heart: ,81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-21T23:51:09Z,and return a list of spans (after recent changes),81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-22T00:07:20Z,liked the previous lines more :( ,81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-22T00:07:45Z,:chefkiss:,81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-22T00:09:02Z,:exploding_head: ,81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-22T00:09:42Z,oh glad it is moved here!,81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-22T00:11:44Z,"I wonder ... we allow replacy to use any nlp, but we require en_core_web_sm in tests? :grimacing: 
It is ok?",81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-22T00:12:04Z,:grimacing: ,81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-22T18:48:38Z,"my editor complained, and I thought... yeah, you are right editor, inflector is not defined!",81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-22T18:49:45Z,I moved it out into `utils` but some projects using replacy call it via `ReplaceMatcher.validate_match_dict` so I wanted to attach it to the class here (which makes it a static method),81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-22T18:51:34Z,"this wasn't a bug, it was just, I wanted to make the components have inputs and outputs, instead of using class properties",81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-22T18:52:07Z,We should add tests with other languages!,81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-22T18:52:20Z,gotta have my dumb IDs,81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-21T23:34:20Z,"@melisa-qordoba Here is how this would be used for #80 

https://github.com/Qordobacode/replaCy/issues/80#issuecomment-696434960",81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-22T18:52:47Z,I installed this version of replaCy in a downstream project (Clarity) and the test suite still passes 💪 ,81
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T19:18:52Z,"not sure this is a reasonable criteria, I guess I have to look at a bigger match dict...",78
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T19:23:59Z,"this isn't blocking. It seems like you had to do a lot of list-membership checking, and used sets, when there are ways that are more :snek:

This one, for example, feels less-pythonic than

```suggestion
            if any([article in item_options for article in [""a"", ""an"", ""the""]]):
```",78
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T20:05:17Z,"again, non-blocking style thing. I think this is the same as:

```suggestion
            if all([el in item_options for el in [""person"", ""people""]]) or all([el in item_options for el in [""ox"", ""oxen""]]):
                return 1
```

Since I am mathy, set operations make sense (and I know the Python syntax for intersection with `&`) but it may be more obvious to use `all`?",78
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T20:18:11Z,wait the lemmas are different? are we testing this just to document the weirdness?,78
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T20:18:49Z,"`plural` and `singular` switched for all of these, not that it matters (but since it's open thought you'd want to know)",78
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T20:19:16Z,Can we have a test case that uses `MAX_COUNT`?,78
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T20:19:39Z,I like little classes like this,78
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T20:59:39Z,"Here is an example where multi-token does not imply max count one:
https://github.com/Qordobacode/service.inclusivity/blob/master/service_inclusivity/resources/match_dicts/age_matches.json#L934-L935

But I thought I would find more... ",78
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T21:00:18Z,"I think I would err on the side of having replaCy assume less, and us having to do more work in the match_dicts to upgrade",78
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T21:02:20Z,"not a recommendation, but fun fact: this can be written `lemmas |= option_lemmas`",78
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T21:47:57Z,:chefkiss:,78
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T21:55:07Z,Good catch! :+1: ,78
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T21:56:11Z,"This is different for people / person and on / oxen.
But you are right - added xfail cases to the test.
Now, whenever we upgrade lemminflect, we can check whether lemmatization of irregular words is the same.",78
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T21:56:29Z,:smiley: ,78
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T22:34:30Z,done :+1: ,78
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T22:39:43Z,"Hmm I would rewrite that match to:
```
{""TEXT"": ""who is""},
{""TEXT"": [""single"", ""unmarried""]}
```
Then those rules would be ok :smile: 
But yeah, I agree suppression might be confusing, and some matches will need rewrites.
I promise to:
- add suppression warnings
- check `match_dicts` in dependent services
- rethink how to make those criteria better.

In other words... let's :shipit: , then fix the reality :rofl: ",78
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T22:42:35Z,Same applies here. Done for fast :shipit: Let's make it better ... later :sweat_smile: ,78
github.com/writerai/replaCy,tests/test_scorer.py,2020-09-09T23:32:12Z,added simple logging :sweat_smile: ,78
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-26T15:54:13Z,"can we put this import in `get_default_lm`? If they don't want to use the LM, we shouldn't die if it isn't installed",63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-26T17:14:03Z,"These 2 parameters are so we can build the LM stuff,
```python
self.scorer = KenLMScorer(nlp=self.nlp, model=get_default_lm(testing=testing)) if use_lm else None
```

Now that I see that, it seems like directly passing in a `scorer` is cleaner (""Dependency Injection"")",63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-26T17:16:20Z,"that is outdated, but same idea: can we put this in `load_lm` ?",63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-29T12:36:49Z,done :ok_hand: ,63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-29T12:37:30Z,Yes! Bonus: using lm is optional now.,63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-29T17:31:07Z,:yay:,63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-29T17:31:21Z,more :yay:,63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-29T17:32:00Z,"```suggestion
Speed and accuracy benchmark (copied from the Lemminflect repo):
```",63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-29T17:32:31Z,even more :yay:!,63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-29T22:43:08Z,"Sorry, I don't really know if my code samples are right, since I don't know the type signatures

`self.scorer` is `None` if there is no `KenLM`... Should we have the line that sets it be :

```python
self.scorer = (
            KenLMScorer(nlp=self.nlp, model=load_lm(lm_path)) if lm_path else lambda x: 1
        )
```

e.g. set it to the constant function?

Or, if there is more than 1 suggestion, maybe `sort_suggestions` should have behavior that depends on `self.scorer`... meaning ""if it's None, either don't change the order, or randomize it""",63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-30T07:56:03Z,"Can you reproduce the bug?

Sorting and scoring happens only if there is the scorer, otherwise this step is completely skipped:
https://github.com/Qordobacode/replaCy/blob/c6eb41fba0b430c95b1feee5261807df716b3151/replacy/__init__.py#L392

I think I disagree with randomizing suggestions since this doesn't look like a desired behavior before adding `kenlm` - what if users want to manually set the order of suggestions (because they feel some options will be better)?",63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-30T08:00:22Z,Take a look at `tests/test_suggestions.py`. This is the case when there is no `lm_path`.,63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-30T16:07:46Z,I see,63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-26T22:36:51Z,"I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)
",63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-29T12:39:03Z,"> I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
> ![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)

Changed :ok_hand: 
Also did one update (after rethinking json schema). Backward compatible.

`INFLECTION` is always a string. You can set `POS`, `TAG` or `ALL`. ",63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-26T15:54:13Z,"can we put this import in `get_default_lm`? If they don't want to use the LM, we shouldn't die if it isn't installed",63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-26T17:14:03Z,"These 2 parameters are so we can build the LM stuff,
```python
self.scorer = KenLMScorer(nlp=self.nlp, model=get_default_lm(testing=testing)) if use_lm else None
```

Now that I see that, it seems like directly passing in a `scorer` is cleaner (""Dependency Injection"")",63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-26T17:16:20Z,"that is outdated, but same idea: can we put this in `load_lm` ?",63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-29T12:36:49Z,done :ok_hand: ,63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-29T12:37:30Z,Yes! Bonus: using lm is optional now.,63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-29T17:31:07Z,:yay:,63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-29T17:31:21Z,more :yay:,63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-29T17:32:00Z,"```suggestion
Speed and accuracy benchmark (copied from the Lemminflect repo):
```",63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-29T17:32:31Z,even more :yay:!,63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-29T22:43:08Z,"Sorry, I don't really know if my code samples are right, since I don't know the type signatures

`self.scorer` is `None` if there is no `KenLM`... Should we have the line that sets it be :

```python
self.scorer = (
            KenLMScorer(nlp=self.nlp, model=load_lm(lm_path)) if lm_path else lambda x: 1
        )
```

e.g. set it to the constant function?

Or, if there is more than 1 suggestion, maybe `sort_suggestions` should have behavior that depends on `self.scorer`... meaning ""if it's None, either don't change the order, or randomize it""",63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-30T07:56:03Z,"Can you reproduce the bug?

Sorting and scoring happens only if there is the scorer, otherwise this step is completely skipped:
https://github.com/Qordobacode/replaCy/blob/c6eb41fba0b430c95b1feee5261807df716b3151/replacy/__init__.py#L392

I think I disagree with randomizing suggestions since this doesn't look like a desired behavior before adding `kenlm` - what if users want to manually set the order of suggestions (because they feel some options will be better)?",63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-30T08:00:22Z,Take a look at `tests/test_suggestions.py`. This is the case when there is no `lm_path`.,63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-30T16:07:46Z,I see,63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-26T22:36:51Z,"I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)
",63
github.com/writerai/replaCy,tests/test_scorer.py,2020-06-29T12:39:03Z,"> I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
> ![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)

Changed :ok_hand: 
Also did one update (after rethinking json schema). Backward compatible.

`INFLECTION` is always a string. You can set `POS`, `TAG` or `ALL`. ",63
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:42:38Z,"""times before the spellcheck in vscode"" :grimacing: ",81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:43:08Z,what does it do? :thinking: ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:48:14Z,oh! :exploding_head: ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:50:39Z,:heart: ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:51:09Z,and return a list of spans (after recent changes),81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:07:20Z,liked the previous lines more :( ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:07:45Z,:chefkiss:,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:09:02Z,:exploding_head: ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:09:42Z,oh glad it is moved here!,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:11:44Z,"I wonder ... we allow replacy to use any nlp, but we require en_core_web_sm in tests? :grimacing: 
It is ok?",81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:12:04Z,:grimacing: ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:48:38Z,"my editor complained, and I thought... yeah, you are right editor, inflector is not defined!",81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:49:45Z,I moved it out into `utils` but some projects using replacy call it via `ReplaceMatcher.validate_match_dict` so I wanted to attach it to the class here (which makes it a static method),81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:51:34Z,"this wasn't a bug, it was just, I wanted to make the components have inputs and outputs, instead of using class properties",81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:52:07Z,We should add tests with other languages!,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:52:20Z,gotta have my dumb IDs,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:34:20Z,"@melisa-qordoba Here is how this would be used for #80 

https://github.com/Qordobacode/replaCy/issues/80#issuecomment-696434960",81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:52:47Z,I installed this version of replaCy in a downstream project (Clarity) and the test suite still passes 💪 ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:42:38Z,"""times before the spellcheck in vscode"" :grimacing: ",81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:43:08Z,what does it do? :thinking: ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:48:14Z,oh! :exploding_head: ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:50:39Z,:heart: ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:51:09Z,and return a list of spans (after recent changes),81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:07:20Z,liked the previous lines more :( ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:07:45Z,:chefkiss:,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:09:02Z,:exploding_head: ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:09:42Z,oh glad it is moved here!,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:11:44Z,"I wonder ... we allow replacy to use any nlp, but we require en_core_web_sm in tests? :grimacing: 
It is ok?",81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:12:04Z,:grimacing: ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:48:38Z,"my editor complained, and I thought... yeah, you are right editor, inflector is not defined!",81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:49:45Z,I moved it out into `utils` but some projects using replacy call it via `ReplaceMatcher.validate_match_dict` so I wanted to attach it to the class here (which makes it a static method),81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:51:34Z,"this wasn't a bug, it was just, I wanted to make the components have inputs and outputs, instead of using class properties",81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:52:07Z,We should add tests with other languages!,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:52:20Z,gotta have my dumb IDs,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:34:20Z,"@melisa-qordoba Here is how this would be used for #80 

https://github.com/Qordobacode/replaCy/issues/80#issuecomment-696434960",81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:52:47Z,I installed this version of replaCy in a downstream project (Clarity) and the test suite still passes 💪 ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:42:38Z,"""times before the spellcheck in vscode"" :grimacing: ",81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:43:08Z,what does it do? :thinking: ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:48:14Z,oh! :exploding_head: ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:50:39Z,:heart: ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:51:09Z,and return a list of spans (after recent changes),81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:07:20Z,liked the previous lines more :( ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:07:45Z,:chefkiss:,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:09:02Z,:exploding_head: ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:09:42Z,oh glad it is moved here!,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:11:44Z,"I wonder ... we allow replacy to use any nlp, but we require en_core_web_sm in tests? :grimacing: 
It is ok?",81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T00:12:04Z,:grimacing: ,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:48:38Z,"my editor complained, and I thought... yeah, you are right editor, inflector is not defined!",81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:49:45Z,I moved it out into `utils` but some projects using replacy call it via `ReplaceMatcher.validate_match_dict` so I wanted to attach it to the class here (which makes it a static method),81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:51:34Z,"this wasn't a bug, it was just, I wanted to make the components have inputs and outputs, instead of using class properties",81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:52:07Z,We should add tests with other languages!,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:52:20Z,gotta have my dumb IDs,81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-21T23:34:20Z,"@melisa-qordoba Here is how this would be used for #80 

https://github.com/Qordobacode/replaCy/issues/80#issuecomment-696434960",81
github.com/writerai/replaCy,tests/test_pipeline.py,2020-09-22T18:52:47Z,I installed this version of replaCy in a downstream project (Clarity) and the test suite still passes 💪 ,81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-21T23:42:38Z,"""times before the spellcheck in vscode"" :grimacing: ",81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-21T23:43:08Z,what does it do? :thinking: ,81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-21T23:48:14Z,oh! :exploding_head: ,81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-21T23:50:39Z,:heart: ,81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-21T23:51:09Z,and return a list of spans (after recent changes),81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-22T00:07:20Z,liked the previous lines more :( ,81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-22T00:07:45Z,:chefkiss:,81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-22T00:09:02Z,:exploding_head: ,81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-22T00:09:42Z,oh glad it is moved here!,81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-22T00:11:44Z,"I wonder ... we allow replacy to use any nlp, but we require en_core_web_sm in tests? :grimacing: 
It is ok?",81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-22T00:12:04Z,:grimacing: ,81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-22T18:48:38Z,"my editor complained, and I thought... yeah, you are right editor, inflector is not defined!",81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-22T18:49:45Z,I moved it out into `utils` but some projects using replacy call it via `ReplaceMatcher.validate_match_dict` so I wanted to attach it to the class here (which makes it a static method),81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-22T18:51:34Z,"this wasn't a bug, it was just, I wanted to make the components have inputs and outputs, instead of using class properties",81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-22T18:52:07Z,We should add tests with other languages!,81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-22T18:52:20Z,gotta have my dumb IDs,81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-21T23:34:20Z,"@melisa-qordoba Here is how this would be used for #80 

https://github.com/Qordobacode/replaCy/issues/80#issuecomment-696434960",81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-22T18:52:47Z,I installed this version of replaCy in a downstream project (Clarity) and the test suite still passes 💪 ,81
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T19:18:52Z,"not sure this is a reasonable criteria, I guess I have to look at a bigger match dict...",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T19:23:59Z,"this isn't blocking. It seems like you had to do a lot of list-membership checking, and used sets, when there are ways that are more :snek:

This one, for example, feels less-pythonic than

```suggestion
            if any([article in item_options for article in [""a"", ""an"", ""the""]]):
```",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:05:17Z,"again, non-blocking style thing. I think this is the same as:

```suggestion
            if all([el in item_options for el in [""person"", ""people""]]) or all([el in item_options for el in [""ox"", ""oxen""]]):
                return 1
```

Since I am mathy, set operations make sense (and I know the Python syntax for intersection with `&`) but it may be more obvious to use `all`?",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:18:11Z,wait the lemmas are different? are we testing this just to document the weirdness?,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:18:49Z,"`plural` and `singular` switched for all of these, not that it matters (but since it's open thought you'd want to know)",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:19:16Z,Can we have a test case that uses `MAX_COUNT`?,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:19:39Z,I like little classes like this,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:59:39Z,"Here is an example where multi-token does not imply max count one:
https://github.com/Qordobacode/service.inclusivity/blob/master/service_inclusivity/resources/match_dicts/age_matches.json#L934-L935

But I thought I would find more... ",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:00:18Z,"I think I would err on the side of having replaCy assume less, and us having to do more work in the match_dicts to upgrade",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:02:20Z,"not a recommendation, but fun fact: this can be written `lemmas |= option_lemmas`",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:47:57Z,:chefkiss:,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:55:07Z,Good catch! :+1: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:56:11Z,"This is different for people / person and on / oxen.
But you are right - added xfail cases to the test.
Now, whenever we upgrade lemminflect, we can check whether lemmatization of irregular words is the same.",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:56:29Z,:smiley: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T22:34:30Z,done :+1: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T22:39:43Z,"Hmm I would rewrite that match to:
```
{""TEXT"": ""who is""},
{""TEXT"": [""single"", ""unmarried""]}
```
Then those rules would be ok :smile: 
But yeah, I agree suppression might be confusing, and some matches will need rewrites.
I promise to:
- add suppression warnings
- check `match_dicts` in dependent services
- rethink how to make those criteria better.

In other words... let's :shipit: , then fix the reality :rofl: ",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T22:42:35Z,Same applies here. Done for fast :shipit: Let's make it better ... later :sweat_smile: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T23:32:12Z,added simple logging :sweat_smile: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T19:18:52Z,"not sure this is a reasonable criteria, I guess I have to look at a bigger match dict...",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T19:23:59Z,"this isn't blocking. It seems like you had to do a lot of list-membership checking, and used sets, when there are ways that are more :snek:

This one, for example, feels less-pythonic than

```suggestion
            if any([article in item_options for article in [""a"", ""an"", ""the""]]):
```",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:05:17Z,"again, non-blocking style thing. I think this is the same as:

```suggestion
            if all([el in item_options for el in [""person"", ""people""]]) or all([el in item_options for el in [""ox"", ""oxen""]]):
                return 1
```

Since I am mathy, set operations make sense (and I know the Python syntax for intersection with `&`) but it may be more obvious to use `all`?",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:18:11Z,wait the lemmas are different? are we testing this just to document the weirdness?,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:18:49Z,"`plural` and `singular` switched for all of these, not that it matters (but since it's open thought you'd want to know)",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:19:16Z,Can we have a test case that uses `MAX_COUNT`?,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:19:39Z,I like little classes like this,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:59:39Z,"Here is an example where multi-token does not imply max count one:
https://github.com/Qordobacode/service.inclusivity/blob/master/service_inclusivity/resources/match_dicts/age_matches.json#L934-L935

But I thought I would find more... ",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:00:18Z,"I think I would err on the side of having replaCy assume less, and us having to do more work in the match_dicts to upgrade",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:02:20Z,"not a recommendation, but fun fact: this can be written `lemmas |= option_lemmas`",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:47:57Z,:chefkiss:,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:55:07Z,Good catch! :+1: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:56:11Z,"This is different for people / person and on / oxen.
But you are right - added xfail cases to the test.
Now, whenever we upgrade lemminflect, we can check whether lemmatization of irregular words is the same.",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:56:29Z,:smiley: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T22:34:30Z,done :+1: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T22:39:43Z,"Hmm I would rewrite that match to:
```
{""TEXT"": ""who is""},
{""TEXT"": [""single"", ""unmarried""]}
```
Then those rules would be ok :smile: 
But yeah, I agree suppression might be confusing, and some matches will need rewrites.
I promise to:
- add suppression warnings
- check `match_dicts` in dependent services
- rethink how to make those criteria better.

In other words... let's :shipit: , then fix the reality :rofl: ",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T22:42:35Z,Same applies here. Done for fast :shipit: Let's make it better ... later :sweat_smile: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T23:32:12Z,added simple logging :sweat_smile: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T19:18:52Z,"not sure this is a reasonable criteria, I guess I have to look at a bigger match dict...",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T19:23:59Z,"this isn't blocking. It seems like you had to do a lot of list-membership checking, and used sets, when there are ways that are more :snek:

This one, for example, feels less-pythonic than

```suggestion
            if any([article in item_options for article in [""a"", ""an"", ""the""]]):
```",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:05:17Z,"again, non-blocking style thing. I think this is the same as:

```suggestion
            if all([el in item_options for el in [""person"", ""people""]]) or all([el in item_options for el in [""ox"", ""oxen""]]):
                return 1
```

Since I am mathy, set operations make sense (and I know the Python syntax for intersection with `&`) but it may be more obvious to use `all`?",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:18:11Z,wait the lemmas are different? are we testing this just to document the weirdness?,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:18:49Z,"`plural` and `singular` switched for all of these, not that it matters (but since it's open thought you'd want to know)",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:19:16Z,Can we have a test case that uses `MAX_COUNT`?,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:19:39Z,I like little classes like this,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:59:39Z,"Here is an example where multi-token does not imply max count one:
https://github.com/Qordobacode/service.inclusivity/blob/master/service_inclusivity/resources/match_dicts/age_matches.json#L934-L935

But I thought I would find more... ",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:00:18Z,"I think I would err on the side of having replaCy assume less, and us having to do more work in the match_dicts to upgrade",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:02:20Z,"not a recommendation, but fun fact: this can be written `lemmas |= option_lemmas`",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:47:57Z,:chefkiss:,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:55:07Z,Good catch! :+1: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:56:11Z,"This is different for people / person and on / oxen.
But you are right - added xfail cases to the test.
Now, whenever we upgrade lemminflect, we can check whether lemmatization of irregular words is the same.",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:56:29Z,:smiley: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T22:34:30Z,done :+1: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T22:39:43Z,"Hmm I would rewrite that match to:
```
{""TEXT"": ""who is""},
{""TEXT"": [""single"", ""unmarried""]}
```
Then those rules would be ok :smile: 
But yeah, I agree suppression might be confusing, and some matches will need rewrites.
I promise to:
- add suppression warnings
- check `match_dicts` in dependent services
- rethink how to make those criteria better.

In other words... let's :shipit: , then fix the reality :rofl: ",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T22:42:35Z,Same applies here. Done for fast :shipit: Let's make it better ... later :sweat_smile: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T23:32:12Z,added simple logging :sweat_smile: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T19:18:52Z,"not sure this is a reasonable criteria, I guess I have to look at a bigger match dict...",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T19:23:59Z,"this isn't blocking. It seems like you had to do a lot of list-membership checking, and used sets, when there are ways that are more :snek:

This one, for example, feels less-pythonic than

```suggestion
            if any([article in item_options for article in [""a"", ""an"", ""the""]]):
```",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:05:17Z,"again, non-blocking style thing. I think this is the same as:

```suggestion
            if all([el in item_options for el in [""person"", ""people""]]) or all([el in item_options for el in [""ox"", ""oxen""]]):
                return 1
```

Since I am mathy, set operations make sense (and I know the Python syntax for intersection with `&`) but it may be more obvious to use `all`?",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:18:11Z,wait the lemmas are different? are we testing this just to document the weirdness?,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:18:49Z,"`plural` and `singular` switched for all of these, not that it matters (but since it's open thought you'd want to know)",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:19:16Z,Can we have a test case that uses `MAX_COUNT`?,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:19:39Z,I like little classes like this,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:59:39Z,"Here is an example where multi-token does not imply max count one:
https://github.com/Qordobacode/service.inclusivity/blob/master/service_inclusivity/resources/match_dicts/age_matches.json#L934-L935

But I thought I would find more... ",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:00:18Z,"I think I would err on the side of having replaCy assume less, and us having to do more work in the match_dicts to upgrade",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:02:20Z,"not a recommendation, but fun fact: this can be written `lemmas |= option_lemmas`",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:47:57Z,:chefkiss:,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:55:07Z,Good catch! :+1: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:56:11Z,"This is different for people / person and on / oxen.
But you are right - added xfail cases to the test.
Now, whenever we upgrade lemminflect, we can check whether lemmatization of irregular words is the same.",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:56:29Z,:smiley: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T22:34:30Z,done :+1: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T22:39:43Z,"Hmm I would rewrite that match to:
```
{""TEXT"": ""who is""},
{""TEXT"": [""single"", ""unmarried""]}
```
Then those rules would be ok :smile: 
But yeah, I agree suppression might be confusing, and some matches will need rewrites.
I promise to:
- add suppression warnings
- check `match_dicts` in dependent services
- rethink how to make those criteria better.

In other words... let's :shipit: , then fix the reality :rofl: ",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T22:42:35Z,Same applies here. Done for fast :shipit: Let's make it better ... later :sweat_smile: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T23:32:12Z,added simple logging :sweat_smile: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T19:18:52Z,"not sure this is a reasonable criteria, I guess I have to look at a bigger match dict...",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T19:23:59Z,"this isn't blocking. It seems like you had to do a lot of list-membership checking, and used sets, when there are ways that are more :snek:

This one, for example, feels less-pythonic than

```suggestion
            if any([article in item_options for article in [""a"", ""an"", ""the""]]):
```",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:05:17Z,"again, non-blocking style thing. I think this is the same as:

```suggestion
            if all([el in item_options for el in [""person"", ""people""]]) or all([el in item_options for el in [""ox"", ""oxen""]]):
                return 1
```

Since I am mathy, set operations make sense (and I know the Python syntax for intersection with `&`) but it may be more obvious to use `all`?",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:18:11Z,wait the lemmas are different? are we testing this just to document the weirdness?,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:18:49Z,"`plural` and `singular` switched for all of these, not that it matters (but since it's open thought you'd want to know)",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:19:16Z,Can we have a test case that uses `MAX_COUNT`?,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:19:39Z,I like little classes like this,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T20:59:39Z,"Here is an example where multi-token does not imply max count one:
https://github.com/Qordobacode/service.inclusivity/blob/master/service_inclusivity/resources/match_dicts/age_matches.json#L934-L935

But I thought I would find more... ",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:00:18Z,"I think I would err on the side of having replaCy assume less, and us having to do more work in the match_dicts to upgrade",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:02:20Z,"not a recommendation, but fun fact: this can be written `lemmas |= option_lemmas`",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:47:57Z,:chefkiss:,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:55:07Z,Good catch! :+1: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:56:11Z,"This is different for people / person and on / oxen.
But you are right - added xfail cases to the test.
Now, whenever we upgrade lemminflect, we can check whether lemmatization of irregular words is the same.",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T21:56:29Z,:smiley: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T22:34:30Z,done :+1: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T22:39:43Z,"Hmm I would rewrite that match to:
```
{""TEXT"": ""who is""},
{""TEXT"": [""single"", ""unmarried""]}
```
Then those rules would be ok :smile: 
But yeah, I agree suppression might be confusing, and some matches will need rewrites.
I promise to:
- add suppression warnings
- check `match_dicts` in dependent services
- rethink how to make those criteria better.

In other words... let's :shipit: , then fix the reality :rofl: ",78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T22:42:35Z,Same applies here. Done for fast :shipit: Let's make it better ... later :sweat_smile: ,78
github.com/writerai/replaCy,tests/test_max_count.py,2020-09-09T23:32:12Z,added simple logging :sweat_smile: ,78
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-21T23:42:38Z,"""times before the spellcheck in vscode"" :grimacing: ",81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-21T23:43:08Z,what does it do? :thinking: ,81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-21T23:48:14Z,oh! :exploding_head: ,81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-21T23:50:39Z,:heart: ,81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-21T23:51:09Z,and return a list of spans (after recent changes),81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-22T00:07:20Z,liked the previous lines more :( ,81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-22T00:07:45Z,:chefkiss:,81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-22T00:09:02Z,:exploding_head: ,81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-22T00:09:42Z,oh glad it is moved here!,81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-22T00:11:44Z,"I wonder ... we allow replacy to use any nlp, but we require en_core_web_sm in tests? :grimacing: 
It is ok?",81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-22T00:12:04Z,:grimacing: ,81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-22T18:48:38Z,"my editor complained, and I thought... yeah, you are right editor, inflector is not defined!",81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-22T18:49:45Z,I moved it out into `utils` but some projects using replacy call it via `ReplaceMatcher.validate_match_dict` so I wanted to attach it to the class here (which makes it a static method),81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-22T18:51:34Z,"this wasn't a bug, it was just, I wanted to make the components have inputs and outputs, instead of using class properties",81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-22T18:52:07Z,We should add tests with other languages!,81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-22T18:52:20Z,gotta have my dumb IDs,81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-21T23:34:20Z,"@melisa-qordoba Here is how this would be used for #80 

https://github.com/Qordobacode/replaCy/issues/80#issuecomment-696434960",81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-09-22T18:52:47Z,I installed this version of replaCy in a downstream project (Clarity) and the test suite still passes 💪 ,81
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-26T15:54:13Z,"can we put this import in `get_default_lm`? If they don't want to use the LM, we shouldn't die if it isn't installed",63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-26T17:14:03Z,"These 2 parameters are so we can build the LM stuff,
```python
self.scorer = KenLMScorer(nlp=self.nlp, model=get_default_lm(testing=testing)) if use_lm else None
```

Now that I see that, it seems like directly passing in a `scorer` is cleaner (""Dependency Injection"")",63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-26T17:16:20Z,"that is outdated, but same idea: can we put this in `load_lm` ?",63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-29T12:36:49Z,done :ok_hand: ,63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-29T12:37:30Z,Yes! Bonus: using lm is optional now.,63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-29T17:31:07Z,:yay:,63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-29T17:31:21Z,more :yay:,63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-29T17:32:00Z,"```suggestion
Speed and accuracy benchmark (copied from the Lemminflect repo):
```",63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-29T17:32:31Z,even more :yay:!,63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-29T22:43:08Z,"Sorry, I don't really know if my code samples are right, since I don't know the type signatures

`self.scorer` is `None` if there is no `KenLM`... Should we have the line that sets it be :

```python
self.scorer = (
            KenLMScorer(nlp=self.nlp, model=load_lm(lm_path)) if lm_path else lambda x: 1
        )
```

e.g. set it to the constant function?

Or, if there is more than 1 suggestion, maybe `sort_suggestions` should have behavior that depends on `self.scorer`... meaning ""if it's None, either don't change the order, or randomize it""",63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-30T07:56:03Z,"Can you reproduce the bug?

Sorting and scoring happens only if there is the scorer, otherwise this step is completely skipped:
https://github.com/Qordobacode/replaCy/blob/c6eb41fba0b430c95b1feee5261807df716b3151/replacy/__init__.py#L392

I think I disagree with randomizing suggestions since this doesn't look like a desired behavior before adding `kenlm` - what if users want to manually set the order of suggestions (because they feel some options will be better)?",63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-30T08:00:22Z,Take a look at `tests/test_suggestions.py`. This is the case when there is no `lm_path`.,63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-30T16:07:46Z,I see,63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-26T22:36:51Z,"I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)
",63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-29T12:39:03Z,"> I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
> ![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)

Changed :ok_hand: 
Also did one update (after rethinking json schema). Backward compatible.

`INFLECTION` is always a string. You can set `POS`, `TAG` or `ALL`. ",63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-26T15:54:13Z,"can we put this import in `get_default_lm`? If they don't want to use the LM, we shouldn't die if it isn't installed",63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-26T17:14:03Z,"These 2 parameters are so we can build the LM stuff,
```python
self.scorer = KenLMScorer(nlp=self.nlp, model=get_default_lm(testing=testing)) if use_lm else None
```

Now that I see that, it seems like directly passing in a `scorer` is cleaner (""Dependency Injection"")",63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-26T17:16:20Z,"that is outdated, but same idea: can we put this in `load_lm` ?",63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-29T12:36:49Z,done :ok_hand: ,63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-29T12:37:30Z,Yes! Bonus: using lm is optional now.,63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-29T17:31:07Z,:yay:,63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-29T17:31:21Z,more :yay:,63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-29T17:32:00Z,"```suggestion
Speed and accuracy benchmark (copied from the Lemminflect repo):
```",63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-29T17:32:31Z,even more :yay:!,63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-29T22:43:08Z,"Sorry, I don't really know if my code samples are right, since I don't know the type signatures

`self.scorer` is `None` if there is no `KenLM`... Should we have the line that sets it be :

```python
self.scorer = (
            KenLMScorer(nlp=self.nlp, model=load_lm(lm_path)) if lm_path else lambda x: 1
        )
```

e.g. set it to the constant function?

Or, if there is more than 1 suggestion, maybe `sort_suggestions` should have behavior that depends on `self.scorer`... meaning ""if it's None, either don't change the order, or randomize it""",63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-30T07:56:03Z,"Can you reproduce the bug?

Sorting and scoring happens only if there is the scorer, otherwise this step is completely skipped:
https://github.com/Qordobacode/replaCy/blob/c6eb41fba0b430c95b1feee5261807df716b3151/replacy/__init__.py#L392

I think I disagree with randomizing suggestions since this doesn't look like a desired behavior before adding `kenlm` - what if users want to manually set the order of suggestions (because they feel some options will be better)?",63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-30T08:00:22Z,Take a look at `tests/test_suggestions.py`. This is the case when there is no `lm_path`.,63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-30T16:07:46Z,I see,63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-26T22:36:51Z,"I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)
",63
github.com/writerai/replaCy,tests/test_suggestions.py,2020-06-29T12:39:03Z,"> I use the JSON Linter in VS Code, so I want to make sure we update the match schema, so I get rid of this warning:
> ![image](https://user-images.githubusercontent.com/47401552/85906333-d8f9a800-b7c2-11ea-88cf-7c0c5b529f5d.png)

Changed :ok_hand: 
Also did one update (after rethinking json schema). Backward compatible.

`INFLECTION` is always a string. You can set `POS`, `TAG` or `ALL`. ",63
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T19:18:52Z,"not sure this is a reasonable criteria, I guess I have to look at a bigger match dict...",78
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T19:23:59Z,"this isn't blocking. It seems like you had to do a lot of list-membership checking, and used sets, when there are ways that are more :snek:

This one, for example, feels less-pythonic than

```suggestion
            if any([article in item_options for article in [""a"", ""an"", ""the""]]):
```",78
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T20:05:17Z,"again, non-blocking style thing. I think this is the same as:

```suggestion
            if all([el in item_options for el in [""person"", ""people""]]) or all([el in item_options for el in [""ox"", ""oxen""]]):
                return 1
```

Since I am mathy, set operations make sense (and I know the Python syntax for intersection with `&`) but it may be more obvious to use `all`?",78
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T20:18:11Z,wait the lemmas are different? are we testing this just to document the weirdness?,78
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T20:18:49Z,"`plural` and `singular` switched for all of these, not that it matters (but since it's open thought you'd want to know)",78
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T20:19:16Z,Can we have a test case that uses `MAX_COUNT`?,78
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T20:19:39Z,I like little classes like this,78
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T20:59:39Z,"Here is an example where multi-token does not imply max count one:
https://github.com/Qordobacode/service.inclusivity/blob/master/service_inclusivity/resources/match_dicts/age_matches.json#L934-L935

But I thought I would find more... ",78
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T21:00:18Z,"I think I would err on the side of having replaCy assume less, and us having to do more work in the match_dicts to upgrade",78
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T21:02:20Z,"not a recommendation, but fun fact: this can be written `lemmas |= option_lemmas`",78
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T21:47:57Z,:chefkiss:,78
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T21:55:07Z,Good catch! :+1: ,78
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T21:56:11Z,"This is different for people / person and on / oxen.
But you are right - added xfail cases to the test.
Now, whenever we upgrade lemminflect, we can check whether lemmatization of irregular words is the same.",78
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T21:56:29Z,:smiley: ,78
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T22:34:30Z,done :+1: ,78
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T22:39:43Z,"Hmm I would rewrite that match to:
```
{""TEXT"": ""who is""},
{""TEXT"": [""single"", ""unmarried""]}
```
Then those rules would be ok :smile: 
But yeah, I agree suppression might be confusing, and some matches will need rewrites.
I promise to:
- add suppression warnings
- check `match_dicts` in dependent services
- rethink how to make those criteria better.

In other words... let's :shipit: , then fix the reality :rofl: ",78
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T22:42:35Z,Same applies here. Done for fast :shipit: Let's make it better ... later :sweat_smile: ,78
github.com/writerai/replaCy,tests/test_ref_matcher.py,2020-09-09T23:32:12Z,added simple logging :sweat_smile: ,78
github.com/writerai/replaCy,tests/test_custom_props.py,2020-02-28T23:58:17Z,:laughing: ,11
github.com/writerai/replaCy,tests/test_custom_props.py,2020-02-28T23:59:35Z,"oh, I must: `flat_map` ? ",11
github.com/writerai/replaCy,tests/test_custom_props.py,2020-02-29T00:08:18Z,:laughing: ,11
github.com/writerai/replaCy,tests/test_custom_props.py,2020-02-28T23:40:20Z,oh my god the part I thought would be easy is impossible :sob:,11
github.com/writerai/replaCy,tests/test_custom_props.py,2020-03-01T20:20:17Z,"Good point about flatmap! I built that iteratively, but didn’t optimize it",11
github.com/writerai/replaCy,tests/test_custom_props.py,2020-02-28T23:58:17Z,:laughing: ,11
github.com/writerai/replaCy,tests/test_custom_props.py,2020-02-28T23:59:35Z,"oh, I must: `flat_map` ? ",11
github.com/writerai/replaCy,tests/test_custom_props.py,2020-02-29T00:08:18Z,:laughing: ,11
github.com/writerai/replaCy,tests/test_custom_props.py,2020-02-28T23:40:20Z,oh my god the part I thought would be easy is impossible :sob:,11
github.com/writerai/replaCy,tests/test_custom_props.py,2020-03-01T20:20:17Z,"Good point about flatmap! I built that iteratively, but didn’t optimize it",11
github.com/writerai/replaCy,tests/test_custom_props.py,2020-02-28T23:58:17Z,:laughing: ,11
github.com/writerai/replaCy,tests/test_custom_props.py,2020-02-28T23:59:35Z,"oh, I must: `flat_map` ? ",11
github.com/writerai/replaCy,tests/test_custom_props.py,2020-02-29T00:08:18Z,:laughing: ,11
github.com/writerai/replaCy,tests/test_custom_props.py,2020-02-28T23:40:20Z,oh my god the part I thought would be easy is impossible :sob:,11
github.com/writerai/replaCy,tests/test_custom_props.py,2020-03-01T20:20:17Z,"Good point about flatmap! I built that iteratively, but didn’t optimize it",11
github.com/dpalmasan/TRUNAJOD2.0,stanza_example.py,2021-03-28T17:43:09Z,Nice,13
github.com/dpalmasan/TRUNAJOD2.0,stanza_example.py,2021-03-28T17:52:03Z,"I think to make easier further improvements to internals, we might create an extra module with the constants, something like:

```python
from enum import Enum


class SupportedModels(str, Enum):
    SPACY = ""spacy""
    STANZA = ""stanza""
```

Then in all instances we could use the enum. For example, the constructor arguments could be:

```python
def __init__(self, doc, model_name=""spacy""):
    # The following might do error checking on model name, will raise if not in Enum
    model = SupportedModels(model_name)

    # Checks could be done as
    if model == SupportedModels.SPACY:

```

In that manner, all instances could be replaced by something like `model=SupportedModels`",13
github.com/dpalmasan/TRUNAJOD2.0,stanza_example.py,2021-03-28T17:52:52Z,Nice!,13
github.com/dpalmasan/TRUNAJOD2.0,stanza_example.py,2021-03-28T19:19:23Z,"alright, I'll look into it",13
github.com/dpalmasan/TRUNAJOD2.0,stanza_example.py,2021-03-29T09:50:16Z,"I made a pull request and some summary:

1. TTR tests were failing due to the keyword and positional argument conflicts. This could be easily resolved by adding a positional argument to the testing function. The used NLP model still defaults to spaCy. On the user side, they won't have to think about the positional arguments unless they change the TTR segment value (0.72). 

2. Thanks for your suggestion on using the enum class. It simplifies a lot of internal matter. I implemented the function in utils.py. Other modules would then be able to call the class each time model verification is needed.

3. I changed the file name from ""stanza_test.py"" to ""stanza_example.py"" in the root directory.",13
github.com/dpalmasan/TRUNAJOD2.0,stanza_example.py,2021-03-29T13:57:23Z,"Hello @brucewlee , this looks pretty good. Could I ask just one last thing I forgot to mention previously. Could you install the `pre-commit` package (https://pre-commit.com/), so basically you follow these steps:

1. `pip install pre-commit`
2. In the root folder (where the `.pre-commit-config.yaml` file lives) run: `pre-commit install`
3. Then do a `git commit --amend` (this will just repush the last commit and will run pre-commit hooks)
4. Check if there is any pre-commit hook failing

Thanks in advance!",13
github.com/dpalmasan/TRUNAJOD2.0,stanza_example.py,2021-04-03T02:37:47Z,"> Hello @brucewlee , this looks pretty good. Could I ask just one last thing I forgot to mention previously. Could you install the `pre-commit` package (https://pre-commit.com/), so basically you follow these steps:
> 
> 1. `pip install pre-commit`
> 2. In the root folder (where the `.pre-commit-config.yaml` file lives) run: `pre-commit install`
> 3. Then do a `git commit --amend` (this will just repush the last commit and will run pre-commit hooks)
> 4. Check if there is any pre-commit hook failing
> 
> Thanks in advance!

Yup, I've tried this but I'm not sure what it does. Nothing seems to be failing nor changing.",13
github.com/dpalmasan/TRUNAJOD2.0,stanza_example.py,2021-04-03T11:54:07Z,"Okay, then we are good to go I guess. The pre-commit hooks are a set of checks that are run before committing, they just do some checks like running `flake8`, check import order, running the code formatter `black` to ensure code standardization. 
If they are all passing, then we are ready to merge, thanks for all the help!",13
github.com/dpalmasan/TRUNAJOD2.0,stanza_example.py,2021-04-03T11:58:32Z,I merged! thanks!,13
github.com/dpalmasan/TRUNAJOD2.0,stanza_example.py,2021-04-06T05:08:38Z,NP :),13
github.com/saulpw/readysetdata,readysetdata/wikipedia.py,2022-08-03T15:52:03Z,(is there a reason the versions aren't pinned in this requirements file?),4
github.com/saulpw/readysetdata,readysetdata/wikipedia.py,2022-08-04T04:13:12Z,"I think we should probably functionize this and call it from the existing pipeline, so we're not downloading/processing the entire corpus twice.  (We are planning to run all the code in readysetdata ourselves once a month or so, so it might make a material difference :)  And then we wouldn't need wikisummaries.sh, though we would need to figure how we'll split the stream in the other shell script.",4
github.com/saulpw/readysetdata,readysetdata/wikipedia.py,2022-08-04T19:07:00Z,"Thanks Saul -- note I just pushed a little fix, since when I ran it over the whole set I ran into a corner case that broke it!
",4
github.com/saulpw/readysetdata,readysetdata/wikipedia.py,2022-10-11T09:13:48Z,"Thanks Saul -- note I just pushed a little fix, since when I ran it over
the whole set I ran into a corner case that broke it!

On Wed, Aug 3, 2022 at 9:27 PM Saul Pwanson ***@***.***>
wrote:

> ***@***.**** requested changes on this pull request.
>
> This is awesome, @dougb5 <https://github.com/dougb5>, thanks for putting
> this together! I ran it and it worked like a charm. I'll also add an option
> to demux-jsonl to remove the signaling column, and think about how best
> to split the stream in the wikipedia.sh.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/saulpw/readysetdata/pull/4#pullrequestreview-1061263740>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAII7MMODRPKWYIYVFDBA7DVXNBCDANCNFSM55PLI7UA>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",4
github.com/saulpw/readysetdata,readysetdata/wikipedia.py,2022-08-03T15:52:03Z,(is there a reason the versions aren't pinned in this requirements file?),4
github.com/saulpw/readysetdata,readysetdata/wikipedia.py,2022-08-04T04:13:12Z,"I think we should probably functionize this and call it from the existing pipeline, so we're not downloading/processing the entire corpus twice.  (We are planning to run all the code in readysetdata ourselves once a month or so, so it might make a material difference :)  And then we wouldn't need wikisummaries.sh, though we would need to figure how we'll split the stream in the other shell script.",4
github.com/saulpw/readysetdata,readysetdata/wikipedia.py,2022-08-04T19:07:00Z,"Thanks Saul -- note I just pushed a little fix, since when I ran it over the whole set I ran into a corner case that broke it!
",4
github.com/saulpw/readysetdata,readysetdata/wikipedia.py,2022-10-11T09:13:48Z,"Thanks Saul -- note I just pushed a little fix, since when I ran it over
the whole set I ran into a corner case that broke it!

On Wed, Aug 3, 2022 at 9:27 PM Saul Pwanson ***@***.***>
wrote:

> ***@***.**** requested changes on this pull request.
>
> This is awesome, @dougb5 <https://github.com/dougb5>, thanks for putting
> this together! I ran it and it worked like a charm. I'll also add an option
> to demux-jsonl to remove the signaling column, and think about how best
> to split the stream in the wikipedia.sh.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/saulpw/readysetdata/pull/4#pullrequestreview-1061263740>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAII7MMODRPKWYIYVFDBA7DVXNBCDANCNFSM55PLI7UA>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",4
github.com/adieyal/dynamicprompts,src/dynamicprompts/generators/attentiongenerator.py,2023-05-23T15:24:35Z,"## [Codecov](https://app.codecov.io/gh/adieyal/dynamicprompts/pull/85?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=Adi+Eyal) Report
Patch coverage: **`85.71`**% and project coverage change: **`-0.04`** :warning:
> Comparison is base [(`c810884`)](https://app.codecov.io/gh/adieyal/dynamicprompts/commit/c810884fc96a9c2ef26eaae581587e004878bdfb?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=Adi+Eyal) 98.13% compared to head [(`4ca8d96`)](https://app.codecov.io/gh/adieyal/dynamicprompts/pull/85?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=Adi+Eyal) 98.10%.

:exclamation: Your organization is not using the GitHub App Integration. As a result you may experience degraded service beginning May 15th. Please [install the Github App Integration](https://github.com/apps/codecov) for your organization. [Read more](https://about.codecov.io/blog/codecov-is-updating-its-github-integration/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=Adi+Eyal).

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff             @@
##             main      #85      +/-   ##
==========================================
- Coverage   98.13%   98.10%   -0.04%     
==========================================
  Files          70       70              
  Lines        2838     2845       +7     
==========================================
+ Hits         2785     2791       +6     
- Misses         53       54       +1     
```


| [Impacted Files](https://app.codecov.io/gh/adieyal/dynamicprompts/pull/85?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=Adi+Eyal) | Coverage Δ | |
|---|---|---|
| [tests/generators/test\_attentiongenerator.py](https://app.codecov.io/gh/adieyal/dynamicprompts/pull/85?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=Adi+Eyal#diff-dGVzdHMvZ2VuZXJhdG9ycy90ZXN0X2F0dGVudGlvbmdlbmVyYXRvci5weQ==) | `100.00% <ø> (ø)` | |
| [...rc/dynamicprompts/generators/attentiongenerator.py](https://app.codecov.io/gh/adieyal/dynamicprompts/pull/85?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=Adi+Eyal#diff-c3JjL2R5bmFtaWNwcm9tcHRzL2dlbmVyYXRvcnMvYXR0ZW50aW9uZ2VuZXJhdG9yLnB5) | `89.36% <85.71%> (-0.39%)` | :arrow_down: |


</details>

[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/adieyal/dynamicprompts/pull/85?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=Adi+Eyal).   
:loudspeaker: Do you have feedback about the report comment? [Let us know in this issue](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=Adi+Eyal).
",85
github.com/adieyal/dynamicprompts,src/dynamicprompts/generators/attentiongenerator.py,2023-05-24T07:56:35Z,"@adieyal Sorry for the barrage of force-pushes, this should now be stable to review :)",85
github.com/adieyal/dynamicprompts,src/dynamicprompts/generators/attentiongenerator.py,2023-01-23T14:48:37Z,Thanks for this - always good to have someone look at your code with a more critical eye.,2
github.com/adieyal/dynamicprompts,src/dynamicprompts/generators/attentiongenerator.py,2023-01-23T16:16:48Z,"> Thanks for this - always good to have someone look at your code with a more critical eye.

You're welcome! I also have a couple of improvement ideas (PRs forthcoming 😁) but I thought it'd be nice to clean things up a bit first, so here we are. :)",2
github.com/adieyal/dynamicprompts,src/dynamicprompts/generators/attentiongenerator.py,2023-01-23T14:48:37Z,Thanks for this - always good to have someone look at your code with a more critical eye.,2
github.com/adieyal/dynamicprompts,src/dynamicprompts/generators/attentiongenerator.py,2023-01-23T16:16:48Z,"> Thanks for this - always good to have someone look at your code with a more critical eye.

You're welcome! I also have a couple of improvement ideas (PRs forthcoming 😁) but I thought it'd be nice to clean things up a bit first, so here we are. :)",2
github.com/adieyal/dynamicprompts,src/dynamicprompts/generators/attentiongenerator.py,2023-01-23T14:48:37Z,Thanks for this - always good to have someone look at your code with a more critical eye.,2
github.com/adieyal/dynamicprompts,src/dynamicprompts/generators/attentiongenerator.py,2023-01-23T16:16:48Z,"> Thanks for this - always good to have someone look at your code with a more critical eye.

You're welcome! I also have a couple of improvement ideas (PRs forthcoming 😁) but I thought it'd be nice to clean things up a bit first, so here we are. :)",2
github.com/adieyal/dynamicprompts,src/dynamicprompts/generators/attentiongenerator.py,2023-01-23T14:48:37Z,Thanks for this - always good to have someone look at your code with a more critical eye.,2
github.com/adieyal/dynamicprompts,src/dynamicprompts/generators/attentiongenerator.py,2023-01-23T16:16:48Z,"> Thanks for this - always good to have someone look at your code with a more critical eye.

You're welcome! I also have a couple of improvement ideas (PRs forthcoming 😁) but I thought it'd be nice to clean things up a bit first, so here we are. :)",2
github.com/tylerneylon/explacy,explacy.py,2018-11-29T13:31:16Z,"I tried run analysis on the sentence bellow when I found the problem:

`""Python é uma linguagem criada para ser simples. Com milhões de funções para os mais diferentes tipos de tarefas, essa linguagem de programação deixa fácil qualquer trabalho computacional. Além das inúmeras bibliotecas que atualmente existem para Python, outra característica que faz dessa linguagem uma simplicidade sem fim é a sua facilidade de criação em questão de sintaxe. Na sua simplicidade, Python é uma linguagem que muito se assemelha à forma em que estamos acostumados a descrever nossas ações, de forma tal que escrever um código não fica muito mais complexo do que escrever um texto comum.""`

[Source](https://medium.com/@thales.freitaz/usando-python-e-jupyter-notebook-f16ec1cadfa4)",1
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-05-21T18:03:02Z,"
[![Coverage Status](https://coveralls.io/builds/30951060/badge)](https://coveralls.io/builds/30951060)

Coverage increased (+0.2%) to 82.231% when pulling **de29f060bbbd564641c6f07e2860b50c768b8555 on marblestation:adsputils_v1.2.4** into **760b9ca8f68423e197692a480a7c2f72376727cc on adsabs:master**.
",125
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-05T20:56:25Z,"This looks quite similar to the next fulltext block, we could reduce code duplication with a function.",119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-05T20:57:34Z,Could we have here a race condition where some other worker overwrites things?,119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-05T21:01:01Z,"This block looks fairly similar to the next one, can we reduce code duplication if we put the if statement elsewhere?",119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-05T21:02:46Z,This is the only place where we call task_identify_facilities? Shouldn't it be called also after extraction? Otherwise extraction will not cause the NER to be executed.,119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-24T16:50:06Z,"You can do this:

```
for key, elem_str, model in zip(keys, ['facility-ack', 'facility-ft'], [model1, model2]):
    ...
```",119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-24T17:29:49Z,"We could simplify and not depend on a dictionary if we set up a task string:
```
if facility_ner and not force_extract:
  task_str = ""task_identify_facilities""
else:
  task_str = ""task_check_if_extract""
```
And then call it via:
```
getattr(tasks, task_str).delay(record)
```",119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-24T17:49:29Z,"We should use logger function options to format strings like we were doing before. If we have something like:
```
logger.debug(""Task: %s"" % (""test""))
```
The part `""Task: %s"" % (""test"")` will always be executed, even if the logging level is `INFO`. While if we do:
```
logger.debug(""Task: %s"", ""test"")
```
The formatting will only happen if the logging level is `DEBUG` or lower. This comments applies to all the logger calls.",119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-24T17:55:20Z,"Let's make this configurable via `config.py` such as:

```
if app.config['RUN_NER_FACILITIES_AFTER_EXTRACTION]:
    task_identify_facilities.delay(message)
```
And then we include it in config.py disabled by default:
```
RUN_NER_FACILITIES_AFTER_EXTRACTION=False
```
This way we can deploy without this, but we will still be able to manually run things if/when needed.",119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-24T21:04:31Z,"In run.py there is a mix of the two examples you listed as well as:
`logger.debug(""Task: {0}.format(""test"")"")`

Is `logger.debug(""Task: %s"", ""test"")` still preferred among the three? ",119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-02T13:02:29Z,"
[![Coverage Status](https://coveralls.io/builds/29592324/badge)](https://coveralls.io/builds/29592324)

Coverage increased (+0.1%) to 82.078% when pulling **0569fa9d5384c7f18b6424f3d857cbb1e6e82981 on krisbukovi:facility_ner** into **94759e26a0630918db1cf37fdd0dccdc3edd6720 on adsabs:master**.
",119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-05T20:56:25Z,"This looks quite similar to the next fulltext block, we could reduce code duplication with a function.",119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-05T20:57:34Z,Could we have here a race condition where some other worker overwrites things?,119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-05T21:01:01Z,"This block looks fairly similar to the next one, can we reduce code duplication if we put the if statement elsewhere?",119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-05T21:02:46Z,This is the only place where we call task_identify_facilities? Shouldn't it be called also after extraction? Otherwise extraction will not cause the NER to be executed.,119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-24T16:50:06Z,"You can do this:

```
for key, elem_str, model in zip(keys, ['facility-ack', 'facility-ft'], [model1, model2]):
    ...
```",119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-24T17:29:49Z,"We could simplify and not depend on a dictionary if we set up a task string:
```
if facility_ner and not force_extract:
  task_str = ""task_identify_facilities""
else:
  task_str = ""task_check_if_extract""
```
And then call it via:
```
getattr(tasks, task_str).delay(record)
```",119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-24T17:49:29Z,"We should use logger function options to format strings like we were doing before. If we have something like:
```
logger.debug(""Task: %s"" % (""test""))
```
The part `""Task: %s"" % (""test"")` will always be executed, even if the logging level is `INFO`. While if we do:
```
logger.debug(""Task: %s"", ""test"")
```
The formatting will only happen if the logging level is `DEBUG` or lower. This comments applies to all the logger calls.",119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-24T17:55:20Z,"Let's make this configurable via `config.py` such as:

```
if app.config['RUN_NER_FACILITIES_AFTER_EXTRACTION]:
    task_identify_facilities.delay(message)
```
And then we include it in config.py disabled by default:
```
RUN_NER_FACILITIES_AFTER_EXTRACTION=False
```
This way we can deploy without this, but we will still be able to manually run things if/when needed.",119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-24T21:04:31Z,"In run.py there is a mix of the two examples you listed as well as:
`logger.debug(""Task: {0}.format(""test"")"")`

Is `logger.debug(""Task: %s"", ""test"")` still preferred among the three? ",119
github.com/adsabs/ADSfulltext,adsft/ner.py,2020-03-02T13:02:29Z,"
[![Coverage Status](https://coveralls.io/builds/29592324/badge)](https://coveralls.io/builds/29592324)

Coverage increased (+0.1%) to 82.078% when pulling **0569fa9d5384c7f18b6424f3d857cbb1e6e82981 on krisbukovi:facility_ner** into **94759e26a0630918db1cf37fdd0dccdc3edd6720 on adsabs:master**.
",119
github.com/jayded/evidence-inference,evidence_inference/preprocess/sentence_split.py,2021-02-26T22:13:41Z,"@elehman16 @sanjanaramprasad @bwallace 

Merging on the public end.",16
github.com/jayded/evidence-inference,evidence_inference/preprocess/representations.py,2021-02-26T22:13:41Z,"@elehman16 @sanjanaramprasad @bwallace 

Merging on the public end.",16
github.com/jayded/evidence-inference,evidence_inference/preprocess/representations.py,2021-02-26T22:13:41Z,"@elehman16 @sanjanaramprasad @bwallace 

Merging on the public end.",16
github.com/crocs-muni/sec-certs,src/sec_certs/utils/strings.py,2023-04-11T12:13:41Z,"## [Codecov](https://codecov.io/gh/crocs-muni/sec-certs/pull/329?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) Report
Patch coverage: **`91.54`**% and project coverage change: **`+3.90`** :tada:
> Comparison is base [(`c0dc17e`)](https://codecov.io/gh/crocs-muni/sec-certs/commit/c0dc17e110e35d0fa67629750677560a86f8985e?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 72.96% compared to head [(`d5121e9`)](https://codecov.io/gh/crocs-muni/sec-certs/pull/329?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 76.85%.

> :exclamation: Current head d5121e9 differs from pull request most recent head 39439fe. Consider uploading reports for the commit 39439fe to get more accurate results

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff             @@
##             main     #329      +/-   ##
==========================================
+ Coverage   72.96%   76.85%   +3.90%     
==========================================
  Files          45       50       +5     
  Lines        5660     6391     +731     
==========================================
+ Hits         4129     4911     +782     
+ Misses       1531     1480      -51     
```


| [Impacted Files](https://codecov.io/gh/crocs-muni/sec-certs/pull/329?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) | Coverage Δ | |
|---|---|---|
| [src/sec\_certs/cli.py](https://codecov.io/gh/crocs-muni/sec-certs/pull/329?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9jbGkucHk=) | `0.00% <0.00%> (ø)` | |
| [src/sec\_certs/utils/strings.py](https://codecov.io/gh/crocs-muni/sec-certs/pull/329?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy91dGlscy9zdHJpbmdzLnB5) | `81.49% <81.49%> (ø)` | |
| [src/sec\_certs/sample/fips\_mip.py](https://codecov.io/gh/crocs-muni/sec-certs/pull/329?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9zYW1wbGUvZmlwc19taXAucHk=) | `91.83% <82.61%> (-1.08%)` | :arrow_down: |
| [src/sec\_certs/dataset/cc.py](https://codecov.io/gh/crocs-muni/sec-certs/pull/329?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9kYXRhc2V0L2NjLnB5) | `87.01% <86.37%> (+9.18%)` | :arrow_up: |
| [src/sec\_certs/model/cc\_matching.py](https://codecov.io/gh/crocs-muni/sec-certs/pull/329?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9jY19tYXRjaGluZy5weQ==) | `89.29% <89.29%> (ø)` | |
| [src/sec\_certs/model/fips\_matching.py](https://codecov.io/gh/crocs-muni/sec-certs/pull/329?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9maXBzX21hdGNoaW5nLnB5) | `91.43% <91.43%> (ø)` | |
| [src/sec\_certs/dataset/cc\_scheme.py](https://codecov.io/gh/crocs-muni/sec-certs/pull/329?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9kYXRhc2V0L2NjX3NjaGVtZS5weQ==) | `91.80% <91.80%> (ø)` | |
| [src/sec\_certs/model/matching.py](https://codecov.io/gh/crocs-muni/sec-certs/pull/329?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9tYXRjaGluZy5weQ==) | `94.45% <94.45%> (ø)` | |
| [src/sec\_certs/configuration.py](https://codecov.io/gh/crocs-muni/sec-certs/pull/329?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9jb25maWd1cmF0aW9uLnB5) | `91.67% <100.00%> (+0.37%)` | :arrow_up: |
| [src/sec\_certs/constants.py](https://codecov.io/gh/crocs-muni/sec-certs/pull/329?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9jb25zdGFudHMucHk=) | `100.00% <100.00%> (ø)` | |
| ... and [7 more](https://codecov.io/gh/crocs-muni/sec-certs/pull/329?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) | |

... and [2 files with indirect coverage changes](https://codecov.io/gh/crocs-muni/sec-certs/pull/329/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni)

Help us with your feedback. Take ten seconds to tell us [how you rate us](https://about.codecov.io/nps?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni). Have a feature suggestion? [Share it here.](https://app.codecov.io/gh/feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni)

</details>

[:umbrella: View full report in Codecov by Sentry](https://codecov.io/gh/crocs-muni/sec-certs/pull/329?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).   
:loudspeaker: Do you have feedback about the report comment? [Let us know in this issue](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).
",329
github.com/crocs-muni/sec-certs,src/sec_certs/utils/strings.py,2023-04-20T21:47:07Z,All green :heavy_check_mark: les gooo!!,329
github.com/crocs-muni/sec-certs,src/sec_certs/model/references_nlp/segment_extractor.py,2024-02-08T00:31:40Z,"## [Codecov](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/389?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) Report
Attention: `48 lines` in your changes are missing coverage. Please review.
> Comparison is base [(`131489e`)](https://app.codecov.io/gh/crocs-muni/sec-certs/commit/131489e8a1f32d5119fbb2a1283827fe6f045c74?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 69.61% compared to head [(`4592f97`)](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/389?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 68.57%.

| [Files](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/389?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) | Patch % | Lines |
|---|---|---|
| [src/sec\_certs/sample/cc.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/389?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9zYW1wbGUvY2MucHk=) | 76.60% | [44 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/389?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [...ec\_certs/model/references\_nlp/segment\_extractor.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/389?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9zZWdtZW50X2V4dHJhY3Rvci5weQ==) | 0.00% | [3 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/389?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/dataset/cc.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/389?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9kYXRhc2V0L2NjLnB5) | 98.00% | [1 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/389?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff             @@
##             main     #389      +/-   ##
==========================================
- Coverage   69.61%   68.57%   -1.04%     
==========================================
  Files          62       62              
  Lines        7548     7565      +17     
==========================================
- Hits         5254     5187      -67     
- Misses       2294     2378      +84     
```



</details>

[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/389?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).   
:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).
",389
github.com/crocs-muni/sec-certs,src/sec_certs/model/references_nlp/segment_extractor.py,2023-03-23T11:00:23Z,"## [Codecov](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) Report
Attention: `675 lines` in your changes are missing coverage. Please review.
> Comparison is base [(`f0f7fa7`)](https://app.codecov.io/gh/crocs-muni/sec-certs/commit/f0f7fa7e6784afefb945effbc9834209a673db47?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 74.61% compared to head [(`68b1c2d`)](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 67.80%.

> :exclamation: Current head 68b1c2d differs from pull request most recent head b648241. Consider uploading reports for the commit b648241 to get more accurate results

| [Files](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) | Patch % | Lines |
|---|---|---|
| [...c\_certs/model/references\_nlp/feature\_extraction.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9mZWF0dXJlX2V4dHJhY3Rpb24ucHk=) | 0.00% | [266 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [...ec\_certs/model/references\_nlp/segment\_extractor.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9zZWdtZW50X2V4dHJhY3Rvci5weQ==) | 0.00% | [154 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [...ec\_certs/model/references\_nlp/annotator\_trainer.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9hbm5vdGF0b3JfdHJhaW5lci5weQ==) | 0.00% | [80 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/annotator.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9hbm5vdGF0b3IucHk=) | 0.00% | [56 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/evaluation.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9ldmFsdWF0aW9uLnB5) | 0.00% | [50 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/training.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC90cmFpbmluZy5weQ==) | 0.00% | [37 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/utils/nlp.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy91dGlscy9ubHAucHk=) | 0.00% | [20 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/\_\_init\_\_.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9fX2luaXRfXy5weQ==) | 0.00% | [10 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/dataset/cc.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9kYXRhc2V0L2NjLnB5) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/sample/cc\_certificate\_id.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9zYW1wbGUvY2NfY2VydGlmaWNhdGVfaWQucHk=) | 85.72% | [1 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff             @@
##             main     #322      +/-   ##
==========================================
- Coverage   74.61%   67.80%   -6.80%     
==========================================
  Files          54       62       +8     
  Lines        6709     7394     +685     
==========================================
+ Hits         5005     5013       +8     
- Misses       1704     2381     +677     
```



</details>

[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).   
:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).
",322
github.com/crocs-muni/sec-certs,src/sec_certs/model/references_nlp/segment_extractor.py,2023-11-14T12:57:38Z,"Just a quick comment on the current state of affairs:
- Soon, hyperparameter tunning will be done. Scripts for hyperparam tuning will not be versioned, I'll back them up separately at GDrive
- I don't think that the annotation engine is production-ready. For that reason, I kept the necessary files in `sec_certs.model.references_nlp` package that has some complex dependencies. Any import from that package requires `sec-certs` installation with `[nlp]` extra. A check is done on any import from that package.
- This requires that all `nlp` deps are also installed on dev machines -- otherwise, linters will likely complain
- In summary, this PR adds:
    - Backend for Reference annotations
    - Notebooks with reference annotation analysis
    - Versioned manual annotations, scripts to measure inter-annotator agreement",322
github.com/crocs-muni/sec-certs,src/sec_certs/model/references_nlp/segment_extractor.py,2023-03-23T11:00:23Z,"## [Codecov](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) Report
Attention: `675 lines` in your changes are missing coverage. Please review.
> Comparison is base [(`f0f7fa7`)](https://app.codecov.io/gh/crocs-muni/sec-certs/commit/f0f7fa7e6784afefb945effbc9834209a673db47?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 74.61% compared to head [(`68b1c2d`)](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 67.80%.

> :exclamation: Current head 68b1c2d differs from pull request most recent head b648241. Consider uploading reports for the commit b648241 to get more accurate results

| [Files](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) | Patch % | Lines |
|---|---|---|
| [...c\_certs/model/references\_nlp/feature\_extraction.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9mZWF0dXJlX2V4dHJhY3Rpb24ucHk=) | 0.00% | [266 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [...ec\_certs/model/references\_nlp/segment\_extractor.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9zZWdtZW50X2V4dHJhY3Rvci5weQ==) | 0.00% | [154 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [...ec\_certs/model/references\_nlp/annotator\_trainer.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9hbm5vdGF0b3JfdHJhaW5lci5weQ==) | 0.00% | [80 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/annotator.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9hbm5vdGF0b3IucHk=) | 0.00% | [56 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/evaluation.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9ldmFsdWF0aW9uLnB5) | 0.00% | [50 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/training.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC90cmFpbmluZy5weQ==) | 0.00% | [37 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/utils/nlp.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy91dGlscy9ubHAucHk=) | 0.00% | [20 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/\_\_init\_\_.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9fX2luaXRfXy5weQ==) | 0.00% | [10 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/dataset/cc.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9kYXRhc2V0L2NjLnB5) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/sample/cc\_certificate\_id.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9zYW1wbGUvY2NfY2VydGlmaWNhdGVfaWQucHk=) | 85.72% | [1 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff             @@
##             main     #322      +/-   ##
==========================================
- Coverage   74.61%   67.80%   -6.80%     
==========================================
  Files          54       62       +8     
  Lines        6709     7394     +685     
==========================================
+ Hits         5005     5013       +8     
- Misses       1704     2381     +677     
```



</details>

[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).   
:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).
",322
github.com/crocs-muni/sec-certs,src/sec_certs/model/references_nlp/segment_extractor.py,2023-11-14T12:57:38Z,"Just a quick comment on the current state of affairs:
- Soon, hyperparameter tunning will be done. Scripts for hyperparam tuning will not be versioned, I'll back them up separately at GDrive
- I don't think that the annotation engine is production-ready. For that reason, I kept the necessary files in `sec_certs.model.references_nlp` package that has some complex dependencies. Any import from that package requires `sec-certs` installation with `[nlp]` extra. A check is done on any import from that package.
- This requires that all `nlp` deps are also installed on dev machines -- otherwise, linters will likely complain
- In summary, this PR adds:
    - Backend for Reference annotations
    - Notebooks with reference annotation analysis
    - Versioned manual annotations, scripts to measure inter-annotator agreement",322
github.com/crocs-muni/sec-certs,src/sec_certs/model/references_nlp/segment_extractor.py,2023-03-23T11:00:23Z,"## [Codecov](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) Report
Attention: `675 lines` in your changes are missing coverage. Please review.
> Comparison is base [(`f0f7fa7`)](https://app.codecov.io/gh/crocs-muni/sec-certs/commit/f0f7fa7e6784afefb945effbc9834209a673db47?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 74.61% compared to head [(`68b1c2d`)](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 67.80%.

> :exclamation: Current head 68b1c2d differs from pull request most recent head b648241. Consider uploading reports for the commit b648241 to get more accurate results

| [Files](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) | Patch % | Lines |
|---|---|---|
| [...c\_certs/model/references\_nlp/feature\_extraction.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9mZWF0dXJlX2V4dHJhY3Rpb24ucHk=) | 0.00% | [266 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [...ec\_certs/model/references\_nlp/segment\_extractor.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9zZWdtZW50X2V4dHJhY3Rvci5weQ==) | 0.00% | [154 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [...ec\_certs/model/references\_nlp/annotator\_trainer.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9hbm5vdGF0b3JfdHJhaW5lci5weQ==) | 0.00% | [80 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/annotator.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9hbm5vdGF0b3IucHk=) | 0.00% | [56 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/evaluation.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9ldmFsdWF0aW9uLnB5) | 0.00% | [50 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/training.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC90cmFpbmluZy5weQ==) | 0.00% | [37 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/utils/nlp.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy91dGlscy9ubHAucHk=) | 0.00% | [20 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/\_\_init\_\_.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9fX2luaXRfXy5weQ==) | 0.00% | [10 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/dataset/cc.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9kYXRhc2V0L2NjLnB5) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/sample/cc\_certificate\_id.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9zYW1wbGUvY2NfY2VydGlmaWNhdGVfaWQucHk=) | 85.72% | [1 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff             @@
##             main     #322      +/-   ##
==========================================
- Coverage   74.61%   67.80%   -6.80%     
==========================================
  Files          54       62       +8     
  Lines        6709     7394     +685     
==========================================
+ Hits         5005     5013       +8     
- Misses       1704     2381     +677     
```



</details>

[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).   
:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).
",322
github.com/crocs-muni/sec-certs,src/sec_certs/model/references_nlp/segment_extractor.py,2023-11-14T12:57:38Z,"Just a quick comment on the current state of affairs:
- Soon, hyperparameter tunning will be done. Scripts for hyperparam tuning will not be versioned, I'll back them up separately at GDrive
- I don't think that the annotation engine is production-ready. For that reason, I kept the necessary files in `sec_certs.model.references_nlp` package that has some complex dependencies. Any import from that package requires `sec-certs` installation with `[nlp]` extra. A check is done on any import from that package.
- This requires that all `nlp` deps are also installed on dev machines -- otherwise, linters will likely complain
- In summary, this PR adds:
    - Backend for Reference annotations
    - Notebooks with reference annotation analysis
    - Versioned manual annotations, scripts to measure inter-annotator agreement",322
github.com/crocs-muni/sec-certs,src/sec_certs/model/references_nlp/segment_extractor.py,2023-03-23T11:00:23Z,"## [Codecov](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) Report
Attention: `675 lines` in your changes are missing coverage. Please review.
> Comparison is base [(`f0f7fa7`)](https://app.codecov.io/gh/crocs-muni/sec-certs/commit/f0f7fa7e6784afefb945effbc9834209a673db47?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 74.61% compared to head [(`68b1c2d`)](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 67.80%.

> :exclamation: Current head 68b1c2d differs from pull request most recent head b648241. Consider uploading reports for the commit b648241 to get more accurate results

| [Files](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) | Patch % | Lines |
|---|---|---|
| [...c\_certs/model/references\_nlp/feature\_extraction.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9mZWF0dXJlX2V4dHJhY3Rpb24ucHk=) | 0.00% | [266 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [...ec\_certs/model/references\_nlp/segment\_extractor.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9zZWdtZW50X2V4dHJhY3Rvci5weQ==) | 0.00% | [154 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [...ec\_certs/model/references\_nlp/annotator\_trainer.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9hbm5vdGF0b3JfdHJhaW5lci5weQ==) | 0.00% | [80 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/annotator.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9hbm5vdGF0b3IucHk=) | 0.00% | [56 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/evaluation.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9ldmFsdWF0aW9uLnB5) | 0.00% | [50 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/training.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC90cmFpbmluZy5weQ==) | 0.00% | [37 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/utils/nlp.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy91dGlscy9ubHAucHk=) | 0.00% | [20 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/\_\_init\_\_.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9fX2luaXRfXy5weQ==) | 0.00% | [10 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/dataset/cc.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9kYXRhc2V0L2NjLnB5) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/sample/cc\_certificate\_id.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9zYW1wbGUvY2NfY2VydGlmaWNhdGVfaWQucHk=) | 85.72% | [1 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff             @@
##             main     #322      +/-   ##
==========================================
- Coverage   74.61%   67.80%   -6.80%     
==========================================
  Files          54       62       +8     
  Lines        6709     7394     +685     
==========================================
+ Hits         5005     5013       +8     
- Misses       1704     2381     +677     
```



</details>

[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).   
:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).
",322
github.com/crocs-muni/sec-certs,src/sec_certs/model/references_nlp/segment_extractor.py,2023-11-14T12:57:38Z,"Just a quick comment on the current state of affairs:
- Soon, hyperparameter tunning will be done. Scripts for hyperparam tuning will not be versioned, I'll back them up separately at GDrive
- I don't think that the annotation engine is production-ready. For that reason, I kept the necessary files in `sec_certs.model.references_nlp` package that has some complex dependencies. Any import from that package requires `sec-certs` installation with `[nlp]` extra. A check is done on any import from that package.
- This requires that all `nlp` deps are also installed on dev machines -- otherwise, linters will likely complain
- In summary, this PR adds:
    - Backend for Reference annotations
    - Notebooks with reference annotation analysis
    - Versioned manual annotations, scripts to measure inter-annotator agreement",322
github.com/crocs-muni/sec-certs,src/sec_certs/model/references_nlp/feature_extraction.py,2023-03-23T11:00:23Z,"## [Codecov](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) Report
Attention: `675 lines` in your changes are missing coverage. Please review.
> Comparison is base [(`f0f7fa7`)](https://app.codecov.io/gh/crocs-muni/sec-certs/commit/f0f7fa7e6784afefb945effbc9834209a673db47?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 74.61% compared to head [(`68b1c2d`)](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 67.80%.

> :exclamation: Current head 68b1c2d differs from pull request most recent head b648241. Consider uploading reports for the commit b648241 to get more accurate results

| [Files](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) | Patch % | Lines |
|---|---|---|
| [...c\_certs/model/references\_nlp/feature\_extraction.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9mZWF0dXJlX2V4dHJhY3Rpb24ucHk=) | 0.00% | [266 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [...ec\_certs/model/references\_nlp/segment\_extractor.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9zZWdtZW50X2V4dHJhY3Rvci5weQ==) | 0.00% | [154 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [...ec\_certs/model/references\_nlp/annotator\_trainer.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9hbm5vdGF0b3JfdHJhaW5lci5weQ==) | 0.00% | [80 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/annotator.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9hbm5vdGF0b3IucHk=) | 0.00% | [56 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/evaluation.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9ldmFsdWF0aW9uLnB5) | 0.00% | [50 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/training.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC90cmFpbmluZy5weQ==) | 0.00% | [37 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/utils/nlp.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy91dGlscy9ubHAucHk=) | 0.00% | [20 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/\_\_init\_\_.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9fX2luaXRfXy5weQ==) | 0.00% | [10 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/dataset/cc.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9kYXRhc2V0L2NjLnB5) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/sample/cc\_certificate\_id.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9zYW1wbGUvY2NfY2VydGlmaWNhdGVfaWQucHk=) | 85.72% | [1 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff             @@
##             main     #322      +/-   ##
==========================================
- Coverage   74.61%   67.80%   -6.80%     
==========================================
  Files          54       62       +8     
  Lines        6709     7394     +685     
==========================================
+ Hits         5005     5013       +8     
- Misses       1704     2381     +677     
```



</details>

[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).   
:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).
",322
github.com/crocs-muni/sec-certs,src/sec_certs/model/references_nlp/feature_extraction.py,2023-11-14T12:57:38Z,"Just a quick comment on the current state of affairs:
- Soon, hyperparameter tunning will be done. Scripts for hyperparam tuning will not be versioned, I'll back them up separately at GDrive
- I don't think that the annotation engine is production-ready. For that reason, I kept the necessary files in `sec_certs.model.references_nlp` package that has some complex dependencies. Any import from that package requires `sec-certs` installation with `[nlp]` extra. A check is done on any import from that package.
- This requires that all `nlp` deps are also installed on dev machines -- otherwise, linters will likely complain
- In summary, this PR adds:
    - Backend for Reference annotations
    - Notebooks with reference annotation analysis
    - Versioned manual annotations, scripts to measure inter-annotator agreement",322
github.com/crocs-muni/sec-certs,src/sec_certs/model/references_nlp/feature_extraction.py,2023-03-23T11:00:23Z,"## [Codecov](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) Report
Attention: `675 lines` in your changes are missing coverage. Please review.
> Comparison is base [(`f0f7fa7`)](https://app.codecov.io/gh/crocs-muni/sec-certs/commit/f0f7fa7e6784afefb945effbc9834209a673db47?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 74.61% compared to head [(`68b1c2d`)](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 67.80%.

> :exclamation: Current head 68b1c2d differs from pull request most recent head b648241. Consider uploading reports for the commit b648241 to get more accurate results

| [Files](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) | Patch % | Lines |
|---|---|---|
| [...c\_certs/model/references\_nlp/feature\_extraction.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9mZWF0dXJlX2V4dHJhY3Rpb24ucHk=) | 0.00% | [266 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [...ec\_certs/model/references\_nlp/segment\_extractor.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9zZWdtZW50X2V4dHJhY3Rvci5weQ==) | 0.00% | [154 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [...ec\_certs/model/references\_nlp/annotator\_trainer.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9hbm5vdGF0b3JfdHJhaW5lci5weQ==) | 0.00% | [80 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/annotator.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9hbm5vdGF0b3IucHk=) | 0.00% | [56 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/evaluation.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9ldmFsdWF0aW9uLnB5) | 0.00% | [50 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/training.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC90cmFpbmluZy5weQ==) | 0.00% | [37 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/utils/nlp.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy91dGlscy9ubHAucHk=) | 0.00% | [20 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/\_\_init\_\_.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9fX2luaXRfXy5weQ==) | 0.00% | [10 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/dataset/cc.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9kYXRhc2V0L2NjLnB5) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/sample/cc\_certificate\_id.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9zYW1wbGUvY2NfY2VydGlmaWNhdGVfaWQucHk=) | 85.72% | [1 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff             @@
##             main     #322      +/-   ##
==========================================
- Coverage   74.61%   67.80%   -6.80%     
==========================================
  Files          54       62       +8     
  Lines        6709     7394     +685     
==========================================
+ Hits         5005     5013       +8     
- Misses       1704     2381     +677     
```



</details>

[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).   
:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).
",322
github.com/crocs-muni/sec-certs,src/sec_certs/model/references_nlp/feature_extraction.py,2023-11-14T12:57:38Z,"Just a quick comment on the current state of affairs:
- Soon, hyperparameter tunning will be done. Scripts for hyperparam tuning will not be versioned, I'll back them up separately at GDrive
- I don't think that the annotation engine is production-ready. For that reason, I kept the necessary files in `sec_certs.model.references_nlp` package that has some complex dependencies. Any import from that package requires `sec-certs` installation with `[nlp]` extra. A check is done on any import from that package.
- This requires that all `nlp` deps are also installed on dev machines -- otherwise, linters will likely complain
- In summary, this PR adds:
    - Backend for Reference annotations
    - Notebooks with reference annotation analysis
    - Versioned manual annotations, scripts to measure inter-annotator agreement",322
github.com/crocs-muni/sec-certs,src/sec_certs/model/references_nlp/feature_extraction.py,2023-03-23T11:00:23Z,"## [Codecov](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) Report
Attention: `675 lines` in your changes are missing coverage. Please review.
> Comparison is base [(`f0f7fa7`)](https://app.codecov.io/gh/crocs-muni/sec-certs/commit/f0f7fa7e6784afefb945effbc9834209a673db47?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 74.61% compared to head [(`68b1c2d`)](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 67.80%.

> :exclamation: Current head 68b1c2d differs from pull request most recent head b648241. Consider uploading reports for the commit b648241 to get more accurate results

| [Files](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) | Patch % | Lines |
|---|---|---|
| [...c\_certs/model/references\_nlp/feature\_extraction.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9mZWF0dXJlX2V4dHJhY3Rpb24ucHk=) | 0.00% | [266 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [...ec\_certs/model/references\_nlp/segment\_extractor.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9zZWdtZW50X2V4dHJhY3Rvci5weQ==) | 0.00% | [154 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [...ec\_certs/model/references\_nlp/annotator\_trainer.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9hbm5vdGF0b3JfdHJhaW5lci5weQ==) | 0.00% | [80 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/annotator.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9hbm5vdGF0b3IucHk=) | 0.00% | [56 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/evaluation.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9ldmFsdWF0aW9uLnB5) | 0.00% | [50 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/training.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC90cmFpbmluZy5weQ==) | 0.00% | [37 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/utils/nlp.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy91dGlscy9ubHAucHk=) | 0.00% | [20 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/\_\_init\_\_.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9fX2luaXRfXy5weQ==) | 0.00% | [10 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/dataset/cc.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9kYXRhc2V0L2NjLnB5) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/sample/cc\_certificate\_id.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9zYW1wbGUvY2NfY2VydGlmaWNhdGVfaWQucHk=) | 85.72% | [1 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff             @@
##             main     #322      +/-   ##
==========================================
- Coverage   74.61%   67.80%   -6.80%     
==========================================
  Files          54       62       +8     
  Lines        6709     7394     +685     
==========================================
+ Hits         5005     5013       +8     
- Misses       1704     2381     +677     
```



</details>

[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).   
:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).
",322
github.com/crocs-muni/sec-certs,src/sec_certs/model/references_nlp/feature_extraction.py,2023-11-14T12:57:38Z,"Just a quick comment on the current state of affairs:
- Soon, hyperparameter tunning will be done. Scripts for hyperparam tuning will not be versioned, I'll back them up separately at GDrive
- I don't think that the annotation engine is production-ready. For that reason, I kept the necessary files in `sec_certs.model.references_nlp` package that has some complex dependencies. Any import from that package requires `sec-certs` installation with `[nlp]` extra. A check is done on any import from that package.
- This requires that all `nlp` deps are also installed on dev machines -- otherwise, linters will likely complain
- In summary, this PR adds:
    - Backend for Reference annotations
    - Notebooks with reference annotation analysis
    - Versioned manual annotations, scripts to measure inter-annotator agreement",322
github.com/crocs-muni/sec-certs,src/sec_certs/model/references_nlp/feature_extraction.py,2023-03-23T11:00:23Z,"## [Codecov](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) Report
Attention: `675 lines` in your changes are missing coverage. Please review.
> Comparison is base [(`f0f7fa7`)](https://app.codecov.io/gh/crocs-muni/sec-certs/commit/f0f7fa7e6784afefb945effbc9834209a673db47?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 74.61% compared to head [(`68b1c2d`)](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) 67.80%.

> :exclamation: Current head 68b1c2d differs from pull request most recent head b648241. Consider uploading reports for the commit b648241 to get more accurate results

| [Files](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) | Patch % | Lines |
|---|---|---|
| [...c\_certs/model/references\_nlp/feature\_extraction.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9mZWF0dXJlX2V4dHJhY3Rpb24ucHk=) | 0.00% | [266 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [...ec\_certs/model/references\_nlp/segment\_extractor.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9zZWdtZW50X2V4dHJhY3Rvci5weQ==) | 0.00% | [154 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [...ec\_certs/model/references\_nlp/annotator\_trainer.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9hbm5vdGF0b3JfdHJhaW5lci5weQ==) | 0.00% | [80 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/annotator.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9hbm5vdGF0b3IucHk=) | 0.00% | [56 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/evaluation.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9ldmFsdWF0aW9uLnB5) | 0.00% | [50 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/training.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC90cmFpbmluZy5weQ==) | 0.00% | [37 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/utils/nlp.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy91dGlscy9ubHAucHk=) | 0.00% | [20 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/model/references\_nlp/\_\_init\_\_.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9tb2RlbC9yZWZlcmVuY2VzX25scC9fX2luaXRfXy5weQ==) | 0.00% | [10 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/dataset/cc.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9kYXRhc2V0L2NjLnB5) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |
| [src/sec\_certs/sample/cc\_certificate\_id.py](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni#diff-c3JjL3NlY19jZXJ0cy9zYW1wbGUvY2NfY2VydGlmaWNhdGVfaWQucHk=) | 85.72% | [1 Missing :warning: ](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni) |

<details><summary>Additional details and impacted files</summary>


```diff
@@            Coverage Diff             @@
##             main     #322      +/-   ##
==========================================
- Coverage   74.61%   67.80%   -6.80%     
==========================================
  Files          54       62       +8     
  Lines        6709     7394     +685     
==========================================
+ Hits         5005     5013       +8     
- Misses       1704     2381     +677     
```



</details>

[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/crocs-muni/sec-certs/pull/322?src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).   
:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=crocs-muni).
",322
github.com/crocs-muni/sec-certs,src/sec_certs/model/references_nlp/feature_extraction.py,2023-11-14T12:57:38Z,"Just a quick comment on the current state of affairs:
- Soon, hyperparameter tunning will be done. Scripts for hyperparam tuning will not be versioned, I'll back them up separately at GDrive
- I don't think that the annotation engine is production-ready. For that reason, I kept the necessary files in `sec_certs.model.references_nlp` package that has some complex dependencies. Any import from that package requires `sec-certs` installation with `[nlp]` extra. A check is done on any import from that package.
- This requires that all `nlp` deps are also installed on dev machines -- otherwise, linters will likely complain
- In summary, this PR adds:
    - Backend for Reference annotations
    - Notebooks with reference annotation analysis
    - Versioned manual annotations, scripts to measure inter-annotator agreement",322
github.com/navervision/lincir,loader.py,2023-12-09T13:20:59Z,Missing `:` for the uri (ref: https://github.com/navervision/lincir/issues/1#issuecomment-1848407580),2
github.com/navervision/lincir,loader.py,2023-12-10T07:22:19Z,Oh. Thanks.,2
github.com/CompTech-IntentClassifier/IntentClassifier,intent_classifier/LogisticRegressionIntentClassifier.py,2019-02-01T14:34:00Z,thks,5
github.com/CompTech-IntentClassifier/IntentClassifier,intent_classifier/LogisticRegressionIntentClassifier.py,2019-02-01T14:34:00Z,thks,5
github.com/CompTech-IntentClassifier/IntentClassifier,intent_classifier/LogisticRegressionIntentClassifier.py,2019-01-31T15:57:18Z,"Только тут не NaiveBayes, а LogisticRegression давно. Поправь имена",2
github.com/CompTech-IntentClassifier/IntentClassifier,intent_classifier/LogisticRegressionIntentClassifier.py,2019-01-31T15:58:02Z,Что хочешь сделать в TODO:? Комментарий бы оставил,2
github.com/CompTech-IntentClassifier/IntentClassifier,intent_classifier/LogisticRegressionIntentClassifier.py,2019-01-31T16:00:20Z,"Не понял вообще. Ты фишку с semhash вообще не заюзал, она же была в ноутбуке. Надо на вход semhash_corpus(X) передавать, а не просто X",2
github.com/CompTech-IntentClassifier/IntentClassifier,intent_classifier/LogisticRegressionIntentClassifier.py,2019-01-31T16:09:25Z,"Чето такое надо в fit() написать было
self.text_clf.fit(semhash_corpus(X), Y)
",2
github.com/CompTech-IntentClassifier/IntentClassifier,intent_classifier/LogisticRegressionIntentClassifier.py,2019-01-31T16:11:25Z,"Аналогично fit(). Надо хеши закинуть, а не исходные текст, т.е.:

text_clf.predict(semhash_corpus(X))",2
github.com/CompTech-IntentClassifier/IntentClassifier,intent_classifier/LogisticRegressionIntentClassifier.py,2019-01-31T16:11:54Z,"Не знаю что мутит эта функция, но возможно надо передать идею с (semhash_corpus) и тут",2
github.com/CompTech-IntentClassifier/IntentClassifier,intent_classifier/LogisticRegressionIntentClassifier.py,2019-01-31T15:56:04Z,Что такое label: enhancement?,2
github.com/raeidsaqur/clevr-parser,clevr_parser/utils.py,2020-05-20T10:41:05Z,Presumes a data folder on the root directory.,32
github.com/raeidsaqur/clevr-parser,clevr_parser/utils.py,2020-04-12T00:44:31Z,@ameet-1997 Please rebase your changes on top of this PR to avoid merge conflicts.,11
github.com/raeidsaqur/clevr-parser,clevr_parser/backends/spacy_parser.py,2020-05-20T02:39:47Z,"@ameet-1997  This should unblock you from testing the embedding visualizers, See `test_Gs_embeddings.py` for implementation and calls.",31
github.com/raeidsaqur/clevr-parser,clevr_parser/backends/spacy_parser.py,2020-04-12T00:44:31Z,@ameet-1997 Please rebase your changes on top of this PR to avoid merge conflicts.,11
github.com/raeidsaqur/clevr-parser,clevr_parser/backends/spacy_parser.py,2020-04-11T23:19:06Z,I'll merge in couple of hours if you haven't reviewed by then.,10
github.com/raeidsaqur/clevr-parser,clevr_parser/backends/spacy_parser.py,2020-04-11T23:19:06Z,I'll merge in couple of hours if you haven't reviewed by then.,10
github.com/raeidsaqur/clevr-parser,clevr_parser/backends/spacy_parser.py,2020-04-11T20:42:59Z,"@ameet-1997 question: so we are assuming the relations are in order of occurrence in sentence correct? For e.g.:

`""There is a <obj> that is <left> of <obj2>."" 
The corresponding edge attribute <obj>-left-<obj2> ?
`
What happens in logical case? like:

`""There is a <obj> that is <left> of <obj2> and <right> of <obj3>""` ?",8
github.com/raeidsaqur/clevr-parser,clevr_parser/backends/spacy_parser.py,2020-04-11T20:52:11Z,"Yes, realized these edge cases. In fact there are mode edge cases that need to be considered. We should write an auxiliary function to handle that.",8
github.com/raeidsaqur/clevr-parser,clevr_parser/backends/spacy_parser.py,2020-03-30T20:01:52Z,@ameet-1997 : maintaining work flow - can you please 'Merge pull request' above?,2
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/skills_extraction/metaflow/flow.py,2022-01-14T17:46:36Z,@georgerichardson it's this bit that seems to be most cumbersome,79
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/skills_extraction/metaflow/flow.py,2022-01-11T10:31:20Z,"```
(skills-taxonomy-v2) elizabethgallagher@NESTA-FVFFC1DFQ05P skills-taxonomy-v2 % python skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class_extras/flow.py --environment=conda --datastore=s3 run --max-num-splits 300
Metaflow 2.4.7 executing PredictSkillSentsExtra for user:elizabethgallagher
Project: predict_sentence_class_extras, Branch: user.elizabethgallagher
Validating your flow...
    The graph looks good!
Running pylint...
    Pylint is happy!
Bootstrapping conda environment...(this could take a few minutes)
2022-01-11 09:49:55,438 - root - INFO - pip installing pip for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:50:03,073 - root - INFO - pip installing pip for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:50:03,979 - root - INFO - pip installing /Users/elizabethgallagher/Code/skills-taxonomy-v2 for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:51:37,846 - root - INFO - pip installing pip for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:51:40,869 - root - INFO - pip installing pip for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:51:43,023 - root - INFO - pip installing /Users/elizabethgallagher/Code/skills-taxonomy-v2 for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:51:50,396 - root - INFO - pip installing pip for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:51:53,607 - root - INFO - pip installing pip for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:51:55,480 - root - INFO - pip installing /Users/elizabethgallagher/Code/skills-taxonomy-v2 for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:52:31,661 - botocore.credentials - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2022-01-11 09:52:32.774 Workflow starting (run-id 2538):
2022-01-11 09:52:34,629 - root - INFO - pip installing pip for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:52:37,643 - root - INFO - pip installing pip for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:52:39,635 - root - INFO - pip installing /Users/elizabethgallagher/Code/skills-taxonomy-v2 for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:52:46.742 [2538/start/15753 (pid 57048)] Task is starting.
2022-01-11 09:53:10.803 [2538/start/15753 (pid 57048)] Running predictions on 1 data files ...
2022-01-11 09:53:14.052 [2538/start/15753 (pid 57048)] Foreach yields 1 child steps.
2022-01-11 09:53:14.052 [2538/start/15753 (pid 57048)] Task finished successfully.
2022-01-11 10:01:16.526 [2538/process_sentences/15756 (pid 58461)] Task is starting.
2022-01-11 10:01:18.137 [2538/process_sentences/15756 (pid 58461)] 2022-01-11 10:01:18,136 - botocore.credentials - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2022-01-11 10:01:20.612 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status SUBMITTED)...
2022-01-11 10:01:23.951 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status RUNNABLE)...
2022-01-11 10:01:54.085 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status RUNNABLE)...
2022-01-11 10:02:24.280 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status RUNNABLE)...
2022-01-11 10:02:54.457 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status RUNNABLE)...
2022-01-11 10:03:24.557 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status RUNNABLE)...
2022-01-11 10:03:29.887 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status STARTING)...
2022-01-11 10:03:59.952 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status STARTING)...
2022-01-11 10:04:29.997 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status STARTING)...
2022-01-11 10:05:00.118 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status STARTING)...
2022-01-11 10:05:30.304 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status STARTING)...
2022-01-11 10:05:50.893 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status RUNNING)...
2022-01-11 10:05:49.293 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Setting up task environment.
2022-01-11 10:05:59.865 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Downloading code package...
2022-01-11 10:06:03.360 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Code package downloaded.
2022-01-11 10:06:14.891 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting.
2022-01-11 10:06:15.371 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Bootstrapping environment...
2022-01-11 10:06:51.018 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Environment bootstrapped.
2022-01-11 10:06:52.206 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
2022-01-11 10:07:25.507 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   ERROR: Command errored out with exit status 1:
2022-01-11 10:07:25.507 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]    command: /workspace/metaflow/metaflow_PredictSkillSentsExtra_linux-64_60c976b6fbbc9cc0b7a9e0578efbd1415bba563c/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-rkekrlpd/mysqlclient_cc2f0d807a31489598a70c305ac68953/setup.py'""'""'; __file__='""'""'/tmp/pip-install-rkekrlpd/mysqlclient_cc2f0d807a31489598a70c305ac68953/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /tmp/pip-pip-egg-info-f6_k6o3l
2022-01-11 10:07:25.507 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]        cwd: /tmp/pip-install-rkekrlpd/mysqlclient_cc2f0d807a31489598a70c305ac68953/
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   Complete output (15 lines):
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   mysql_config --version
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   /bin/sh: 1: mysql_config: not found
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   mariadb_config --version
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   /bin/sh: 1: mariadb_config: not found
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   mysql_config --libs
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   /bin/sh: 1: mysql_config: not found
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   Traceback (most recent call last):
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]     File ""<string>"", line 1, in <module>
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]     File ""/tmp/pip-install-rkekrlpd/mysqlclient_cc2f0d807a31489598a70c305ac68953/setup.py"", line 15, in <module>
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]       metadata, options = get_config()
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]     File ""/tmp/pip-install-rkekrlpd/mysqlclient_cc2f0d807a31489598a70c305ac68953/setup_posix.py"", line 70, in get_config
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]       libs = mysql_config(""libs"")
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]     File ""/tmp/pip-install-rkekrlpd/mysqlclient_cc2f0d807a31489598a70c305ac68953/setup_posix.py"", line 31, in mysql_config
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]       raise OSError(""{} not found"".format(_mysql_config_path))
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   OSError: mysql_config not found
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   ----------------------------------------
```
`OSError: mysql_config not found` error log repeated about 30 times, then:
```
2022-01-11 10:07:31.603 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] WARNING: Discarding https://files.pythonhosted.org/packages/6a/91/bdfe808fb5dc99a5f65833b370818161b77ef6d1e19b488e4c146ab615aa/mysqlclient-1.3.0.tar.gz#sha256=06eb5664e3738b283ea2262ee60ed83192e898f019cc7ff251f4d05a564ab3b7 (from https://pypi.org/simple/mysqlclient/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   ERROR: Command errored out with exit status 1:
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]    command: /workspace/metaflow/metaflow_PredictSkillSentsExtra_linux-64_60c976b6fbbc9cc0b7a9e0578efbd1415bba563c/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-rkekrlpd/pattern_ccbc9ea7c4394596bb6c89f551f3c194/setup.py'""'""'; __file__='""'""'/tmp/pip-install-rkekrlpd/pattern_ccbc9ea7c4394596bb6c89f551f3c194/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /tmp/pip-pip-egg-info-26vdqs6u
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]        cwd: /tmp/pip-install-rkekrlpd/pattern_ccbc9ea7c4394596bb6c89f551f3c194/
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   Complete output (6 lines):
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   Traceback (most recent call last):
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]     File ""<string>"", line 1, in <module>
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]     File ""/tmp/pip-install-rkekrlpd/pattern_ccbc9ea7c4394596bb6c89f551f3c194/setup.py"", line 40
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]       print n
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]             ^
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   SyntaxError: Missing parentheses in call to 'print'. Did you mean print(n)?
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   ----------------------------------------
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] WARNING: Discarding https://files.pythonhosted.org/packages/bf/50/d09941d53416f2a86676bd0dc341d5968b599a763b73f5d13f51c57b5641/pattern-2.6.zip#sha256=003aa285adc23b72255ca8b9f052c6a2644b245b3a9666af007e086428a950be (from https://pypi.org/simple/pattern/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.
2022-01-11 10:07:41.343 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] ERROR: Could not find a version that satisfies the requirement mysqlclient (from pattern) (from versions: 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.3.4, 1.3.5, 1.3.6, 1.3.7, 1.3.8, 1.3.9, 1.3.10, 1.3.11rc1, 1.3.11, 1.3.12, 1.3.13, 1.3.14, 1.4.0rc1, 1.4.0rc2, 1.4.0rc3, 1.4.0, 1.4.1, 1.4.2, 1.4.2.post1, 1.4.3, 1.4.4, 1.4.5, 1.4.6, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.1.0rc1, 2.1.0)
2022-01-11 10:07:41.343 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] ERROR: No matching distribution found for mysqlclient
2022-01-11 10:07:42.737 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Traceback (most recent call last):
2022-01-11 10:07:42.737 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   File ""flow.py"", line 16, in <module>
2022-01-11 10:07:42.738 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]     from skills_taxonomy_v2 import BUCKET_NAME
2022-01-11 10:07:42.738 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   File ""/workspace/metaflow/pkg_self/skills_taxonomy_v2/__init__.py"", line 7, in <module>
2022-01-11 10:07:42.738 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]     import yaml
2022-01-11 10:07:42.738 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] ModuleNotFoundError: No module named 'yaml'
2022-01-11 10:07:45.033 [2538/process_sentences/15756 (pid 58461)] Task failed.
2022-01-11 10:07:45.217 Workflow failed.
2022-01-11 10:07:45.217 Terminating 0 active tasks...
2022-01-11 10:07:45.217 Flushing logs...
    Step failure:
    Step process_sentences (task-id 15756) failed.
```",79
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/skills_extraction/metaflow/flow.py,2022-01-14T20:00:52Z,note: https://github.com/explosion/spaCy/issues/6498,79
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-10-27T11:13:14Z,this takes 5 minutes,73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-10-27T11:20:58Z,this takes about 10 minutes,73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-10-27T15:50:04Z,now down to <5 seconds thanks to comments by @jaklinger ,73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-10-27T13:48:48Z,"First note (another coming I think, but have a meeting now!): `nltk`'s `sent_tokenize` is 10-100x faster than `nlp(...)`. This should bring us from 7-9 days to 4-6 days 😄 ",73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-10-27T14:39:29Z,"Second note, also applying to the sentence processing is that quite often there is an overhead in creating threads, and so rather than doing 10000 operations over 4 cores in 2500 threads, you can do 4 x 2500 operations over 4 cores in 4 threads. In general, a more practical way to do this is by splitting into chunks and then flattening the output. Potentially here you will make a saving of another factor of 10 on the sentence splitting

```python
def split_sentence_over_chunk(chunk, nlp, min_length):
    partial_split_sentence = partial(split_sentence, nlp=nlp, min_length=min_length)
    return list(map(partial_split_sentence, chunk))

def make_chunks(lst, n):
    for i in range(0, len(lst), n):
        yield lst[i:i + n]

...

with Pool(4) as pool:  # 4 cpus
    chunks = make_chunks(data, 1000)  # chunks of 1000s sentences
    partial_split_sentence = partial(split_sentence_over_chunk, nlp=nlp, min_length=30)
    # NB the output will be a list of lists, so make sure to flatten after this!
    split_sentence_pool_output = pool.map(partial_split_sentence, chunks)

```",73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-10-27T15:12:33Z,"General comment: you could get a speed up of around 100 by switching the pipeline to metaflow + batch with `max-workers=100` whilst splitting the embeddings up into chunks. Something like (note, just pseudo-code) which would fan-out over files and then fan-out again over sentence chunks, and then in the end save some data either locally, to S3 or as an S3 artefact, over which you then do your analytic step.

I suspect that this would take just a couple of hours to run for your whole dataset, so even if it would take 5 days to write it would still be worth it, not taking into account additional development cycles of batches of 5 days 😄 

```python

class SentenceFlow(FlowSpec):
	@step
	def start(self):
		self.file_names = job_ad_file_names
		self.next(self.process_sentences, foreach=""file_names"")

	@batch()
	@step
	def process_sentences(self):
		self.file_name = self.input
        sentence_data = get_sentences(self.file_name)  # a list of dict
        self.chunks = make_chunks(sentence_data)
        self.next(self.embedding_chunks, foreach=""chunks"")

	@batch()
	@step
	def embedding_chunks(self):
        # save on memory with while/pop
        texts, ids = [], []
        while self.input:
			row = self.input.pop(0)
            texts.append(row['text'])
            ids.append(row['ids'])
        bert_model = SentenceTransformer(bert_model_name)
        bert_model.max_seq_length = 512
        vecs = bert_model.encode(texts)
        self.data = list(*zip(ids, vecs))
        self.next(self.join_embedding_chunks)

	@step
	def join_embedding_chunks(self, inputs):
        self.data = []
		for input in inputs:
             self.data += input.data
        self.next(self.process_sentences)

... etc ...
```",73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-10-27T15:21:12Z,"> First note (another coming I think, but have a meeting now!): `nltk`'s `sent_tokenize` is 10-100x faster than `nlp(...)`. This should bring us from 7-9 days to 4-6 days 😄

whoa! ok this was much better. Went from 25 secs to 3 secs (on 100 job adverts)",73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-11-04T09:37:33Z,"After making some changes, the code actually just took 4.5 days to run",73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-11-05T16:56:39Z,"There are some files included in the sample which don't contain the full text metadata. This leaves us with 4,312,285 job adverts job adverts from the following distribution over time (in comparison to all the data files minus the ones without the full text metadata)
![tk_sample_dates_no_expired](https://user-images.githubusercontent.com/15956065/140548976-3cfd814f-ffbc-4c01-a844-2ad34650596c.jpg)


",73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-06T08:59:42Z,it seems like you just add all the non-skills data here rather than taking a sample (as the name `balanced_augment_training` suggests)? was this what you meant?,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-06T09:03:02Z,same in experiment no. 7,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-06T09:04:04Z,"I'm not sure that this will be causing a bug, but note that you're input variable name is `skills_data` not `skills`",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-06T09:04:38Z,this is a cool idea!,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-06T09:06:10Z,oh I see you sort it out in experiment 8!,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-06T09:07:09Z,"yeah, the variable name is bad though!! I tried oversampling and balancing ",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T13:51:30Z,"You should probably say that this isn't just a local run, but also a run on a small sample of the data. I suppose it can be seen as a way to test things run.",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T13:51:53Z,this should be the default command and config file,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T13:53:59Z,"How come you changed this to 30, did you see that it gave better results?",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T14:02:17Z,"At this point I think it's ok to write this more instruction-y, e.g. ""There are three main scripts: ..."". I suppose the story of the experimentation and journey can go in the analysis/experiments document. If that makes sense!",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T14:04:34Z,Do you have these numbers for the 2021.08.16.yaml yet?,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T14:12:17Z,I don't think this will know what `params` is. I'd suggest having every single parameter needed as an input to the class like you do with `split_random_seed` and `test_size` etc.,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T14:13:44Z,i think you will need many more inputs to this from your params file.,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T14:15:17Z,"thinking about it i'm not sure why I didnt just do `split_random_seed=params[""split_random_seed""]`  here rather than creating a new `split_random_seed` variable on like 233 :shrug:",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T14:25:34Z,"I may be wrong but I think this may need a clause for when sentence=None due to `remove_short_sents` i.e. if the length is outside 30-100 then `clean_text(sent.text, training=False)` will be None (I think!), so when you do `if len(sentence) in range(min_length, max_length):` it will break with `TypeError: object of type 'NoneType' has no len()`.
So might be fixed with:
```
if sentence and len(sentence) in range(min_length, max_length):
        ...

```",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T14:34:28Z,"`os.path.join(training_data_path, training_data_file_name + "".pickle"")` would be slightly better to use just in case anyone with a windows computer uses the code!",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T14:47:21Z,just wondering where you got this from as your stochasticity experiments suggested 22 was best,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T14:52:38Z,sklearn is already in the requirements,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T15:02:12Z,"I got an error `Resource averaged_perceptron_tagger not found.
  Please use the NLTK Downloader to obtain the resource:` so I needed to add:

`nltk.download('averaged_perceptron_tagger')` here",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T15:10:25Z,"when I ran this I got
```
              precision    recall  f1-score   support

           0       0.99      1.00      1.00      2299
           1       1.00      0.98      0.99       931

    accuracy                           0.99      3230
   macro avg       1.00      0.99      0.99      3230
weighted avg       0.99      0.99      0.99      3230
```
and
```
              precision    recall  f1-score   support

           0       0.90      0.97      0.93       406
           1       0.91      0.73      0.81       164

    accuracy                           0.90       570
   macro avg       0.90      0.85      0.87       570
weighted avg       0.90      0.90      0.90       570
```
So seems like maybe the data I have (`/inputs/new_training_data/final_training_data.pickle`) is smaller than the version you have?",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T15:11:56Z,I think this might work better as a parameter in the config with the extension included rather than hardcoded here,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T15:26:06Z,"yeah, it did for me ",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T15:28:24Z,"tbh this is a rather janky solution - as i set training=False, the cleaning pipeline doesn't get rid of sentences of a certain length and instead relies on your min_length, max_length range ",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T15:29:04Z,yikes - good catch!!,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T15:29:56Z,hmmmm - lemme check as the final training set should be larger ,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T15:33:27Z,"ah yeh - this issue comes up when I run `predict_sentence_class.py`, I get:
```
File ""/Users/elizabethgallagher/Code/skills-taxonomy-v2/skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py"", line 220, in <listcomp>
    int(np.where(prob[1] >= params[""probability_threshold""], 1, 0))
NameError: name 'params' is not defined
```",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T15:37:53Z,I'll modify this so it will run! ,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-25T08:41:26Z,modified parameters so they are inputs! ,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-25T08:45:36Z,oooh!! good idea ,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-25T08:47:10Z,os it is,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-25T08:48:04Z,whoops - deleted!!,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-25T08:49:17Z,average_perceptron_tagger added! ,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-25T08:49:41Z,good idea! no longer hardcoded,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T12:05:12Z,"@lizgzil 

I've updated your scaled up sentence classifier to reflect the new pipeline!

The current pipeline results in a precision score of 0.92 for the positive class and 0.90 for the negative class. It results in a recall score of 0.73 for the positive class and 0.97 for the negative class. This is for the new, updated training data where I modified some incorrect labels. 

I would take this with a slight pinch of salt as the training labels aren't perfect -qualitatively, i took a look at mislabelled sents where the true label was 1 and the model predicted 0 - it appeared that while there were some sentences that were certainly skills, many of them also contained 'characteristics' - I give some examples in `sentence_classifier.md` I also took a look at sents that the model labelled as skills that were manually labelled 0 and it also seems rather edge case-y!

1. `pipeline/sentence_classifier/sentence_classifier.py` - modified to accommodate the new pipeline + utils
2. `pipeline/sentence_classifier/utils.py` - for cleaning, splitting and generating 'verb' features 
3. `pipeline/sentence_classifier/predict_sentence_class.py` - barely modified   

Can you let me know if:
1. There are problems running the code
2. Code could be better written
3. any style issues w/ docstrings etc. 

Thanks so much Liz! ",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T14:56:59Z,"@india-kerle looks good but see some of my comments as I think there may be some bugs. I also think we should store the models and data in S3 not in github, so if you agree perhaps we could remove them from this pull request? 

Just about to try and run the scripts (I pressed to submit my comments accidently before I'd finished reviewing!)",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py,2021-08-20T15:15:35Z,"@india-kerle don't forget to upload the code to create the training data (or any processing you did)?

edit: this would be fine in another PR - e.g. the code to create the training data and a document about how to create it/how it was created",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/skills_extraction/get_sentence_embeddings.py,2021-08-10T11:19:49Z,could be helpful to have a description of this file as well! ,31
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/skills_extraction/get_sentence_embeddings.py,2021-08-10T11:20:51Z,maybe make this a txt file and save it in `inputs` so you can add to the list as well and it won't be unruly in the code?  ,31
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/skills_extraction/get_sentence_embeddings.py,2021-08-10T11:23:48Z,same as here - a small description could be helpful,31
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/skills_extraction/get_sentence_embeddings.py,2021-08-10T11:30:10Z,this code runs! although might be good to add `python-Levenshtein` to the `requirements.txt` because i keep getting warning messages to pip install it in order to suppress the message. ,31
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/skills_extraction/get_sentence_embeddings.py,2021-08-10T11:30:53Z,really helpful description!!,31
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/skills_extraction/get_sentence_embeddings.py,2021-08-10T11:36:56Z,"this is annoying!! maybe worth talking to someone in data engineering i.e. Joel, Jack to see if they've dealt with this before and have a more elegant solution? ",31
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/skills_extraction/get_sentence_embeddings.py,2021-08-20T10:15:58Z,good idea!,31
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/skills_extraction/get_sentence_embeddings.py,2021-08-20T10:21:09Z,oh good to know!,31
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/skills_extraction/get_sentence_embeddings.py,2021-08-20T10:26:00Z,thanks for the review @india-kerle ! I've made your changes in the latest commit. Good call on the custom stop words going in their own txt file.,31
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2022-01-14T17:46:36Z,@georgerichardson it's this bit that seems to be most cumbersome,79
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2022-01-11T10:31:20Z,"```
(skills-taxonomy-v2) elizabethgallagher@NESTA-FVFFC1DFQ05P skills-taxonomy-v2 % python skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class_extras/flow.py --environment=conda --datastore=s3 run --max-num-splits 300
Metaflow 2.4.7 executing PredictSkillSentsExtra for user:elizabethgallagher
Project: predict_sentence_class_extras, Branch: user.elizabethgallagher
Validating your flow...
    The graph looks good!
Running pylint...
    Pylint is happy!
Bootstrapping conda environment...(this could take a few minutes)
2022-01-11 09:49:55,438 - root - INFO - pip installing pip for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:50:03,073 - root - INFO - pip installing pip for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:50:03,979 - root - INFO - pip installing /Users/elizabethgallagher/Code/skills-taxonomy-v2 for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:51:37,846 - root - INFO - pip installing pip for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:51:40,869 - root - INFO - pip installing pip for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:51:43,023 - root - INFO - pip installing /Users/elizabethgallagher/Code/skills-taxonomy-v2 for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:51:50,396 - root - INFO - pip installing pip for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:51:53,607 - root - INFO - pip installing pip for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:51:55,480 - root - INFO - pip installing /Users/elizabethgallagher/Code/skills-taxonomy-v2 for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:52:31,661 - botocore.credentials - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2022-01-11 09:52:32.774 Workflow starting (run-id 2538):
2022-01-11 09:52:34,629 - root - INFO - pip installing pip for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:52:37,643 - root - INFO - pip installing pip for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:52:39,635 - root - INFO - pip installing /Users/elizabethgallagher/Code/skills-taxonomy-v2 for /Users/elizabethgallagher/miniconda3/envs/metaflow_PredictSkillSentsExtra_osx-64_da8477850865277c22d5e645896ab050103cb6be/bin/python.
2022-01-11 09:52:46.742 [2538/start/15753 (pid 57048)] Task is starting.
2022-01-11 09:53:10.803 [2538/start/15753 (pid 57048)] Running predictions on 1 data files ...
2022-01-11 09:53:14.052 [2538/start/15753 (pid 57048)] Foreach yields 1 child steps.
2022-01-11 09:53:14.052 [2538/start/15753 (pid 57048)] Task finished successfully.
2022-01-11 10:01:16.526 [2538/process_sentences/15756 (pid 58461)] Task is starting.
2022-01-11 10:01:18.137 [2538/process_sentences/15756 (pid 58461)] 2022-01-11 10:01:18,136 - botocore.credentials - INFO - Found credentials in shared credentials file: ~/.aws/credentials
2022-01-11 10:01:20.612 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status SUBMITTED)...
2022-01-11 10:01:23.951 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status RUNNABLE)...
2022-01-11 10:01:54.085 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status RUNNABLE)...
2022-01-11 10:02:24.280 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status RUNNABLE)...
2022-01-11 10:02:54.457 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status RUNNABLE)...
2022-01-11 10:03:24.557 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status RUNNABLE)...
2022-01-11 10:03:29.887 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status STARTING)...
2022-01-11 10:03:59.952 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status STARTING)...
2022-01-11 10:04:29.997 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status STARTING)...
2022-01-11 10:05:00.118 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status STARTING)...
2022-01-11 10:05:30.304 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status STARTING)...
2022-01-11 10:05:50.893 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting (status RUNNING)...
2022-01-11 10:05:49.293 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Setting up task environment.
2022-01-11 10:05:59.865 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Downloading code package...
2022-01-11 10:06:03.360 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Code package downloaded.
2022-01-11 10:06:14.891 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Task is starting.
2022-01-11 10:06:15.371 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Bootstrapping environment...
2022-01-11 10:06:51.018 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Environment bootstrapped.
2022-01-11 10:06:52.206 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
2022-01-11 10:07:25.507 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   ERROR: Command errored out with exit status 1:
2022-01-11 10:07:25.507 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]    command: /workspace/metaflow/metaflow_PredictSkillSentsExtra_linux-64_60c976b6fbbc9cc0b7a9e0578efbd1415bba563c/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-rkekrlpd/mysqlclient_cc2f0d807a31489598a70c305ac68953/setup.py'""'""'; __file__='""'""'/tmp/pip-install-rkekrlpd/mysqlclient_cc2f0d807a31489598a70c305ac68953/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /tmp/pip-pip-egg-info-f6_k6o3l
2022-01-11 10:07:25.507 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]        cwd: /tmp/pip-install-rkekrlpd/mysqlclient_cc2f0d807a31489598a70c305ac68953/
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   Complete output (15 lines):
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   mysql_config --version
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   /bin/sh: 1: mysql_config: not found
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   mariadb_config --version
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   /bin/sh: 1: mariadb_config: not found
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   mysql_config --libs
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   /bin/sh: 1: mysql_config: not found
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   Traceback (most recent call last):
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]     File ""<string>"", line 1, in <module>
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]     File ""/tmp/pip-install-rkekrlpd/mysqlclient_cc2f0d807a31489598a70c305ac68953/setup.py"", line 15, in <module>
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]       metadata, options = get_config()
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]     File ""/tmp/pip-install-rkekrlpd/mysqlclient_cc2f0d807a31489598a70c305ac68953/setup_posix.py"", line 70, in get_config
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]       libs = mysql_config(""libs"")
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]     File ""/tmp/pip-install-rkekrlpd/mysqlclient_cc2f0d807a31489598a70c305ac68953/setup_posix.py"", line 31, in mysql_config
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]       raise OSError(""{} not found"".format(_mysql_config_path))
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   OSError: mysql_config not found
2022-01-11 10:07:25.508 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   ----------------------------------------
```
`OSError: mysql_config not found` error log repeated about 30 times, then:
```
2022-01-11 10:07:31.603 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] WARNING: Discarding https://files.pythonhosted.org/packages/6a/91/bdfe808fb5dc99a5f65833b370818161b77ef6d1e19b488e4c146ab615aa/mysqlclient-1.3.0.tar.gz#sha256=06eb5664e3738b283ea2262ee60ed83192e898f019cc7ff251f4d05a564ab3b7 (from https://pypi.org/simple/mysqlclient/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   ERROR: Command errored out with exit status 1:
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]    command: /workspace/metaflow/metaflow_PredictSkillSentsExtra_linux-64_60c976b6fbbc9cc0b7a9e0578efbd1415bba563c/bin/python -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-rkekrlpd/pattern_ccbc9ea7c4394596bb6c89f551f3c194/setup.py'""'""'; __file__='""'""'/tmp/pip-install-rkekrlpd/pattern_ccbc9ea7c4394596bb6c89f551f3c194/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /tmp/pip-pip-egg-info-26vdqs6u
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]        cwd: /tmp/pip-install-rkekrlpd/pattern_ccbc9ea7c4394596bb6c89f551f3c194/
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   Complete output (6 lines):
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   Traceback (most recent call last):
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]     File ""<string>"", line 1, in <module>
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]     File ""/tmp/pip-install-rkekrlpd/pattern_ccbc9ea7c4394596bb6c89f551f3c194/setup.py"", line 40
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]       print n
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]             ^
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   SyntaxError: Missing parentheses in call to 'print'. Did you mean print(n)?
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   ----------------------------------------
2022-01-11 10:07:32.705 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] WARNING: Discarding https://files.pythonhosted.org/packages/bf/50/d09941d53416f2a86676bd0dc341d5968b599a763b73f5d13f51c57b5641/pattern-2.6.zip#sha256=003aa285adc23b72255ca8b9f052c6a2644b245b3a9666af007e086428a950be (from https://pypi.org/simple/pattern/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.
2022-01-11 10:07:41.343 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] ERROR: Could not find a version that satisfies the requirement mysqlclient (from pattern) (from versions: 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.3.4, 1.3.5, 1.3.6, 1.3.7, 1.3.8, 1.3.9, 1.3.10, 1.3.11rc1, 1.3.11, 1.3.12, 1.3.13, 1.3.14, 1.4.0rc1, 1.4.0rc2, 1.4.0rc3, 1.4.0, 1.4.1, 1.4.2, 1.4.2.post1, 1.4.3, 1.4.4, 1.4.5, 1.4.6, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.1.0rc1, 2.1.0)
2022-01-11 10:07:41.343 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] ERROR: No matching distribution found for mysqlclient
2022-01-11 10:07:42.737 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] Traceback (most recent call last):
2022-01-11 10:07:42.737 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   File ""flow.py"", line 16, in <module>
2022-01-11 10:07:42.738 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]     from skills_taxonomy_v2 import BUCKET_NAME
2022-01-11 10:07:42.738 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]   File ""/workspace/metaflow/pkg_self/skills_taxonomy_v2/__init__.py"", line 7, in <module>
2022-01-11 10:07:42.738 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778]     import yaml
2022-01-11 10:07:42.738 [2538/process_sentences/15756 (pid 58461)] [84a8fab2-bdbd-4aee-94d0-d05072fa3778] ModuleNotFoundError: No module named 'yaml'
2022-01-11 10:07:45.033 [2538/process_sentences/15756 (pid 58461)] Task failed.
2022-01-11 10:07:45.217 Workflow failed.
2022-01-11 10:07:45.217 Terminating 0 active tasks...
2022-01-11 10:07:45.217 Flushing logs...
    Step failure:
    Step process_sentences (task-id 15756) failed.
```",79
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2022-01-14T20:00:52Z,note: https://github.com/explosion/spaCy/issues/6498,79
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-10-27T11:13:14Z,this takes 5 minutes,73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-10-27T11:20:58Z,this takes about 10 minutes,73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-10-27T15:50:04Z,now down to <5 seconds thanks to comments by @jaklinger ,73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-10-27T13:48:48Z,"First note (another coming I think, but have a meeting now!): `nltk`'s `sent_tokenize` is 10-100x faster than `nlp(...)`. This should bring us from 7-9 days to 4-6 days 😄 ",73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-10-27T14:39:29Z,"Second note, also applying to the sentence processing is that quite often there is an overhead in creating threads, and so rather than doing 10000 operations over 4 cores in 2500 threads, you can do 4 x 2500 operations over 4 cores in 4 threads. In general, a more practical way to do this is by splitting into chunks and then flattening the output. Potentially here you will make a saving of another factor of 10 on the sentence splitting

```python
def split_sentence_over_chunk(chunk, nlp, min_length):
    partial_split_sentence = partial(split_sentence, nlp=nlp, min_length=min_length)
    return list(map(partial_split_sentence, chunk))

def make_chunks(lst, n):
    for i in range(0, len(lst), n):
        yield lst[i:i + n]

...

with Pool(4) as pool:  # 4 cpus
    chunks = make_chunks(data, 1000)  # chunks of 1000s sentences
    partial_split_sentence = partial(split_sentence_over_chunk, nlp=nlp, min_length=30)
    # NB the output will be a list of lists, so make sure to flatten after this!
    split_sentence_pool_output = pool.map(partial_split_sentence, chunks)

```",73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-10-27T15:12:33Z,"General comment: you could get a speed up of around 100 by switching the pipeline to metaflow + batch with `max-workers=100` whilst splitting the embeddings up into chunks. Something like (note, just pseudo-code) which would fan-out over files and then fan-out again over sentence chunks, and then in the end save some data either locally, to S3 or as an S3 artefact, over which you then do your analytic step.

I suspect that this would take just a couple of hours to run for your whole dataset, so even if it would take 5 days to write it would still be worth it, not taking into account additional development cycles of batches of 5 days 😄 

```python

class SentenceFlow(FlowSpec):
	@step
	def start(self):
		self.file_names = job_ad_file_names
		self.next(self.process_sentences, foreach=""file_names"")

	@batch()
	@step
	def process_sentences(self):
		self.file_name = self.input
        sentence_data = get_sentences(self.file_name)  # a list of dict
        self.chunks = make_chunks(sentence_data)
        self.next(self.embedding_chunks, foreach=""chunks"")

	@batch()
	@step
	def embedding_chunks(self):
        # save on memory with while/pop
        texts, ids = [], []
        while self.input:
			row = self.input.pop(0)
            texts.append(row['text'])
            ids.append(row['ids'])
        bert_model = SentenceTransformer(bert_model_name)
        bert_model.max_seq_length = 512
        vecs = bert_model.encode(texts)
        self.data = list(*zip(ids, vecs))
        self.next(self.join_embedding_chunks)

	@step
	def join_embedding_chunks(self, inputs):
        self.data = []
		for input in inputs:
             self.data += input.data
        self.next(self.process_sentences)

... etc ...
```",73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-10-27T15:21:12Z,"> First note (another coming I think, but have a meeting now!): `nltk`'s `sent_tokenize` is 10-100x faster than `nlp(...)`. This should bring us from 7-9 days to 4-6 days 😄

whoa! ok this was much better. Went from 25 secs to 3 secs (on 100 job adverts)",73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-11-04T09:37:33Z,"After making some changes, the code actually just took 4.5 days to run",73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-11-05T16:56:39Z,"There are some files included in the sample which don't contain the full text metadata. This leaves us with 4,312,285 job adverts job adverts from the following distribution over time (in comparison to all the data files minus the ones without the full text metadata)
![tk_sample_dates_no_expired](https://user-images.githubusercontent.com/15956065/140548976-3cfd814f-ffbc-4c01-a844-2ad34650596c.jpg)


",73
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-06T08:59:42Z,it seems like you just add all the non-skills data here rather than taking a sample (as the name `balanced_augment_training` suggests)? was this what you meant?,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-06T09:03:02Z,same in experiment no. 7,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-06T09:04:04Z,"I'm not sure that this will be causing a bug, but note that you're input variable name is `skills_data` not `skills`",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-06T09:04:38Z,this is a cool idea!,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-06T09:06:10Z,oh I see you sort it out in experiment 8!,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-06T09:07:09Z,"yeah, the variable name is bad though!! I tried oversampling and balancing ",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T13:51:30Z,"You should probably say that this isn't just a local run, but also a run on a small sample of the data. I suppose it can be seen as a way to test things run.",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T13:51:53Z,this should be the default command and config file,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T13:53:59Z,"How come you changed this to 30, did you see that it gave better results?",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T14:02:17Z,"At this point I think it's ok to write this more instruction-y, e.g. ""There are three main scripts: ..."". I suppose the story of the experimentation and journey can go in the analysis/experiments document. If that makes sense!",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T14:04:34Z,Do you have these numbers for the 2021.08.16.yaml yet?,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T14:12:17Z,I don't think this will know what `params` is. I'd suggest having every single parameter needed as an input to the class like you do with `split_random_seed` and `test_size` etc.,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T14:13:44Z,i think you will need many more inputs to this from your params file.,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T14:15:17Z,"thinking about it i'm not sure why I didnt just do `split_random_seed=params[""split_random_seed""]`  here rather than creating a new `split_random_seed` variable on like 233 :shrug:",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T14:25:34Z,"I may be wrong but I think this may need a clause for when sentence=None due to `remove_short_sents` i.e. if the length is outside 30-100 then `clean_text(sent.text, training=False)` will be None (I think!), so when you do `if len(sentence) in range(min_length, max_length):` it will break with `TypeError: object of type 'NoneType' has no len()`.
So might be fixed with:
```
if sentence and len(sentence) in range(min_length, max_length):
        ...

```",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T14:34:28Z,"`os.path.join(training_data_path, training_data_file_name + "".pickle"")` would be slightly better to use just in case anyone with a windows computer uses the code!",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T14:47:21Z,just wondering where you got this from as your stochasticity experiments suggested 22 was best,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T14:52:38Z,sklearn is already in the requirements,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T15:02:12Z,"I got an error `Resource averaged_perceptron_tagger not found.
  Please use the NLTK Downloader to obtain the resource:` so I needed to add:

`nltk.download('averaged_perceptron_tagger')` here",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T15:10:25Z,"when I ran this I got
```
              precision    recall  f1-score   support

           0       0.99      1.00      1.00      2299
           1       1.00      0.98      0.99       931

    accuracy                           0.99      3230
   macro avg       1.00      0.99      0.99      3230
weighted avg       0.99      0.99      0.99      3230
```
and
```
              precision    recall  f1-score   support

           0       0.90      0.97      0.93       406
           1       0.91      0.73      0.81       164

    accuracy                           0.90       570
   macro avg       0.90      0.85      0.87       570
weighted avg       0.90      0.90      0.90       570
```
So seems like maybe the data I have (`/inputs/new_training_data/final_training_data.pickle`) is smaller than the version you have?",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T15:11:56Z,I think this might work better as a parameter in the config with the extension included rather than hardcoded here,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T15:26:06Z,"yeah, it did for me ",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T15:28:24Z,"tbh this is a rather janky solution - as i set training=False, the cleaning pipeline doesn't get rid of sentences of a certain length and instead relies on your min_length, max_length range ",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T15:29:04Z,yikes - good catch!!,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T15:29:56Z,hmmmm - lemme check as the final training set should be larger ,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T15:33:27Z,"ah yeh - this issue comes up when I run `predict_sentence_class.py`, I get:
```
File ""/Users/elizabethgallagher/Code/skills-taxonomy-v2/skills_taxonomy_v2/pipeline/sentence_classifier/sentence_classifier.py"", line 220, in <listcomp>
    int(np.where(prob[1] >= params[""probability_threshold""], 1, 0))
NameError: name 'params' is not defined
```",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T15:37:53Z,I'll modify this so it will run! ,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-25T08:41:26Z,modified parameters so they are inputs! ,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-25T08:45:36Z,oooh!! good idea ,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-25T08:47:10Z,os it is,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-25T08:48:04Z,whoops - deleted!!,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-25T08:49:17Z,average_perceptron_tagger added! ,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-25T08:49:41Z,good idea! no longer hardcoded,30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T12:05:12Z,"@lizgzil 

I've updated your scaled up sentence classifier to reflect the new pipeline!

The current pipeline results in a precision score of 0.92 for the positive class and 0.90 for the negative class. It results in a recall score of 0.73 for the positive class and 0.97 for the negative class. This is for the new, updated training data where I modified some incorrect labels. 

I would take this with a slight pinch of salt as the training labels aren't perfect -qualitatively, i took a look at mislabelled sents where the true label was 1 and the model predicted 0 - it appeared that while there were some sentences that were certainly skills, many of them also contained 'characteristics' - I give some examples in `sentence_classifier.md` I also took a look at sents that the model labelled as skills that were manually labelled 0 and it also seems rather edge case-y!

1. `pipeline/sentence_classifier/sentence_classifier.py` - modified to accommodate the new pipeline + utils
2. `pipeline/sentence_classifier/utils.py` - for cleaning, splitting and generating 'verb' features 
3. `pipeline/sentence_classifier/predict_sentence_class.py` - barely modified   

Can you let me know if:
1. There are problems running the code
2. Code could be better written
3. any style issues w/ docstrings etc. 

Thanks so much Liz! ",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T14:56:59Z,"@india-kerle looks good but see some of my comments as I think there may be some bugs. I also think we should store the models and data in S3 not in github, so if you agree perhaps we could remove them from this pull request? 

Just about to try and run the scripts (I pressed to submit my comments accidently before I'd finished reviewing!)",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-08-20T15:15:35Z,"@india-kerle don't forget to upload the code to create the training data (or any processing you did)?

edit: this would be fine in another PR - e.g. the code to create the training data and a document about how to create it/how it was created",30
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-07-28T13:02:25Z,"Thanks so much @india-kerle ! Really good points which I hadn't thought about. I've added an outputs folder gitkeep in https://github.com/nestauk/skills-taxonomy-v2/pull/26/commits/9238e5837ea483a97b4086e5eb6c8908d573d356 and the PROJECT_DIR was in the folder init file, so I've pulled this from here instead of the base config file in https://github.com/nestauk/skills-taxonomy-v2/pull/26/commits/4c64fb98bb4e002b43bd477e2d5807b7a158fff6. Hope those look ok to you?

In terms of docstrings - you are right they are needed, but I've got a feeling that these functions may still be in flux (e.g. I've got a plan to move all the s3 data getters to a separate location, and when you edit the sentence classifier there may be more changes to this script), so if you don't mind I'd prefer to add them in a later PR? 
",26
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/pipeline/sentence_classifier/predict_sentence_class.py,2021-07-28T13:08:50Z,@lizgzil looks good to me! doc strings etc. makes sense to include in a later PR :) I think it should be good to merge!,26
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/analysis/skills_extraction/notebooks/better_skills_naming.py,2021-12-08T11:21:35Z,above you say that you aren't merging skills - is this step different somehow?,76
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/analysis/skills_extraction/notebooks/better_skills_naming.py,2021-12-08T11:27:49Z,"I don't think these need to be prefixed with the `new_` bit, unless I'm missing something?",76
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/analysis/skills_extraction/notebooks/better_skills_naming.py,2021-12-08T11:58:41Z,"For this, I've been doing `on= ['job id', 'sentence id']` since this combo is unique for each sentence in a particular job advert. Although it's true that the sentence embedding should be the same if the sentence is the same (regardless of which job advert it is from), I think there is potentially a problem with duplicated rows in the merge if you don't use `on= ['job id', 'sentence id']` . Perhaps it makes no difference, but just to be on the safe side. Haven't investigated this, so I may be talking crap!",76
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/analysis/skills_extraction/notebooks/better_skills_naming.py,2021-12-08T12:02:25Z,"I guess this is reliant on the order of `skill_df` being the same skill number order as `sent_cluster_embeds`. Not sure if this is always going to be the case, so I'd just do something like:
```
skills_df[""Mean embedding""] = skills_df[""Skill number""].apply(lambda x: sent_cluster_embeds[x])
```
(You may need to create `skills_df[""Skill number""]` with the index?)",76
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/analysis/skills_extraction/notebooks/better_skills_naming.py,2021-12-08T12:16:28Z,"You may be able to use a default dict? Something like:
```
from collections import defaultdict
sentence_embeds = defaultdict(list)
for i in tqdm(range(0, 8)):  # 8 files
    new_sentences_dict = load_s3_data(
            s3, bucket_name, new_skills_embeds_path + f""sentences_data_{i}.json""
        )
    for k, v in new_sentences_dict.items():
        sentence_embeds[k].append(v)

```
Also to note instead of hardcoding the `range(0,8)` bit, I have done it this way:
```
reduced_embeddings_paths = get_s3_data_paths(
            s3,
            bucket_name,
            new_skills_embeds_path,
            file_types=[""*sentences_data_*.json""]
            )

sentences_data = pd.DataFrame()
for reduced_embeddings_path in tqdm(reduced_embeddings_paths):
    sentences_data_i = load_s3_data(
                s3, bucket_name,
                new_skills_embeds_path
            )
    ...
    

```
",76
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/analysis/skills_extraction/notebooks/better_skills_naming.py,2021-12-08T16:07:11Z,I think this is overwriting every iteration of the for loop? as `cluster_number` is just one number,76
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/analysis/skills_extraction/notebooks/better_skills_naming.py,2021-12-08T16:13:44Z,I don't think the `clean_cluster_description` or `get_clean_ngrams` functions need `cluster_number` as an input at all since they only process one skill as a time anyway.,76
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/analysis/skills_extraction/notebooks/better_skills_naming.py,2021-12-08T16:19:03Z,"I think if you remove `skills_num` as an input to `get_clean_ngrams` then the output `cluster_descriptions` can just be a list rather than a one key dictionary (so later you can do `""Texts"": cluster_descriptions` rather than `""Texts"": cluster_descriptions[skills_num]`)",76
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/analysis/skills_extraction/notebooks/better_skills_naming.py,2021-12-08T12:32:24Z,"thanks @lizgzil! yeah, i experimented with merging with data from the first batch but didn't do any merging with the new skill clusters based on our previous conversations. The merging comments are now just in the experiments.md bit! I'll make the changes you suggested in the meantime. ",76
github.com/nestauk/skills-taxonomy-v2,skills_taxonomy_v2/analysis/skills_extraction/notebooks/better_skills_naming.py,2021-12-08T15:49:17Z,"@india-kerle I was thinking it'd be nice if the output name of `skills_naming.py` was a bit more clearly linked to the input skills file version.

At the moment `skills_naming.py` inputs `extracted_skills/2021.11.05_skills_data.json` and outputs `extracted_skills/2021.12.07_skills_data.json`, so it's not clear that the second one is just the first one with the names added.

So I'd suggest `skills_data_output_path = params[""new_skills_path""].split('.json')[0] + '_named.json'`
",76
github.com/usc-isi-i2/etk,etk/etk.py,2018-11-19T21:11:45Z,This version is basically runnable without SHACL validation.,376
github.com/usc-isi-i2/etk,etk/etk.py,2019-01-04T18:56:08Z,"this has an open security alert, recommend upgrading if possible.

https://github.com/usc-isi-i2/etk/network/alert/requirements.txt/urllib3/open",389
github.com/usc-isi-i2/etk,etk/etk.py,2019-01-04T18:56:23Z,Is jupyter still needed?,389
github.com/usc-isi-i2/etk,etk/etk.py,2019-01-04T19:00:15Z,"Usually instead of flags I would recommend using an enum pattern, eg prefer passing tokenizer='spacy' over use_spacy_tokenizer=True",389
github.com/usc-isi-i2/etk,etk/etk.py,2019-01-04T19:07:04Z,"Instead of miss_day/month/week/year variables, maybe a dictionary 
```
is_missing = {'D':True, 'M':True, 'Y': True, 'W':True}
```

and then you can loop:

```
for u in is_missing.keys() :
    if p in units[u]:
        is_missing[u] = False
        break
```

",389
github.com/usc-isi-i2/etk,etk/etk.py,2019-01-04T19:10:46Z,👍 ,389
github.com/usc-isi-i2/etk,etk/etk.py,2019-01-04T19:12:39Z,This could be a helper function.,389
github.com/usc-isi-i2/etk,etk/etk.py,2019-01-04T19:17:21Z,See above.,389
github.com/usc-isi-i2/etk,etk/etk.py,2019-01-04T18:56:08Z,"this has an open security alert, recommend upgrading if possible.

https://github.com/usc-isi-i2/etk/network/alert/requirements.txt/urllib3/open",389
github.com/usc-isi-i2/etk,etk/etk.py,2019-01-04T18:56:23Z,Is jupyter still needed?,389
github.com/usc-isi-i2/etk,etk/etk.py,2019-01-04T19:00:15Z,"Usually instead of flags I would recommend using an enum pattern, eg prefer passing tokenizer='spacy' over use_spacy_tokenizer=True",389
github.com/usc-isi-i2/etk,etk/etk.py,2019-01-04T19:07:04Z,"Instead of miss_day/month/week/year variables, maybe a dictionary 
```
is_missing = {'D':True, 'M':True, 'Y': True, 'W':True}
```

and then you can loop:

```
for u in is_missing.keys() :
    if p in units[u]:
        is_missing[u] = False
        break
```

",389
github.com/usc-isi-i2/etk,etk/etk.py,2019-01-04T19:10:46Z,👍 ,389
github.com/usc-isi-i2/etk,etk/etk.py,2019-01-04T19:12:39Z,This could be a helper function.,389
github.com/usc-isi-i2/etk,etk/etk.py,2019-01-04T19:17:21Z,See above.,389
github.com/usc-isi-i2/etk,etk/etk.py,2018-05-10T22:54:45Z,Why are there 2 file changes? Did you delete the second file by mistake? @iAmeeth ,272
github.com/usc-isi-i2/etk,etk/etk.py,2018-05-10T22:58:25Z,"I get this when I switch to the branch.

`$ git checkout etk2
error: unable to create file examples/ranking_pipeline/resources/output/Will North Korea's Supreme Leader Kim Jong-un experience a significant leadership disruption before 1 July 2018?  _result.jl: Invalid argument`

That's why the file is getting deleted.",272
github.com/usc-isi-i2/etk,etk/etk.py,2018-05-10T23:23:30Z,"renamed that file, pull again",272
github.com/usc-isi-i2/etk,etk/etk.py,2018-05-10T23:43:54Z,path is`./tmp/etk.log`? why?,272
github.com/usc-isi-i2/etk,etk/etk.py,2018-05-10T23:46:29Z,"It's not the correct way to fix. the problem is windows doesn't have `/tmp`, if you change it to `./tmp`, yes problem can be fixed but it's confusing (why do I need to create a `tmp` in my current directory).

the fix should be, make etk can get temp path on different os correctly, check this: https://docs.python.org/3.6/library/tempfile.html

```
logger_path = os.path.join(func_to_get_temp_dir(), 'etk.log')
```",272
github.com/usc-isi-i2/etk,etk/etk.py,2018-05-11T20:00:47Z,commit https://github.com/usc-isi-i2/etk/commit/b15e69fd4a2432625bbf26ae8773b930fbbe4cad fixed this issue,272
github.com/usc-isi-i2/etk,etk/etk.py,2018-05-10T22:21:57Z,"to fix the unit tests at my end, have to merge this",271
github.com/usc-isi-i2/etk,etk/tokenizer.py,2019-01-04T18:56:08Z,"this has an open security alert, recommend upgrading if possible.

https://github.com/usc-isi-i2/etk/network/alert/requirements.txt/urllib3/open",389
github.com/usc-isi-i2/etk,etk/tokenizer.py,2019-01-04T18:56:23Z,Is jupyter still needed?,389
github.com/usc-isi-i2/etk,etk/tokenizer.py,2019-01-04T19:00:15Z,"Usually instead of flags I would recommend using an enum pattern, eg prefer passing tokenizer='spacy' over use_spacy_tokenizer=True",389
github.com/usc-isi-i2/etk,etk/tokenizer.py,2019-01-04T19:07:04Z,"Instead of miss_day/month/week/year variables, maybe a dictionary 
```
is_missing = {'D':True, 'M':True, 'Y': True, 'W':True}
```

and then you can loop:

```
for u in is_missing.keys() :
    if p in units[u]:
        is_missing[u] = False
        break
```

",389
github.com/usc-isi-i2/etk,etk/tokenizer.py,2019-01-04T19:10:46Z,👍 ,389
github.com/usc-isi-i2/etk,etk/tokenizer.py,2019-01-04T19:12:39Z,This could be a helper function.,389
github.com/usc-isi-i2/etk,etk/tokenizer.py,2019-01-04T19:17:21Z,See above.,389
github.com/usc-isi-i2/etk,etk/tokenizer.py,2019-01-04T18:56:08Z,"this has an open security alert, recommend upgrading if possible.

https://github.com/usc-isi-i2/etk/network/alert/requirements.txt/urllib3/open",389
github.com/usc-isi-i2/etk,etk/tokenizer.py,2019-01-04T18:56:23Z,Is jupyter still needed?,389
github.com/usc-isi-i2/etk,etk/tokenizer.py,2019-01-04T19:00:15Z,"Usually instead of flags I would recommend using an enum pattern, eg prefer passing tokenizer='spacy' over use_spacy_tokenizer=True",389
github.com/usc-isi-i2/etk,etk/tokenizer.py,2019-01-04T19:07:04Z,"Instead of miss_day/month/week/year variables, maybe a dictionary 
```
is_missing = {'D':True, 'M':True, 'Y': True, 'W':True}
```

and then you can loop:

```
for u in is_missing.keys() :
    if p in units[u]:
        is_missing[u] = False
        break
```

",389
github.com/usc-isi-i2/etk,etk/tokenizer.py,2019-01-04T19:10:46Z,👍 ,389
github.com/usc-isi-i2/etk,etk/tokenizer.py,2019-01-04T19:12:39Z,This could be a helper function.,389
github.com/usc-isi-i2/etk,etk/tokenizer.py,2019-01-04T19:17:21Z,See above.,389
github.com/usc-isi-i2/etk,etk/doc_retrieve_processor.py,2018-05-24T23:30:16Z,^This is more of a quick and dirty patch than a real bug fix. May require attention in the future... ,286
github.com/usc-isi-i2/etk,etk/doc_retrieve_processor.py,2018-05-25T01:06:43Z,please remove all `print` statements (`print` should only be used in examples),286
github.com/usc-isi-i2/etk,etk/doc_retrieve_processor.py,2018-05-25T01:52:49Z,"Rodger that. 

- Lukas

Sent from my iPhone

> On May 24, 2018, at 6:06 PM, GreatYYX <notifications@github.com> wrote:
> 
> please remove all print statements (print should only be used in examples)
> 
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub, or mute the thread.
",286
github.com/usc-isi-i2/etk,etk/doc_retrieve_processor.py,2018-05-27T23:15:48Z,"@GreatYYX please review and merge if ready, thx.",286
github.com/usc-isi-i2/etk,etk/doc_retrieve_processor.py,2018-05-24T23:30:16Z,^This is more of a quick and dirty patch than a real bug fix. May require attention in the future... ,286
github.com/usc-isi-i2/etk,etk/doc_retrieve_processor.py,2018-05-25T01:06:43Z,please remove all `print` statements (`print` should only be used in examples),286
github.com/usc-isi-i2/etk,etk/doc_retrieve_processor.py,2018-05-25T01:52:49Z,"Rodger that. 

- Lukas

Sent from my iPhone

> On May 24, 2018, at 6:06 PM, GreatYYX <notifications@github.com> wrote:
> 
> please remove all print statements (print should only be used in examples)
> 
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub, or mute the thread.
",286
github.com/usc-isi-i2/etk,etk/doc_retrieve_processor.py,2018-05-27T23:15:48Z,"@GreatYYX please review and merge if ready, thx.",286
github.com/usc-isi-i2/etk,etk/doc_retrieve_processor.py,2018-05-24T23:30:16Z,^This is more of a quick and dirty patch than a real bug fix. May require attention in the future... ,286
github.com/usc-isi-i2/etk,etk/doc_retrieve_processor.py,2018-05-25T01:06:43Z,please remove all `print` statements (`print` should only be used in examples),286
github.com/usc-isi-i2/etk,etk/doc_retrieve_processor.py,2018-05-25T01:52:49Z,"Rodger that. 

- Lukas

Sent from my iPhone

> On May 24, 2018, at 6:06 PM, GreatYYX <notifications@github.com> wrote:
> 
> please remove all print statements (print should only be used in examples)
> 
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub, or mute the thread.
",286
github.com/usc-isi-i2/etk,etk/doc_retrieve_processor.py,2018-05-27T23:15:48Z,"@GreatYYX please review and merge if ready, thx.",286
github.com/usc-isi-i2/etk,etk/extractors/sentence_extractor.py,2018-08-29T23:14:29Z,"Hey, please merge this pull request although there are three test cases fail. The test case failures are caused by unreasonable test case design. Please refer this issue #335 ",334
github.com/usc-isi-i2/etk,etk/extractors/sentence_extractor.py,2018-08-31T22:56:41Z,"FYI, if the variable or method needs to be private, it should starts with SINGLE underscore (PEP8). double underscore is used by interpreter for name mangling. also, double heading and trailing underscore is a name convention of builtin methods in python class.",334
github.com/usc-isi-i2/etk,etk/extractors/sentence_extractor.py,2018-09-05T05:22:20Z,suggestion accepted. Has refactored.,334
github.com/usc-isi-i2/etk,etk/extractors/sentence_extractor.py,2018-09-10T20:29:54Z,"@linqyd the latest commit is failing in travis, pls check",334
github.com/usc-isi-i2/etk,etk/extractors/sentence_extractor.py,2018-09-10T20:33:48Z,"This is not because of my modification.

Just created an issue. Please refer to #339 
",334
github.com/usc-isi-i2/etk,etk/extractors/sentence_extractor.py,2018-08-29T23:14:29Z,"Hey, please merge this pull request although there are three test cases fail. The test case failures are caused by unreasonable test case design. Please refer this issue #335 ",334
github.com/usc-isi-i2/etk,etk/extractors/sentence_extractor.py,2018-08-31T22:56:41Z,"FYI, if the variable or method needs to be private, it should starts with SINGLE underscore (PEP8). double underscore is used by interpreter for name mangling. also, double heading and trailing underscore is a name convention of builtin methods in python class.",334
github.com/usc-isi-i2/etk,etk/extractors/sentence_extractor.py,2018-09-05T05:22:20Z,suggestion accepted. Has refactored.,334
github.com/usc-isi-i2/etk,etk/extractors/sentence_extractor.py,2018-09-10T20:29:54Z,"@linqyd the latest commit is failing in travis, pls check",334
github.com/usc-isi-i2/etk,etk/extractors/sentence_extractor.py,2018-09-10T20:33:48Z,"This is not because of my modification.

Just created an issue. Please refer to #339 
",334
github.com/usc-isi-i2/etk,etk/extractors/sentence_extractor.py,2018-08-29T23:14:29Z,"Hey, please merge this pull request although there are three test cases fail. The test case failures are caused by unreasonable test case design. Please refer this issue #335 ",334
github.com/usc-isi-i2/etk,etk/extractors/sentence_extractor.py,2018-08-31T22:56:41Z,"FYI, if the variable or method needs to be private, it should starts with SINGLE underscore (PEP8). double underscore is used by interpreter for name mangling. also, double heading and trailing underscore is a name convention of builtin methods in python class.",334
github.com/usc-isi-i2/etk,etk/extractors/sentence_extractor.py,2018-09-05T05:22:20Z,suggestion accepted. Has refactored.,334
github.com/usc-isi-i2/etk,etk/extractors/sentence_extractor.py,2018-09-10T20:29:54Z,"@linqyd the latest commit is failing in travis, pls check",334
github.com/usc-isi-i2/etk,etk/extractors/sentence_extractor.py,2018-09-10T20:33:48Z,"This is not because of my modification.

Just created an issue. Please refer to #339 
",334
github.com/usc-isi-i2/etk,etk/extractors/spacy_ner_extractor.py,2019-01-04T18:56:08Z,"this has an open security alert, recommend upgrading if possible.

https://github.com/usc-isi-i2/etk/network/alert/requirements.txt/urllib3/open",389
github.com/usc-isi-i2/etk,etk/extractors/spacy_ner_extractor.py,2019-01-04T18:56:23Z,Is jupyter still needed?,389
github.com/usc-isi-i2/etk,etk/extractors/spacy_ner_extractor.py,2019-01-04T19:00:15Z,"Usually instead of flags I would recommend using an enum pattern, eg prefer passing tokenizer='spacy' over use_spacy_tokenizer=True",389
github.com/usc-isi-i2/etk,etk/extractors/spacy_ner_extractor.py,2019-01-04T19:07:04Z,"Instead of miss_day/month/week/year variables, maybe a dictionary 
```
is_missing = {'D':True, 'M':True, 'Y': True, 'W':True}
```

and then you can loop:

```
for u in is_missing.keys() :
    if p in units[u]:
        is_missing[u] = False
        break
```

",389
github.com/usc-isi-i2/etk,etk/extractors/spacy_ner_extractor.py,2019-01-04T19:10:46Z,👍 ,389
github.com/usc-isi-i2/etk,etk/extractors/spacy_ner_extractor.py,2019-01-04T19:12:39Z,This could be a helper function.,389
github.com/usc-isi-i2/etk,etk/extractors/spacy_ner_extractor.py,2019-01-04T19:17:21Z,See above.,389
github.com/usc-isi-i2/etk,etk/extractors/spacy_ner_extractor.py,2018-08-29T23:14:29Z,"Hey, please merge this pull request although there are three test cases fail. The test case failures are caused by unreasonable test case design. Please refer this issue #335 ",334
github.com/usc-isi-i2/etk,etk/extractors/spacy_ner_extractor.py,2018-08-31T22:56:41Z,"FYI, if the variable or method needs to be private, it should starts with SINGLE underscore (PEP8). double underscore is used by interpreter for name mangling. also, double heading and trailing underscore is a name convention of builtin methods in python class.",334
github.com/usc-isi-i2/etk,etk/extractors/spacy_ner_extractor.py,2018-09-05T05:22:20Z,suggestion accepted. Has refactored.,334
github.com/usc-isi-i2/etk,etk/extractors/spacy_ner_extractor.py,2018-09-10T20:29:54Z,"@linqyd the latest commit is failing in travis, pls check",334
github.com/usc-isi-i2/etk,etk/extractors/spacy_ner_extractor.py,2018-09-10T20:33:48Z,"This is not because of my modification.

Just created an issue. Please refer to #339 
",334
github.com/usc-isi-i2/etk,etk/extractors/spacy_ner_extractor.py,2018-08-29T23:14:29Z,"Hey, please merge this pull request although there are three test cases fail. The test case failures are caused by unreasonable test case design. Please refer this issue #335 ",334
github.com/usc-isi-i2/etk,etk/extractors/spacy_ner_extractor.py,2018-08-31T22:56:41Z,"FYI, if the variable or method needs to be private, it should starts with SINGLE underscore (PEP8). double underscore is used by interpreter for name mangling. also, double heading and trailing underscore is a name convention of builtin methods in python class.",334
github.com/usc-isi-i2/etk,etk/extractors/spacy_ner_extractor.py,2018-09-05T05:22:20Z,suggestion accepted. Has refactored.,334
github.com/usc-isi-i2/etk,etk/extractors/spacy_ner_extractor.py,2018-09-10T20:29:54Z,"@linqyd the latest commit is failing in travis, pls check",334
github.com/usc-isi-i2/etk,etk/extractors/spacy_ner_extractor.py,2018-09-10T20:33:48Z,"This is not because of my modification.

Just created an issue. Please refer to #339 
",334
github.com/usc-isi-i2/etk,etk/unit_tests/test_sentence_extractor.py,2019-04-18T16:54:06Z,Thanks. CI failed due to some dependencies. Please fix them.,397
github.com/usc-isi-i2/etk,etk/unit_tests/test_sentence_extractor.py,2019-04-18T17:35:35Z,CI failed due to non-kg issues. Might be addressed in other branch.,397
github.com/usc-isi-i2/etk,etk/unit_tests/test_sentence_extractor.py,2019-04-18T19:19:48Z,Probably you need to synchronize kg_graph with development branch first for somebody fixed unit tests.,397
