repo_url,filepath,commit_date,message
github.com/google-research/google-research,agile_modeling/load_clip.py,2024-01-23T00:22:24Z,"Open-sourcing the code for ""CLIP as RNN: Segment Countless Visual Concepts without Training Endeavor"".
https://arxiv.org/abs/2312.07661

PiperOrigin-RevId: 600601383"
github.com/google-research/google-research,agile_modeling/load_clip.py,2023-09-15T18:25:10Z,"Steps 1-3 (up to initial model training) ported to external colab.

PiperOrigin-RevId: 565729930"
github.com/Stability-AI/stablediffusion,ldm/modules/encoders/modules.py,2023-03-24T10:18:44Z,add stable unclip
github.com/Stability-AI/stablediffusion,ldm/modules/encoders/modules.py,2022-11-24T00:22:28Z,release more models
github.com/lllyasviel/ControlNet,ldm/modules/encoders/modules.py,2023-02-10T19:28:11Z,i
github.com/langchain-ai/langchain,libs/experimental/langchain_experimental/open_clip/open_clip.py,2024-02-24T02:24:16Z,"experimental: docstrings update (#18048)

Added missed docstrings. Formatted docsctrings to the consistent format."
github.com/langchain-ai/langchain,libs/experimental/langchain_experimental/open_clip/open_clip.py,2024-01-02T20:09:45Z,"langchain[patch], experimental[patch]: replace langchain.schema imports (#15410)

Import from core instead.

Ran:
```bash
git grep -l 'from langchain.schema\.output_parser' | xargs -L 1 sed -i '' ""s/from\ langchain\.schema\.output_parser/from\ langchain_core.output_parsers/g""
git grep -l 'from langchain.schema\.messages' | xargs -L 1 sed -i '' ""s/from\ langchain\.schema\.messages/from\ langchain_core.messages/g""
git grep -l 'from langchain.schema\.document' | xargs -L 1 sed -i '' ""s/from\ langchain\.schema\.document/from\ langchain_core.documents/g""
git grep -l 'from langchain.schema\.runnable' | xargs -L 1 sed -i '' ""s/from\ langchain\.schema\.runnable/from\ langchain_core.runnables/g""
git grep -l 'from langchain.schema\.vectorstore' | xargs -L 1 sed -i '' ""s/from\ langchain\.schema\.vectorstore/from\ langchain_core.vectorstores/g""
git grep -l 'from langchain.schema\.language_model' | xargs -L 1 sed -i '' ""s/from\ langchain\.schema\.language_model/from\ langchain_core.language_models/g""
git grep -l 'from langchain.schema\.embeddings' | xargs -L 1 sed -i '' ""s/from\ langchain\.schema\.embeddings/from\ langchain_core.embeddings/g""
git grep -l 'from langchain.schema\.storage' | xargs -L 1 sed -i '' ""s/from\ langchain\.schema\.storage/from\ langchain_core.stores/g""
git checkout master libs/langchain/tests/unit_tests/schema/
make format
cd libs/experimental
make format
cd ../langchain
make format
```"
github.com/langchain-ai/langchain,libs/experimental/langchain_experimental/open_clip/open_clip.py,2023-12-05T21:36:38Z,"Multi-modal RAG template (#14186)

* OpenCLIP embeddings
* GPT-4V

---------

Co-authored-by: Erick Friis <erick@langchain.dev>"
github.com/langchain-ai/langchain,libs/experimental/langchain_experimental/open_clip/open_clip.py,2023-12-01T23:13:20Z,"Update Open CLIP embd (#14155)

Prior default model required a large amt of RAM and often crashed
Jupyter ntbk kernel."
github.com/langchain-ai/langchain,libs/experimental/langchain_experimental/open_clip/open_clip.py,2023-11-10T17:43:10Z,"Add Chroma multimodal cookbook (#12952)

Pending:
* https://github.com/chroma-core/chroma/pull/1294
* https://github.com/chroma-core/chroma/pull/1293

---------

Co-authored-by: Erick Friis <erick@langchain.dev>
Co-authored-by: Bagatur <baskaryan@gmail.com>"
github.com/Stability-AI/generative-models,sgm/modules/encoders/modules.py,2023-11-21T18:40:21Z,Stable Video Diffusion
github.com/Stability-AI/generative-models,sgm/modules/encoders/modules.py,2023-07-26T08:30:21Z,"Revert ""Replace most print()s with logging calls (#42)"" (#65)

This reverts commit 6f6d3f8716bda7d9c74405a7d1d8e4beaa74f9d2."
github.com/Stability-AI/generative-models,sgm/modules/encoders/modules.py,2023-07-25T13:21:30Z,Replace most print()s with logging calls (#42)
github.com/Stability-AI/generative-models,sgm/modules/encoders/modules.py,2023-06-22T16:53:12Z,soon is now
github.com/AUTOMATIC1111/stable-diffusion-webui,modules/sd_disable_initialization.py,2023-12-14T07:15:22Z,"Merge pull request #14216 from wfjsw/state-dict-ref-comparison

change state dict comparison to ref compare"
github.com/AUTOMATIC1111/stable-diffusion-webui,modules/sd_disable_initialization.py,2023-08-16T09:11:01Z,send weights to target device instead of CPU memory
github.com/AUTOMATIC1111/stable-diffusion-webui,modules/sd_disable_initialization.py,2023-08-16T06:55:35Z,RAM optimization round 2
github.com/AUTOMATIC1111/stable-diffusion-webui,modules/sd_disable_initialization.py,2023-07-24T19:08:08Z,Use less RAM when creating models
github.com/AUTOMATIC1111/stable-diffusion-webui,modules/sd_disable_initialization.py,2023-05-10T04:52:45Z,autofixes from ruff
github.com/AUTOMATIC1111/stable-diffusion-webui,modules/sd_disable_initialization.py,2023-02-05T08:21:00Z,make it possible to load SD1 checkpoints without CLIP
github.com/AUTOMATIC1111/stable-diffusion-webui,modules/sd_disable_initialization.py,2023-01-22T05:20:48Z,fix missing field for aesthetic embedding extension
github.com/AUTOMATIC1111/stable-diffusion-webui,modules/sd_disable_initialization.py,2023-01-11T15:54:13Z,"fix for an error caused by skipping initialization, for realsies this time: TypeError: expected str, bytes or os.PathLike object, not NoneType"
github.com/AUTOMATIC1111/stable-diffusion-webui,modules/sd_disable_initialization.py,2023-01-10T14:46:59Z,"add support for transformers==4.25.1
add fallback for when quick model creation fails"
github.com/AUTOMATIC1111/stable-diffusion-webui,modules/sd_disable_initialization.py,2023-01-10T13:51:04Z,"add more stuff to ignore when creating model from config
prevent .vae.safetensors files from being listed as stable diffusion models"
github.com/AUTOMATIC1111/stable-diffusion-webui,modules/sd_disable_initialization.py,2023-01-10T11:08:29Z,disable torch weight initialization and CLIP downloading/reading checkpoint to speedup creating sd model from config
github.com/hpcaitech/ColossalAI,examples/images/diffusion/ldm/modules/encoders/modules.py,2023-09-19T06:20:26Z,"[misc] update pre-commit and run all files (#4752)

* [misc] update pre-commit

* [misc] run pre-commit

* [misc] remove useless configuration files

* [misc] ignore cuda for clang-format"
github.com/hpcaitech/ColossalAI,examples/images/diffusion/ldm/modules/encoders/modules.py,2022-12-13T06:26:49Z,support stable diffusion v2
github.com/hpcaitech/ColossalAI,examples/images/diffusion/ldm/modules/encoders/modules.py,2022-11-08T06:39:35Z,"add ColoDiffusion codes: /ldm/module/, /ldm/data/, /scripts/test/"
github.com/brycedrennan/imaginAIry,imaginairy/modules/encoders.py,2023-12-15T22:32:01Z,"docs: add docstrings

Wrote an openai script and custom prompt to generate them."
github.com/brycedrennan/imaginAIry,imaginairy/modules/encoders.py,2023-09-30T06:01:50Z,style: speed up linting and autoformatting. fix lints
github.com/brycedrennan/imaginAIry,imaginairy/modules/encoders.py,2023-01-02T22:11:36Z,lint: new ruff linter
github.com/brycedrennan/imaginAIry,imaginairy/modules/encoders.py,2022-11-25T22:39:20Z,refactor: fix lint issues
github.com/brycedrennan/imaginAIry,imaginairy/modules/encoders.py,2022-11-24T08:50:57Z,"feature: Stable Diffusion 2.0

working: CUDA and MacOS
working: 512p model with all samplers
working: inpainting with all samplers
working: 768p model with ddim sampler"
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2023-06-23T02:58:24Z,"[pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci"
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-11-03T07:05:54Z,Initial conversion of the sd_util.py file into a package with smaller modules in it.
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-11-01T17:25:43Z,Cleaned some commented code that is no longer needed.
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-31T20:38:31Z,Added support for webp images in the img2txt tab
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-27T01:40:17Z,Moved the generate button to the top of the page so it doesn't get pushed down and disappear when there are many images or the expanders are not collapsed.
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-27T00:21:51Z,Fixed log not in defaults.
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-24T11:45:09Z,Added logging back to the img2txt tab.
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-24T10:48:45Z,Update img2txt.py
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-24T10:15:22Z,Update img2txt.py
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-24T07:22:36Z,Improved the img2txt tab by having more tags.
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-24T07:21:54Z,"Added option to make the grid format the same as the individual image format.
There is a new option called grid quality now that allow you to specify on the settings page the quality for the grid image."
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-24T01:54:10Z,"More renaming and changed to links related to the organization, docs and repo names."
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-24T00:17:50Z,"More renaming and changes to links related to the organization, docs an repo names."
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-23T23:22:40Z,Fixed links so they point to the new repo and organization names.
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-22T20:30:12Z,Made sure the log variable is still around on the img2txt after its being cleared.
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-17T22:59:29Z,Improved logging for img2txt.
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-17T12:10:06Z,Added reraise option for loguru.
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-15T16:32:15Z,Replaced most if not all print statements with loguru to make the console output easier to understand and just look better overall.
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-06T07:03:45Z,Added extra models back to img2txt.
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-05T04:31:20Z,img2txt speed + vram issues
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-04T18:39:52Z,"model manager

model manager"
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-04T10:43:36Z,"Update img2txt.py

// is not a comment"
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-02T02:19:04Z,Merge remote-tracking branch 'origin/dev' into dev
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-01T22:39:12Z,Added WIP code for img2txt to get information dynamically from artstation.
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-01T21:50:40Z,docker / local cache paths
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-10-01T20:47:26Z,Update img2txt.py
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-09-30T22:46:02Z,...
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-09-30T20:04:08Z,Add more print statements to provide more info on whats happening behind the scenes.
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-09-30T19:41:01Z,Improved img2txt layout and performance.
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-09-30T15:47:30Z,Added open clip dependency which is needed for some CLIP models.
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-09-30T09:40:02Z,Update img2txt.py
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-09-29T15:52:46Z,Img2txt working now but needs more than 8GB og VRAM to work. Will be trying to improve it as the next step.
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-09-29T14:27:56Z,More fixes for img2txt
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-09-29T08:07:32Z,More fixes to img2txt
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-09-28T19:37:15Z,Img2txt dependencies and necessary files. (#1354)
github.com/Sygil-Dev/Sygil-WebUI,scripts/img2txt.py,2022-09-28T16:33:54Z,"Changed the default streamlit import for hydralit as we will be using hydralit as replacement for the default streamlit library, hydralit provides better control over css as well as having a lot more options. (#1352)"
github.com/TheLastBen/fast-stable-diffusion,Dreambooth/det.py,2023-04-16T21:55:55Z,Update det.py
github.com/TheLastBen/fast-stable-diffusion,Dreambooth/det.py,2023-04-13T03:42:50Z,Update det.py
github.com/TheLastBen/fast-stable-diffusion,Dreambooth/det.py,2023-04-12T20:54:38Z,Add files via upload
github.com/NVIDIA/NeMo,scripts/fid-eval-text2img/compute_clip_score.py,2024-01-20T01:59:23Z,"Final multimodal PR with our recent developments on MM side (#8127)

* Hotfix (#7501) (#7568)

Signed-off-by: Jan Baczek <jbaczek@nvidia.com>
Co-authored-by: jbaczek <45043825+jbaczek@users.noreply.github.com>

* Avoid duplicated checkpoint save (#7555) (#7566)

Signed-off-by: Mikołaj Błaż <mblaz@nvidia.com>
Co-authored-by: mikolajblaz <mikolajblaz@users.noreply.github.com>

* Cache FP8 weight and transpose only at the first micro-batch in each validation and test routine (#7470) (#7483)

* Cache weight and transpose only in the first batch in all training, val, and test runs



* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Add an option to disable manual GC in validation (#7467) (#7476)

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>

* Remove PUBLICATIONS.md, point to github.io NeMo page instead (#7694) (#7695)

* update publications section to point to blog website page



* add hyphen



* use double backquotes for code formatting



---------

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>
Signed-off-by: Elena Rastorgueva <80532067+erastorgueva-nv@users.noreply.github.com>
Co-authored-by: Elena Rastorgueva <80532067+erastorgueva-nv@users.noreply.github.com>

* Fix multi rank finetune for ASR (#7684) (#7699)

* Fix multi rank finetune for ASR



* Actually add time



* Actually add time



---------

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>

* Update docs: readme, getting started, ASR intro (#7679)

* [TTS] Add dataset to path of logged artifacts (#7462)

* [TTS] Add dataset to path of logged artifacts

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Revert axis name back to Audio Frames

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* move install info to INSTALLATION.md

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* tidy up links

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix sft dataset truncation (#7464)

* Add fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Automatic Lip Reading Recognition (ALR) - ASR/CV (Visual ASR) (#7330)

* striding_conv1d_k5 and dw_striding_conv1d_k5 subsampling

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* transpose conv1d inputs

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* Update subsampling.py

change striding_conv1d_k5 to striding_conv1d

Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>

* cv branch

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* video manifest

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* add collection classes

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add test_step_outputs

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* correct manifest bug when having only audio or only videos

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* correct manifest bug when having only audio or only videos

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* clean references

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* freeze unfreeze transcribe cv models

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* correct manifest get_full_path bug

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* update for PR

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* guard torchvision

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Update nemo/collections/cv/data/video_to_text_dataset.py

Co-authored-by: Igor Gitman <igor.a.gitman@gmail.com>
Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>

* _video_speech_collate_fn in cv/data/video_to_text.py

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* add self.out = None to asr subsampling

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* Update nemo/collections/cv/data/video_to_text_dataset.py

Co-authored-by: Igor Gitman <igor.a.gitman@gmail.com>
Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>

* cv -> multimodal/speech_cv branch

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: mburchi <maxime.burchi@gmail.com>
Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Igor Gitman <igor.a.gitman@gmail.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* HF StarCoder to NeMo conversion script (#7421)

* Script to convert HF StarCoder checkpoint to NeMo

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* StarCoder conversion test

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Fix test

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Catch up with save_to changes

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Don't abbreviate args for clarity

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Configurable precision: BF16 vs FP32

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* fix bug when loading dist ckpt in peft (#7452)

Signed-off-by: Hongbin Liu <hongbinl@nvidia.com>
Co-authored-by: Hongbin Liu <hongbinl@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix adding positional embeddings in-place in transformer module (#7440)

Signed-off-by: Tamerlan Tabolov <tktabolov@gmail.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix (#7478)

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* add sleep (#7498) (#7499)

* add sleep



* add sleep onto config instead



* add comment



---------

Signed-off-by: Gerald Shen <geshen@nvidia.com>
Co-authored-by: Gerald Shen <119401249+gshennvm@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix exp manager check for sleep (#7503) (#7504)

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* bugfix: trainer.accelerator=auto from None. (#7492) (#7493)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [doc] fix broken link (#7481)

Signed-off-by: Stas Bekman <stas00@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [TTS] Read audio as int32 to avoid flac read errors (#7477)

* [TTS] Read audio as int32 to avoid flac read errors

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Add comment about read failures

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS (#7409)

* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS
* Train 'AISHELL-3' dataset with multi-speakers

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update get_data.py

update copyright header

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* Update get_data.py

added a disclaimer

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add new configuration file for AISHELL3 with multispeaker of fastpitch

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* dllogger - log on rank 0 only (#7513)

Signed-off-by: Stas Bekman <stas00@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix TTS FastPitch tutorial (#7494) (#7516)

* Fix

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix get_dist() tensor dimension (#7506) (#7515)

Signed-off-by: Jocelyn Huang <jocelynh@nvidia.com>
Co-authored-by: Jocelyn <jocelynh@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* bugfix: specify trainer.strategy=auto when devices=1 (#7509) (#7512)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* fix (#7511)

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [TTS] Fix FastPitch data prep tutorial (#7524)

Signed-off-by: Ryan <rlangman@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* add italian tokenization (#7486)

* add italian tokenization

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add more ipa lexicon it

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix error deletion

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* add test

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Replace None strategy with auto in tutorial notebooks (#7521) (#7527)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* unpin setuptools (#7534) (#7535)

Signed-off-by: fayejf <36722593+fayejf@users.noreply.github.com>
Co-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* remove auto generated examples (#7510)

* explicitly remove autogenerated examples for data parallel evaluation

Signed-off-by: arendu <adithyare@nvidia.com>

* mark autogenrated and remove it for test

Signed-off-by: arendu <adithyare@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: arendu <adithyare@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Add the `strategy` argument to `MegatronGPTModel.generate()` (#7264)

It is passed as an explicit argument rather than through
`**strategy_args` so as to ensure someone cannot accidentally pass other
arguments that would end up being ignored.

It is a keyword-only argument to ensure that if in the future we want to
update the signature to `**strategy_args`, we can do it without breaking
code.

Signed-off-by: Olivier Delalleau <507137+odelalleau@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix PTL2.0 related ASR bugs in r1.21.0: Val metrics logging, None dataloader issue (#7531) (#7533)

* fix none dataloader issue ptl2



* ptl2.0 logging fixes for rnnt_models



---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Co-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* gpus -> devices (#7542) (#7545)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Update FFMPEG version to fix issue with torchaudio (#7551) (#7553)

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* PEFT GPT & T5 Refactor (#7308)

* initial implementation of add_adapters API

* correct type hint

* Add config in add_adapters for save and load (@author bobchen)

* Remove AdapterConfig to avoid import error

* Add AdaterConfig back and move adaptermixin to sft model

* Add NLPSaveRestoreConnector as default in NLPModel.restore_from

* Add restore_from_nemo_with_adapter and test script

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* rename t5 file and classes to be consistent with GPT

* add t5 sft dataset

* add support for single-file format with T5SFTDataset

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Various small changes to make T5 SFT work like GPT SFT

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add adapter evaluation test script

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add MultiAdaterConfig for ia3 and fix builder issue

* Make ptuning for T5SFTModel work using mixin

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add IA3_Adapter for AdapterName

* Add adapter name for ptuning and attention adapter

* Make test script GPT/T5 agnostic

* Add layer selection feature

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Integrate adapter name and config

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update gpt peft tuning script to new API

* add t5 peft tuning script with new API

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix IA3 layer selection issue

* Override state_dict on SFT model instead of mixin

* Add load adapter by adapter config

* move peft config map away from example script

* auto get config from nemo adapter

* Move PEFTConfig to new file

* fix ckpt save/load for t5

* name change: add_adapters -> add_adapter

* variable name change

* update t5 script

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix t5 issues

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add weight tying

* update gpt tuning script

* PEFT-API proposal

* Fix according to comments

* update tuning scripts

* move merge_cfg_with to mixin class since it applies to both gpt and t5 and requires the model class for restore

* Add mcore_gpt support for NLPAdapterMixin

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix typo

* variable name change to distinguish ""peft"" and ""adapter""

* override `load_adapters` to support `add_adapter` name change

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update tuning and eval script for adapter save/load

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add Ptuning on first stage only

* add lora tutorial for review

* Fix layer selection for mcore

* add landing page

* fix resume training

Signed-off-by: jasonwan <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add mcore condition in sharded_state_dict to make sft work

* Update lora_tutorial.md

First edit of this file for PEFT documentation for NeMO

Signed-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>

* rename Adapter to AttentionAdapter to avoid confusion in doc

* Change load_adapters to load .nemo

* add quick start guide

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add load_adapters with .ckpt

* Remove setup_complete changes in load_adapters

* update landing page

* remove typo

* Updated quick_start.md per Chen Cui

Signed-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>

* Add inference config merger and tutorial

* Add doc string for NLPAdapterModelMixin and deprecated warning on MegatronGPTPEFTModel

* add supported_methods.md and update other documentations

* Update supported_methods.md

minor updates.

Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>

* Update landing_page.md

minor update.

Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>

* Modify doc string for NLPAdapterModelMixin

* Add doc string add_adapters in NLPAdapterModelMixin

* rename canonical adapters

* remove mcore hard dependency

* [PATCH] move microbatch calculator to nemo from apex

* remove apex dependency in gpt and t5 sft models

* remove apex dependency in gpt model

* render doc strings

* fix

* Add missing virtual_tokens on ptuning

* fix docstrings

* update gpt-style model coverage in docs

* update docstring

* Remove pdb

* add lightning_fabric to make docstring rendering work

* Add Ptuning missing key

* try docstring rendering

* Fix ptuning issue

* update gpt t5 peft tuning and eval scripts

* typos

* update eval config

* fix bug relating to apex dependency removal

* typo

* make predict step behave the same as test step

* make lora tutorial work in notebook

* cosmetics

* update yaml scripts

* mcore_gpt attribute optional

* typo

* update eval scripts and fix T5 eval bugs

* add NLPDDPStrategyNotebook and trainer builder logic to use it

* update lora notebook to use new trainer builder

* fix microbatch calculator bug for inference after training

* Convert markdown files to RST and incorporate with doc

* typo

* revise language

* remove extra cell

* remove unnecessary inheritance

* remove old tests

* move layer selection default so logging messages make sense

* remove `save_adapters` as adapter weights are saved automatically during training

* initialize weights from a checkpoint instead of randomly

* multiple fields can form a context (#7147)

* list of context fields and flexible prompt template

Signed-off-by: arendu <adithya.r@gmail.com>

* list of fields for context

Signed-off-by: arendu <adithya.r@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Add multiple truncation fields and middle truncation

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Compatible to old ckpt

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix tokenize detokenize issue

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Remove detokenization, add truncation augmentation

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Resolve comments

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Remove unused import

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* revert eos

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Add tokenizer space_sensitive attribute

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix error

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Fix erorr and use re

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Change assert logic

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Follow adi suggestion

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Remove merge function

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add example and comment

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Remove context_key and add comment

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Remove random truncation

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix template none

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: arendu <adithya.r@gmail.com>
Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Signed-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

* revert config changes

* remove accidental breakpoint

* support TP>1 loading

* infer adapter type from checkpoint in during eval

* breakup add adapter

* enable interpolation of train_ds and validation_ds

* update metric calc script to conform to single-file eval format

* remove extraneous print

* update lora notebook for updated merge_inference_cfg

* Update nlp_adapter_mixins.py

variable name change

Signed-off-by: Chen Cui <chcui@nvidia.com>

* turn off grad scaler for PP to match old scripts

* remove PEFTSaveRestoreConnector since functionality all covered by the new mixin class

* remove resume_from_checkpoint check since covered in #7335

* revert changes made in eval config interpolation

* more interpolation

* typo

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* remove dup line

Signed-off-by: Chen Cui <chcui@nvidia.com>

* code style warnings

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix config mistake

Signed-off-by: Chen Cui <chcui@nvidia.com>

* add copyright header

Signed-off-by: Chen Cui <chcui@nvidia.com>

* fix code check warnings

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* revert changes to remove apex dependency (mixed apex+nemo microbatch calculator broke some CI tests)

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add more deprecation notices

Signed-off-by: Chen Cui <chcui@nvidia.com>

* update deprecation notices

Signed-off-by: Chen Cui <chcui@nvidia.com>

* update deprecation notices

Signed-off-by: Chen Cui <chcui@nvidia.com>

* consolidate peft and sft scripts

Signed-off-by: Chen Cui <chcui@nvidia.com>

* update CI tests

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* notebook branch points to main to prepare for merge

Signed-off-by: Chen Cui <chcui@nvidia.com>

* fix gpt and t5 validation with any metric other than loss

Signed-off-by: Chen Cui <chcui@nvidia.com>

* support pre-extracted checkpoints

Signed-off-by: Chen Cui <chcui@nvidia.com>

---------

Signed-off-by: jasonwan <jasonwan@nvidia.com>
Signed-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>
Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>
Signed-off-by: arendu <adithya.r@gmail.com>
Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Signed-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>
Signed-off-by: Chen Cui <chcui@nvidia.com>
Co-authored-by: Chen Cui <chcui@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Marc Romeyn <marcromeyn@gmail.com>
Co-authored-by: jasonwan <jasonwan@nvidia.com>
Co-authored-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>
Co-authored-by: Adi Renduchintala <adithyare@nvidia.com>
Co-authored-by: Yuanzhe Dong <yudong@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* fix a typo (#7496)

Signed-off-by: BestJuly <chntaoli@163.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [TTS] remove curly braces from ${BRANCH} in jupyer notebook cell. (#7554) (#7560)

* remove curly braces.
* remove installation of pynini.
---------

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* add youtube embed url (#7570)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Remap speakers to continuous range of speaker_id for dataset AISHELL3 (#7536)

* Remap speakers to continuous range of speaker_id for dataset AISHELL3
* Add new key/value pair to record raw speaker for AISHELL3 dataset

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* fix validation_step_outputs initialization for multi-dataloader (#7546) (#7572)

* added correct validation_step_outputs initialization for mutli-dataloader



* changed kernel for display



* Update logic for validation and test step outputs



* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* revert multidataloader changes in multilang ASR notebook



---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Append output of val step to self.validation_step_outputs (#7530) (#7532)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [TTS] fixed trainer's accelerator and strategy. (#7569) (#7574)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Append val/test output to instance variable in EncDecSpeakerLabelModel (#7562) (#7573)

* Append val/test output to the instance variable in EncDecSpeakerLabelModel



* Handle test case in evaluation_step



* Replace type with isinstance



---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix CustomProgressBar for resume (#7427) (#7522)

* Fix CustomProgress Bar for resume and multiple epochs



* Edit num_training_batches



* Use max_steps as total for progress bar for resume



* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* fix typos in nfa and speech enhancement tutorials (#7580) (#7583)

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>
Co-authored-by: Elena Rastorgueva <80532067+erastorgueva-nv@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Add strategy as ddp_find_unused_parameters_true for glue_benchmark.py (#7454) (#7461)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* update strategy (#7577) (#7578)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix typos (#7581)

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Change hifigan finetune strategy to ddp_find_unused_parameters_true (#7579) (#7584)

* Change strategy to auto



---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [BugFix] Add missing quotes for auto strategy in tutorial notebooks (#7541) (#7548)

* Add missing quotes for auto strategy



* Revert trainer.gpus to trainer.devices in Self_Supervised_Pre_Training.ipynb



---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Signed-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* add build os key (#7596) (#7599)

* add build os key



* add tools



* update to stable version



---------

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* StarCoder SFT test + bump PyT NGC image to 23.09 (#7540)

* Add SFT StarCoder test

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Remove _modify_config call as it is covered in load_from_nemo just below

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Test with pyt:23.09 container

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

---------

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* defaults changed (#7600)

* defaults changed

Signed-off-by: arendu <adithyare@nvidia.com>

* typo

Signed-off-by: arendu <adithyare@nvidia.com>

* update

Signed-off-by: arendu <adithyare@nvidia.com>

---------

Signed-off-by: arendu <adithyare@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* add ItalianPhonemesTokenizer (#7587)

* add ItalianPhonemesTokenizer

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix Italian phonemes

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add test

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

---------

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* best ckpt fix (#7564) (#7588)

Signed-off-by: dimapihtar <dpihtar@gmail.com>
Co-authored-by: Dmytro Pykhtar <37850217+dimapihtar@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Add files via upload (#7598)

specifies the branch

Signed-off-by: George <37293288+Jorjeous@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix validation in G2PModel and ThutmoseTaggerModel (#7597) (#7606)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain (#7576) (#7586)

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain
* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Safeguard nemo_text_processing installation on ARM (#7485)

* safeguard nemo_text_processing installing

Signed-off-by: Jason <jasoli@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update check

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Bound transformers version in requirements (#7620)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* fix llama2 70b lora tuning bug (#7622)

* fix llama2 70b lora tuning bug

Signed-off-by: Chen Cui <chcui@nvidia.com>

* Update peft_config.py

brackets

Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>

---------

Signed-off-by: Chen Cui <chcui@nvidia.com>
Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>
Co-authored-by: Adi Renduchintala <adithyare@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix import error no module name model_utils (#7629)

Signed-off-by: Mehadi Hasan Menon <mehadihasan80@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* add fc large ls models (#7641)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao Koluguri <nithinraok>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* bugfix: trainer.gpus, trainer.strategy, trainer.accelerator (#7621) (#7642)

* [TTS] bugfix for Tacotron2 tutorial due to PTL 2.0
* trainer.gpus -> trainer.devices
* fixed related tutorial bugs
---------
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* fix ssl models ptl monitor val through logging (#7608) (#7614)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix metrics for SE tutorial (#7604) (#7612)

Signed-off-by: Ante Jukić <ajukic@nvidia.com>
Co-authored-by: anteju <108555623+anteju@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Add ddp_find_unused_parameters=True and change accelerator to auto (#7623) (#7644)

* Add ddp_find_unused_parameters=True and change acclerator to auto



* Add ddp_find_unused_parameters True for normalization_as_tagging_train.py



---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix py3.11 dataclasses issue  (#7616)

* Fix py3.11 dataclasses issue  (#7582)

* Update ASR configs to support Python 3.11

Signed-off-by: smajumdar <titu1994@gmail.com>

* Update TTS configs to support Python 3.11

Signed-off-by: smajumdar <titu1994@gmail.com>

* Guard MeCab and Ipadic

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix remaining ASR dataclasses

Signed-off-by: smajumdar <titu1994@gmail.com>

* Fix remaining ASR dataclasses

Signed-off-by: smajumdar <titu1994@gmail.com>

* Fix scripts

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Update name to ConfidenceMethodConfig

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain (#7576) (#7586)

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain
* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Safeguard nemo_text_processing installation on ARM (#7485)

* safeguard nemo_text_processing installing

Signed-off-by: Jason <jasoli@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update check

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Fix changes to confidence measure

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: smajumdar <titu1994@gmail.com>
Signed-off-by: Sangkug Lym <slym@nvidia.com>
Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: github-actions[bot] <41898282+github-actions[bot]@users.noreply.github.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Jason <jasoli@nvidia.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix issues with Dockerfile (#7650) (#7652)

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [ASR] RNN-T greedy decoding max_frames fix for alignment and confidence (#7635)

* decoding and test fix

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [ASR] Fix type error in jasper (#7636) (#7653)

Signed-off-by: Ryan <rlangman@nvidia.com>
Co-authored-by: Ryan Langman <rlangman@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [TTS] Add STFT and SI-SDR loss to audio codec recipe (#7468)

* [TTS] Add STFT and SI-SDR loss to audio codec recipe

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix STFT resolution

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix training metric logging

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Add docstring to mel and stft losses

Signed-off-by: Ryan <rlangman@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Ryan <rlangman@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* add outline of asr quickstart info to asr/intro.rst

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* add CLI, LM and real-time transcription sections

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Create per.py (#7538)

* Move model precision copy (#7336)

* move cfg precision set to megatron base model

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* remove copy from other models

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* modify attribute not arg

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* fix gpt model test for ptl 2.0

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* rename function and add docstring

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* replace precision to dtype conditionals with func call

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* unnecessary function and cfg reset

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* set default value

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* fix precision lookup in a few more places

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* rename mapping function

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* ununsed import

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* save torch datatype to model

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* set weights precision wrt amp o2

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* Revert ""set weights precision wrt amp o2""

This reverts commit 313a4bfe5eb69d771a6d2433898c0685836aef5c.

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* revert half precision at inference attempt

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* move autocast dtype to base model

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* move params dtype to base model, enable fp16 O2 inf

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* unused imports

Signed-off-by: Maanu Grover <maanug@nvidia.com>

---------

Signed-off-by: Maanu Grover <maanug@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix PEFT checkpoint loading (#7388)

* Fix PEFT checkpoint loading

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Jason Wang <jasonwan@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Use distributed optimizer support for multiple dtypes (#7359)

* Update distopt wrapper with multiple dtype support

Remove manual handling of separate FP32 optimizer.

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Use distopt support for contiguous buffers with multiple dtypes

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Fix typo

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Separate distopt buckets for first GPT layer and non-overlapped params

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Add distopt logic for int dtypes

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Update Apex commit

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Remove unused variables

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Update Apex commit in README and Jenkensfile

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Debug Dockerfile and Jenkinsfile

Signed-off-by: Tim Moon <tmoon@nvidia.com>

---------

Signed-off-by: Tim Moon <tmoon@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* minor fix for llama ckpt conversion script (#7387)

* minor fix for llama ckpt conversion script

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* Update Jenkinsfile

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* remove fast_swiglu configuration

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

---------

Signed-off-by: Jason Wang <jasonwan@nvidia.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix wrong calling of librosa.get_duration() in notebook (#7376)

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [PATCH] PEFT import mcore (#7393)

* [PATCH] PEFT import mcore

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Jason Wang <jasonwan@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Create per.py

Script for calculation Punctuation Error Rate and related rates (correct rate, deletions rate, etc.)

Signed-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [TTS] Added a callback for logging initial data (#7384)

Signed-off-by: Ante Jukić <ajukic@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update Core Commit (#7402)

* Update Core Commit

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* update commit

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

---------

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Use cfg attribute in bert (#7394)

* use cfg attribute instead of arg

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* use torch_dtype in place of cfg.precision

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* move precision copy before super constructor

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* use trainer arg

Signed-off-by: Maanu Grover <maanug@nvidia.com>

---------

Signed-off-by: Maanu Grover <maanug@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add support for bias conversion in Swiglu models (#7386)

* Add support for bias conversion in Swiglu models

Signed-off-by: smajumdar <titu1994@gmail.com>

* Add support for auto extracting tokenizer model

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add support for auto extracting tokenizer model

Signed-off-by: smajumdar <titu1994@gmail.com>

* Fix issue with missing tokenizer

Signed-off-by: smajumdar <titu1994@gmail.com>

* Refactor

Signed-off-by: smajumdar <titu1994@gmail.com>

* Refactor

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update save_to and restore_from for dist checkpointing (#7343)

* add dist ckpt to save to, in progress

Signed-off-by: eharper <eharper@nvidia.com>

* move dist ckpt

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* clean up

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update restore from, need to figure out how to initialize distributed

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* launch distrib if needed when restoring dist ckpt

Signed-off-by: eharper <eharper@nvidia.com>

* when using mcore we can change tp pp on the fly

Signed-off-by: eharper <eharper@nvidia.com>

* add load_from_checkpoint support for dist ckpt

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update llama convert script to save dist .nemo

Signed-off-by: eharper <eharper@nvidia.com>

* fix load dist ckpt

Signed-off-by: jasonwan <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* setup TE TP groups if needed

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* setup te tp groups if needed

Signed-off-by: eharper <eharper@nvidia.com>

* remove import

Signed-off-by: eharper <eharper@nvidia.com>

---------

Signed-off-by: eharper <eharper@nvidia.com>
Signed-off-by: jasonwan <jasonwan@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: jasonwan <jasonwan@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* fix forward for with mcore=false (#7403)

Signed-off-by: Jimmy Zhang <jiemingz@nvidia.com>
Co-authored-by: Jimmy Zhang <jiemingz@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix logging to remove 's/it' from progress bar in Megatron models and add train_step_timing (#7374)

* Add CustomProgressBar class to exp_manager and trainer callbacks

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix the progress bar to reflect total microbatch cnt

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* Modify CustomProgressBar class

1) Modify CustomProgressBar class to update progress bar per global_step instead of per microbatch
2) Add the callback to other megatron training/finetuning files that are not using MegatronTrainerBuilder

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* Add CustomProgressBar callback to tuning files

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Set Activation Checkpointing Defaults (#7404)

* Set Activation Checkpointing Defaults

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* check for None

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* make loss mask default to false (#7407)

Signed-off-by: eharper <eharper@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add dummy userbuffer config files (#7408)

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* add missing ubconf files (#7412)

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* New tutorial on Speech Data Explorer (#7405)

* Added Google Colab based tutorial on Speech Data Explorer

Signed-off-by: George Zelenfroynd <gzelenfroind@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update ptl training ckpt conversion script to work with dist ckpt (#7416)

* update ptl convert script

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* don't break legacy

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: eharper <eharper@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Allow disabling sanity checking when num_sanity_val_steps=0 (#7413)

* Allow disabling sanity checking when num_sanity_val_steps=0

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* Update num_sanity_val_steps to be a multiple of num_microbatches

Signed-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Signed-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add comprehensive error messages (#7261)

Signed-off-by: Anton Peganov <apeganov@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* check NEMO_PATH (#7418)

Signed-off-by: Nikolay Karpov <karpnv@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* layer selection for ia3 (#7417)

* layer selection for ia3

Signed-off-by: arendu <adithyare@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: arendu <adithyare@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix missing pip package 'einops' (#7397)

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix failure of pyaudio in Google Colab (#7396)

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update README.md: output_path --> output_manifest_filepath (#7442)

Signed-off-by: Samuele Cornell <cornellsamuele@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add rope dynamic linear scaling (#7437)

* Add dynamic linear scaling

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix None dataloader issue in PTL2.0 (#7455)

* Fix None dataloader issue in PTL2.0

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* updating values of self._validation_dl and self._test_dl as well

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* updating values of self._validation_dl and self._test_dl as well

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [ASR] Confidence measure -> method renames (#7434)

* measure -> method

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add steps for document of getting dataset 'SF Bilingual Speech' (#7378)

* Add steps for document of getting dataset 'SF Bilingual Speech'

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update datasets.rst

added a link from a tutorial demonstrating detailed data prep steps.

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* RNN-T confidence and alignment bugfix (#7381)

* new frame_confidence and alignments lists are now always created after the while loop

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* tests added

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix resume from checkpoint in exp_manager (#7424) (#7426)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix checking of cuda/cpu device for inputs of Decoder (#7444)

* Fix checking of cuda/cpu device for inputs of Decoder

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update tacotron2.py

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: Jason <jasoli@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix failure of ljspeech's get_data.py (#7430)

* Fix failure of ljspeech's get_data.py

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [TTS] Fix audio codec type checks (#7373)

* [TTS] Fix audio codec type checks

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix audio codec tests

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* […"
github.com/brycedrennan/imaginAIry,imaginairy/modules/sgm/encoders/modules.py,2023-12-15T22:32:01Z,"docs: add docstrings

Wrote an openai script and custom prompt to generate them."
github.com/brycedrennan/imaginAIry,imaginairy/modules/sgm/encoders/modules.py,2023-11-23T01:20:08Z,feature: stable diffusion video (SVD)
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2024-02-21T21:37:25Z,"[ENH] Remove ONNX Logspam (#1747)

## Description of changes

After 1.17, ONNXRuntime produces scary warnings on mac platforms,
because it tries to put our default embedding function into the CoreML
execution environment, where it doesn't fit.

This PR suppresses warnings from ONNX within the default embedding
function so that users don't see scary warnings.

## Test plan

Locally tested via the `start_here` notebook.

## Documentation Changes
N/A"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2024-01-17T17:13:57Z,"[WIP] [ENH] add exponential backoff and jitter to embedding calls (#1526)

This is a WIP, closes https://github.com/chroma-core/chroma/issues/1524

*Summarize the changes made by this PR.*
 - Improvements & Bug fixes
	 - Use `tenacity` to add exponential backoff and jitter
 - New functionality
- control the parameters of the exponential backoff and jitter and allow
the user to use their own wait functions from `tenacity`'s API

## Test plan
*How are these changes tested?*

- [x] Tests pass locally with `pytest` for python, `yarn test` for js

## Documentation Changes
None"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2024-01-11T21:13:27Z,"[BUG]Type errors in embading function #1169 (#1517)

## Description of changes

- Added correct type annotations for these methods #1169 

## Test plan
*How are these changes tested?*

- [ ] Tests pass locally with `pytest` for python, `yarn test` for js

## Documentation Changes
*Are all docstrings for user-facing APIs updated if required? Do we need
to make documentation changes in the [docs
repository](https://github.com/chroma-core/docs)?*

---------

Co-authored-by: Ran <rccalman@gmail.com>
Co-authored-by: Ben Eggers <64657842+beggers@users.noreply.github.com>"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2024-01-05T18:14:56Z,"Replace ONNXMiniLM_L6_V2._init_model_and_tokenizer with tokenizer and model cached properties (#1194)

## Description of changes

*Summarize the changes made by this PR.*
 - Improvements & Bug fixes
- Fixes #1193: race condition in
`ONNXMiniLM_L6_V2._init_model_and_tokenizer`

## Test plan
*How are these changes tested?*

- [x] Tests pass locally with `pytest` for python, `yarn test` for js"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2024-01-04T17:11:40Z,"[CLN] Import json at top-level in embedding_functions (#1562)

## Description of changes

*Summarize the changes made by this PR.*
 - Improvements & Bug fixes
	 - Move `import json` out of Amazon Bedrock EF and to top-level imports

## Test plan
*How are these changes tested?*

- [x] Tests pass locally with `pytest` for python, `yarn test` for js

## Documentation Changes
*Are all docstrings for user-facing APIs updated if required? Do we need
to make documentation changes in the [docs
repository](https://github.com/chroma-core/docs)?*"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-12-23T21:46:19Z,"identity to equality check (#1566)

## Description of changes

Changes identity `is` to equality `==` check

Co-authored-by: Jeffrey Huber <jeff@trychroma.com>"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-12-20T23:26:50Z,"Add Amazon Bedrock Embedding function (#1361)

https://docs.aws.amazon.com/bedrock/latest/userguide/embeddings.html

## Description of changes

 - New functionality
	 - Support Amazon Bedrock embedding function

## Test plan

- [ ] Tests pass locally with `pytest` for python, `yarn test` for js

Tested locally by given profile_name with appropreate `~/.aws/config`

```py
>>> import boto3
>>> from chromadb.utils.embedding_functions import AmazonBedrockEmbeddingFunction
>>> session = boto3.Session(profile_name=""myprofile"", region_name=""us-east-1"")
>>> ef = AmazonBedrockEmbeddingFunction(session=session)
>>> ef([""Hello Bedrock""])
[[-0.73046875, 0.390625, 0.24511719, 0.111816406, 0.83203125, 0.79296875,...,]]
```

## Documentation Changes
Written docstrings as much as possible.

---------

Co-authored-by: Ben Eggers <64657842+beggers@users.noreply.github.com>"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-12-19T21:56:33Z,"[ENH]: SHA256 sum check of Chroma's onnx model. (#1493)

Refs: #883

## Description of changes

*Summarize the changes made by this PR.*
 - Improvements & Bug fixes
- Verify ONNX all-MiniLM-L6 model model download from s3 with static
SHA256 (within the python code)

## Test plan
*How are these changes tested?*

- [x] Tests pass locally with `pytest` for python

## Documentation Changes
N/A"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-12-15T01:19:37Z,"Gemini (#1520)

This adds a Google Gemini embedding function and an RAG chat example 

TODO
- [x] JS support
- [x] Docs PR"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-11-29T18:53:09Z,"[ENH]: Embedding Function - Hugging Face Text Embedding Server (#1371)

Refs: [Feature Request]: Hugging Face text embedding inference custom
embedding #1367

## Description of changes

*Summarize the changes made by this PR.*
 - New functionality
	 - New Embedding Function for HF Text Embedding Server
	 - Added sample docker compose to run things locally
	 - Added example notebook

## Test plan
*How are these changes tested?*

- [x] Tests pass locally with `pytest` for python

## Documentation Changes
TBD

https://github.com/huggingface/text-embeddings-inference"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-11-28T22:58:15Z,"Remove redundant check for ""requests"" module (#1427)

`requests` is imported in line 17, and hence required:


https://github.com/chroma-core/chroma/blob/33289e8c5b0b5d65132a2995ab7199e83eaeacdf/chromadb/utils/embedding_functions.py#L17"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-11-17T18:01:17Z,"Pass input_type to cohere embedding models (#1407)

## Description of changes

*Summarize the changes made by this PR.*
 - Improvements & Bug fixes
	 - Fixes https://github.com/chroma-core/chroma/issues/1385
 - New functionality
	 - ...

## Test plan
*How are these changes tested?*

Got a Cohere API key and repro'd the issue locally. With this change,
calling the embedding function no longer breaks.

- [x] Tests pass locally with `pytest` for python, `yarn test` for js

## Documentation Changes
*Are all docstrings for user-facing APIs updated if required? Do we need
to make documentation changes in the [docs
repository](https://github.com/chroma-core/docs)?*"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-11-17T06:32:03Z,"feat: add Jina AI embedding function (#1324)

## Description of changes

Hey Chroma team!

We just launched [Jina Embeddings](https://jina.ai/embeddings/) and
would love to add a possibilty for the community to use it with
JinaEmbeddingFunctions.

Thanks!

## Documentation Changes
Link to docs PR: https://github.com/chroma-core/docs/pull/153

---------

Signed-off-by: Joan Fontanals Martinez <joan.martinez@jina.ai>"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-11-16T05:55:58Z,"ENH: Allow default headers to be passed to OpenAI API (#1397)

## Description of changes

*Summarize the changes made by this PR.*
 - Improvements & Bug fixes
- Allows users to pass custom headers to OpenAI API, enabling
intermediary proxies with different authentication methods.
 - New functionality
- New optional `default_headers` input at the `OpenAIEmbeddingFunction`
class.

## Test plan
*How are these changes tested?*

- [x] Tests pass locally with `pytest` for python, `yarn test` for js

## Documentation Changes
*Are all docstrings for user-facing APIs updated if required? Do we need
to make documentation changes in the [docs
repository](https://github.com/chroma-core/docs)?*

Since this is a relatively specific feature, I believe it won't require
an usage example in the docs.

Co-authored-by: Gustavo Antoniassi <gustavo.antoniassi@ifood.com.br>"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-11-08T22:22:58Z,"support of OpenAI package v1.X.X for utils.OpenAIEmbeddingFunction, deployment_id parameter for openai v0.X.X (#1338)

## Description of changes
- Add support of OpenAI package v1.X.X for utils.OpenAIEmbeddingFunction
- Add Azure OpenAI Deployment ID parameter for openai v0.X.X lib in
utils.OpenAIEmbeddingFunction

## Test plan
*How are these changes tested?*

Tested as dependency of https://github.com/Nayjest/ai-microcore with
Azure & openai packages v0.28.1 & v1.0.1, v1.1.0"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-11-07T22:07:53Z,"[ENH] Multimodal Embedding Functions (#1345)

## Description of changes

This PR introduces multi-modal embeddings into Chroma. 
- It adds the generic `EmbeddingFunction` which can take various data
types. Existing functions take the `Documents` type.
- Adds `Images` as a type (numpy NDArray taking ints or floats)
- Add `OpenCLIPEmbeddingFunction` which is an
`EmbeddingFunction[Union[Documents, Images]]`

## Test

Integration tests pass. 

A new test for multimodal embedding functions:
[chromadb/test/ef/test_multimodal_ef.py](https://github.com/chroma-core/chroma/blob/86a9e2620352ee0b2844bc3233f9e001cc4aa3d9/chromadb/test/ef/test_multimodal_ef.py)

## Documentation

See https://github.com/chroma-core/chroma/pull/1294

## TODOs
- [x] Tests
- [x] ~Wiring through FastAPI~ Nothing to wire through
- [x] Documentation
- [x] Telemetry
- [ ] JavaScript"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-11-07T18:00:00Z,"Revert ""[ENH] Multimodal Embeddings"" (#1344)

Reverts chroma-core/chroma#1293"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-11-07T17:57:00Z,"[ENH] Multimodal Embeddings (#1293)

## Description of changes

This PR introduces multi-modal embeddings into Chroma. 
- It adds the generic `EmbeddingFunction` which can take various data
types. Existing functions take the `Documents` type.
- Adds `Images` as a type (numpy NDArray taking ints or floats)
- Add `OpenCLIPEmbeddingFunction` which is an
`EmbeddingFunction[Union[Documents, Images]]`

## Test

Integration tests pass. 

A new test for multimodal embedding functions:
[chromadb/test/ef/test_multimodal_ef.py](https://github.com/chroma-core/chroma/blob/86a9e2620352ee0b2844bc3233f9e001cc4aa3d9/chromadb/test/ef/test_multimodal_ef.py)

## Documentation

See https://github.com/chroma-core/chroma/pull/1294

## TODOs
- [x] Tests
- [x] ~Wiring through FastAPI~ Nothing to wire through
- [x] Documentation
- [x] Telemetry
- [ ] ~JavaScript~"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-09-22T22:49:58Z,"[ENH] Metric batching and more metrics (#1163)

## Description of changes
This PR accomplishes two things:
- Adds batching to metrics to decrease load to Posthog
- Adds more metric instrumentation

Each `TelemetryEvent` type now has a `batch_size` member defining how
many of that Event to include in a batch. `TelemetryEvent`s with
`batch_size > 1` must also define `can_batch()` and `batch()` methods to
do the actual batching -- our posthog client can't do this itself since
different `TelemetryEvent`s use different count fields. The Posthog
client combines events until they hit their `batch_size` then fires them
off as one event.

NB: this means we can drop up to `batch_size` events -- since we only
batch `add()` calls right now this seems fine, though we may want to
address it in the future.

As for the additional telemetry, I pretty much copied Anton's draft
https://github.com/chroma-core/chroma/pull/859 with some minor changes.

Other considerations: Maybe we should implement `can_batch()` and
`batch()` on all events, even those which don't currently use them? I'd
prefer not to leave dead code hanging around but happy to go either way.

I created a ticket for the type ignores:
https://github.com/chroma-core/chroma/issues/1169

## Test plan
pytest passes modulo a couple unrelated failures

With `print(event.properties)` in posthog client's `_direct_capture()`:
```
>>> import chromadb
>>> client = chromadb.Client()
{'batch_size': 1}
>>> collection = client.create_collection(""sample_collection"")
{'batch_size': 1, 'collection_uuid': 'bb19d790-4ec7-436c-b781-46dab047625d', 'embedding_function': 'ONNXMiniLM_L6_V2'}
>>> collection.add(
...     documents=[""This is document1"", ""This is document2""], # we embed for you, or bring your own
...     metadatas=[{""source"": ""notion""}, {""source"": ""google-docs""}], # filter on arbitrary metadata!
...     ids=[""doc1"", ""doc2""], # must be unique for each doc 
... )
{'batch_size': 1, 'collection_uuid': 'bb19d790-4ec7-436c-b781-46dab047625d', 'add_amount': 2, 'with_documents': 2, 'with_metadata': 2}
>>> for i in range(50):
...   collection.add(documents=[str(i)], ids=[str(i)])
... 
{'batch_size': 20, 'collection_uuid': 'bb19d790-4ec7-436c-b781-46dab047625d', 'add_amount': 20, 'with_documents': 20, 'with_metadata': 0}
{'batch_size': 20, 'collection_uuid': 'bb19d790-4ec7-436c-b781-46dab047625d', 'add_amount': 20, 'with_documents': 20, 'with_metadata': 0}
>>> for i in range(50):
...   collection.add(documents=[str(i) + ' ' + str(n) for n in range(20)], ids=[str(i) + ' ' + str(n) for n in range(20)])
... 
{'batch_size': 20, 'collection_uuid': 'bb19d790-4ec7-436c-b781-46dab047625d', 'add_amount': 210, 'with_documents': 210, 'with_metadata': 0}
{'batch_size': 20, 'collection_uuid': 'bb19d790-4ec7-436c-b781-46dab047625d', 'add_amount': 400, 'with_documents': 400, 'with_metadata': 0}
{'batch_size': 20, 'collection_uuid': 'bb19d790-4ec7-436c-b781-46dab047625d', 'add_amount': 400, 'with_documents': 400, 'with_metadata': 0}
```

## Documentation Changes
https://github.com/chroma-core/docs/pull/139

https://github.com/chroma-core/docs/commit/a4fd57d4d2cc3cae00cbb4a9245b938e2f0d1842"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-08-29T17:18:53Z,"[ENH] Added providers to onnx runtime session (#1006)

Refs:  https://onnxruntime.ai/docs/api/python/api_summary.html

Refs: #1004

## Description of changes

*Summarize the changes made by this PR.*
 - Improvements & Bug fixes
- In multi-provider envs Onnyx Runtime requires that providers are
specified (with order of preference) as input to the InferrenceSession

## Test plan
Ideally, we'll need a GPU runners for testing -
https://github.com/github/roadmap/issues/505

## Documentation Changes
No change to docs is required.

> Note: Sorry for the unsigned commit, I tried using GH Codespaces for
this one."
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-08-15T01:18:11Z,"Fix model download for ONNX embedder (#976)

## Description of changes
The current function is looking for the tar.gz file instead of checking
if the folder already exists, so if the tar.gz gets deleted after
extraction, it downloads it again.. This PR resolves this and checks for
the model in the extracted folder before attempting to download or
extract again.

## Test plan
By using it

## Documentation Changes
I didn't find any documentation about how this does the download."
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-07-28T21:35:31Z,"fix: update api request (#890)

## Description of changes

*Summarize the changes made by this PR.*
 - Improvements & Bug fixes
	 - Update the API endpoint for Google VertexEmbedding
 - New functionality
	 - ...

## Test plan
*How are these changes tested?*
At the moment, there is any unit test for embedding function. However I
have tested the new code change locally and it worked.

## Documentation Changes
*Are all docstrings for user-facing APIs updated if required? Do we need
to make documentation changes in the [docs
repository](https://github.com/chroma-core/docs)?*

1. The default model_name should be textembedding-gecko instead of
textembedding-gecko-001
2. The _api_url should be changed to
3. The json payload should take in only 1 string instead of array of
strings. Thus I made a for loop to call the api endpoint in the event
there are arrays of text documents passed into the _call() function"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-07-27T23:09:43Z,"add azure openai api_version param (#832)

## Description of changes

*Summarize the changes made by this PR.*
 - Improvements & Bug fixes
Fix the bug that causes functionality to be unavailable when using
azure-openai due to missing api version parameter.
openai examples:
https://github.com/openai/openai-cookbook/blob/main/examples/azure/embeddings.ipynb
 - New functionality
	 - ...

## Test plan
*How are these changes tested?*

## Documentation Changes
*Are all docstrings for user-facing APIs updated if required? Do we need
to make documentation changes in the [docs
repository](https://github.com/chroma-core/docs)?*

fix https://github.com/chroma-core/chroma/issues/698

---------

Co-authored-by: litong <you@example.com>"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-07-27T23:06:23Z,"Update chromadb/utils/embedding_functions.py (#816)

This is a copy of https://github.com/kevinlu1248/chroma/pull/7, written
by Sweep, an AI junior dev.

## Description of changes
This PR adds documentation for the HuggingFace embeddings feature in the
chroma repository. The HuggingFaceEmbeddingFunction class is already
implemented in the `chromadb/utils/embedding_functions.py` file, but it
is currently undocumented. This PR adds docstrings to the class and
updates the README.md file to explain how to use the class and what it
does.

## Changes Made
- Added docstrings to the HuggingFaceEmbeddingFunction class in
`chromadb/utils/embedding_functions.py`
- Updated the README.md file to include a section about the
HuggingFaceEmbeddingFunction class, explaining its usage and providing
an example
- Mentioned that the requests package is required and provided the
command to install it

---------

Co-authored-by: sweep-ai[bot] <128439645+sweep-ai[bot]@users.noreply.github.com>"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-06-28T17:16:06Z,"Normalized embeddings (#737)

## Description of changes
Added support to the use of normalize embeddings in the
`SentenceTransformerEmbeddingFunction` class by adding a new attribute
to the class and use it when calling the `encode` function.

## Test plan
I was planning to add a new test case where an object was created with
`normalize_embeddings=True` but I haven't found any test which is
currently testing `SentenceTransformerEmbeddingFunction` (I guess that
should be in the folder `test/utils`).

## Documentation Changes
The document talking about [embeddings] should be changed. In the
section *Sentence Transformers* it should be mentioned the possiblitiy
of using an optional parameter `normalize_embeddings`. A similar text to
the one in the SentenceTransformer documentation could be used (or
adapted):

> If set to True, returned vectors will have length 1. In that case, the
faster dot-product (util.dot_score) instead of cosine similarity can be
used."
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-06-21T21:01:34Z,"fix wrong return type (#613)

## Description of changes
Related issue: #594
*Summarize the changes made by this PR.*
 - Improvements & Bug fixes
- HuggingFaceEmbeddingFunction: fix wrong return type from List to
List[List]
- GoogleVertexEmbeddingFunction: fix wrong return type of empty dict to
empty List

## Test plan
*How are these changes tested?*

## Documentation Changes
*Are all docstrings for user-facing APIs updated if required? Do we need
to make documentation changes in the [docs
repository](https://github.com/chroma-core/docs)?*

---------

Co-authored-by: Tegar Dani Pratama <tegar.dani@hukumonline.com>
Co-authored-by: Jeffrey Huber <jeff@trychroma.com>"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-05-31T21:23:10Z,"Add a thin client (#610)

## Description of changes
*Summarize the changes made by this PR.*
 - Improvements & Bug fixes
	 - Typing cleanup
- Changes embedding function defaults to work through the default params
as opposed to via None so that None now means - NO embedding function as
opposed to use the default. This is technically a breaking change.
 - New functionality
- Adds a thin client that restricts what you can create to the REST api
client and builds it separately so it can be published to its own pypi
package. The thin client restricts the default embedding function to be
None always - forcing manual specification of the embedding function
while using the thin client.
- The thin client is built with its own pyproject.toml with a limited
set of dependencies and a is_thin_client.py file that acts as a compile
flag. The build script stages the toml, places the two files in the
right place, performs the build and then tears down the changes.
	 
Addresses #289 

## Test plan
The existing tests should cover this configuration. We can add CI for
the thin-client in the future.

## Documentation Changes
We will add a section on the docs that explains the thin client and its
limitations."
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-05-19T22:07:41Z,"Add Google Vertex Embedding Function (#528)

Add Google Vertex Embedding Function


https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/textembedding-gecko?project=noted-victory-383712

## Description of changes
Added Google Vertex Embedding Function

## Test plan
By providing the API key and project ID.

## Documentation Changes
Has as much documentation as the others in that file.

---------

Co-authored-by: Jeffrey Huber <jeff@trychroma.com>"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-05-19T22:06:46Z,"Add task instruction pairing to InstructorEmbeddingFunction (#556)

## Description of changes

- Add an optional `instruction` constructor parameter to
InstructorEmbeddingFunction to allow `instruction` and Document pairs to
be encoded.

## Test plan


## Documentation Changes
Added examples to the Alternative Embedding notebook.

Not sure if this is a good implementation, since you'll need a separate
Collection for each instruction you want to use (or reassign
`self._instruction`), but at least the change is pretty minimal. For my
use case, two instructions are enough (one for storing, one for
retrieving). For a scenario where you need lots of different
instructions, perhaps ""Represent the <Science|Financial|Political|etc.>
article: "", another solution is needed.

Feature Request #546

---------

Co-authored-by: Jeffrey Huber <jeff@trychroma.com>"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-05-19T07:30:04Z,"Switch to ONNX model for default embedding model (#267)

## Description of changes

*Summarize the changes made by this PR.* 
 - Improvements & Bug fixes
	 - None
 - New functionality
- Adds a ONNX port of sentence-transformers all-MiniLM-L6-v2 in order to
remove the dependencies on pytorch, sentence-transformers,
sentence-piece and other heavy depdencies. This reduced the on disk
environment size needed for dependencies to run chroma from ~900MB to
~300MB
- The ONNX port and verification of its accuracy live in
https://github.com/chroma-core/onnx-embedding
- The ONNX model is hosted on S3 after being generated in the above repo
- The implementation here runs the model and applies mean-pooling using
numpy since that's the final layer.
- The embedding model will download the model using tqdm to provide the
same download experience as before
	 - If the model is cached it will not be downloaded. 
	 - In contrast to before, the model is now ONLY downloaded if used!
- The net-new dependencies are onnxruntime and tokenizers, both are
lightweight.
	 - Updated the default model to be this one instead of ST.
- We create a new DefaultEmbeddingFunction which aliases the ONNX
embedding function

## Test plan
Added a test to test multiple batches with the new model

## Documentation Changes
*Are all docstrings for user-facing APIs updated if required? Do we need
to make documentation changes in the [docs
repository](https://github.com/chroma-core/docs)?*
We will need to change the documentation here
https://docs.trychroma.com/embeddings#default-sentence-transformers to
highlight this fact."
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-05-19T05:11:55Z,"Added api_base and api_type to the OpenAIEmbeddingFunction  (#517)

Added api_base and api_type to the OpenAIEmbeddingFunction to support
outside the base openai deployment like Azure etc

## Description of changes

This PR adds support for deploying the OpenAIEmbeddingFunction on
platforms other than the base OpenAI deployment, such as Azure, by
allowing users to specify the `api_base` and `api_type` parameters.

### Improvements & Bug fixes
- None

### New functionality
- Added `api_base` and `api_type` as optional parameters to the
`OpenAIEmbeddingFunction` to support deployment on other platforms like
Azure, etc.

## Test plan

To test the changes made in this PR, the following steps can be taken:

### Test against Azure
1. Set up the OpenAIEmbeddingFunction with the new `api_base` and
`api_type` parameters.
2. Deploy the embedding model on the desired platform (e.g., Azure).
3. Run sample embeddings and test the new deployment against the Azure
deployment instance.

### Test against Base Open AI
1. Set up the OpenAIEmbeddingFunction with just the `api_key and without
the new `api_base` and `api_type` parameters.
2. Run sample embeddings and test the new deployment against the OpenAI
instance.

## Documentation Changes

All docstrings for user-facing APIs needs to be updated to reflect the
new `api_base` and `api_type` parameters. Additionally, documentation in
the [docs repository](https://github.com/chroma-core/docs) should be
updated to provide guidance on how to use the new parameters for
deploying the OpenAIEmbeddingFunction on platforms other than the base
OpenAI deployment. This change will be submitted as a separate pull
request.

---------

Co-authored-by: Jeff Huber <jeff@trychroma.com>"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-05-18T04:49:54Z,"Add organization_id to openai embeddings (#548)

## Description of changes
This related to #547 issue.
 - New functionality added:
	 - add optional organization_id parameter to OpenAIEmbeddingFunction.

## Test plan
- Create the class object without organization_id and no errors
expected.
- Create the class object with organization_id.

## Documentation Changes
*Are all docstrings for user-facing APIs updated if required? Do we need
to make documentation changes in the [docs
repository](https://github.com/chroma-core/docs)?*
- The class optional parameters are not mentioned explicitly."
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-05-12T23:43:17Z,"Add Text2VecEmbeddingFunction (#417)

Add Text2VecEmbeddingFunction for Chinese sentence embedding.

Co-authored-by: hammadb <hammad@trychroma.com>"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-05-11T21:50:57Z,Merge branch 'main' into main
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-05-10T05:52:12Z,"Add precommit hooks (#483)

Adds precommit hooks based on #433 to our repository. Only one file here is new - the configuration for the hooks, everything else is linting/formatting fixes. We do not run the typechecker globally since that would be quite lengthy to clean up - instead we will have to incrementally clean up type check issues as we go."
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-05-09T18:23:22Z,"Add Google PaLM embedding function. (#445)

* Add Google PaLM embedding function.

* Address feedback by @markmcd.

* Default model, import failure string

---------

Co-authored-by: atroyn <anton.troynikov@gmail.com>"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-05-06T04:03:15Z,"Team/hypothesis tests (#474)

Merges the team/hypothesis-tests branch to main. Which adds a robust property-based testing suite to Chroma. lfg."
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-04-18T00:59:45Z,"make api_key in OpenAIEmbeddingFunction optional (#320)

* make api_key in OpenAIEmbeddingFunction optional

* make optional api_key actually work

* Early error

---------

Co-authored-by: atroyn <anton.troynikov@gmail.com>"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-04-18T00:54:53Z,"[bugfix] Ensure Openai batch embeddings are sorted by index (#344)

* Ensure openai batch embeddings are sorted by index

* Use lambda

---------

Co-authored-by: atroyn <anton.troynikov@gmail.com>"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-04-11T21:04:25Z,"Adds option to pass compute device like cpu, cuda, cuda:1 to SentenceTransformerEmbeddingFunction"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-04-03T19:37:16Z,"Add flake8 linter, address linter issues (#287)

Adds the flake8 linter configured to run with black in vscode"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-03-24T03:07:13Z,added embedding function for the Instructor models.
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-03-17T05:46:48Z,"Merge pull request #206 from danielgross/patch-2

In my experience T5 is much better, add comment with that as an option."
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-03-17T05:35:25Z,Update embedding_functions.py
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-03-16T02:42:15Z,use requests Session object to keep requests imported
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-03-16T02:02:25Z,need to access instance variables
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-03-16T01:48:52Z,add wrapper for hugging faces embedding api
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-03-07T19:45:19Z,"In my experience T5 is much better, add comment with that as an option."
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-03-03T18:40:46Z,"Unified error messages (#199)

Unifies error messages across the project to make them more useful and consistent
Improves the error message for invalid collection names

---------

Co-authored-by: Hammad Bashir <HammadB@users.noreply.github.com>"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-02-17T18:06:08Z,"Add support for cohere embeddings (#141)

* Add support for cohere embeddings

* Keep newlines"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-02-15T20:13:22Z,"Remove newlines to improve performance

Per OpenAI's get_embedding function here: https://github.com/openai/openai-python/blob/main/openai/embeddings_utils.py"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-02-14T03:45:38Z,"OpenAI Embeddings (#117)

* Adding OpenAI embedding functions

* OpenAI"
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-02-13T01:08:56Z,Default embedding function (#26)
github.com/chroma-core/chroma,chromadb/utils/embedding_functions.py,2023-02-11T05:58:44Z,"Add embedding functions (#19)

* Pass in embedding function.

* Embedding function

* Text-only queries

* Add correct result and types for get (#15)

* Reactor get result to client (#16)

* Add query result (#17)

* fix

* Nit

---------

Co-authored-by: Hammad Bashir <HammadB@users.noreply.github.com>
Co-authored-by: Jeffrey Huber <jeff@trychroma.com>"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2023-04-20T14:05:29Z,remove einops exts for better pytorch 2.0 compile compatibility
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2023-03-07T20:41:55Z,"use .to(device) to avoid copy, within one_unet_in_gpu context"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2023-03-05T18:45:44Z,always rederive the predicted noise from the clipped x0 for ddim + predict noise objective
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2023-02-12T01:18:40Z,fix for self conditioning in diffusion prior network https://github.com/lucidrains/DALLE2-pytorch/issues/273
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-12-23T21:23:09Z,default ddim sampling eta to 0
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-12-15T18:54:21Z,extra insurance in case eos id is not there
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-11-23T16:41:25Z,address https://github.com/lucidrains/DALLE2-pytorch/issues/266
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-10-29T01:21:07Z,"bring in prediction of v objective, combining the findings from progressive distillation paper and imagen-video to the eventual extension of dalle2 to make-a-video"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-10-23T22:12:09Z,fix openclipadapter to be able to use latest open sourced sota model
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-10-19T16:26:06Z,"fix a dtype conversion issue for the diffusion timesteps in the diffusion prior, thanks to @JiaHeng-DLUT"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-10-18T15:50:59Z,Fix assert message (#253)
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-09-29T16:09:47Z,fix for use with larger openai clip models by extracting dimension of last layernorm in clip
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-09-19T17:27:14Z,handle open clip adapter image size being a tuple
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-09-01T16:40:47Z,"in ddim, noise should be predicted after x0 is maybe clipped, thanks to @lukovnikov for pointing this out in another repository"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-09-01T00:19:05Z,fix bug with misnamed variable in diffusion prior network
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-08-31T14:40:46Z,fix ddim to use alpha_cumprod
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-08-28T17:11:37Z,"add two asserts to diffusion prior to ensure matching image embedding dimensions for clip, diffusion prior network, and what was set on diffusion prior"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-08-25T17:37:02Z,upgrade to best downsample
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-08-23T15:29:01Z,"fix classifier free guidance for diffusion prior, thanks to @jaykim9870 for spotting the issue"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-08-20T17:56:01Z,cast attention matrix back to original dtype pre-softmax in attention
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-08-19T18:28:58Z,make it work for @ethancohen123
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-08-14T18:34:45Z,"add weight standardization behind feature flag, which may potentially work well with group norm"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-08-13T17:03:40Z,make it so diffusion prior p_sample_loop returns unnormalized image embeddings
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-08-12T22:25:03Z,dry up some code around handling unet outputs with learned variance
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-08-12T19:30:03Z,fix self conditioning shape in diffusion prior
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-08-12T19:20:51Z,make self conditioning technique work with diffusion prior
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-08-12T18:41:23Z,comment
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-08-12T18:36:08Z,bet on the new self-conditioning technique out of geoffrey hintons group
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-08-03T02:21:44Z,add gradient checkpointing for all resnet blocks
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-30T16:02:31Z,make open clip available for use with dalle2 pytorch
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-29T20:17:12Z,quick fix for linear attention
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-29T19:48:20Z,"add cosine sim for self attention as well, as a setting"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-29T19:41:02Z,"change up epsilon in layernorm the case of using fp16, thanks to @Veldrovive for figuring out this stabilizes training"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-29T18:12:18Z,"allow for cosine sim cross attention, modify linear attention in attempt to resolve issue on fp16"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-28T17:17:43Z,make sure entire readme runs without errors
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-28T15:33:51Z,fix readme and a small bug in DALLE2 class
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-27T19:27:38Z,rescale values in linear attention to mitigate overflows in fp16 setting
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-26T17:46:04Z,add upsample combiner feature for the unets
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-24T22:29:06Z,fix repaint
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-20T02:07:50Z,"Improved upsampler training (#181)

Sampling is now possible without the first decoder unet

Non-training unets are deleted in the decoder trainer since they are never used and it is harder merge the models is they have keys in this state dict

Fixed a mistake where clip was not re-added after saving"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-19T18:31:56Z,@jacobwjs reports dynamic thresholding works very well and 0.95 is a better value
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-19T16:26:55Z,complete inpainting ability using inpaint_image and inpaint_mask passed into sample function for decoder
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-19T02:04:26Z,fix a bug with ddim and predict x0 objective
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-18T22:02:04Z,comments
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-18T20:50:22Z,fix sample bug
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-18T20:43:57Z,complete imagen-like noise level conditioning
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-16T00:29:10Z,"offer way to turn off initial cross embed convolutional module, for debugging upsampler artifacts"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-14T22:28:34Z,takes care of a grad strides error at https://github.com/lucidrains/DALLE2-pytorch/issues/196 thanks to @YUHANG-Ma
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-14T19:49:43Z,protect against random cropping for base unet
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-14T17:27:04Z,"let the neural network peek at the low resolution conditioning one last time before making prediction, for upsamplers"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-14T03:59:43Z,"just always use nearest neighbor interpolation when resizing for low resolution conditioning, for https://github.com/lucidrains/DALLE2-pytorch/pull/181"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-13T20:12:30Z,"allow for using classifier free guidance for some unets but not others, by passing in a tuple of cond_scale during sampling for decoder, just in case it is causing issues for upsamplers"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-13T19:56:02Z,"hack around some inplace error, also make sure for openai clip text encoding, only tokens after eos_id is masked out"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-13T17:16:02Z,fix non pixel shuffle upsample
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-13T17:11:49Z,"fix a potential bug with conditioning with blurred low resolution image, blur should be applied only 50% of the time"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-13T16:48:40Z,fix issue with ddim and normalization of lowres conditioning image
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-13T14:56:30Z,only use the stable layernorm for final output norm in transformer
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-13T00:49:16Z,add yet another transformer stability measure
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-13T00:33:14Z,"add learned padding tokens, same strategy as dalle1, for diffusion prior, and get rid of masking in causal transformer"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-13T00:08:12Z,"add setting to attend to all text encodings regardless of padding, for diffusion prior"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-12T23:00:19Z,make sure text encodings being passed in has the correct batch dimension
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-12T22:40:31Z,remove text masking altogether in favor of deriving from text encodings (padded text encodings must be pad value of 0.)
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-12T22:33:13Z,protect against bad text mask being passed into decoder
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-12T22:01:46Z,"one more fix for text mask, if the length of the text encoding exceeds max_text_len, add an assert for better error msg"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-12T19:54:59Z,"generate text mask within the unet and diffusion prior itself from the text encodings, if not given"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-11T23:07:23Z,add PixelShuffleUpsample thanks to @MalumaDev and @marunine for running the experiment and verifyng absence of checkboard artifacts
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-11T20:22:06Z,"zero init final projection in unet, since openai and @crowsonkb are both doing it"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-11T17:56:19Z,"make it so even if text mask is omitted, it will be derived based on whether text encodings are all 0s or not, simplify dataloading"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-10T16:44:38Z,allow for final l2norm clamping of the sampled image embed
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-10T02:01:37Z,"fix misnamed variable, thanks to @nousr"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-10T01:38:40Z,do not noise for the last step in ddim
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-10T00:31:54Z,fix for small validation bug for sampling steps
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-10T00:28:14Z,more informative error for something that tripped me up
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-10T00:25:34Z,"complete ddim integration of diffusion prior as well as decoder for each unet, feature complete for https://github.com/lucidrains/DALLE2-pytorch/issues/157"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-09T01:17:29Z,just force it so researcher can never pass in an image that is less than the size that is required for CLIP or CoCa
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-08T18:44:43Z,"allow for control over use of nearest interp method of downsampling low res conditioning, in addition to being able to turn it off"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-07T16:41:49Z,"fix a potential issue in the low resolution conditioner, when downsampling and then upsampling using resize right, thanks to @marunine"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-07T14:43:41Z,"fix condition_on_text_encodings in dalle2 orchestrator class, fix readme"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-07T02:05:50Z,more shots in the dark regarding fp16 with learned variance for deepspeed issue
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-06T15:27:34Z,attempting to fix issue with deepspeed fp16 seeing overflowing gradient
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-06T01:22:43Z,debugging with Aidan
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-06T01:01:22Z,cast long as float before deriving sinusoidal pos emb
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-05T23:53:58Z,"remove forcing of softmax in f32, in case it is interfering with deepspeed"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-05T21:27:04Z,"bring in two tricks from the cogview paper for reducing the chances of overflow, for attention and layernorm"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-05T20:09:58Z,do bias-less layernorm manually
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-01T17:22:07Z,add ability to specify full self attention on specific stages in the unet
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-01T16:35:39Z,allow for returning low resolution conditioning image on forward through decoder with return_lowres_cond_image flag
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-01T16:21:47Z,"bring back convtranspose2d upsampling, allow for nearest upsample with hyperparam, change kernel size of last conv to 1, make configurable, cleanup"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-07-01T00:03:16Z,"blur sigma for upsampling training was 0.6 in the paper, make that the default value"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-06-29T15:16:58Z,"add skip connections for all intermediate resnet blocks, also add an extra resnet block for memory efficient version of unet, time condition for both initial resnet block and last one before output"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-06-27T04:59:55Z,"bring in the skip connection scaling factor, used by imagen in their unets, cite original paper using it"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-06-27T04:07:42Z,fix remaining issues with deriving cond_on_text_encodings from child unet settings
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-06-26T23:12:32Z,bug fixes for text conditioning update (#175)
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-06-26T19:45:05Z,"nevermind, do not enforce text encodings on first unet"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-06-26T19:32:17Z,"remove unnecessary decoder setting, and if not unconditional, always make sure the first unet is condition-able on text"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-06-25T23:37:06Z,"autoswitch tqdm for notebooks (#171)

avoids printing the `tqdm` progress bar to a newline in notebooks when detected"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-06-20T16:43:31Z,be able to turn off p2 loss reweighting for upsamplers
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-06-20T16:05:08Z,"in paper, blur sigma was 0.6"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-06-20T15:56:37Z,"allow for setting beta schedules of unets differently in the decoder, as what was used in the paper was cosine, cosine, linear"
github.com/lucidrains/DALLE2-pytorch,dalle2_pytorch/dalle2_pytorch.py,2022-06-19T16:25:54Z,"Distributed Training of the Decoder (#121)

* Converted decoder trainer to use accelerate

* Fixed issue where metric evaluation would hang on distributed mode

* Implemented functional saving
Loading still fails due to some issue with the optimizer

* Fixed issue with loading decoders

* Fixed issue with tracker config

* Fixed issue with amp
Updated logging to be more logical

* Saving checkpoint now saves position in training as well
Fixed an issue with running out of gpu space due to loading weights into the gpu twice

* Fixed ema for distributed training

* Fixed isue where get_pkg_version was reintroduced

* Changed decoder trainer to upload config as a file

Fixed issue where loading best would error"
github.com/open-mmlab/mmsegmentation,projects/CAT-Seg/cat_seg/models/clip_ovseg.py,2023-08-09T15:57:30Z,"[Project] Support CAT-Seg from CVPR2023 (#3098)

Thanks for your contribution and we appreciate it a lot. The following
instructions would make your pull request more healthy and more easily
get feedback. If you do not understand some items, don't worry, just
make the pull request and seek help from maintainers.

## Motivation

Support CAT-Seg open-vocabulary semantic segmentation (CVPR2023).

## Modification

Support CAT-Seg open-vocabulary semantic segmentation (CVPR2023).
- [x] Support CAT-Seg model training.
- [x] CLIP model based `backbone` (R101 & Swin-B), aggregation layers
based `neck`, and `decoder` head.
  - [x] Provide customized coco-stuff164k_384x384 training configs.
- [x] Language model supports for `open vocabulary` (OV) tasks. 
  - [x] Support CLIP-based pretrained language model (LM) inference.
  - [x] Add commonly used prompts templates. 
- [x] Add README tutorials.
- [x] Add zero-shot testing scripts.

**Working on the following tasks.**
- [x] Add unit test.

## BC-breaking (Optional)

Does the modification introduce changes that break the
backward-compatibility of the downstream repos?
If so, please describe how it breaks the compatibility and how the
downstream projects should modify their code to keep compatibility with
this PR.

## Use cases (Optional)

If this PR introduces a new feature, it is better to list some use cases
here, and update the documentation.

## Checklist

1. Pre-commit or other linting tools are used to fix the potential lint
issues.
2. The modification is covered by complete unit tests. If not, please
add more unit test to ensure the correctness.
3. If the modification has potential influence on downstream projects,
this PR should be tested with downstream projects, like MMDet or
MMDet3D.
4. The documentation has been modified accordingly, like docstring or
example tutorials.

---------

Co-authored-by: xiexinch <xiexinch@outlook.com>"
github.com/modelscope/modelscope,modelscope/models/multi_modal/videocomposer/clip.py,2023-08-15T04:01:03Z,"VideoComposer: Compositional Video Synthesis with Motion Controllability (#431)

* VideoComposer: Compositional Video Synthesis with Motion Controllability

* videocomposer pipeline

* pre commit

* delete xformers"
github.com/Sygil-Dev/Sygil-WebUI,webui/streamlit/scripts/img2txt.py,2023-06-23T02:58:24Z,"[pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci"
github.com/Sygil-Dev/Sygil-WebUI,webui/streamlit/scripts/img2txt.py,2023-01-31T21:30:59Z,"Started to move all the streamlit code and dependencies to its own folder in `webui/streamlit` and moving the backend to use nataili, this should help make it self-contained and reduce the amount of code we have in other places which should also make it so the code is easier to understand and read."
github.com/brycedrennan/imaginAIry,tests/test_guidance.py,2022-11-26T03:23:06Z,"Fix typos

Found via `codespell -S ./imaginairy/vendored`"
github.com/brycedrennan/imaginAIry,tests/test_guidance.py,2022-09-17T22:49:38Z,tests: add more tests
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2024-01-07T23:34:40Z,"Improve error handling and API error codes (#656)

Co-authored-by: Farshid Zavareh <farshid@marqo.ai>"
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-07-26T07:35:54Z,"Improve image download validation and resource management (#551)

Explicitly close streaming HTTP connections and PIL images. Ensure _id is never treated as an image URL. Error out if _id is specified as a tensor field by the user."
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-06-26T13:10:20Z,"download integrity (#502)

* catch automodel.pretrained error

* finished open_clip part

* finished open_clip part

* catch mainline

* finish the test

* finish the test

* raise internal errors now.

* update string

* update error message

* update error message

* update error message

* update error message

* update error catching

* update error catching for loading clip model into openclip

* update error handling in s2_inference

* update error handling in s2_inference

* catch mainline

* catch mainline"
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-06-23T06:31:19Z,"Consolidating default device to CUDA when available (#508)

* preliminary replacement work

* changed a few cpus to cuda

* add defaults in tensor search, bulk search, add docs, also added env var

* 1st sweep of removing device params, on parallel now

* transferred default calc from add docs to orch

* replaced defaults in clip_utils.py

* replaced defaults in s2_inference, clip_utils, onnx_utils

* removed defaults everywhere

* added device to vectorise, CLIP calls

* updated device in other models, aux functions

* added device for vectorise and encoding tests

* added device to everything before test_add_documents

* more test fixes

* fixed more test, hardcoded cpu for _float_tensor_to_list

* hardcoded cpu for _float_tensor_to_list

* removed debug message for best available device

* changed comment on vector text search

* all tensor_search tests pass

* fixed errors raised

* added new unit tests, changed env var name

* util env var, replace with empty dict

* updated bulk search default and utils tests

* separated on start method, added search test

* updated validation and more tests

* added unit tests for all internal func validations

* added tests for add docs mp and batch request

* removed validation from Model. Added to SBERT and HF models instead

* added tests to fail if no default orch, search, bulk search

* removed Model test

* moved validation back to Model parent class

* added Model no device test back in"
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-06-22T06:09:05Z,"Return metrics (#506)

* basic Request level metrics/telemetry

* add unit tests for telemetry

* add request metrics to add/search APIs

* python 3.8 fixes

* simplify threaded metrics in download_images

* fix bug

* simplify tests

* fix None in tests

* make tests extra clean

* make metric names more user friendly

* add image download for search. Other improvements

* fix unit tests for clip_utils

* remove 'vector_inference'

* search.create_vectors -> search.vector_inference_full_pipeline

* preprocess -> processing_before_opensearch

* better naming for RequestMetric(s)"
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-06-13T00:07:26Z,"remove autocast for cpu (#491)

* remove autocast for cpu

* add tests

* add tests"
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-05-22T03:01:11Z,"Refactor `tensor_search::search` to use shared functions from `tensor_search::bulk_search` (#469)

* refactor tensor_search/search

* move SearchQuery.context and SearchQuery.scoreModifiers to pydantic

* fix removed SearchContext object

* fix tests

* fix inference for model auth tests

* PR fixes

* add more tests

* multi modal test +1"
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-05-19T07:08:17Z,"custom hf model loading with authentication  (#474)

* custom hf model loading with authentication for hf model

* custom hf model loading with authentication for hf model

* custom hf model loading with authentication for hf model

* custom hf model loading with authentication for hf model

* custom hf model loading with authentication for hf model

* pass the loading from huggingface repo directly test

* test for loading model

* only need to test variants

* add more tests

* add more tests

* fix a test and remove pring

* fix a test and remove pring

* fix a test and remove pring

* fix a test and remove pring

* fix a test and remove pring

* fix a test and remove pring

* fix a test and remove pring

* fix a test and remove pring

* use repo_id instead of name now

* use repo_id instead of name now

* revise from jack

* revise from pandu

* revise from pandu

* update code

* catch automodel.pretrained error

* catch automodel.pretrained error

* catch automodel.pretrained error

* catch automodel.pretrained error

* catch automodel.pretrained error

* catch automodel.pretrained error

* reivise

* add extra tests

* bug fix"
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-05-11T00:35:53Z,"Stateless model auth (#460)

* added model auth

* Added objects for structure

* introducing AddDocsParams object for addDocuments calls

untested

* added pydantic plugin advice to dev guide

* refactored test_add_docs to use AddDocsParams class

* updated tensor search docstring

* refactored tests to work with new AddDocsParams object

* Commit for refactoring done to test_add_documents_use_existing_tensors.py

* refactored delete_documents to use the add_documents wrapper

* added transitional add_docs wrapper

* added transition add docs wrappers to add_documents calls in these test cases

* added transition add docs wrappers to add_documents calls in these test cases

* test updated to use new add_docs param object

* cleaning up tests with issues

* made progress integrating s3

* add docs, s3 works

* search seems to work (it at least passes through the auth info OK)

* added boto to reqs add hf skeleton funcs

* added changes

* fixed test_bulk_search_different_models_separate_vectorise_calls

* created test_model_auth_s3 ()

* test_model_auth_s3() asserts boto3 client instantiation

* made assertions about the presence of the model file

* added hf loading tests

* added tests for hf, s3 search

* added test for s3/hf mismatch

* test refactor

* added cuda test

* add_docs parses model auth str

* corrected add_docs derivatives test

* removed unused vectorise params

* fixed bug, not passing through auth in multimodal_combination

* added test for no creds

* added test_bad_creds_error_s3

* test for access to non existent hf repo

* Added test_after_downloading_search_doesnt_redownload

* fixed checking loaded models

* added from_s3 tests

* added from_hf tests

* added test_custom_clip_utils.py

need to fix tests

* added call to search before add docs parallel

* Added search call before parallel add_docs

* fixed casing issue in SearchQuery

* fixed tests

* completed custom clip utils test

* updated version

* improved error msg, added bulk search tests

* made custom clip tests stricter

* added device to model auth cuda setup

* added tests for CLIP._download_from_repo

* added CLIP.load() tests

* added OPEN_CLIP.load() tests

* fixed private model and test

* corrected HF auth and location inheritance

* removed test_put_documents_orchestrator() as put_documents is deprecated

* corrected version"
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-02-28T03:18:22Z,"[feature] Multimodal tensor combination (#332)

* draft PR

* add test

* delete comments and prints

* new design

* adding test

* add assertion

* change comments

* add more args

* add more test

* remove print

* catch mainline

* catch mainline

* catch mainline

* catch mainline

* catch mainline

* catch mainline

* adding test

* adding test

* change _infer_opensearch_data_type

* support dictionary

* fix text

* add test

* revise parameters

* add to image repo

* revise again.

* revised

* add batch downloading.

* revise test

* add new test

* remove space

* revised.

* revised.

* revised.

* revised.

* update index info

* update index info

* update validation

* update test for new api

* updated

* updated

* add validate mappings

* add todo

* revised

* revised

* revised

* revised

* revised

* revised

* revised

* add test

* add test

* add test

* Mappings for add_docs (#355)

* Update CONTRIBUTING.md

* Update CONTRIBUTING.md

* Adding mappings validation

* mappings validation within add_documents

* added mappings to endpoint and orchestrator: untested

* add test

* add more tests

* add more tests

* add more tests

* finalise

* add open_search test

* update all the error messages.

* update all the error messages.

---------

Co-authored-by: pandu-k <107458762+pandu-k@users.noreply.github.com>"
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-02-27T05:04:57Z,"Update clip_utils.py (#351)

update custom open_clip models to use open_clip base tokenizer instead of clip"
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-02-20T11:09:11Z,"Image download headings (#336)

* add header for authentication

* update load image path tests

* remove headers as a required argument

* update tests and image utils

* fixed bugs

* Changed headers type to dict internally

* Image download headers propagated for search()

* changed remaining image_download_headers param defaults to None

---------

Co-authored-by: Tom Hamer <tom@marqo.ai>"
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-02-16T23:42:55Z,"Fp16 clip update (#331)

* update fp16 model and add tests

* update fp16 model and add tests"
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-02-14T00:39:38Z,"[features] Open clip update (#305)

* update open_clip models

* update open_clip models

* update open_clip models

* update open_clip models

* update open_clip models

* add auto_cast to open_clip

* add auto_cast to open_clip

* convert to float32 at output to normalize it.

* convert to float32 at output to normalize it.

* add onnx32/open_clip/ViT-L-14/openai and
onnx16/open_clip/ViT-L-14/openai"
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-02-13T23:17:02Z,"Broaden catch download error (#321)

* RequestException is excepted, which is the super class of all requests errors

* Fixed unit tests"
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-02-12T23:14:31Z,bug fix (#315)
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-02-10T04:30:25Z,"Concurrent image downloads  (#281)

* added changed files from branch concurrent download img 2

* refactored model registry/multilingual clip to prevent circular import

* Fixed bug where a bounding box is returned rather than highlights

* added test cases

* removed unnecessary extra call

* remove unused circular reference

* added timeout of 3 seconds to image downloads

* added timeout and unit tests

* added timeout test to clip_utils

* Widened the net of image download errors

* Specific image retrieval error is passed to user"
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-02-02T22:55:01Z,change downloading path for clip
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-02-01T23:52:19Z,revised based on pandu's comments
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-02-01T06:51:40Z,change error message
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-02-01T06:51:28Z,change error message
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-02-01T06:47:39Z,remove space
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-02-01T06:37:28Z,revise error style!
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-30T07:22:21Z,Separate clip and open_clip load
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-30T07:18:29Z,Separate clip and open_clip load
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-30T04:50:53Z,add test
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-30T04:46:12Z,add test
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-30T03:21:40Z,add test
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-27T01:59:01Z,add test
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-27T01:58:11Z,add test
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-27T01:57:31Z,add test
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-27T01:38:27Z,add test
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-27T01:29:58Z,add test
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-27T01:27:12Z,add test
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-27T01:20:08Z,open_clip finish
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-27T01:15:07Z,open_clip finish
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-25T07:40:14Z,add generic clip model tests
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-25T03:26:41Z,generic clip revise
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-25T03:13:52Z,generic clip revise
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-25T03:12:50Z,generic clip revise
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-25T03:11:16Z,generic clip revise
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-25T03:00:54Z,generic clip revise
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-25T02:52:44Z,add fp16 model support
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-25T01:02:11Z,add fp16 model support
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-25T00:21:15Z,add fp16 model support
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-24T09:50:24Z,add fp16 model support
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-24T02:43:56Z,add fp16 model support
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-24T02:40:26Z,add fp16 model support
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-24T02:34:39Z,add fp16 model support
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-24T02:25:40Z,add fp16 model support
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-24T01:01:04Z,add large scale test
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-11T05:42:19Z,only load visual in clip
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-11T05:39:20Z,only load visual in clip
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-10T23:00:56Z,add unit test for multilingual clip
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-10T07:20:56Z,add multilingual clip
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-10T07:18:59Z,add multilingual clip
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-10T05:31:24Z,add model registry
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-10T05:30:47Z,add model registry
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2023-01-06T07:28:22Z,"Onnx refactor: adding open_clip onnx support, decouple image preprocess (#255)

* merge model properties

* add transform and open_clip support for onnx_clip

* add transform and open_clip support for onnx_clip

* add transform and open_clip support for onnx_clip

* add transform and open_clip support for onnx_clip

* add transform and open_clip support for onnx_clip

* add transform and open_clip support for onnx_clip

* update open_clip tokenizer function

* update open_clip tokenizer function

* add ""onnx32/open_clip/ViT-L-14/laionb_s32b_b82k"" and ""onnx16/open_clip/ViT-L-14/laionb_s32b_b82k""

* add ""onnx32/open_clip/ViT-L-14/laionb_s32b_b82k"" and ""onnx16/open_clip/ViT-L-14/laionb_s32b_b82k""

* add ""onnx32/open_clip/ViT-L-14/laionb_s32b_b82k"" and ""onnx16/open_clip/ViT-L-14/laionb_s32b_b82k""

* add ""onnx32/open_clip/ViT-L-14/laionb_s32b_b82k"" and ""onnx16/open_clip/ViT-L-14/laionb_s32b_b82k""

* add ""onnx32/open_clip/ViT-L-14/laionb_s32b_b82k"" and ""onnx16/open_clip/ViT-L-14/laionb_s32b_b82k""

* add ""onnx32/open_clip/ViT-L-14/laionb_s32b_b82k"" and ""onnx16/open_clip/ViT-L-14/laionb_s32b_b82k""

* add ""onnx32/open_clip/ViT-L-14-336/openai""

* add ""onnx32/open_clip/ViT-L-14-336/openai""

* onnx/open_clip/ViT-B-32/openai

* onnx/open_clip/ViT-B-32/laion400m_e31

* onnx/open_clip/ViT-B-32/laion400m_e31

* onnx/open_clip/ViT-B-32/laion400m_e31

* 'onnx32/open_clip/ViT-B-32-quickgelu/laion400m_e31'

* 'onnx32/open_clip/ViT-B-32-quickgelu/laion400m_e32'

* 'onnx32/open_clip/ViT-B-16/openai'

* ViT-B-16/laion400m_e31

* ViT-B-16/laion400m_e32

* onnx32/open_clip/ViT-B-16-plus-240/laion400m_e31

* ViT-B-16-plus-240/laion400m_e32

* onnx32/open_clip/ViT-H-14/laion2b_s32b_b79k

* adding zip, unzip logic

* adding zip, unzip logic

* adding zip, unzip logic

* adding zip, unzip logic

* adding zip, unzip logic

* adding zip, unzip logic

* adding zip, unzip logic

* adding zip, unzip logic

* adding zip, unzip logic

* 'onnx32/open_clip/ViT-g-14/laion2b_s12b_b42k'

* finish all the open_clip onnx model card

* add test for onnx/open_clip

* add test for onnx/open_clip

* clear loaded models in encoding test

* clear loaded models in encoding test

* clear loaded models in encoding test

* revise space between functions

* revise space between functions"
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2022-12-13T22:45:12Z,"Visual search update release (#214)

* Visual search update (#210)

* add parametrisation for chunking, overlapping boxes and combined model+boxes

* add more tests

* integrate yolox and simple grid changes

* helper functions for opencv and yolox

* add yolox patch class and helper functions

* update to use opencv

* update model cache and add logging

* fix model caching and device selection

* device conflicts

* add attention based bb generation

* update bboxes and test yolo

* refactor and add attention based ViT for bb determination

* create dino specific utils file for vit attention

* include dino files

* split the image file into seperate utils

* refactor, split into seperate files and use a proper base class

* add more tests

* update and add more tests

* refactor and clean up

* add more packages

* clean up and refactor

* update tests

* docker and cloud versions

* change

* fix device for owl

* update types and dco strings

* rename file

* rename file

* move tests

* pytorch utils test

* add another error for model loading

* update functions to handle some edge cases and update types

* add more tests

* update the yolox utils to download the proper model

* add yolox specific tests

* update reqs and setup to be on the latest

* update dockerfile to be same as new one

* clean up

* add the example and app

* update file locations

* update demo

* bump model version

* update demo

* minor text edits

* update demo

* update demo

* better error handling

* update tests

* change to PIL error

* add more error types

* small fixes for errors

* error handling

* update tests

* remove models

* clean up, doc strings and formatting

* update tests

* minor formatting

Co-authored-by: Jesse Clark <jesse@s2search.io>

* update some function names after merge

* clean up and rename

* Pinning tox ci (#211)

* Branch aware ci tests (#209)

* set the MQ_API_TEST_BRANCH to the current branch

* setting github ref to just branch name

* Adding quotes around env var

* fixed syntax error

* parsing the github.ref string

* exporting just before running

* added image_to_test input

* fix: typo

* default image to test is now explicit

* updated documentation for image_to_test var

* Update unit_test_CI.yml

* tox pinned to 3.26

Co-authored-by: pandu-k <107458762+pandu-k@users.noreply.github.com>
Co-authored-by: Pandu Oliver Kerr <pandu@s2search.io>

* Update Dockerfile

remove space

* clean up

* move to headless opencv

* tidying up

* update error

* minor edits

* fix PR feedback and add more descriptions in the docstrings

* use literal type

* clean up, make the names more descriptive

* change logging level to debug for some messages

Co-authored-by: Jesse Clark <jesse@s2search.io>
Co-authored-by: pandu-k <107458762+pandu-k@users.noreply.github.com>
Co-authored-by: Pandu Oliver Kerr <pandu@s2search.io>"
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2022-12-02T06:30:39Z,use UnidentifiedImageError if it cannot be loaded from URL source
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2022-11-29T01:36:55Z,Check HTTP status for remote image paths
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2022-10-10T00:06:42Z,finish several comments
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2022-10-10T00:02:54Z,finish several comments
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2022-10-07T05:10:32Z,"""using clip model from open_clip"""
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2022-08-26T04:27:24Z,split the image load to be used elsewhere
github.com/marqo-ai/marqo,src/marqo/s2_inference/clip_utils.py,2022-08-02T09:06:24Z,init commit
github.com/modelscope/modelscope,modelscope/models/multi_modal/clip_interrogator/model.py,2024-02-21T06:24:24Z,Fix word pubicly -> publicly (#748)
github.com/modelscope/modelscope,modelscope/models/multi_modal/clip_interrogator/model.py,2023-05-22T02:53:18Z,add 1.6
github.com/jina-ai/discoart,discoart/helper.py,2022-08-07T15:08:23Z,feat: add completed tab (#145)
github.com/jina-ai/discoart,discoart/helper.py,2022-08-04T20:41:56Z,"fix: cutouts generation (#138)

* fix: cutouts generation

* fix: cutouts generation

* fix: cutouts generation

* fix: cutouts generation

* fix: cutouts generation

* fix: cutouts generation

* fix: cutouts generation

* fix: cutouts generation

* fix: cutouts generation

* fix: cutouts generation

* fix: cutouts generation

* fix: cutouts generation

* fix: cutouts generation

* fix: cutouts generation

* fix: cutouts generation

* fix: cutouts generation

* style: fix overload and cli autocomplete

* fix: cutouts generation

* fix: cutouts generation

Co-authored-by: Jina Dev Bot <dev-bot@jina.ai>"
github.com/jina-ai/discoart,discoart/helper.py,2022-08-03T18:26:48Z,"feat: add option for visualizing cuts (#130)


* style: fix overload and cli autocomplete

* feat: add option for visualizing cuts

Co-authored-by: Jina Dev Bot <dev-bot@jina.ai>"
github.com/jina-ai/discoart,discoart/helper.py,2022-08-02T19:04:56Z,fix: make eval schedule string safe (#126)
github.com/jina-ai/discoart,discoart/helper.py,2022-08-02T08:19:53Z,fix: eval schedule string (#125)
github.com/jina-ai/discoart,discoart/helper.py,2022-07-31T16:06:00Z,"refactor: disable wandb by default (#117)



Co-authored-by: Jina Dev Bot <dev-bot@jina.ai>"
github.com/jina-ai/discoart,discoart/helper.py,2022-07-30T22:32:33Z,refactor: default no sha for faster load (#110)
github.com/jina-ai/discoart,discoart/helper.py,2022-07-30T14:51:41Z,"feat: add name var substitute (#105)

* feat: add name var substitute

* refactor: ipython display in tabs

* style: fix overload and cli autocomplete

Co-authored-by: Jina Dev Bot <dev-bot@jina.ai>"
github.com/jina-ai/discoart,discoart/helper.py,2022-07-30T11:09:47Z,fix: save gif and progress correctly on batch size (#104)
github.com/jina-ai/discoart,discoart/helper.py,2022-07-28T09:28:25Z,"feat: allow scheduling on prompt weight (#96)

* fix: add use checkpoint

* feat: allow scheduling on prompt weight

* feat: allow scheduling on prompt weight

* feat: allow scheduling on prompt weight

* feat: allow scheduling on prompt weight

* feat: allow scheduling on prompt weight

* style: fix overload and cli autocomplete

* feat: allow scheduling on prompt weight

Co-authored-by: Jina Dev Bot <dev-bot@jina.ai>"
github.com/jina-ai/discoart,discoart/helper.py,2022-07-27T12:44:13Z,feat: 0.8 add prompt scheduling (#91)
github.com/jina-ai/discoart,discoart/helper.py,2022-07-25T10:33:19Z,"fix: ic_cut_gray in docstring (#83)

* fix: ic_cut_gray in docstring

* style: fix overload and cli autocomplete

* fix: ic_cut_gray in docstring

* fix: ic_cut_gray in docstring

Co-authored-by: Jina Dev Bot <dev-bot@jina.ai>"
github.com/jina-ai/discoart,discoart/helper.py,2022-07-24T23:39:35Z,fix: version panel print
github.com/jina-ai/discoart,discoart/helper.py,2022-07-24T19:55:54Z,refactor: optimize loss compute logic (#78)
github.com/jina-ai/discoart,discoart/helper.py,2022-07-24T13:01:40Z,feat: allow customized remote url for diff models
github.com/jina-ai/discoart,discoart/helper.py,2022-07-24T12:19:40Z,feat: output gif for intermediate results (#76)
github.com/jina-ai/discoart,discoart/helper.py,2022-07-24T09:39:24Z,fix: set strict to false (#75)
github.com/jina-ai/discoart,discoart/helper.py,2022-07-23T21:18:09Z,fix: protobuf store path (#72)
github.com/jina-ai/discoart,discoart/helper.py,2022-07-21T22:45:57Z,"fix: display thread problem (#68)

* fix: display thread problem

* fix: display thread problem

* revert: text clip on gpu

* fix: #67

* style: fix overload and cli autocomplete

* fix: #67

Co-authored-by: Jina Dev Bot <dev-bot@jina.ai>"
github.com/jina-ai/discoart,discoart/helper.py,2022-07-21T16:19:25Z,fix: open clip loader device placement (#64)
github.com/jina-ai/discoart,discoart/helper.py,2022-07-21T14:20:44Z,feat: move text transformer to cpu (#62)
github.com/jina-ai/discoart,discoart/helper.py,2022-07-20T11:34:15Z,refactor: do plot and persist in another thread (#55)
github.com/jina-ai/discoart,discoart/helper.py,2022-07-20T11:00:10Z,Fix encoding PromptParser (#54)
github.com/jina-ai/discoart,discoart/helper.py,2022-07-19T13:23:26Z,fix: #47
github.com/jina-ai/discoart,discoart/helper.py,2022-07-19T13:13:15Z,fix: #43 (#48)
github.com/jina-ai/discoart,discoart/helper.py,2022-07-17T17:00:52Z,fix: models_list
github.com/jina-ai/discoart,discoart/helper.py,2022-07-17T15:53:46Z,feat: add FeiArt_Handpainted_CG_Diffusion
github.com/jina-ai/discoart,discoart/helper.py,2022-07-16T22:33:05Z,fix: #33 (#38)
github.com/jina-ai/discoart,discoart/helper.py,2022-07-16T20:09:34Z,fix: save filename on done (#37)
github.com/jina-ai/discoart,discoart/helper.py,2022-07-16T11:26:35Z,"refactor: core (#36)

* refactor: core

* refactor: core

* refactor: remove git clone install

* refactor: remove git clone install

* refactor: remove git clone install"
github.com/jina-ai/discoart,discoart/helper.py,2022-07-15T19:17:31Z,fix: #32 (#34)
github.com/jina-ai/discoart,discoart/helper.py,2022-07-14T21:31:18Z,feat: add image output
github.com/jina-ai/discoart,discoart/helper.py,2022-07-14T21:08:23Z,feat: add image output
github.com/jina-ai/discoart,discoart/helper.py,2022-07-14T11:40:43Z,feat: add cli (#29)
github.com/jina-ai/discoart,discoart/helper.py,2022-07-13T17:39:38Z,feat: allow customize default files
github.com/jina-ai/discoart,discoart/helper.py,2022-07-13T10:45:49Z,"feat: add complete tag (#26)

* fix: update help text

* fix: update help text"
github.com/jina-ai/discoart,discoart/helper.py,2022-07-13T10:08:32Z,"feat: add all scheduler (#25)

* feat: add all scheduler

* style: fix overload and cli autocomplete

* feat: add all scheduler

* feat: add all scheduler

* fix: update help text

* fix: update help text

* fix: update help text

Co-authored-by: Jina Dev Bot <dev-bot@jina.ai>"
github.com/jina-ai/discoart,discoart/helper.py,2022-07-12T14:54:10Z,feat: add comics diffusion model
github.com/jina-ai/discoart,discoart/helper.py,2022-07-12T14:48:40Z,"feat: add comics diffusion model (#21)

* feat: add comics diffusion model

* feat: add comics diffusion model"
github.com/jina-ai/discoart,discoart/helper.py,2022-07-12T12:16:31Z,"feat: 0.3 (#19)

* refactor: improve final result instruction

* feat: support more diffusion models

* fix: secondary model scheduling

* refactor: create api

* refactor: create api

* refactor: create api

* refactor: create api

* refactor: create api

* style: fix overload and cli autocomplete

* refactor: create api

* style: fix overload and cli autocomplete

* refactor: create api

* style: fix overload and cli autocomplete

* feat: add recommended size

* feat: add recommended size

* feat: add recommended size

Co-authored-by: Jina Dev Bot <dev-bot@jina.ai>"
github.com/jina-ai/discoart,discoart/helper.py,2022-07-11T21:58:22Z,"feat: add secondary model scheduling (#15)

* chore: fix readme

* style: fix overload and cli autocomplete

* feat: add secondary model scheduling

* feat: add secondary model scheduling

* feat: add secondary model scheduling

* style: fix overload and cli autocomplete

* ci: add tests ci

* ci: add tests ci

* refactor: remove wget

* refactor: remove wget

* refactor: remove wget

* refactor: remove wget

* refactor: remove wget

Co-authored-by: Jina Dev Bot <dev-bot@jina.ai>"
github.com/jina-ai/discoart,discoart/helper.py,2022-07-11T16:30:44Z,"feat: add clip model scheduling (#14)

* feat: add clip model scheduling

* feat: support customized model config

* feat: support customized model config

* feat: support customized model config

* feat: support customized model config

* feat: add cheatsheet

* feat: add cheatsheet

* feat: add cheatsheet

* feat: add cheatsheet

* feat: add cheatsheet

* feat: add cheatsheet

* feat: add cheatsheet

* feat: add cheatsheet"
github.com/jina-ai/discoart,discoart/helper.py,2022-07-10T20:00:31Z,feat: ipython deps is optional fix cpu support
github.com/jina-ai/discoart,discoart/helper.py,2022-07-10T19:42:54Z,feat: ipython deps is optional fix cpu support
github.com/jina-ai/discoart,discoart/helper.py,2022-07-10T19:26:31Z,feat: ipython deps is optional fix cpu support
github.com/jina-ai/discoart,discoart/helper.py,2022-07-09T21:42:14Z,fix: first time clone repo
github.com/jina-ai/discoart,discoart/helper.py,2022-07-09T19:04:11Z,"feat: 0.1 (#10)

* fix: upstream #116

* refactor: replace clip with open-clip

* feat: add custom models support and symmetry

* style: reformat with blacl

* style: reformat with blacl

* fix: broken compression on race condition #9

* fix: use uuid instead of seed as da name

* docs: update readme

* docs: update readme

* docs: update readme

* fix: update guided diffusion upstream

* fix: update guided diffusion upstream

* fix: update guided diffusion upstream

* fix: update guided diffusion upstream

* fix: update guided diffusion upstream

* fix: update guided diffusion upstream

* fix: update guided diffusion upstream

* fix: update guided diffusion upstream

* fix: update guided diffusion upstream

* fix: update guided diffusion upstream

* fix: update guided diffusion upstream

* feat: add spell checker

* feat: add spell checker

* feat: add spell checker

* feat: add spell checker

* feat: add spell checker

* feat: add spell checker

* feat: add spell checker

* feat: add spell checker

* feat: add spell checker

* feat: add spell checker

* feat: add spell checker

* feat: add spell checker

* feat: add spell checker

* feat: add spell checker

* feat: add spell checker

* feat: add spell checker

* feat: add spell checker

* feat: add spell checker"
github.com/jina-ai/discoart,discoart/helper.py,2022-07-08T20:28:55Z,feat: add open clip pretrained models
github.com/jina-ai/discoart,discoart/helper.py,2022-07-08T20:13:59Z,feat: add open clip pretrained models
github.com/jina-ai/discoart,discoart/helper.py,2022-07-02T20:10:08Z,feat: add clip model selector
github.com/jina-ai/discoart,discoart/helper.py,2022-07-02T20:06:11Z,feat: add clip model selector
github.com/jina-ai/discoart,discoart/helper.py,2022-07-02T19:53:19Z,feat: add clip model selector
github.com/jina-ai/discoart,discoart/helper.py,2022-07-02T19:31:28Z,feat: add clip model selector
github.com/jina-ai/discoart,discoart/helper.py,2022-07-01T13:44:09Z,feat: add dockerfile
github.com/jina-ai/discoart,discoart/helper.py,2022-07-01T12:40:48Z,feat(api): add batch_name back
github.com/jina-ai/discoart,discoart/helper.py,2022-07-01T12:39:58Z,feat(api): add batch_name back
github.com/jina-ai/discoart,discoart/helper.py,2022-06-30T23:18:17Z,chore: first commit
github.com/jina-ai/discoart,discoart/helper.py,2022-06-30T23:16:01Z,chore: first commit
github.com/jina-ai/discoart,discoart/helper.py,2022-06-30T23:05:16Z,chore: first commit
github.com/jina-ai/discoart,discoart/helper.py,2022-06-30T23:04:51Z,chore: first commit
github.com/jina-ai/discoart,discoart/helper.py,2022-06-30T20:12:49Z,chore: first commit
github.com/jina-ai/discoart,discoart/helper.py,2022-06-30T16:29:11Z,chore: first commit
github.com/Docta-ai/docta,docta/core/preprocess.py,2023-05-08T06:35:08Z,first commit
github.com/lllyasviel/ControlNet-v1-1-nightly,ldm/modules/encoders/modules.py,2023-04-12T17:45:57Z,i
github.com/AIGC-Audio/AudioGPT,text_to_audio/Make_An_Audio/ldm/modules/encoders/modules.py,2023-04-30T15:20:22Z,update
github.com/microsoft/onnxruntime,onnxruntime/python/tools/transformers/models/stable_diffusion/test/check_image.py,2024-01-31T01:39:27Z,"Save stablediffusion and open-clip in pipeline cache (#19314)

### Description
1. save the model to pipeline cache
2. lower the similarly bar to 97
3. publish the generated image that we can check it once the test fails


### Motivation and Context
Reduce model downloads"
github.com/microsoft/onnxruntime,onnxruntime/python/tools/transformers/models/stable_diffusion/test/check_image.py,2024-01-29T17:33:58Z,"Add VP test in Stable diffusion pipeline (#19300)

### Description
1. Add visual parity test based on openai clip model
2. Add trigger rules

### Motivation and Context
1. check generated image is expected
2. reduce unnecessary triggers"
github.com/NVIDIA/NeMo,nemo/collections/multimodal/modules/stable_diffusion/encoders/modules.py,2024-01-20T01:59:23Z,"Final multimodal PR with our recent developments on MM side (#8127)

* Hotfix (#7501) (#7568)

Signed-off-by: Jan Baczek <jbaczek@nvidia.com>
Co-authored-by: jbaczek <45043825+jbaczek@users.noreply.github.com>

* Avoid duplicated checkpoint save (#7555) (#7566)

Signed-off-by: Mikołaj Błaż <mblaz@nvidia.com>
Co-authored-by: mikolajblaz <mikolajblaz@users.noreply.github.com>

* Cache FP8 weight and transpose only at the first micro-batch in each validation and test routine (#7470) (#7483)

* Cache weight and transpose only in the first batch in all training, val, and test runs



* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Add an option to disable manual GC in validation (#7467) (#7476)

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>

* Remove PUBLICATIONS.md, point to github.io NeMo page instead (#7694) (#7695)

* update publications section to point to blog website page



* add hyphen



* use double backquotes for code formatting



---------

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>
Signed-off-by: Elena Rastorgueva <80532067+erastorgueva-nv@users.noreply.github.com>
Co-authored-by: Elena Rastorgueva <80532067+erastorgueva-nv@users.noreply.github.com>

* Fix multi rank finetune for ASR (#7684) (#7699)

* Fix multi rank finetune for ASR



* Actually add time



* Actually add time



---------

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>

* Update docs: readme, getting started, ASR intro (#7679)

* [TTS] Add dataset to path of logged artifacts (#7462)

* [TTS] Add dataset to path of logged artifacts

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Revert axis name back to Audio Frames

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* move install info to INSTALLATION.md

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* tidy up links

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix sft dataset truncation (#7464)

* Add fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Automatic Lip Reading Recognition (ALR) - ASR/CV (Visual ASR) (#7330)

* striding_conv1d_k5 and dw_striding_conv1d_k5 subsampling

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* transpose conv1d inputs

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* Update subsampling.py

change striding_conv1d_k5 to striding_conv1d

Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>

* cv branch

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* video manifest

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* add collection classes

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add test_step_outputs

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* correct manifest bug when having only audio or only videos

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* correct manifest bug when having only audio or only videos

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* clean references

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* freeze unfreeze transcribe cv models

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* correct manifest get_full_path bug

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* update for PR

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* guard torchvision

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Update nemo/collections/cv/data/video_to_text_dataset.py

Co-authored-by: Igor Gitman <igor.a.gitman@gmail.com>
Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>

* _video_speech_collate_fn in cv/data/video_to_text.py

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* add self.out = None to asr subsampling

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* Update nemo/collections/cv/data/video_to_text_dataset.py

Co-authored-by: Igor Gitman <igor.a.gitman@gmail.com>
Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>

* cv -> multimodal/speech_cv branch

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: mburchi <maxime.burchi@gmail.com>
Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Igor Gitman <igor.a.gitman@gmail.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* HF StarCoder to NeMo conversion script (#7421)

* Script to convert HF StarCoder checkpoint to NeMo

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* StarCoder conversion test

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Fix test

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Catch up with save_to changes

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Don't abbreviate args for clarity

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Configurable precision: BF16 vs FP32

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* fix bug when loading dist ckpt in peft (#7452)

Signed-off-by: Hongbin Liu <hongbinl@nvidia.com>
Co-authored-by: Hongbin Liu <hongbinl@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix adding positional embeddings in-place in transformer module (#7440)

Signed-off-by: Tamerlan Tabolov <tktabolov@gmail.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix (#7478)

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* add sleep (#7498) (#7499)

* add sleep



* add sleep onto config instead



* add comment



---------

Signed-off-by: Gerald Shen <geshen@nvidia.com>
Co-authored-by: Gerald Shen <119401249+gshennvm@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix exp manager check for sleep (#7503) (#7504)

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* bugfix: trainer.accelerator=auto from None. (#7492) (#7493)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [doc] fix broken link (#7481)

Signed-off-by: Stas Bekman <stas00@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [TTS] Read audio as int32 to avoid flac read errors (#7477)

* [TTS] Read audio as int32 to avoid flac read errors

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Add comment about read failures

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS (#7409)

* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS
* Train 'AISHELL-3' dataset with multi-speakers

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update get_data.py

update copyright header

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* Update get_data.py

added a disclaimer

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add new configuration file for AISHELL3 with multispeaker of fastpitch

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* dllogger - log on rank 0 only (#7513)

Signed-off-by: Stas Bekman <stas00@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix TTS FastPitch tutorial (#7494) (#7516)

* Fix

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix get_dist() tensor dimension (#7506) (#7515)

Signed-off-by: Jocelyn Huang <jocelynh@nvidia.com>
Co-authored-by: Jocelyn <jocelynh@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* bugfix: specify trainer.strategy=auto when devices=1 (#7509) (#7512)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* fix (#7511)

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [TTS] Fix FastPitch data prep tutorial (#7524)

Signed-off-by: Ryan <rlangman@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* add italian tokenization (#7486)

* add italian tokenization

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add more ipa lexicon it

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix error deletion

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* add test

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Replace None strategy with auto in tutorial notebooks (#7521) (#7527)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* unpin setuptools (#7534) (#7535)

Signed-off-by: fayejf <36722593+fayejf@users.noreply.github.com>
Co-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* remove auto generated examples (#7510)

* explicitly remove autogenerated examples for data parallel evaluation

Signed-off-by: arendu <adithyare@nvidia.com>

* mark autogenrated and remove it for test

Signed-off-by: arendu <adithyare@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: arendu <adithyare@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Add the `strategy` argument to `MegatronGPTModel.generate()` (#7264)

It is passed as an explicit argument rather than through
`**strategy_args` so as to ensure someone cannot accidentally pass other
arguments that would end up being ignored.

It is a keyword-only argument to ensure that if in the future we want to
update the signature to `**strategy_args`, we can do it without breaking
code.

Signed-off-by: Olivier Delalleau <507137+odelalleau@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix PTL2.0 related ASR bugs in r1.21.0: Val metrics logging, None dataloader issue (#7531) (#7533)

* fix none dataloader issue ptl2



* ptl2.0 logging fixes for rnnt_models



---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Co-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* gpus -> devices (#7542) (#7545)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Update FFMPEG version to fix issue with torchaudio (#7551) (#7553)

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* PEFT GPT & T5 Refactor (#7308)

* initial implementation of add_adapters API

* correct type hint

* Add config in add_adapters for save and load (@author bobchen)

* Remove AdapterConfig to avoid import error

* Add AdaterConfig back and move adaptermixin to sft model

* Add NLPSaveRestoreConnector as default in NLPModel.restore_from

* Add restore_from_nemo_with_adapter and test script

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* rename t5 file and classes to be consistent with GPT

* add t5 sft dataset

* add support for single-file format with T5SFTDataset

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Various small changes to make T5 SFT work like GPT SFT

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add adapter evaluation test script

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add MultiAdaterConfig for ia3 and fix builder issue

* Make ptuning for T5SFTModel work using mixin

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add IA3_Adapter for AdapterName

* Add adapter name for ptuning and attention adapter

* Make test script GPT/T5 agnostic

* Add layer selection feature

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Integrate adapter name and config

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update gpt peft tuning script to new API

* add t5 peft tuning script with new API

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix IA3 layer selection issue

* Override state_dict on SFT model instead of mixin

* Add load adapter by adapter config

* move peft config map away from example script

* auto get config from nemo adapter

* Move PEFTConfig to new file

* fix ckpt save/load for t5

* name change: add_adapters -> add_adapter

* variable name change

* update t5 script

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix t5 issues

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add weight tying

* update gpt tuning script

* PEFT-API proposal

* Fix according to comments

* update tuning scripts

* move merge_cfg_with to mixin class since it applies to both gpt and t5 and requires the model class for restore

* Add mcore_gpt support for NLPAdapterMixin

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix typo

* variable name change to distinguish ""peft"" and ""adapter""

* override `load_adapters` to support `add_adapter` name change

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update tuning and eval script for adapter save/load

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add Ptuning on first stage only

* add lora tutorial for review

* Fix layer selection for mcore

* add landing page

* fix resume training

Signed-off-by: jasonwan <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add mcore condition in sharded_state_dict to make sft work

* Update lora_tutorial.md

First edit of this file for PEFT documentation for NeMO

Signed-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>

* rename Adapter to AttentionAdapter to avoid confusion in doc

* Change load_adapters to load .nemo

* add quick start guide

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add load_adapters with .ckpt

* Remove setup_complete changes in load_adapters

* update landing page

* remove typo

* Updated quick_start.md per Chen Cui

Signed-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>

* Add inference config merger and tutorial

* Add doc string for NLPAdapterModelMixin and deprecated warning on MegatronGPTPEFTModel

* add supported_methods.md and update other documentations

* Update supported_methods.md

minor updates.

Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>

* Update landing_page.md

minor update.

Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>

* Modify doc string for NLPAdapterModelMixin

* Add doc string add_adapters in NLPAdapterModelMixin

* rename canonical adapters

* remove mcore hard dependency

* [PATCH] move microbatch calculator to nemo from apex

* remove apex dependency in gpt and t5 sft models

* remove apex dependency in gpt model

* render doc strings

* fix

* Add missing virtual_tokens on ptuning

* fix docstrings

* update gpt-style model coverage in docs

* update docstring

* Remove pdb

* add lightning_fabric to make docstring rendering work

* Add Ptuning missing key

* try docstring rendering

* Fix ptuning issue

* update gpt t5 peft tuning and eval scripts

* typos

* update eval config

* fix bug relating to apex dependency removal

* typo

* make predict step behave the same as test step

* make lora tutorial work in notebook

* cosmetics

* update yaml scripts

* mcore_gpt attribute optional

* typo

* update eval scripts and fix T5 eval bugs

* add NLPDDPStrategyNotebook and trainer builder logic to use it

* update lora notebook to use new trainer builder

* fix microbatch calculator bug for inference after training

* Convert markdown files to RST and incorporate with doc

* typo

* revise language

* remove extra cell

* remove unnecessary inheritance

* remove old tests

* move layer selection default so logging messages make sense

* remove `save_adapters` as adapter weights are saved automatically during training

* initialize weights from a checkpoint instead of randomly

* multiple fields can form a context (#7147)

* list of context fields and flexible prompt template

Signed-off-by: arendu <adithya.r@gmail.com>

* list of fields for context

Signed-off-by: arendu <adithya.r@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Add multiple truncation fields and middle truncation

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Compatible to old ckpt

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix tokenize detokenize issue

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Remove detokenization, add truncation augmentation

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Resolve comments

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Remove unused import

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* revert eos

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Add tokenizer space_sensitive attribute

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix error

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Fix erorr and use re

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Change assert logic

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Follow adi suggestion

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Remove merge function

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add example and comment

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Remove context_key and add comment

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Remove random truncation

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix template none

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: arendu <adithya.r@gmail.com>
Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Signed-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

* revert config changes

* remove accidental breakpoint

* support TP>1 loading

* infer adapter type from checkpoint in during eval

* breakup add adapter

* enable interpolation of train_ds and validation_ds

* update metric calc script to conform to single-file eval format

* remove extraneous print

* update lora notebook for updated merge_inference_cfg

* Update nlp_adapter_mixins.py

variable name change

Signed-off-by: Chen Cui <chcui@nvidia.com>

* turn off grad scaler for PP to match old scripts

* remove PEFTSaveRestoreConnector since functionality all covered by the new mixin class

* remove resume_from_checkpoint check since covered in #7335

* revert changes made in eval config interpolation

* more interpolation

* typo

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* remove dup line

Signed-off-by: Chen Cui <chcui@nvidia.com>

* code style warnings

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix config mistake

Signed-off-by: Chen Cui <chcui@nvidia.com>

* add copyright header

Signed-off-by: Chen Cui <chcui@nvidia.com>

* fix code check warnings

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* revert changes to remove apex dependency (mixed apex+nemo microbatch calculator broke some CI tests)

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add more deprecation notices

Signed-off-by: Chen Cui <chcui@nvidia.com>

* update deprecation notices

Signed-off-by: Chen Cui <chcui@nvidia.com>

* update deprecation notices

Signed-off-by: Chen Cui <chcui@nvidia.com>

* consolidate peft and sft scripts

Signed-off-by: Chen Cui <chcui@nvidia.com>

* update CI tests

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* notebook branch points to main to prepare for merge

Signed-off-by: Chen Cui <chcui@nvidia.com>

* fix gpt and t5 validation with any metric other than loss

Signed-off-by: Chen Cui <chcui@nvidia.com>

* support pre-extracted checkpoints

Signed-off-by: Chen Cui <chcui@nvidia.com>

---------

Signed-off-by: jasonwan <jasonwan@nvidia.com>
Signed-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>
Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>
Signed-off-by: arendu <adithya.r@gmail.com>
Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Signed-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>
Signed-off-by: Chen Cui <chcui@nvidia.com>
Co-authored-by: Chen Cui <chcui@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Marc Romeyn <marcromeyn@gmail.com>
Co-authored-by: jasonwan <jasonwan@nvidia.com>
Co-authored-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>
Co-authored-by: Adi Renduchintala <adithyare@nvidia.com>
Co-authored-by: Yuanzhe Dong <yudong@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* fix a typo (#7496)

Signed-off-by: BestJuly <chntaoli@163.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [TTS] remove curly braces from ${BRANCH} in jupyer notebook cell. (#7554) (#7560)

* remove curly braces.
* remove installation of pynini.
---------

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* add youtube embed url (#7570)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Remap speakers to continuous range of speaker_id for dataset AISHELL3 (#7536)

* Remap speakers to continuous range of speaker_id for dataset AISHELL3
* Add new key/value pair to record raw speaker for AISHELL3 dataset

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* fix validation_step_outputs initialization for multi-dataloader (#7546) (#7572)

* added correct validation_step_outputs initialization for mutli-dataloader



* changed kernel for display



* Update logic for validation and test step outputs



* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* revert multidataloader changes in multilang ASR notebook



---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Append output of val step to self.validation_step_outputs (#7530) (#7532)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [TTS] fixed trainer's accelerator and strategy. (#7569) (#7574)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Append val/test output to instance variable in EncDecSpeakerLabelModel (#7562) (#7573)

* Append val/test output to the instance variable in EncDecSpeakerLabelModel



* Handle test case in evaluation_step



* Replace type with isinstance



---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix CustomProgressBar for resume (#7427) (#7522)

* Fix CustomProgress Bar for resume and multiple epochs



* Edit num_training_batches



* Use max_steps as total for progress bar for resume



* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* fix typos in nfa and speech enhancement tutorials (#7580) (#7583)

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>
Co-authored-by: Elena Rastorgueva <80532067+erastorgueva-nv@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Add strategy as ddp_find_unused_parameters_true for glue_benchmark.py (#7454) (#7461)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* update strategy (#7577) (#7578)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix typos (#7581)

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Change hifigan finetune strategy to ddp_find_unused_parameters_true (#7579) (#7584)

* Change strategy to auto



---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [BugFix] Add missing quotes for auto strategy in tutorial notebooks (#7541) (#7548)

* Add missing quotes for auto strategy



* Revert trainer.gpus to trainer.devices in Self_Supervised_Pre_Training.ipynb



---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Signed-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* add build os key (#7596) (#7599)

* add build os key



* add tools



* update to stable version



---------

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* StarCoder SFT test + bump PyT NGC image to 23.09 (#7540)

* Add SFT StarCoder test

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Remove _modify_config call as it is covered in load_from_nemo just below

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Test with pyt:23.09 container

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

---------

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* defaults changed (#7600)

* defaults changed

Signed-off-by: arendu <adithyare@nvidia.com>

* typo

Signed-off-by: arendu <adithyare@nvidia.com>

* update

Signed-off-by: arendu <adithyare@nvidia.com>

---------

Signed-off-by: arendu <adithyare@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* add ItalianPhonemesTokenizer (#7587)

* add ItalianPhonemesTokenizer

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix Italian phonemes

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add test

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

---------

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* best ckpt fix (#7564) (#7588)

Signed-off-by: dimapihtar <dpihtar@gmail.com>
Co-authored-by: Dmytro Pykhtar <37850217+dimapihtar@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Add files via upload (#7598)

specifies the branch

Signed-off-by: George <37293288+Jorjeous@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix validation in G2PModel and ThutmoseTaggerModel (#7597) (#7606)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain (#7576) (#7586)

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain
* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Safeguard nemo_text_processing installation on ARM (#7485)

* safeguard nemo_text_processing installing

Signed-off-by: Jason <jasoli@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update check

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Bound transformers version in requirements (#7620)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* fix llama2 70b lora tuning bug (#7622)

* fix llama2 70b lora tuning bug

Signed-off-by: Chen Cui <chcui@nvidia.com>

* Update peft_config.py

brackets

Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>

---------

Signed-off-by: Chen Cui <chcui@nvidia.com>
Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>
Co-authored-by: Adi Renduchintala <adithyare@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix import error no module name model_utils (#7629)

Signed-off-by: Mehadi Hasan Menon <mehadihasan80@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* add fc large ls models (#7641)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao Koluguri <nithinraok>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* bugfix: trainer.gpus, trainer.strategy, trainer.accelerator (#7621) (#7642)

* [TTS] bugfix for Tacotron2 tutorial due to PTL 2.0
* trainer.gpus -> trainer.devices
* fixed related tutorial bugs
---------
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* fix ssl models ptl monitor val through logging (#7608) (#7614)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix metrics for SE tutorial (#7604) (#7612)

Signed-off-by: Ante Jukić <ajukic@nvidia.com>
Co-authored-by: anteju <108555623+anteju@users.noreply.github.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Add ddp_find_unused_parameters=True and change accelerator to auto (#7623) (#7644)

* Add ddp_find_unused_parameters=True and change acclerator to auto



* Add ddp_find_unused_parameters True for normalization_as_tagging_train.py



---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix py3.11 dataclasses issue  (#7616)

* Fix py3.11 dataclasses issue  (#7582)

* Update ASR configs to support Python 3.11

Signed-off-by: smajumdar <titu1994@gmail.com>

* Update TTS configs to support Python 3.11

Signed-off-by: smajumdar <titu1994@gmail.com>

* Guard MeCab and Ipadic

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix remaining ASR dataclasses

Signed-off-by: smajumdar <titu1994@gmail.com>

* Fix remaining ASR dataclasses

Signed-off-by: smajumdar <titu1994@gmail.com>

* Fix scripts

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Update name to ConfidenceMethodConfig

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain (#7576) (#7586)

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain
* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Safeguard nemo_text_processing installation on ARM (#7485)

* safeguard nemo_text_processing installing

Signed-off-by: Jason <jasoli@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update check

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Fix changes to confidence measure

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: smajumdar <titu1994@gmail.com>
Signed-off-by: Sangkug Lym <slym@nvidia.com>
Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: github-actions[bot] <41898282+github-actions[bot]@users.noreply.github.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Jason <jasoli@nvidia.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Fix issues with Dockerfile (#7650) (#7652)

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [ASR] RNN-T greedy decoding max_frames fix for alignment and confidence (#7635)

* decoding and test fix

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [ASR] Fix type error in jasper (#7636) (#7653)

Signed-off-by: Ryan <rlangman@nvidia.com>
Co-authored-by: Ryan Langman <rlangman@nvidia.com>
Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* [TTS] Add STFT and SI-SDR loss to audio codec recipe (#7468)

* [TTS] Add STFT and SI-SDR loss to audio codec recipe

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix STFT resolution

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix training metric logging

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Add docstring to mel and stft losses

Signed-off-by: Ryan <rlangman@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Ryan <rlangman@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* add outline of asr quickstart info to asr/intro.rst

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* add CLI, LM and real-time transcription sections

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>

* Create per.py (#7538)

* Move model precision copy (#7336)

* move cfg precision set to megatron base model

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* remove copy from other models

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* modify attribute not arg

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* fix gpt model test for ptl 2.0

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* rename function and add docstring

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* replace precision to dtype conditionals with func call

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* unnecessary function and cfg reset

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* set default value

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* fix precision lookup in a few more places

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* rename mapping function

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* ununsed import

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* save torch datatype to model

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* set weights precision wrt amp o2

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* Revert ""set weights precision wrt amp o2""

This reverts commit 313a4bfe5eb69d771a6d2433898c0685836aef5c.

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* revert half precision at inference attempt

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* move autocast dtype to base model

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* move params dtype to base model, enable fp16 O2 inf

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* unused imports

Signed-off-by: Maanu Grover <maanug@nvidia.com>

---------

Signed-off-by: Maanu Grover <maanug@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix PEFT checkpoint loading (#7388)

* Fix PEFT checkpoint loading

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Jason Wang <jasonwan@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Use distributed optimizer support for multiple dtypes (#7359)

* Update distopt wrapper with multiple dtype support

Remove manual handling of separate FP32 optimizer.

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Use distopt support for contiguous buffers with multiple dtypes

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Fix typo

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Separate distopt buckets for first GPT layer and non-overlapped params

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Add distopt logic for int dtypes

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Update Apex commit

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Remove unused variables

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Update Apex commit in README and Jenkensfile

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Debug Dockerfile and Jenkinsfile

Signed-off-by: Tim Moon <tmoon@nvidia.com>

---------

Signed-off-by: Tim Moon <tmoon@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* minor fix for llama ckpt conversion script (#7387)

* minor fix for llama ckpt conversion script

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* Update Jenkinsfile

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* remove fast_swiglu configuration

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

---------

Signed-off-by: Jason Wang <jasonwan@nvidia.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix wrong calling of librosa.get_duration() in notebook (#7376)

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [PATCH] PEFT import mcore (#7393)

* [PATCH] PEFT import mcore

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Jason Wang <jasonwan@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Create per.py

Script for calculation Punctuation Error Rate and related rates (correct rate, deletions rate, etc.)

Signed-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [TTS] Added a callback for logging initial data (#7384)

Signed-off-by: Ante Jukić <ajukic@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update Core Commit (#7402)

* Update Core Commit

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* update commit

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

---------

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Use cfg attribute in bert (#7394)

* use cfg attribute instead of arg

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* use torch_dtype in place of cfg.precision

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* move precision copy before super constructor

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* use trainer arg

Signed-off-by: Maanu Grover <maanug@nvidia.com>

---------

Signed-off-by: Maanu Grover <maanug@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add support for bias conversion in Swiglu models (#7386)

* Add support for bias conversion in Swiglu models

Signed-off-by: smajumdar <titu1994@gmail.com>

* Add support for auto extracting tokenizer model

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add support for auto extracting tokenizer model

Signed-off-by: smajumdar <titu1994@gmail.com>

* Fix issue with missing tokenizer

Signed-off-by: smajumdar <titu1994@gmail.com>

* Refactor

Signed-off-by: smajumdar <titu1994@gmail.com>

* Refactor

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update save_to and restore_from for dist checkpointing (#7343)

* add dist ckpt to save to, in progress

Signed-off-by: eharper <eharper@nvidia.com>

* move dist ckpt

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* clean up

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update restore from, need to figure out how to initialize distributed

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* launch distrib if needed when restoring dist ckpt

Signed-off-by: eharper <eharper@nvidia.com>

* when using mcore we can change tp pp on the fly

Signed-off-by: eharper <eharper@nvidia.com>

* add load_from_checkpoint support for dist ckpt

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update llama convert script to save dist .nemo

Signed-off-by: eharper <eharper@nvidia.com>

* fix load dist ckpt

Signed-off-by: jasonwan <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* setup TE TP groups if needed

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* setup te tp groups if needed

Signed-off-by: eharper <eharper@nvidia.com>

* remove import

Signed-off-by: eharper <eharper@nvidia.com>

---------

Signed-off-by: eharper <eharper@nvidia.com>
Signed-off-by: jasonwan <jasonwan@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: jasonwan <jasonwan@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* fix forward for with mcore=false (#7403)

Signed-off-by: Jimmy Zhang <jiemingz@nvidia.com>
Co-authored-by: Jimmy Zhang <jiemingz@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix logging to remove 's/it' from progress bar in Megatron models and add train_step_timing (#7374)

* Add CustomProgressBar class to exp_manager and trainer callbacks

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix the progress bar to reflect total microbatch cnt

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* Modify CustomProgressBar class

1) Modify CustomProgressBar class to update progress bar per global_step instead of per microbatch
2) Add the callback to other megatron training/finetuning files that are not using MegatronTrainerBuilder

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* Add CustomProgressBar callback to tuning files

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Set Activation Checkpointing Defaults (#7404)

* Set Activation Checkpointing Defaults

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* check for None

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* make loss mask default to false (#7407)

Signed-off-by: eharper <eharper@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add dummy userbuffer config files (#7408)

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* add missing ubconf files (#7412)

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* New tutorial on Speech Data Explorer (#7405)

* Added Google Colab based tutorial on Speech Data Explorer

Signed-off-by: George Zelenfroynd <gzelenfroind@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update ptl training ckpt conversion script to work with dist ckpt (#7416)

* update ptl convert script

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* don't break legacy

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: eharper <eharper@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Allow disabling sanity checking when num_sanity_val_steps=0 (#7413)

* Allow disabling sanity checking when num_sanity_val_steps=0

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* Update num_sanity_val_steps to be a multiple of num_microbatches

Signed-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Signed-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add comprehensive error messages (#7261)

Signed-off-by: Anton Peganov <apeganov@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* check NEMO_PATH (#7418)

Signed-off-by: Nikolay Karpov <karpnv@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* layer selection for ia3 (#7417)

* layer selection for ia3

Signed-off-by: arendu <adithyare@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: arendu <adithyare@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix missing pip package 'einops' (#7397)

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix failure of pyaudio in Google Colab (#7396)

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update README.md: output_path --> output_manifest_filepath (#7442)

Signed-off-by: Samuele Cornell <cornellsamuele@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add rope dynamic linear scaling (#7437)

* Add dynamic linear scaling

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix None dataloader issue in PTL2.0 (#7455)

* Fix None dataloader issue in PTL2.0

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* updating values of self._validation_dl and self._test_dl as well

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* updating values of self._validation_dl and self._test_dl as well

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [ASR] Confidence measure -> method renames (#7434)

* measure -> method

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add steps for document of getting dataset 'SF Bilingual Speech' (#7378)

* Add steps for document of getting dataset 'SF Bilingual Speech'

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update datasets.rst

added a link from a tutorial demonstrating detailed data prep steps.

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* RNN-T confidence and alignment bugfix (#7381)

* new frame_confidence and alignments lists are now always created after the while loop

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* tests added

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix resume from checkpoint in exp_manager (#7424) (#7426)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix checking of cuda/cpu device for inputs of Decoder (#7444)

* Fix checking of cuda/cpu device for inputs of Decoder

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update tacotron2.py

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: Jason <jasoli@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix failure of ljspeech's get_data.py (#7430)

* Fix failure of ljspeech's get_data.py

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [TTS] Fix audio codec type checks (#7373)

* [TTS] Fix audio codec type checks

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix audio codec tests

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* […"
github.com/NVIDIA/NeMo,nemo/collections/multimodal/modules/stable_diffusion/encoders/modules.py,2024-01-11T06:32:19Z,"Add All Multimodal Source Code Part 2: Text to image, x to nerf (#7970)

* Update README.md: output_path --> output_manifest_filepath (#7442)

Signed-off-by: Samuele Cornell <cornellsamuele@gmail.com>

* Updating FlashAttention API to match FlashAttentionV2

* Multiple fixes for mm

* Fix CI inductor issue and update to torch compile

* Remove suppress error

* Fix when conversion config uses fp16 and it complains about precision plugin

* Fixing FAv2 API usage

* Initial release of content filtering model

* Added synthetic dataloader for precached and online mode

* Mingyuanm/dreambooth opt

* Add llama2 support in neva training

* Fix sampler length

* Fix all precision issues in nemo multimodal

* Add rope dynamic linear scaling (#7437)

* Add dynamic linear scaling

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>

* Fix None dataloader issue in PTL2.0 (#7455)

* Fix None dataloader issue in PTL2.0

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* updating values of self._validation_dl and self._test_dl as well

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* updating values of self._validation_dl and self._test_dl as well

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* [ASR] Confidence measure -> method renames (#7434)

* measure -> method

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Add steps for document of getting dataset 'SF Bilingual Speech' (#7378)

* Add steps for document of getting dataset 'SF Bilingual Speech'

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update datasets.rst

added a link from a tutorial demonstrating detailed data prep steps.

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* RNN-T confidence and alignment bugfix (#7381)

* new frame_confidence and alignments lists are now always created after the while loop

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* tests added

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* Fix resume from checkpoint in exp_manager (#7424) (#7426)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: Eric Harper <complex451@gmail.com>

* Fix checking of cuda/cpu device for inputs of Decoder (#7444)

* Fix checking of cuda/cpu device for inputs of Decoder

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update tacotron2.py

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: Jason <jasoli@nvidia.com>

* Fix failure of ljspeech's get_data.py (#7430)

* Fix failure of ljspeech's get_data.py

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* [TTS] Fix audio codec type checks (#7373)

* [TTS] Fix audio codec type checks

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix audio codec tests

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Add dataset to path of logged artifacts (#7462)

* [TTS] Add dataset to path of logged artifacts

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Revert axis name back to Audio Frames

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>

* Fix sft dataset truncation (#7464)

* Add fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Automatic Lip Reading Recognition (ALR) - ASR/CV (Visual ASR) (#7330)

* striding_conv1d_k5 and dw_striding_conv1d_k5 subsampling

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* transpose conv1d inputs

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* Update subsampling.py

change striding_conv1d_k5 to striding_conv1d

Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>

* cv branch

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* video manifest

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* add collection classes

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add test_step_outputs

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* correct manifest bug when having only audio or only videos

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* correct manifest bug when having only audio or only videos

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* clean references

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* freeze unfreeze transcribe cv models

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* correct manifest get_full_path bug

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* update for PR

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* guard torchvision

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Update nemo/collections/cv/data/video_to_text_dataset.py

Co-authored-by: Igor Gitman <igor.a.gitman@gmail.com>
Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>

* _video_speech_collate_fn in cv/data/video_to_text.py

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* add self.out = None to asr subsampling

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* Update nemo/collections/cv/data/video_to_text_dataset.py

Co-authored-by: Igor Gitman <igor.a.gitman@gmail.com>
Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>

* cv -> multimodal/speech_cv branch

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: mburchi <maxime.burchi@gmail.com>
Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Igor Gitman <igor.a.gitman@gmail.com>

* HF StarCoder to NeMo conversion script (#7421)

* Script to convert HF StarCoder checkpoint to NeMo

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* StarCoder conversion test

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Fix test

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Catch up with save_to changes

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Don't abbreviate args for clarity

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Configurable precision: BF16 vs FP32

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* fix bug when loading dist ckpt in peft (#7452)

Signed-off-by: Hongbin Liu <hongbinl@nvidia.com>
Co-authored-by: Hongbin Liu <hongbinl@nvidia.com>

* Fix adding positional embeddings in-place in transformer module (#7440)

Signed-off-by: Tamerlan Tabolov <tktabolov@gmail.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

* Fix (#7478)

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* add sleep (#7498) (#7499)

* add sleep



* add sleep onto config instead



* add comment



---------

Signed-off-by: Gerald Shen <geshen@nvidia.com>
Co-authored-by: Gerald Shen <119401249+gshennvm@users.noreply.github.com>

* Fix exp manager check for sleep (#7503) (#7504)

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>

* bugfix: trainer.accelerator=auto from None. (#7492) (#7493)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>

* [doc] fix broken link (#7481)

Signed-off-by: Stas Bekman <stas00@users.noreply.github.com>

* [TTS] Read audio as int32 to avoid flac read errors (#7477)

* [TTS] Read audio as int32 to avoid flac read errors

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Add comment about read failures

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>

* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS (#7409)

* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS
* Train 'AISHELL-3' dataset with multi-speakers

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update get_data.py

update copyright header

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* Update get_data.py

added a disclaimer

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add new configuration file for AISHELL3 with multispeaker of fastpitch

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* dllogger - log on rank 0 only (#7513)

Signed-off-by: Stas Bekman <stas00@users.noreply.github.com>

* Fix TTS FastPitch tutorial (#7494) (#7516)

* Fix

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

* Fix get_dist() tensor dimension (#7506) (#7515)

Signed-off-by: Jocelyn Huang <jocelynh@nvidia.com>
Co-authored-by: Jocelyn <jocelynh@nvidia.com>

* bugfix: specify trainer.strategy=auto when devices=1 (#7509) (#7512)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>

* fix (#7511)

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* [TTS] Fix FastPitch data prep tutorial (#7524)

Signed-off-by: Ryan <rlangman@nvidia.com>

* add italian tokenization (#7486)

* add italian tokenization

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add more ipa lexicon it

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix error deletion

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* add test

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Replace None strategy with auto in tutorial notebooks (#7521) (#7527)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* unpin setuptools (#7534) (#7535)

Signed-off-by: fayejf <36722593+fayejf@users.noreply.github.com>
Co-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>

* remove auto generated examples (#7510)

* explicitly remove autogenerated examples for data parallel evaluation

Signed-off-by: arendu <adithyare@nvidia.com>

* mark autogenrated and remove it for test

Signed-off-by: arendu <adithyare@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: arendu <adithyare@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Add the `strategy` argument to `MegatronGPTModel.generate()` (#7264)

It is passed as an explicit argument rather than through
`**strategy_args` so as to ensure someone cannot accidentally pass other
arguments that would end up being ignored.

It is a keyword-only argument to ensure that if in the future we want to
update the signature to `**strategy_args`, we can do it without breaking
code.

Signed-off-by: Olivier Delalleau <507137+odelalleau@users.noreply.github.com>

* Fix PTL2.0 related ASR bugs in r1.21.0: Val metrics logging, None dataloader issue (#7531) (#7533)

* fix none dataloader issue ptl2



* ptl2.0 logging fixes for rnnt_models



---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Co-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>

* gpus -> devices (#7542) (#7545)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>

* Update FFMPEG version to fix issue with torchaudio (#7551) (#7553)

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>

* PEFT GPT & T5 Refactor (#7308)

* initial implementation of add_adapters API

* correct type hint

* Add config in add_adapters for save and load (@author bobchen)

* Remove AdapterConfig to avoid import error

* Add AdaterConfig back and move adaptermixin to sft model

* Add NLPSaveRestoreConnector as default in NLPModel.restore_from

* Add restore_from_nemo_with_adapter and test script

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* rename t5 file and classes to be consistent with GPT

* add t5 sft dataset

* add support for single-file format with T5SFTDataset

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Various small changes to make T5 SFT work like GPT SFT

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add adapter evaluation test script

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add MultiAdaterConfig for ia3 and fix builder issue

* Make ptuning for T5SFTModel work using mixin

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add IA3_Adapter for AdapterName

* Add adapter name for ptuning and attention adapter

* Make test script GPT/T5 agnostic

* Add layer selection feature

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Integrate adapter name and config

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update gpt peft tuning script to new API

* add t5 peft tuning script with new API

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix IA3 layer selection issue

* Override state_dict on SFT model instead of mixin

* Add load adapter by adapter config

* move peft config map away from example script

* auto get config from nemo adapter

* Move PEFTConfig to new file

* fix ckpt save/load for t5

* name change: add_adapters -> add_adapter

* variable name change

* update t5 script

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix t5 issues

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add weight tying

* update gpt tuning script

* PEFT-API proposal

* Fix according to comments

* update tuning scripts

* move merge_cfg_with to mixin class since it applies to both gpt and t5 and requires the model class for restore

* Add mcore_gpt support for NLPAdapterMixin

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix typo

* variable name change to distinguish ""peft"" and ""adapter""

* override `load_adapters` to support `add_adapter` name change

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update tuning and eval script for adapter save/load

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add Ptuning on first stage only

* add lora tutorial for review

* Fix layer selection for mcore

* add landing page

* fix resume training

Signed-off-by: jasonwan <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add mcore condition in sharded_state_dict to make sft work

* Update lora_tutorial.md

First edit of this file for PEFT documentation for NeMO

Signed-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>

* rename Adapter to AttentionAdapter to avoid confusion in doc

* Change load_adapters to load .nemo

* add quick start guide

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add load_adapters with .ckpt

* Remove setup_complete changes in load_adapters

* update landing page

* remove typo

* Updated quick_start.md per Chen Cui

Signed-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>

* Add inference config merger and tutorial

* Add doc string for NLPAdapterModelMixin and deprecated warning on MegatronGPTPEFTModel

* add supported_methods.md and update other documentations

* Update supported_methods.md

minor updates.

Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>

* Update landing_page.md

minor update.

Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>

* Modify doc string for NLPAdapterModelMixin

* Add doc string add_adapters in NLPAdapterModelMixin

* rename canonical adapters

* remove mcore hard dependency

* [PATCH] move microbatch calculator to nemo from apex

* remove apex dependency in gpt and t5 sft models

* remove apex dependency in gpt model

* render doc strings

* fix

* Add missing virtual_tokens on ptuning

* fix docstrings

* update gpt-style model coverage in docs

* update docstring

* Remove pdb

* add lightning_fabric to make docstring rendering work

* Add Ptuning missing key

* try docstring rendering

* Fix ptuning issue

* update gpt t5 peft tuning and eval scripts

* typos

* update eval config

* fix bug relating to apex dependency removal

* typo

* make predict step behave the same as test step

* make lora tutorial work in notebook

* cosmetics

* update yaml scripts

* mcore_gpt attribute optional

* typo

* update eval scripts and fix T5 eval bugs

* add NLPDDPStrategyNotebook and trainer builder logic to use it

* update lora notebook to use new trainer builder

* fix microbatch calculator bug for inference after training

* Convert markdown files to RST and incorporate with doc

* typo

* revise language

* remove extra cell

* remove unnecessary inheritance

* remove old tests

* move layer selection default so logging messages make sense

* remove `save_adapters` as adapter weights are saved automatically during training

* initialize weights from a checkpoint instead of randomly

* multiple fields can form a context (#7147)

* list of context fields and flexible prompt template

Signed-off-by: arendu <adithya.r@gmail.com>

* list of fields for context

Signed-off-by: arendu <adithya.r@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Add multiple truncation fields and middle truncation

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Compatible to old ckpt

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix tokenize detokenize issue

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Remove detokenization, add truncation augmentation

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Resolve comments

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Remove unused import

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* revert eos

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Add tokenizer space_sensitive attribute

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix error

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Fix erorr and use re

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Change assert logic

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Follow adi suggestion

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Remove merge function

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add example and comment

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Remove context_key and add comment

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Remove random truncation

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix template none

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: arendu <adithya.r@gmail.com>
Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Signed-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

* revert config changes

* remove accidental breakpoint

* support TP>1 loading

* infer adapter type from checkpoint in during eval

* breakup add adapter

* enable interpolation of train_ds and validation_ds

* update metric calc script to conform to single-file eval format

* remove extraneous print

* update lora notebook for updated merge_inference_cfg

* Update nlp_adapter_mixins.py

variable name change

Signed-off-by: Chen Cui <chcui@nvidia.com>

* turn off grad scaler for PP to match old scripts

* remove PEFTSaveRestoreConnector since functionality all covered by the new mixin class

* remove resume_from_checkpoint check since covered in #7335

* revert changes made in eval config interpolation

* more interpolation

* typo

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* remove dup line

Signed-off-by: Chen Cui <chcui@nvidia.com>

* code style warnings

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix config mistake

Signed-off-by: Chen Cui <chcui@nvidia.com>

* add copyright header

Signed-off-by: Chen Cui <chcui@nvidia.com>

* fix code check warnings

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* revert changes to remove apex dependency (mixed apex+nemo microbatch calculator broke some CI tests)

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add more deprecation notices

Signed-off-by: Chen Cui <chcui@nvidia.com>

* update deprecation notices

Signed-off-by: Chen Cui <chcui@nvidia.com>

* update deprecation notices

Signed-off-by: Chen Cui <chcui@nvidia.com>

* consolidate peft and sft scripts

Signed-off-by: Chen Cui <chcui@nvidia.com>

* update CI tests

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* notebook branch points to main to prepare for merge

Signed-off-by: Chen Cui <chcui@nvidia.com>

* fix gpt and t5 validation with any metric other than loss

Signed-off-by: Chen Cui <chcui@nvidia.com>

* support pre-extracted checkpoints

Signed-off-by: Chen Cui <chcui@nvidia.com>

---------

Signed-off-by: jasonwan <jasonwan@nvidia.com>
Signed-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>
Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>
Signed-off-by: arendu <adithya.r@gmail.com>
Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Signed-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>
Signed-off-by: Chen Cui <chcui@nvidia.com>
Co-authored-by: Chen Cui <chcui@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Marc Romeyn <marcromeyn@gmail.com>
Co-authored-by: jasonwan <jasonwan@nvidia.com>
Co-authored-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>
Co-authored-by: Adi Renduchintala <adithyare@nvidia.com>
Co-authored-by: Yuanzhe Dong <yudong@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

* fix a typo (#7496)

Signed-off-by: BestJuly <chntaoli@163.com>

* [TTS] remove curly braces from ${BRANCH} in jupyer notebook cell. (#7554) (#7560)

* remove curly braces.
* remove installation of pynini.
---------

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>

* add youtube embed url (#7570)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>

* Remap speakers to continuous range of speaker_id for dataset AISHELL3 (#7536)

* Remap speakers to continuous range of speaker_id for dataset AISHELL3
* Add new key/value pair to record raw speaker for AISHELL3 dataset

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* fix validation_step_outputs initialization for multi-dataloader (#7546) (#7572)

* added correct validation_step_outputs initialization for mutli-dataloader



* changed kernel for display



* Update logic for validation and test step outputs



* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* revert multidataloader changes in multilang ASR notebook



---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Append output of val step to self.validation_step_outputs (#7530) (#7532)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* [TTS] fixed trainer's accelerator and strategy. (#7569) (#7574)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>

* Append val/test output to instance variable in EncDecSpeakerLabelModel (#7562) (#7573)

* Append val/test output to the instance variable in EncDecSpeakerLabelModel



* Handle test case in evaluation_step



* Replace type with isinstance



---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* Fix CustomProgressBar for resume (#7427) (#7522)

* Fix CustomProgress Bar for resume and multiple epochs



* Edit num_training_batches



* Use max_steps as total for progress bar for resume



* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* fix typos in nfa and speech enhancement tutorials (#7580) (#7583)

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>
Co-authored-by: Elena Rastorgueva <80532067+erastorgueva-nv@users.noreply.github.com>

* Add strategy as ddp_find_unused_parameters_true for glue_benchmark.py (#7454) (#7461)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* update strategy (#7577) (#7578)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>

* Fix typos (#7581)

* Change hifigan finetune strategy to ddp_find_unused_parameters_true (#7579) (#7584)

* Change strategy to auto



---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

* [BugFix] Add missing quotes for auto strategy in tutorial notebooks (#7541) (#7548)

* Add missing quotes for auto strategy



* Revert trainer.gpus to trainer.devices in Self_Supervised_Pre_Training.ipynb



---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Signed-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* add build os key (#7596) (#7599)

* add build os key



* add tools



* update to stable version



---------

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>

* StarCoder SFT test + bump PyT NGC image to 23.09 (#7540)

* Add SFT StarCoder test

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Remove _modify_config call as it is covered in load_from_nemo just below

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Test with pyt:23.09 container

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

---------

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* defaults changed (#7600)

* defaults changed

Signed-off-by: arendu <adithyare@nvidia.com>

* typo

Signed-off-by: arendu <adithyare@nvidia.com>

* update

Signed-off-by: arendu <adithyare@nvidia.com>

---------

Signed-off-by: arendu <adithyare@nvidia.com>

* add ItalianPhonemesTokenizer (#7587)

* add ItalianPhonemesTokenizer

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix Italian phonemes

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add test

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

---------

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* best ckpt fix (#7564) (#7588)

Signed-off-by: dimapihtar <dpihtar@gmail.com>
Co-authored-by: Dmytro Pykhtar <37850217+dimapihtar@users.noreply.github.com>

* Add files via upload (#7598)

specifies the branch

Signed-off-by: George <37293288+Jorjeous@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* Fix validation in G2PModel and ThutmoseTaggerModel (#7597) (#7606)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain (#7576) (#7586)

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain
* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Safeguard nemo_text_processing installation on ARM (#7485)

* safeguard nemo_text_processing installing

Signed-off-by: Jason <jasoli@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update check

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Bound transformers version in requirements (#7620)

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* fix llama2 70b lora tuning bug (#7622)

* fix llama2 70b lora tuning bug

Signed-off-by: Chen Cui <chcui@nvidia.com>

* Update peft_config.py

brackets

Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>

---------

Signed-off-by: Chen Cui <chcui@nvidia.com>
Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>
Co-authored-by: Adi Renduchintala <adithyare@nvidia.com>

* Fix import error no module name model_utils (#7629)

Signed-off-by: Mehadi Hasan Menon <mehadihasan80@gmail.com>

* add fc large ls models (#7641)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao Koluguri <nithinraok>

* bugfix: trainer.gpus, trainer.strategy, trainer.accelerator (#7621) (#7642)

* [TTS] bugfix for Tacotron2 tutorial due to PTL 2.0
* trainer.gpus -> trainer.devices
* fixed related tutorial bugs
---------
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* fix ssl models ptl monitor val through logging (#7608) (#7614)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* Fix metrics for SE tutorial (#7604) (#7612)

Signed-off-by: Ante Jukić <ajukic@nvidia.com>
Co-authored-by: anteju <108555623+anteju@users.noreply.github.com>

* Add ddp_find_unused_parameters=True and change accelerator to auto (#7623) (#7644)

* Add ddp_find_unused_parameters=True and change acclerator to auto



* Add ddp_find_unused_parameters True for normalization_as_tagging_train.py



---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* Fix py3.11 dataclasses issue  (#7616)

* Fix py3.11 dataclasses issue  (#7582)

* Update ASR configs to support Python 3.11

Signed-off-by: smajumdar <titu1994@gmail.com>

* Update TTS configs to support Python 3.11

Signed-off-by: smajumdar <titu1994@gmail.com>

* Guard MeCab and Ipadic

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix remaining ASR dataclasses

Signed-off-by: smajumdar <titu1994@gmail.com>

* Fix remaining ASR dataclasses

Signed-off-by: smajumdar <titu1994@gmail.com>

* Fix scripts

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Update name to ConfidenceMethodConfig

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain (#7576) (#7586)

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain
* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Safeguard nemo_text_processing installation on ARM (#7485)

* safeguard nemo_text_processing installing

Signed-off-by: Jason <jasoli@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update check

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Fix changes to confidence measure

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: smajumdar <titu1994@gmail.com>
Signed-off-by: Sangkug Lym <slym@nvidia.com>
Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: github-actions[bot] <41898282+github-actions[bot]@users.noreply.github.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Jason <jasoli@nvidia.com>

* [Stable Diffusion/ControlNet] Enable O2 training for SD and Fix ControlNet CI failure

* Mingyuanm/dreambooth fix

* Fix NeMo CI Infer Issue

* DreamFusion

* Move neva export changes

* Add Imagen Synthetic Dataloader

* Add VITWrapper and export stuff to wrapper

* Update neva with megatron-core support

* Fix issues with Dockerfile (#7650) (#7652)

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>

* [ASR] RNN-T greedy decoding max_frames fix for alignment and confidence (#7635)

* decoding and test fix

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* [ASR] Fix type error in jasper (#7636) (#7653)

Signed-off-by: Ryan <rlangman@nvidia.com>
Co-authored-by: Ryan Langman <rlangman@nvidia.com>

* [TTS] Add STFT and SI-SDR loss to audio codec recipe (#7468)

* [TTS] Add STFT and SI-SDR loss to audio codec recipe

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix STFT resolution

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix training metric logging

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Add docstring to mel and stft losses

Signed-off-by: Ryan <rlangman@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Ryan <rlangman@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Create per.py (#7538)

* Move model precision copy (#7336)

* move cfg precision set to megatron base model

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* remove copy from other models

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* modify attribute not arg

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* fix gpt model test for ptl 2.0

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* rename function and add docstring

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* replace precision to dtype conditionals with func call

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* unnecessary function and cfg reset

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* set default value

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* fix precision lookup in a few more places

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* rename mapping function

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* ununsed import

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* save torch datatype to model

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* set weights precision wrt amp o2

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* Revert ""set weights precision wrt amp o2""

This reverts commit 313a4bfe5eb69d771a6d2433898c0685836aef5c.

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* revert half precision at inference attempt

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* move autocast dtype to base model

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* move params dtype to base model, enable fp16 O2 inf

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* unused imports

Signed-off-by: Maanu Grover <maanug@nvidia.com>

---------

Signed-off-by: Maanu Grover <maanug@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix PEFT checkpoint loading (#7388)

* Fix PEFT checkpoint loading

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Jason Wang <jasonwan@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Use distributed optimizer support for multiple dtypes (#7359)

* Update distopt wrapper with multiple dtype support

Remove manual handling of separate FP32 optimizer.

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Use distopt support for contiguous buffers with multiple dtypes

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Fix typo

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Separate distopt buckets for first GPT layer and non-overlapped params

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Add distopt logic for int dtypes

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Update Apex commit

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Remove unused variables

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Update Apex commit in README and Jenkensfile

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Debug Dockerfile and Jenkinsfile

Signed-off-by: Tim Moon <tmoon@nvidia.com>

---------

Signed-off-by: Tim Moon <tmoon@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* minor fix for llama ckpt conversion script (#7387)

* minor fix for llama ckpt conversion script

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* Update Jenkinsfile

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* remove fast_swiglu configuration

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

---------

Signed-off-by: Jason Wang <jasonwan@nvidia.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix wrong calling of librosa.get_duration() in notebook (#7376)

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [PATCH] PEFT import mcore (#7393)

* [PATCH] PEFT import mcore

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Jason Wang <jasonwan@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Create per.py

Script for calculation Punctuation Error Rate and related rates (correct rate, deletions rate, etc.)

Signed-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [TTS] Added a callback for logging initial data (#7384)

Signed-off-by: Ante Jukić <ajukic@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update Core Commit (#7402)

* Update Core Commit

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* update commit

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

---------

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Use cfg attribute in bert (#7394)

* use cfg attribute instead of arg

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* use torch_dtype in place of cfg.precision

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* move precision copy before super constructor

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* use trainer arg

Signed-off-by: Maanu Grover <maanug@nvidia.com>

---------

Signed-off-by: Maanu Grover <maanug@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add support for bias conversion in Swiglu models (#7386)

* Add support for bias conversion in Swiglu models

Signed-off-by: smajumdar <titu1994@gmail.com>

* Add support for auto extracting tokenizer model

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add support for auto extracting tokenizer model

Signed-off-by: smajumdar <titu1994@gmail.com>

* Fix issue with missing tokenizer

Signed-off-by: smajumdar <titu1994@gmail.com>

* Refactor

Signed-off-by: smajumdar <titu1994@gmail.com>

* Refactor

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update save_to and restore_from for dist checkpointing (#7343)

* add dist ckpt to save to, in progress

Signed-off-by: eharper <eharper@nvidia.com>

* move dist ckpt

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* clean up

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update restore from, need to figure out how to initialize distributed

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* launch distrib if needed when restoring dist ckpt

Signed-off-by: eharper <eharper@nvidia.com>

* when using mcore we can change tp pp on the fly

Signed-off-by: eharper <eharper@nvidia.com>

* add load_from_checkpoint support for dist ckpt

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update llama convert script to save dist .nemo

Signed-off-by: eharper <eharper@nvidia.com>

* fix load dist ckpt

Signed-off-by: jasonwan <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* setup TE TP groups if needed

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* setup te tp groups if needed

Signed-off-by: eharper <eharper@nvidia.com>

* remove import

Signed-off-by: eharper <eharper@nvidia.com>

---------

Signed-off-by: eharper <eharper@nvidia.com>
Signed-off-by: jasonwan <jasonwan@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: jasonwan <jasonwan@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* fix forward for with mcore=false (#7403)

Signed-off-by: Jimmy Zhang <jiemingz@nvidia.com>
Co-authored-by: Jimmy Zhang <jiemingz@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix logging to remove 's/it' from progress bar in Megatron models and add train_step_timing (#7374)

* Add CustomProgressBar class to exp_manager and trainer callbacks

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix the progress bar to reflect total microbatch cnt

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* Modify CustomProgressBar class

1) Modify CustomProgressBar class to update progress bar per global_step instead of per microbatch
2) Add the callback to other megatron training/finetuning files that are not using MegatronTrainerBuilder

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* Add CustomProgressBar callback to tuning files

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Set Activation Checkpointing Defaults (#7404)

* Set Activation Checkpointing Defaults

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* check for None

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* make loss mask default to false (#7407)

Signed-off-by: eharper <eharper@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add dummy userbuffer config files (#7408)

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* add missing ubconf files (#7412)

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* New tutorial on Speech Data Explorer (#7405)

* Added Google Colab based tutorial on Speech Data Explorer

Signed-off-by: George Zelenfroynd <gzelenfroind@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update ptl training ckpt conversion script to work with dist ckpt (#7416)

* update ptl convert script

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* don't break legacy

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: eharper <eharper@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Allow disabling sanity checking when num_sanity_val_steps=0 (#7413)

* Allow disabling sanity checking when num_sanity_val_steps=0

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* Update num_sanity_val_steps to be a multiple of num_microbatches

Signed-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Signed-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add comprehensive error messages (#7261)

Signed-off-by: Anton Peganov <apeganov@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* check NEMO_PATH (#7418)

Signed-off-by: Nikolay Karpov <karpnv@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* layer selection for ia3 (#7417)

* layer selection for ia3

Signed-off-by: arendu <adithyare@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: arendu <adithyare@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix missing pip package 'einops' (#7397)

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix failure of pyaudio in Google Colab (#7396)

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update README.md: output_path --> output_manifest_filepath (#7442)

Signed-off-by: Samuele Cornell <cornellsamuele@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add rope dynamic linear scaling (#7437)

* Add dynamic linear scaling

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix None dataloader issue in PTL2.0 (#7455)

* Fix None dataloader issue in PTL2.0

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* updating values of self._validation_dl and self._test_dl as well

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* updating values of self._validation_dl and self._test_dl as well

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [ASR] Confidence measure -> method renames (#7434)

* measure -> method

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add steps for document of getting dataset 'SF Bilingual Speech' (#7378)

* Add steps for document of getting dataset 'SF Bilingual Speech'

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update datasets.rst

added a link from a tutorial demonstrating detailed data prep steps.

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* RNN-T confidence and alignment bugfix (#7381)

* new frame_confidence and alignments lists are now always created after the while loop

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* tests added

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix resume from checkpoint in exp_manager (#7424) (#7426)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix checking of cuda/cpu device for inputs of Decoder (#7444)

* Fix checking of cuda/cpu device for inputs of Decoder

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update tacotron2.py

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: Jason <jasoli@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix failure of ljspeech's get_data.py (#7430)

* Fix failure of ljspeech's get_data.py

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [TTS] Fix audio codec type checks (#7373)

* [TTS] Fix audio codec type checks

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix audio codec tests

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [TTS] Add dataset to path of logged artifacts (#7462)

* [TTS] Add dataset to path of logged artifacts

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Revert axis name back to Audio Frames

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix sft dataset truncation (#7464)

* Add fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-of…"
github.com/modelscope/modelscope,modelscope/models/cv/anydoor/ldm/modules/encoders/modules.py,2023-12-26T08:59:47Z,update ckpt to general_v0.1 (#696)
github.com/modelscope/modelscope,modelscope/models/cv/anydoor/ldm/modules/encoders/modules.py,2023-12-25T11:01:50Z,"Add AnyDoor support (#688)

* support anydoor

* add dinov2

* fix bug

* convert rgb

* update anydoor_pipeline and add docstr"
github.com/mlfoundations/open_flamingo,open_flamingo/eval/rices.py,2023-08-21T20:09:32Z,Remove hardcoded path in rices.py
github.com/mlfoundations/open_flamingo,open_flamingo/eval/rices.py,2023-08-02T19:54:36Z,"Evaluation updates: add RICES + prompt ensembling (#220)

* added rices for picking demos for captioning and vqa

* add caching

* script to cache RICES features; RICES DDP

* RICES for Hatefulmemes

* make RICES a command line argument

* remove DDP

* refactor classification

* add prompt ensembling

* enforce correct class ordering

* refactor cached classification

* fix classification caching

* customize rices encoder

* scripts for vqav2 test-dev json; code cleanup

* move cache script to scripts/

* add vizwiz testdev helper to script

* fixed seeding in dist eval among other things

* add vizwiz test questions to data

* added rices instructions and fixed fill script

* applied linter

---------

Co-authored-by: Anas Awadalla <anasa2@uw.edu>"
github.com/mlfoundations/open_flamingo,open_flamingo/eval/rices.py,2023-07-01T16:51:14Z,Fix accident where I pushed RICES code to main (#212)
github.com/mlfoundations/open_flamingo,open_flamingo/eval/rices.py,2023-07-01T16:43:31Z,added rices for captioning and vqa
github.com/lllyasviel/stable-diffusion-webui-forge,modules/sd_disable_initialization.py,2023-12-06T00:00:48Z,change state dict comparison to ref compare
github.com/lllyasviel/stable-diffusion-webui-forge,modules/sd_disable_initialization.py,2023-08-16T09:11:01Z,send weights to target device instead of CPU memory
github.com/lllyasviel/stable-diffusion-webui-forge,modules/sd_disable_initialization.py,2023-08-16T06:55:35Z,RAM optimization round 2
github.com/lllyasviel/stable-diffusion-webui-forge,modules/sd_disable_initialization.py,2023-07-24T19:08:08Z,Use less RAM when creating models
github.com/lllyasviel/stable-diffusion-webui-forge,modules/sd_disable_initialization.py,2023-05-10T04:52:45Z,autofixes from ruff
github.com/lllyasviel/stable-diffusion-webui-forge,modules/sd_disable_initialization.py,2023-02-05T08:21:00Z,make it possible to load SD1 checkpoints without CLIP
github.com/lllyasviel/stable-diffusion-webui-forge,modules/sd_disable_initialization.py,2023-01-22T05:20:48Z,fix missing field for aesthetic embedding extension
github.com/lllyasviel/stable-diffusion-webui-forge,modules/sd_disable_initialization.py,2023-01-11T15:54:13Z,"fix for an error caused by skipping initialization, for realsies this time: TypeError: expected str, bytes or os.PathLike object, not NoneType"
github.com/lllyasviel/stable-diffusion-webui-forge,modules/sd_disable_initialization.py,2023-01-10T14:46:59Z,"add support for transformers==4.25.1
add fallback for when quick model creation fails"
github.com/lllyasviel/stable-diffusion-webui-forge,modules/sd_disable_initialization.py,2023-01-10T13:51:04Z,"add more stuff to ignore when creating model from config
prevent .vae.safetensors files from being listed as stable diffusion models"
github.com/lllyasviel/stable-diffusion-webui-forge,modules/sd_disable_initialization.py,2023-01-10T11:08:29Z,disable torch weight initialization and CLIP downloading/reading checkpoint to speedup creating sd model from config
github.com/NVIDIA/NeMo,examples/multimodal/vision_language_foundation/clip/convert_external_clip_to_nemo.py,2024-01-11T06:32:19Z,"Add All Multimodal Source Code Part 2: Text to image, x to nerf (#7970)

* Update README.md: output_path --> output_manifest_filepath (#7442)

Signed-off-by: Samuele Cornell <cornellsamuele@gmail.com>

* Updating FlashAttention API to match FlashAttentionV2

* Multiple fixes for mm

* Fix CI inductor issue and update to torch compile

* Remove suppress error

* Fix when conversion config uses fp16 and it complains about precision plugin

* Fixing FAv2 API usage

* Initial release of content filtering model

* Added synthetic dataloader for precached and online mode

* Mingyuanm/dreambooth opt

* Add llama2 support in neva training

* Fix sampler length

* Fix all precision issues in nemo multimodal

* Add rope dynamic linear scaling (#7437)

* Add dynamic linear scaling

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>

* Fix None dataloader issue in PTL2.0 (#7455)

* Fix None dataloader issue in PTL2.0

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* updating values of self._validation_dl and self._test_dl as well

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* updating values of self._validation_dl and self._test_dl as well

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* [ASR] Confidence measure -> method renames (#7434)

* measure -> method

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Add steps for document of getting dataset 'SF Bilingual Speech' (#7378)

* Add steps for document of getting dataset 'SF Bilingual Speech'

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update datasets.rst

added a link from a tutorial demonstrating detailed data prep steps.

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* RNN-T confidence and alignment bugfix (#7381)

* new frame_confidence and alignments lists are now always created after the while loop

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* tests added

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* Fix resume from checkpoint in exp_manager (#7424) (#7426)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: Eric Harper <complex451@gmail.com>

* Fix checking of cuda/cpu device for inputs of Decoder (#7444)

* Fix checking of cuda/cpu device for inputs of Decoder

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update tacotron2.py

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: Jason <jasoli@nvidia.com>

* Fix failure of ljspeech's get_data.py (#7430)

* Fix failure of ljspeech's get_data.py

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* [TTS] Fix audio codec type checks (#7373)

* [TTS] Fix audio codec type checks

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix audio codec tests

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Add dataset to path of logged artifacts (#7462)

* [TTS] Add dataset to path of logged artifacts

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Revert axis name back to Audio Frames

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>

* Fix sft dataset truncation (#7464)

* Add fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Automatic Lip Reading Recognition (ALR) - ASR/CV (Visual ASR) (#7330)

* striding_conv1d_k5 and dw_striding_conv1d_k5 subsampling

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* transpose conv1d inputs

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* Update subsampling.py

change striding_conv1d_k5 to striding_conv1d

Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>

* cv branch

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* video manifest

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* add collection classes

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add test_step_outputs

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* correct manifest bug when having only audio or only videos

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* correct manifest bug when having only audio or only videos

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* clean references

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* freeze unfreeze transcribe cv models

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* correct manifest get_full_path bug

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* update for PR

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* guard torchvision

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Update nemo/collections/cv/data/video_to_text_dataset.py

Co-authored-by: Igor Gitman <igor.a.gitman@gmail.com>
Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>

* _video_speech_collate_fn in cv/data/video_to_text.py

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* add self.out = None to asr subsampling

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* Update nemo/collections/cv/data/video_to_text_dataset.py

Co-authored-by: Igor Gitman <igor.a.gitman@gmail.com>
Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>

* cv -> multimodal/speech_cv branch

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: mburchi <maxime.burchi@gmail.com>
Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Igor Gitman <igor.a.gitman@gmail.com>

* HF StarCoder to NeMo conversion script (#7421)

* Script to convert HF StarCoder checkpoint to NeMo

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* StarCoder conversion test

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Fix test

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Catch up with save_to changes

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Don't abbreviate args for clarity

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Configurable precision: BF16 vs FP32

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* fix bug when loading dist ckpt in peft (#7452)

Signed-off-by: Hongbin Liu <hongbinl@nvidia.com>
Co-authored-by: Hongbin Liu <hongbinl@nvidia.com>

* Fix adding positional embeddings in-place in transformer module (#7440)

Signed-off-by: Tamerlan Tabolov <tktabolov@gmail.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

* Fix (#7478)

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* add sleep (#7498) (#7499)

* add sleep



* add sleep onto config instead



* add comment



---------

Signed-off-by: Gerald Shen <geshen@nvidia.com>
Co-authored-by: Gerald Shen <119401249+gshennvm@users.noreply.github.com>

* Fix exp manager check for sleep (#7503) (#7504)

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>

* bugfix: trainer.accelerator=auto from None. (#7492) (#7493)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>

* [doc] fix broken link (#7481)

Signed-off-by: Stas Bekman <stas00@users.noreply.github.com>

* [TTS] Read audio as int32 to avoid flac read errors (#7477)

* [TTS] Read audio as int32 to avoid flac read errors

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Add comment about read failures

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>

* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS (#7409)

* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS
* Train 'AISHELL-3' dataset with multi-speakers

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update get_data.py

update copyright header

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* Update get_data.py

added a disclaimer

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add new configuration file for AISHELL3 with multispeaker of fastpitch

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* dllogger - log on rank 0 only (#7513)

Signed-off-by: Stas Bekman <stas00@users.noreply.github.com>

* Fix TTS FastPitch tutorial (#7494) (#7516)

* Fix

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

* Fix get_dist() tensor dimension (#7506) (#7515)

Signed-off-by: Jocelyn Huang <jocelynh@nvidia.com>
Co-authored-by: Jocelyn <jocelynh@nvidia.com>

* bugfix: specify trainer.strategy=auto when devices=1 (#7509) (#7512)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>

* fix (#7511)

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* [TTS] Fix FastPitch data prep tutorial (#7524)

Signed-off-by: Ryan <rlangman@nvidia.com>

* add italian tokenization (#7486)

* add italian tokenization

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add more ipa lexicon it

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix error deletion

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* add test

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Replace None strategy with auto in tutorial notebooks (#7521) (#7527)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* unpin setuptools (#7534) (#7535)

Signed-off-by: fayejf <36722593+fayejf@users.noreply.github.com>
Co-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>

* remove auto generated examples (#7510)

* explicitly remove autogenerated examples for data parallel evaluation

Signed-off-by: arendu <adithyare@nvidia.com>

* mark autogenrated and remove it for test

Signed-off-by: arendu <adithyare@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: arendu <adithyare@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Add the `strategy` argument to `MegatronGPTModel.generate()` (#7264)

It is passed as an explicit argument rather than through
`**strategy_args` so as to ensure someone cannot accidentally pass other
arguments that would end up being ignored.

It is a keyword-only argument to ensure that if in the future we want to
update the signature to `**strategy_args`, we can do it without breaking
code.

Signed-off-by: Olivier Delalleau <507137+odelalleau@users.noreply.github.com>

* Fix PTL2.0 related ASR bugs in r1.21.0: Val metrics logging, None dataloader issue (#7531) (#7533)

* fix none dataloader issue ptl2



* ptl2.0 logging fixes for rnnt_models



---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Co-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>

* gpus -> devices (#7542) (#7545)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>

* Update FFMPEG version to fix issue with torchaudio (#7551) (#7553)

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>

* PEFT GPT & T5 Refactor (#7308)

* initial implementation of add_adapters API

* correct type hint

* Add config in add_adapters for save and load (@author bobchen)

* Remove AdapterConfig to avoid import error

* Add AdaterConfig back and move adaptermixin to sft model

* Add NLPSaveRestoreConnector as default in NLPModel.restore_from

* Add restore_from_nemo_with_adapter and test script

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* rename t5 file and classes to be consistent with GPT

* add t5 sft dataset

* add support for single-file format with T5SFTDataset

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Various small changes to make T5 SFT work like GPT SFT

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add adapter evaluation test script

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add MultiAdaterConfig for ia3 and fix builder issue

* Make ptuning for T5SFTModel work using mixin

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add IA3_Adapter for AdapterName

* Add adapter name for ptuning and attention adapter

* Make test script GPT/T5 agnostic

* Add layer selection feature

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Integrate adapter name and config

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update gpt peft tuning script to new API

* add t5 peft tuning script with new API

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix IA3 layer selection issue

* Override state_dict on SFT model instead of mixin

* Add load adapter by adapter config

* move peft config map away from example script

* auto get config from nemo adapter

* Move PEFTConfig to new file

* fix ckpt save/load for t5

* name change: add_adapters -> add_adapter

* variable name change

* update t5 script

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix t5 issues

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add weight tying

* update gpt tuning script

* PEFT-API proposal

* Fix according to comments

* update tuning scripts

* move merge_cfg_with to mixin class since it applies to both gpt and t5 and requires the model class for restore

* Add mcore_gpt support for NLPAdapterMixin

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix typo

* variable name change to distinguish ""peft"" and ""adapter""

* override `load_adapters` to support `add_adapter` name change

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update tuning and eval script for adapter save/load

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add Ptuning on first stage only

* add lora tutorial for review

* Fix layer selection for mcore

* add landing page

* fix resume training

Signed-off-by: jasonwan <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add mcore condition in sharded_state_dict to make sft work

* Update lora_tutorial.md

First edit of this file for PEFT documentation for NeMO

Signed-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>

* rename Adapter to AttentionAdapter to avoid confusion in doc

* Change load_adapters to load .nemo

* add quick start guide

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add load_adapters with .ckpt

* Remove setup_complete changes in load_adapters

* update landing page

* remove typo

* Updated quick_start.md per Chen Cui

Signed-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>

* Add inference config merger and tutorial

* Add doc string for NLPAdapterModelMixin and deprecated warning on MegatronGPTPEFTModel

* add supported_methods.md and update other documentations

* Update supported_methods.md

minor updates.

Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>

* Update landing_page.md

minor update.

Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>

* Modify doc string for NLPAdapterModelMixin

* Add doc string add_adapters in NLPAdapterModelMixin

* rename canonical adapters

* remove mcore hard dependency

* [PATCH] move microbatch calculator to nemo from apex

* remove apex dependency in gpt and t5 sft models

* remove apex dependency in gpt model

* render doc strings

* fix

* Add missing virtual_tokens on ptuning

* fix docstrings

* update gpt-style model coverage in docs

* update docstring

* Remove pdb

* add lightning_fabric to make docstring rendering work

* Add Ptuning missing key

* try docstring rendering

* Fix ptuning issue

* update gpt t5 peft tuning and eval scripts

* typos

* update eval config

* fix bug relating to apex dependency removal

* typo

* make predict step behave the same as test step

* make lora tutorial work in notebook

* cosmetics

* update yaml scripts

* mcore_gpt attribute optional

* typo

* update eval scripts and fix T5 eval bugs

* add NLPDDPStrategyNotebook and trainer builder logic to use it

* update lora notebook to use new trainer builder

* fix microbatch calculator bug for inference after training

* Convert markdown files to RST and incorporate with doc

* typo

* revise language

* remove extra cell

* remove unnecessary inheritance

* remove old tests

* move layer selection default so logging messages make sense

* remove `save_adapters` as adapter weights are saved automatically during training

* initialize weights from a checkpoint instead of randomly

* multiple fields can form a context (#7147)

* list of context fields and flexible prompt template

Signed-off-by: arendu <adithya.r@gmail.com>

* list of fields for context

Signed-off-by: arendu <adithya.r@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Add multiple truncation fields and middle truncation

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Compatible to old ckpt

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix tokenize detokenize issue

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Remove detokenization, add truncation augmentation

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Resolve comments

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Remove unused import

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* revert eos

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Add tokenizer space_sensitive attribute

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix error

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Fix erorr and use re

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Change assert logic

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Follow adi suggestion

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Remove merge function

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add example and comment

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Remove context_key and add comment

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Remove random truncation

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix template none

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: arendu <adithya.r@gmail.com>
Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Signed-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

* revert config changes

* remove accidental breakpoint

* support TP>1 loading

* infer adapter type from checkpoint in during eval

* breakup add adapter

* enable interpolation of train_ds and validation_ds

* update metric calc script to conform to single-file eval format

* remove extraneous print

* update lora notebook for updated merge_inference_cfg

* Update nlp_adapter_mixins.py

variable name change

Signed-off-by: Chen Cui <chcui@nvidia.com>

* turn off grad scaler for PP to match old scripts

* remove PEFTSaveRestoreConnector since functionality all covered by the new mixin class

* remove resume_from_checkpoint check since covered in #7335

* revert changes made in eval config interpolation

* more interpolation

* typo

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* remove dup line

Signed-off-by: Chen Cui <chcui@nvidia.com>

* code style warnings

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix config mistake

Signed-off-by: Chen Cui <chcui@nvidia.com>

* add copyright header

Signed-off-by: Chen Cui <chcui@nvidia.com>

* fix code check warnings

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* revert changes to remove apex dependency (mixed apex+nemo microbatch calculator broke some CI tests)

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add more deprecation notices

Signed-off-by: Chen Cui <chcui@nvidia.com>

* update deprecation notices

Signed-off-by: Chen Cui <chcui@nvidia.com>

* update deprecation notices

Signed-off-by: Chen Cui <chcui@nvidia.com>

* consolidate peft and sft scripts

Signed-off-by: Chen Cui <chcui@nvidia.com>

* update CI tests

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* notebook branch points to main to prepare for merge

Signed-off-by: Chen Cui <chcui@nvidia.com>

* fix gpt and t5 validation with any metric other than loss

Signed-off-by: Chen Cui <chcui@nvidia.com>

* support pre-extracted checkpoints

Signed-off-by: Chen Cui <chcui@nvidia.com>

---------

Signed-off-by: jasonwan <jasonwan@nvidia.com>
Signed-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>
Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>
Signed-off-by: arendu <adithya.r@gmail.com>
Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Signed-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>
Signed-off-by: Chen Cui <chcui@nvidia.com>
Co-authored-by: Chen Cui <chcui@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Marc Romeyn <marcromeyn@gmail.com>
Co-authored-by: jasonwan <jasonwan@nvidia.com>
Co-authored-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>
Co-authored-by: Adi Renduchintala <adithyare@nvidia.com>
Co-authored-by: Yuanzhe Dong <yudong@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

* fix a typo (#7496)

Signed-off-by: BestJuly <chntaoli@163.com>

* [TTS] remove curly braces from ${BRANCH} in jupyer notebook cell. (#7554) (#7560)

* remove curly braces.
* remove installation of pynini.
---------

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>

* add youtube embed url (#7570)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>

* Remap speakers to continuous range of speaker_id for dataset AISHELL3 (#7536)

* Remap speakers to continuous range of speaker_id for dataset AISHELL3
* Add new key/value pair to record raw speaker for AISHELL3 dataset

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* fix validation_step_outputs initialization for multi-dataloader (#7546) (#7572)

* added correct validation_step_outputs initialization for mutli-dataloader



* changed kernel for display



* Update logic for validation and test step outputs



* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* revert multidataloader changes in multilang ASR notebook



---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Append output of val step to self.validation_step_outputs (#7530) (#7532)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* [TTS] fixed trainer's accelerator and strategy. (#7569) (#7574)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>

* Append val/test output to instance variable in EncDecSpeakerLabelModel (#7562) (#7573)

* Append val/test output to the instance variable in EncDecSpeakerLabelModel



* Handle test case in evaluation_step



* Replace type with isinstance



---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* Fix CustomProgressBar for resume (#7427) (#7522)

* Fix CustomProgress Bar for resume and multiple epochs



* Edit num_training_batches



* Use max_steps as total for progress bar for resume



* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* fix typos in nfa and speech enhancement tutorials (#7580) (#7583)

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>
Co-authored-by: Elena Rastorgueva <80532067+erastorgueva-nv@users.noreply.github.com>

* Add strategy as ddp_find_unused_parameters_true for glue_benchmark.py (#7454) (#7461)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* update strategy (#7577) (#7578)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>

* Fix typos (#7581)

* Change hifigan finetune strategy to ddp_find_unused_parameters_true (#7579) (#7584)

* Change strategy to auto



---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

* [BugFix] Add missing quotes for auto strategy in tutorial notebooks (#7541) (#7548)

* Add missing quotes for auto strategy



* Revert trainer.gpus to trainer.devices in Self_Supervised_Pre_Training.ipynb



---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Signed-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* add build os key (#7596) (#7599)

* add build os key



* add tools



* update to stable version



---------

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>

* StarCoder SFT test + bump PyT NGC image to 23.09 (#7540)

* Add SFT StarCoder test

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Remove _modify_config call as it is covered in load_from_nemo just below

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Test with pyt:23.09 container

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

---------

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* defaults changed (#7600)

* defaults changed

Signed-off-by: arendu <adithyare@nvidia.com>

* typo

Signed-off-by: arendu <adithyare@nvidia.com>

* update

Signed-off-by: arendu <adithyare@nvidia.com>

---------

Signed-off-by: arendu <adithyare@nvidia.com>

* add ItalianPhonemesTokenizer (#7587)

* add ItalianPhonemesTokenizer

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix Italian phonemes

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add test

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

---------

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* best ckpt fix (#7564) (#7588)

Signed-off-by: dimapihtar <dpihtar@gmail.com>
Co-authored-by: Dmytro Pykhtar <37850217+dimapihtar@users.noreply.github.com>

* Add files via upload (#7598)

specifies the branch

Signed-off-by: George <37293288+Jorjeous@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* Fix validation in G2PModel and ThutmoseTaggerModel (#7597) (#7606)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain (#7576) (#7586)

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain
* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Safeguard nemo_text_processing installation on ARM (#7485)

* safeguard nemo_text_processing installing

Signed-off-by: Jason <jasoli@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update check

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Bound transformers version in requirements (#7620)

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* fix llama2 70b lora tuning bug (#7622)

* fix llama2 70b lora tuning bug

Signed-off-by: Chen Cui <chcui@nvidia.com>

* Update peft_config.py

brackets

Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>

---------

Signed-off-by: Chen Cui <chcui@nvidia.com>
Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>
Co-authored-by: Adi Renduchintala <adithyare@nvidia.com>

* Fix import error no module name model_utils (#7629)

Signed-off-by: Mehadi Hasan Menon <mehadihasan80@gmail.com>

* add fc large ls models (#7641)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao Koluguri <nithinraok>

* bugfix: trainer.gpus, trainer.strategy, trainer.accelerator (#7621) (#7642)

* [TTS] bugfix for Tacotron2 tutorial due to PTL 2.0
* trainer.gpus -> trainer.devices
* fixed related tutorial bugs
---------
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* fix ssl models ptl monitor val through logging (#7608) (#7614)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* Fix metrics for SE tutorial (#7604) (#7612)

Signed-off-by: Ante Jukić <ajukic@nvidia.com>
Co-authored-by: anteju <108555623+anteju@users.noreply.github.com>

* Add ddp_find_unused_parameters=True and change accelerator to auto (#7623) (#7644)

* Add ddp_find_unused_parameters=True and change acclerator to auto



* Add ddp_find_unused_parameters True for normalization_as_tagging_train.py



---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* Fix py3.11 dataclasses issue  (#7616)

* Fix py3.11 dataclasses issue  (#7582)

* Update ASR configs to support Python 3.11

Signed-off-by: smajumdar <titu1994@gmail.com>

* Update TTS configs to support Python 3.11

Signed-off-by: smajumdar <titu1994@gmail.com>

* Guard MeCab and Ipadic

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix remaining ASR dataclasses

Signed-off-by: smajumdar <titu1994@gmail.com>

* Fix remaining ASR dataclasses

Signed-off-by: smajumdar <titu1994@gmail.com>

* Fix scripts

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Update name to ConfidenceMethodConfig

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain (#7576) (#7586)

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain
* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Safeguard nemo_text_processing installation on ARM (#7485)

* safeguard nemo_text_processing installing

Signed-off-by: Jason <jasoli@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update check

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Fix changes to confidence measure

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: smajumdar <titu1994@gmail.com>
Signed-off-by: Sangkug Lym <slym@nvidia.com>
Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: github-actions[bot] <41898282+github-actions[bot]@users.noreply.github.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Jason <jasoli@nvidia.com>

* [Stable Diffusion/ControlNet] Enable O2 training for SD and Fix ControlNet CI failure

* Mingyuanm/dreambooth fix

* Fix NeMo CI Infer Issue

* DreamFusion

* Move neva export changes

* Add Imagen Synthetic Dataloader

* Add VITWrapper and export stuff to wrapper

* Update neva with megatron-core support

* Fix issues with Dockerfile (#7650) (#7652)

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>

* [ASR] RNN-T greedy decoding max_frames fix for alignment and confidence (#7635)

* decoding and test fix

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* [ASR] Fix type error in jasper (#7636) (#7653)

Signed-off-by: Ryan <rlangman@nvidia.com>
Co-authored-by: Ryan Langman <rlangman@nvidia.com>

* [TTS] Add STFT and SI-SDR loss to audio codec recipe (#7468)

* [TTS] Add STFT and SI-SDR loss to audio codec recipe

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix STFT resolution

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix training metric logging

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Add docstring to mel and stft losses

Signed-off-by: Ryan <rlangman@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Ryan <rlangman@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Create per.py (#7538)

* Move model precision copy (#7336)

* move cfg precision set to megatron base model

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* remove copy from other models

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* modify attribute not arg

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* fix gpt model test for ptl 2.0

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* rename function and add docstring

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* replace precision to dtype conditionals with func call

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* unnecessary function and cfg reset

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* set default value

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* fix precision lookup in a few more places

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* rename mapping function

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* ununsed import

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* save torch datatype to model

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* set weights precision wrt amp o2

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* Revert ""set weights precision wrt amp o2""

This reverts commit 313a4bfe5eb69d771a6d2433898c0685836aef5c.

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* revert half precision at inference attempt

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* move autocast dtype to base model

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* move params dtype to base model, enable fp16 O2 inf

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* unused imports

Signed-off-by: Maanu Grover <maanug@nvidia.com>

---------

Signed-off-by: Maanu Grover <maanug@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix PEFT checkpoint loading (#7388)

* Fix PEFT checkpoint loading

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Jason Wang <jasonwan@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Use distributed optimizer support for multiple dtypes (#7359)

* Update distopt wrapper with multiple dtype support

Remove manual handling of separate FP32 optimizer.

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Use distopt support for contiguous buffers with multiple dtypes

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Fix typo

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Separate distopt buckets for first GPT layer and non-overlapped params

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Add distopt logic for int dtypes

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Update Apex commit

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Remove unused variables

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Update Apex commit in README and Jenkensfile

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Debug Dockerfile and Jenkinsfile

Signed-off-by: Tim Moon <tmoon@nvidia.com>

---------

Signed-off-by: Tim Moon <tmoon@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* minor fix for llama ckpt conversion script (#7387)

* minor fix for llama ckpt conversion script

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* Update Jenkinsfile

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* remove fast_swiglu configuration

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

---------

Signed-off-by: Jason Wang <jasonwan@nvidia.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix wrong calling of librosa.get_duration() in notebook (#7376)

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [PATCH] PEFT import mcore (#7393)

* [PATCH] PEFT import mcore

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Jason Wang <jasonwan@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Create per.py

Script for calculation Punctuation Error Rate and related rates (correct rate, deletions rate, etc.)

Signed-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [TTS] Added a callback for logging initial data (#7384)

Signed-off-by: Ante Jukić <ajukic@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update Core Commit (#7402)

* Update Core Commit

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* update commit

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

---------

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Use cfg attribute in bert (#7394)

* use cfg attribute instead of arg

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* use torch_dtype in place of cfg.precision

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* move precision copy before super constructor

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* use trainer arg

Signed-off-by: Maanu Grover <maanug@nvidia.com>

---------

Signed-off-by: Maanu Grover <maanug@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add support for bias conversion in Swiglu models (#7386)

* Add support for bias conversion in Swiglu models

Signed-off-by: smajumdar <titu1994@gmail.com>

* Add support for auto extracting tokenizer model

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add support for auto extracting tokenizer model

Signed-off-by: smajumdar <titu1994@gmail.com>

* Fix issue with missing tokenizer

Signed-off-by: smajumdar <titu1994@gmail.com>

* Refactor

Signed-off-by: smajumdar <titu1994@gmail.com>

* Refactor

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update save_to and restore_from for dist checkpointing (#7343)

* add dist ckpt to save to, in progress

Signed-off-by: eharper <eharper@nvidia.com>

* move dist ckpt

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* clean up

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update restore from, need to figure out how to initialize distributed

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* launch distrib if needed when restoring dist ckpt

Signed-off-by: eharper <eharper@nvidia.com>

* when using mcore we can change tp pp on the fly

Signed-off-by: eharper <eharper@nvidia.com>

* add load_from_checkpoint support for dist ckpt

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update llama convert script to save dist .nemo

Signed-off-by: eharper <eharper@nvidia.com>

* fix load dist ckpt

Signed-off-by: jasonwan <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* setup TE TP groups if needed

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* setup te tp groups if needed

Signed-off-by: eharper <eharper@nvidia.com>

* remove import

Signed-off-by: eharper <eharper@nvidia.com>

---------

Signed-off-by: eharper <eharper@nvidia.com>
Signed-off-by: jasonwan <jasonwan@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: jasonwan <jasonwan@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* fix forward for with mcore=false (#7403)

Signed-off-by: Jimmy Zhang <jiemingz@nvidia.com>
Co-authored-by: Jimmy Zhang <jiemingz@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix logging to remove 's/it' from progress bar in Megatron models and add train_step_timing (#7374)

* Add CustomProgressBar class to exp_manager and trainer callbacks

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix the progress bar to reflect total microbatch cnt

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* Modify CustomProgressBar class

1) Modify CustomProgressBar class to update progress bar per global_step instead of per microbatch
2) Add the callback to other megatron training/finetuning files that are not using MegatronTrainerBuilder

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* Add CustomProgressBar callback to tuning files

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Set Activation Checkpointing Defaults (#7404)

* Set Activation Checkpointing Defaults

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* check for None

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* make loss mask default to false (#7407)

Signed-off-by: eharper <eharper@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add dummy userbuffer config files (#7408)

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* add missing ubconf files (#7412)

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* New tutorial on Speech Data Explorer (#7405)

* Added Google Colab based tutorial on Speech Data Explorer

Signed-off-by: George Zelenfroynd <gzelenfroind@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update ptl training ckpt conversion script to work with dist ckpt (#7416)

* update ptl convert script

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* don't break legacy

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: eharper <eharper@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Allow disabling sanity checking when num_sanity_val_steps=0 (#7413)

* Allow disabling sanity checking when num_sanity_val_steps=0

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* Update num_sanity_val_steps to be a multiple of num_microbatches

Signed-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Signed-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add comprehensive error messages (#7261)

Signed-off-by: Anton Peganov <apeganov@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* check NEMO_PATH (#7418)

Signed-off-by: Nikolay Karpov <karpnv@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* layer selection for ia3 (#7417)

* layer selection for ia3

Signed-off-by: arendu <adithyare@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: arendu <adithyare@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix missing pip package 'einops' (#7397)

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix failure of pyaudio in Google Colab (#7396)

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update README.md: output_path --> output_manifest_filepath (#7442)

Signed-off-by: Samuele Cornell <cornellsamuele@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add rope dynamic linear scaling (#7437)

* Add dynamic linear scaling

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix None dataloader issue in PTL2.0 (#7455)

* Fix None dataloader issue in PTL2.0

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* updating values of self._validation_dl and self._test_dl as well

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* updating values of self._validation_dl and self._test_dl as well

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [ASR] Confidence measure -> method renames (#7434)

* measure -> method

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add steps for document of getting dataset 'SF Bilingual Speech' (#7378)

* Add steps for document of getting dataset 'SF Bilingual Speech'

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update datasets.rst

added a link from a tutorial demonstrating detailed data prep steps.

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* RNN-T confidence and alignment bugfix (#7381)

* new frame_confidence and alignments lists are now always created after the while loop

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* tests added

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix resume from checkpoint in exp_manager (#7424) (#7426)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix checking of cuda/cpu device for inputs of Decoder (#7444)

* Fix checking of cuda/cpu device for inputs of Decoder

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update tacotron2.py

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: Jason <jasoli@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix failure of ljspeech's get_data.py (#7430)

* Fix failure of ljspeech's get_data.py

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [TTS] Fix audio codec type checks (#7373)

* [TTS] Fix audio codec type checks

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix audio codec tests

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [TTS] Add dataset to path of logged artifacts (#7462)

* [TTS] Add dataset to path of logged artifacts

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Revert axis name back to Audio Frames

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix sft dataset truncation (#7464)

* Add fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-of…"
github.com/NVIDIA/NeMo,examples/multimodal/vision_language_foundation/clip/convert_external_clip_to_nemo.py,2023-12-13T02:12:55Z,"Add All Multimodal Source Code (#7791)

* Add comprehensive error messages (#7261)

Signed-off-by: Anton Peganov <apeganov@nvidia.com>

* check NEMO_PATH (#7418)

Signed-off-by: Nikolay Karpov <karpnv@gmail.com>

* layer selection for ia3 (#7417)

* layer selection for ia3

Signed-off-by: arendu <adithyare@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: arendu <adithyare@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Fix missing pip package 'einops' (#7397)

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Fix failure of pyaudio in Google Colab (#7396)

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update README.md: output_path --> output_manifest_filepath (#7442)

Signed-off-by: Samuele Cornell <cornellsamuele@gmail.com>

* Updating FlashAttention API to match FlashAttentionV2

* Multiple fixes for mm

* Fix CI inductor issue and update to torch compile

* Remove suppress error

* Fix when conversion config uses fp16 and it complains about precision plugin

* Fixing FAv2 API usage

* Initial release of content filtering model

* Added synthetic dataloader for precached and online mode

* Mingyuanm/dreambooth opt

* Add llama2 support in neva training

* Fix sampler length

* Fix all precision issues in nemo multimodal

* Add rope dynamic linear scaling (#7437)

* Add dynamic linear scaling

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>

* Fix None dataloader issue in PTL2.0 (#7455)

* Fix None dataloader issue in PTL2.0

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* updating values of self._validation_dl and self._test_dl as well

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* updating values of self._validation_dl and self._test_dl as well

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* [ASR] Confidence measure -> method renames (#7434)

* measure -> method

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Add steps for document of getting dataset 'SF Bilingual Speech' (#7378)

* Add steps for document of getting dataset 'SF Bilingual Speech'

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update datasets.rst

added a link from a tutorial demonstrating detailed data prep steps.

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* RNN-T confidence and alignment bugfix (#7381)

* new frame_confidence and alignments lists are now always created after the while loop

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* tests added

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* Fix resume from checkpoint in exp_manager (#7424) (#7426)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: Eric Harper <complex451@gmail.com>

* Fix checking of cuda/cpu device for inputs of Decoder (#7444)

* Fix checking of cuda/cpu device for inputs of Decoder

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update tacotron2.py

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: Jason <jasoli@nvidia.com>

* Fix failure of ljspeech's get_data.py (#7430)

* Fix failure of ljspeech's get_data.py

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* [TTS] Fix audio codec type checks (#7373)

* [TTS] Fix audio codec type checks

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix audio codec tests

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Add dataset to path of logged artifacts (#7462)

* [TTS] Add dataset to path of logged artifacts

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Revert axis name back to Audio Frames

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>

* Fix sft dataset truncation (#7464)

* Add fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Automatic Lip Reading Recognition (ALR) - ASR/CV (Visual ASR) (#7330)

* striding_conv1d_k5 and dw_striding_conv1d_k5 subsampling

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* transpose conv1d inputs

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* Update subsampling.py

change striding_conv1d_k5 to striding_conv1d

Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>

* cv branch

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* video manifest

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* add collection classes

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add test_step_outputs

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* correct manifest bug when having only audio or only videos

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* correct manifest bug when having only audio or only videos

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* clean references

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* freeze unfreeze transcribe cv models

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* correct manifest get_full_path bug

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* update for PR

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* guard torchvision

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Update nemo/collections/cv/data/video_to_text_dataset.py

Co-authored-by: Igor Gitman <igor.a.gitman@gmail.com>
Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>

* _video_speech_collate_fn in cv/data/video_to_text.py

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* add self.out = None to asr subsampling

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* Update nemo/collections/cv/data/video_to_text_dataset.py

Co-authored-by: Igor Gitman <igor.a.gitman@gmail.com>
Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>

* cv -> multimodal/speech_cv branch

Signed-off-by: mburchi <maxime.burchi@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: mburchi <maxime.burchi@gmail.com>
Signed-off-by: Maxime Burchi <60737204+burchim@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Igor Gitman <igor.a.gitman@gmail.com>

* HF StarCoder to NeMo conversion script (#7421)

* Script to convert HF StarCoder checkpoint to NeMo

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* StarCoder conversion test

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Fix test

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Catch up with save_to changes

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Don't abbreviate args for clarity

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Configurable precision: BF16 vs FP32

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* fix bug when loading dist ckpt in peft (#7452)

Signed-off-by: Hongbin Liu <hongbinl@nvidia.com>
Co-authored-by: Hongbin Liu <hongbinl@nvidia.com>

* Fix adding positional embeddings in-place in transformer module (#7440)

Signed-off-by: Tamerlan Tabolov <tktabolov@gmail.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

* Fix (#7478)

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* add sleep (#7498) (#7499)

* add sleep



* add sleep onto config instead



* add comment



---------

Signed-off-by: Gerald Shen <geshen@nvidia.com>
Co-authored-by: Gerald Shen <119401249+gshennvm@users.noreply.github.com>

* Fix exp manager check for sleep (#7503) (#7504)

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>

* bugfix: trainer.accelerator=auto from None. (#7492) (#7493)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>

* [doc] fix broken link (#7481)

Signed-off-by: Stas Bekman <stas00@users.noreply.github.com>

* [TTS] Read audio as int32 to avoid flac read errors (#7477)

* [TTS] Read audio as int32 to avoid flac read errors

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Add comment about read failures

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>

* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS (#7409)

* Add dataset 'AISHELL-3' from OpenSLR for training mandarin TTS
* Train 'AISHELL-3' dataset with multi-speakers

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update get_data.py

update copyright header

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* Update get_data.py

added a disclaimer

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add new configuration file for AISHELL3 with multispeaker of fastpitch

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* dllogger - log on rank 0 only (#7513)

Signed-off-by: Stas Bekman <stas00@users.noreply.github.com>

* Fix TTS FastPitch tutorial (#7494) (#7516)

* Fix

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

* Fix get_dist() tensor dimension (#7506) (#7515)

Signed-off-by: Jocelyn Huang <jocelynh@nvidia.com>
Co-authored-by: Jocelyn <jocelynh@nvidia.com>

* bugfix: specify trainer.strategy=auto when devices=1 (#7509) (#7512)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>

* fix (#7511)

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* [TTS] Fix FastPitch data prep tutorial (#7524)

Signed-off-by: Ryan <rlangman@nvidia.com>

* add italian tokenization (#7486)

* add italian tokenization

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add more ipa lexicon it

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix error deletion

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* add test

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Replace None strategy with auto in tutorial notebooks (#7521) (#7527)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* unpin setuptools (#7534) (#7535)

Signed-off-by: fayejf <36722593+fayejf@users.noreply.github.com>
Co-authored-by: fayejf <36722593+fayejf@users.noreply.github.com>

* remove auto generated examples (#7510)

* explicitly remove autogenerated examples for data parallel evaluation

Signed-off-by: arendu <adithyare@nvidia.com>

* mark autogenrated and remove it for test

Signed-off-by: arendu <adithyare@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: arendu <adithyare@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Add the `strategy` argument to `MegatronGPTModel.generate()` (#7264)

It is passed as an explicit argument rather than through
`**strategy_args` so as to ensure someone cannot accidentally pass other
arguments that would end up being ignored.

It is a keyword-only argument to ensure that if in the future we want to
update the signature to `**strategy_args`, we can do it without breaking
code.

Signed-off-by: Olivier Delalleau <507137+odelalleau@users.noreply.github.com>

* Fix PTL2.0 related ASR bugs in r1.21.0: Val metrics logging, None dataloader issue (#7531) (#7533)

* fix none dataloader issue ptl2



* ptl2.0 logging fixes for rnnt_models



---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Co-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>

* gpus -> devices (#7542) (#7545)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>

* Update FFMPEG version to fix issue with torchaudio (#7551) (#7553)

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>

* PEFT GPT & T5 Refactor (#7308)

* initial implementation of add_adapters API

* correct type hint

* Add config in add_adapters for save and load (@author bobchen)

* Remove AdapterConfig to avoid import error

* Add AdaterConfig back and move adaptermixin to sft model

* Add NLPSaveRestoreConnector as default in NLPModel.restore_from

* Add restore_from_nemo_with_adapter and test script

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* rename t5 file and classes to be consistent with GPT

* add t5 sft dataset

* add support for single-file format with T5SFTDataset

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Various small changes to make T5 SFT work like GPT SFT

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add adapter evaluation test script

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add MultiAdaterConfig for ia3 and fix builder issue

* Make ptuning for T5SFTModel work using mixin

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add IA3_Adapter for AdapterName

* Add adapter name for ptuning and attention adapter

* Make test script GPT/T5 agnostic

* Add layer selection feature

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Integrate adapter name and config

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update gpt peft tuning script to new API

* add t5 peft tuning script with new API

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix IA3 layer selection issue

* Override state_dict on SFT model instead of mixin

* Add load adapter by adapter config

* move peft config map away from example script

* auto get config from nemo adapter

* Move PEFTConfig to new file

* fix ckpt save/load for t5

* name change: add_adapters -> add_adapter

* variable name change

* update t5 script

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix t5 issues

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add weight tying

* update gpt tuning script

* PEFT-API proposal

* Fix according to comments

* update tuning scripts

* move merge_cfg_with to mixin class since it applies to both gpt and t5 and requires the model class for restore

* Add mcore_gpt support for NLPAdapterMixin

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix typo

* variable name change to distinguish ""peft"" and ""adapter""

* override `load_adapters` to support `add_adapter` name change

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update tuning and eval script for adapter save/load

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add Ptuning on first stage only

* add lora tutorial for review

* Fix layer selection for mcore

* add landing page

* fix resume training

Signed-off-by: jasonwan <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add mcore condition in sharded_state_dict to make sft work

* Update lora_tutorial.md

First edit of this file for PEFT documentation for NeMO

Signed-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>

* rename Adapter to AttentionAdapter to avoid confusion in doc

* Change load_adapters to load .nemo

* add quick start guide

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add load_adapters with .ckpt

* Remove setup_complete changes in load_adapters

* update landing page

* remove typo

* Updated quick_start.md per Chen Cui

Signed-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>

* Add inference config merger and tutorial

* Add doc string for NLPAdapterModelMixin and deprecated warning on MegatronGPTPEFTModel

* add supported_methods.md and update other documentations

* Update supported_methods.md

minor updates.

Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>

* Update landing_page.md

minor update.

Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>

* Modify doc string for NLPAdapterModelMixin

* Add doc string add_adapters in NLPAdapterModelMixin

* rename canonical adapters

* remove mcore hard dependency

* [PATCH] move microbatch calculator to nemo from apex

* remove apex dependency in gpt and t5 sft models

* remove apex dependency in gpt model

* render doc strings

* fix

* Add missing virtual_tokens on ptuning

* fix docstrings

* update gpt-style model coverage in docs

* update docstring

* Remove pdb

* add lightning_fabric to make docstring rendering work

* Add Ptuning missing key

* try docstring rendering

* Fix ptuning issue

* update gpt t5 peft tuning and eval scripts

* typos

* update eval config

* fix bug relating to apex dependency removal

* typo

* make predict step behave the same as test step

* make lora tutorial work in notebook

* cosmetics

* update yaml scripts

* mcore_gpt attribute optional

* typo

* update eval scripts and fix T5 eval bugs

* add NLPDDPStrategyNotebook and trainer builder logic to use it

* update lora notebook to use new trainer builder

* fix microbatch calculator bug for inference after training

* Convert markdown files to RST and incorporate with doc

* typo

* revise language

* remove extra cell

* remove unnecessary inheritance

* remove old tests

* move layer selection default so logging messages make sense

* remove `save_adapters` as adapter weights are saved automatically during training

* initialize weights from a checkpoint instead of randomly

* multiple fields can form a context (#7147)

* list of context fields and flexible prompt template

Signed-off-by: arendu <adithya.r@gmail.com>

* list of fields for context

Signed-off-by: arendu <adithya.r@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Add multiple truncation fields and middle truncation

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Compatible to old ckpt

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix tokenize detokenize issue

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Remove detokenization, add truncation augmentation

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Resolve comments

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Remove unused import

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* revert eos

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Add tokenizer space_sensitive attribute

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix error

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Fix erorr and use re

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Change assert logic

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Follow adi suggestion

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Remove merge function

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add example and comment

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Remove context_key and add comment

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* Remove random truncation

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix template none

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: arendu <adithya.r@gmail.com>
Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Signed-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

* revert config changes

* remove accidental breakpoint

* support TP>1 loading

* infer adapter type from checkpoint in during eval

* breakup add adapter

* enable interpolation of train_ds and validation_ds

* update metric calc script to conform to single-file eval format

* remove extraneous print

* update lora notebook for updated merge_inference_cfg

* Update nlp_adapter_mixins.py

variable name change

Signed-off-by: Chen Cui <chcui@nvidia.com>

* turn off grad scaler for PP to match old scripts

* remove PEFTSaveRestoreConnector since functionality all covered by the new mixin class

* remove resume_from_checkpoint check since covered in #7335

* revert changes made in eval config interpolation

* more interpolation

* typo

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* remove dup line

Signed-off-by: Chen Cui <chcui@nvidia.com>

* code style warnings

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix config mistake

Signed-off-by: Chen Cui <chcui@nvidia.com>

* add copyright header

Signed-off-by: Chen Cui <chcui@nvidia.com>

* fix code check warnings

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* revert changes to remove apex dependency (mixed apex+nemo microbatch calculator broke some CI tests)

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add more deprecation notices

Signed-off-by: Chen Cui <chcui@nvidia.com>

* update deprecation notices

Signed-off-by: Chen Cui <chcui@nvidia.com>

* update deprecation notices

Signed-off-by: Chen Cui <chcui@nvidia.com>

* consolidate peft and sft scripts

Signed-off-by: Chen Cui <chcui@nvidia.com>

* update CI tests

Signed-off-by: Chen Cui <chcui@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* notebook branch points to main to prepare for merge

Signed-off-by: Chen Cui <chcui@nvidia.com>

* fix gpt and t5 validation with any metric other than loss

Signed-off-by: Chen Cui <chcui@nvidia.com>

* support pre-extracted checkpoints

Signed-off-by: Chen Cui <chcui@nvidia.com>

---------

Signed-off-by: jasonwan <jasonwan@nvidia.com>
Signed-off-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>
Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>
Signed-off-by: arendu <adithya.r@gmail.com>
Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Signed-off-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>
Signed-off-by: Chen Cui <chcui@nvidia.com>
Co-authored-by: Chen Cui <chcui@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Marc Romeyn <marcromeyn@gmail.com>
Co-authored-by: jasonwan <jasonwan@nvidia.com>
Co-authored-by: hkelly33 <58792115+hkelly33@users.noreply.github.com>
Co-authored-by: Adi Renduchintala <adithyare@nvidia.com>
Co-authored-by: Yuanzhe Dong <yudong@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

* fix a typo (#7496)

Signed-off-by: BestJuly <chntaoli@163.com>

* [TTS] remove curly braces from ${BRANCH} in jupyer notebook cell. (#7554) (#7560)

* remove curly braces.
* remove installation of pynini.
---------

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>

* add youtube embed url (#7570)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>

* Remap speakers to continuous range of speaker_id for dataset AISHELL3 (#7536)

* Remap speakers to continuous range of speaker_id for dataset AISHELL3
* Add new key/value pair to record raw speaker for AISHELL3 dataset

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* fix validation_step_outputs initialization for multi-dataloader (#7546) (#7572)

* added correct validation_step_outputs initialization for mutli-dataloader



* changed kernel for display



* Update logic for validation and test step outputs



* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* revert multidataloader changes in multilang ASR notebook



---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Kunal Dhawan <kunaldhawan97@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Append output of val step to self.validation_step_outputs (#7530) (#7532)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* [TTS] fixed trainer's accelerator and strategy. (#7569) (#7574)

Signed-off-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <16880-xueyang@users.noreply.gitlab-master.nvidia.com>

* Append val/test output to instance variable in EncDecSpeakerLabelModel (#7562) (#7573)

* Append val/test output to the instance variable in EncDecSpeakerLabelModel



* Handle test case in evaluation_step



* Replace type with isinstance



---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* Fix CustomProgressBar for resume (#7427) (#7522)

* Fix CustomProgress Bar for resume and multiple epochs



* Edit num_training_batches



* Use max_steps as total for progress bar for resume



* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* fix typos in nfa and speech enhancement tutorials (#7580) (#7583)

Signed-off-by: Elena Rastorgueva <erastorgueva@nvidia.com>
Co-authored-by: Elena Rastorgueva <80532067+erastorgueva-nv@users.noreply.github.com>

* Add strategy as ddp_find_unused_parameters_true for glue_benchmark.py (#7454) (#7461)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* update strategy (#7577) (#7578)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>

* Fix typos (#7581)

* Change hifigan finetune strategy to ddp_find_unused_parameters_true (#7579) (#7584)

* Change strategy to auto



---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: Cheng-Ping Hsieh <37269846+hsiehjackson@users.noreply.github.com>

* [BugFix] Add missing quotes for auto strategy in tutorial notebooks (#7541) (#7548)

* Add missing quotes for auto strategy



* Revert trainer.gpus to trainer.devices in Self_Supervised_Pre_Training.ipynb



---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Signed-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* add build os key (#7596) (#7599)

* add build os key



* add tools



* update to stable version



---------

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>

* StarCoder SFT test + bump PyT NGC image to 23.09 (#7540)

* Add SFT StarCoder test

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Remove _modify_config call as it is covered in load_from_nemo just below

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* Test with pyt:23.09 container

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

---------

Signed-off-by: Jan Lasek <janek.lasek@gmail.com>

* defaults changed (#7600)

* defaults changed

Signed-off-by: arendu <adithyare@nvidia.com>

* typo

Signed-off-by: arendu <adithyare@nvidia.com>

* update

Signed-off-by: arendu <adithyare@nvidia.com>

---------

Signed-off-by: arendu <adithyare@nvidia.com>

* add ItalianPhonemesTokenizer (#7587)

* add ItalianPhonemesTokenizer

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* fix Italian phonemes

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* add test

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>

---------

Signed-off-by: GiacomoLeoneMaria <giacomoleonemaria@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* best ckpt fix (#7564) (#7588)

Signed-off-by: dimapihtar <dpihtar@gmail.com>
Co-authored-by: Dmytro Pykhtar <37850217+dimapihtar@users.noreply.github.com>

* Add files via upload (#7598)

specifies the branch

Signed-off-by: George <37293288+Jorjeous@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* Fix validation in G2PModel and ThutmoseTaggerModel (#7597) (#7606)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain (#7576) (#7586)

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain
* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Safeguard nemo_text_processing installation on ARM (#7485)

* safeguard nemo_text_processing installing

Signed-off-by: Jason <jasoli@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update check

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Bound transformers version in requirements (#7620)

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* fix llama2 70b lora tuning bug (#7622)

* fix llama2 70b lora tuning bug

Signed-off-by: Chen Cui <chcui@nvidia.com>

* Update peft_config.py

brackets

Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>

---------

Signed-off-by: Chen Cui <chcui@nvidia.com>
Signed-off-by: Adi Renduchintala <adithyare@nvidia.com>
Co-authored-by: Adi Renduchintala <adithyare@nvidia.com>

* Fix import error no module name model_utils (#7629)

Signed-off-by: Mehadi Hasan Menon <mehadihasan80@gmail.com>

* add fc large ls models (#7641)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao Koluguri <nithinraok>

* bugfix: trainer.gpus, trainer.strategy, trainer.accelerator (#7621) (#7642)

* [TTS] bugfix for Tacotron2 tutorial due to PTL 2.0
* trainer.gpus -> trainer.devices
* fixed related tutorial bugs
---------
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* fix ssl models ptl monitor val through logging (#7608) (#7614)

Signed-off-by: Nithin Rao Koluguri <nithinraok>
Co-authored-by: Nithin Rao <nithinrao.koluguri@gmail.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

* Fix metrics for SE tutorial (#7604) (#7612)

Signed-off-by: Ante Jukić <ajukic@nvidia.com>
Co-authored-by: anteju <108555623+anteju@users.noreply.github.com>

* Add ddp_find_unused_parameters=True and change accelerator to auto (#7623) (#7644)

* Add ddp_find_unused_parameters=True and change acclerator to auto



* Add ddp_find_unused_parameters True for normalization_as_tagging_train.py



---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* Fix py3.11 dataclasses issue  (#7616)

* Fix py3.11 dataclasses issue  (#7582)

* Update ASR configs to support Python 3.11

Signed-off-by: smajumdar <titu1994@gmail.com>

* Update TTS configs to support Python 3.11

Signed-off-by: smajumdar <titu1994@gmail.com>

* Guard MeCab and Ipadic

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix remaining ASR dataclasses

Signed-off-by: smajumdar <titu1994@gmail.com>

* Fix remaining ASR dataclasses

Signed-off-by: smajumdar <titu1994@gmail.com>

* Fix scripts

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Update name to ConfidenceMethodConfig

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain (#7576) (#7586)

* Broadcast loss only when using pipeline parallelism and within the pipeline parallel domain
* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Safeguard nemo_text_processing installation on ARM (#7485)

* safeguard nemo_text_processing installing

Signed-off-by: Jason <jasoli@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update check

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Fix changes to confidence measure

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: smajumdar <titu1994@gmail.com>
Signed-off-by: Sangkug Lym <slym@nvidia.com>
Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: github-actions[bot] <41898282+github-actions[bot]@users.noreply.github.com>
Co-authored-by: Sangkug Lym <slym@nvidia.com>
Co-authored-by: Jason <jasoli@nvidia.com>

* [Stable Diffusion/ControlNet] Enable O2 training for SD and Fix ControlNet CI failure

* Mingyuanm/dreambooth fix

* Fix NeMo CI Infer Issue

* DreamFusion

* Move neva export changes

* Add Imagen Synthetic Dataloader

* Add VITWrapper and export stuff to wrapper

* Update neva with megatron-core support

* Fix issues with Dockerfile (#7650) (#7652)

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>

* [ASR] RNN-T greedy decoding max_frames fix for alignment and confidence (#7635)

* decoding and test fix

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* [ASR] Fix type error in jasper (#7636) (#7653)

Signed-off-by: Ryan <rlangman@nvidia.com>
Co-authored-by: Ryan Langman <rlangman@nvidia.com>

* [TTS] Add STFT and SI-SDR loss to audio codec recipe (#7468)

* [TTS] Add STFT and SI-SDR loss to audio codec recipe

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix STFT resolution

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix training metric logging

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Add docstring to mel and stft losses

Signed-off-by: Ryan <rlangman@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Ryan <rlangman@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>

* Create per.py (#7538)

* Move model precision copy (#7336)

* move cfg precision set to megatron base model

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* remove copy from other models

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* modify attribute not arg

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* fix gpt model test for ptl 2.0

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* rename function and add docstring

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* replace precision to dtype conditionals with func call

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* unnecessary function and cfg reset

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* set default value

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* fix precision lookup in a few more places

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* rename mapping function

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* ununsed import

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* save torch datatype to model

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* set weights precision wrt amp o2

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* Revert ""set weights precision wrt amp o2""

This reverts commit 313a4bfe5eb69d771a6d2433898c0685836aef5c.

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* revert half precision at inference attempt

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* move autocast dtype to base model

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* move params dtype to base model, enable fp16 O2 inf

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* unused imports

Signed-off-by: Maanu Grover <maanug@nvidia.com>

---------

Signed-off-by: Maanu Grover <maanug@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix PEFT checkpoint loading (#7388)

* Fix PEFT checkpoint loading

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Jason Wang <jasonwan@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Use distributed optimizer support for multiple dtypes (#7359)

* Update distopt wrapper with multiple dtype support

Remove manual handling of separate FP32 optimizer.

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Use distopt support for contiguous buffers with multiple dtypes

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Fix typo

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Separate distopt buckets for first GPT layer and non-overlapped params

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Add distopt logic for int dtypes

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Update Apex commit

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Remove unused variables

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Update Apex commit in README and Jenkensfile

Signed-off-by: Tim Moon <tmoon@nvidia.com>

* Debug Dockerfile and Jenkinsfile

Signed-off-by: Tim Moon <tmoon@nvidia.com>

---------

Signed-off-by: Tim Moon <tmoon@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* minor fix for llama ckpt conversion script (#7387)

* minor fix for llama ckpt conversion script

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* Update Jenkinsfile

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* remove fast_swiglu configuration

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

---------

Signed-off-by: Jason Wang <jasonwan@nvidia.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix wrong calling of librosa.get_duration() in notebook (#7376)

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: Somshubra Majumdar <titu1994@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [PATCH] PEFT import mcore (#7393)

* [PATCH] PEFT import mcore

Signed-off-by: Jason Wang <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Jason Wang <jasonwan@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Create per.py

Script for calculation Punctuation Error Rate and related rates (correct rate, deletions rate, etc.)

Signed-off-by: Sasha Meister <117230141+ssh-meister@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [TTS] Added a callback for logging initial data (#7384)

Signed-off-by: Ante Jukić <ajukic@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update Core Commit (#7402)

* Update Core Commit

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* update commit

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

---------

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Use cfg attribute in bert (#7394)

* use cfg attribute instead of arg

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* use torch_dtype in place of cfg.precision

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* move precision copy before super constructor

Signed-off-by: Maanu Grover <maanug@nvidia.com>

* use trainer arg

Signed-off-by: Maanu Grover <maanug@nvidia.com>

---------

Signed-off-by: Maanu Grover <maanug@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add support for bias conversion in Swiglu models (#7386)

* Add support for bias conversion in Swiglu models

Signed-off-by: smajumdar <titu1994@gmail.com>

* Add support for auto extracting tokenizer model

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add support for auto extracting tokenizer model

Signed-off-by: smajumdar <titu1994@gmail.com>

* Fix issue with missing tokenizer

Signed-off-by: smajumdar <titu1994@gmail.com>

* Refactor

Signed-off-by: smajumdar <titu1994@gmail.com>

* Refactor

Signed-off-by: smajumdar <titu1994@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: smajumdar <titu1994@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update save_to and restore_from for dist checkpointing (#7343)

* add dist ckpt to save to, in progress

Signed-off-by: eharper <eharper@nvidia.com>

* move dist ckpt

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* clean up

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update restore from, need to figure out how to initialize distributed

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* launch distrib if needed when restoring dist ckpt

Signed-off-by: eharper <eharper@nvidia.com>

* when using mcore we can change tp pp on the fly

Signed-off-by: eharper <eharper@nvidia.com>

* add load_from_checkpoint support for dist ckpt

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* update llama convert script to save dist .nemo

Signed-off-by: eharper <eharper@nvidia.com>

* fix load dist ckpt

Signed-off-by: jasonwan <jasonwan@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* setup TE TP groups if needed

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* setup te tp groups if needed

Signed-off-by: eharper <eharper@nvidia.com>

* remove import

Signed-off-by: eharper <eharper@nvidia.com>

---------

Signed-off-by: eharper <eharper@nvidia.com>
Signed-off-by: jasonwan <jasonwan@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: jasonwan <jasonwan@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* fix forward for with mcore=false (#7403)

Signed-off-by: Jimmy Zhang <jiemingz@nvidia.com>
Co-authored-by: Jimmy Zhang <jiemingz@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix logging to remove 's/it' from progress bar in Megatron models and add train_step_timing (#7374)

* Add CustomProgressBar class to exp_manager and trainer callbacks

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix the progress bar to reflect total microbatch cnt

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* Modify CustomProgressBar class

1) Modify CustomProgressBar class to update progress bar per global_step instead of per microbatch
2) Add the callback to other megatron training/finetuning files that are not using MegatronTrainerBuilder

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* Add CustomProgressBar callback to tuning files

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Set Activation Checkpointing Defaults (#7404)

* Set Activation Checkpointing Defaults

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* check for None

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* make loss mask default to false (#7407)

Signed-off-by: eharper <eharper@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add dummy userbuffer config files (#7408)

Signed-off-by: Sangkug Lym <slym@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* add missing ubconf files (#7412)

Signed-off-by: Abhinav Khattar <aklife97@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* New tutorial on Speech Data Explorer (#7405)

* Added Google Colab based tutorial on Speech Data Explorer

Signed-off-by: George Zelenfroynd <gzelenfroind@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update ptl training ckpt conversion script to work with dist ckpt (#7416)

* update ptl convert script

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* don't break legacy

Signed-off-by: eharper <eharper@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: eharper <eharper@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Allow disabling sanity checking when num_sanity_val_steps=0 (#7413)

* Allow disabling sanity checking when num_sanity_val_steps=0

Signed-off-by: Abhishree <abhishreetm@gmail.com>

* Update num_sanity_val_steps to be a multiple of num_microbatches

Signed-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Signed-off-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add comprehensive error messages (#7261)

Signed-off-by: Anton Peganov <apeganov@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* check NEMO_PATH (#7418)

Signed-off-by: Nikolay Karpov <karpnv@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* layer selection for ia3 (#7417)

* layer selection for ia3

Signed-off-by: arendu <adithyare@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: arendu <adithyare@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix missing pip package 'einops' (#7397)

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix failure of pyaudio in Google Colab (#7396)

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Update README.md: output_path --> output_manifest_filepath (#7442)

Signed-off-by: Samuele Cornell <cornellsamuele@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add rope dynamic linear scaling (#7437)

* Add dynamic linear scaling

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix bug

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Fix

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>

---------

Signed-off-by: Cheng-Ping Hsieh <chsieh@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Yang Zhang <yzhang123@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix None dataloader issue in PTL2.0 (#7455)

* Fix None dataloader issue in PTL2.0

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* updating values of self._validation_dl and self._test_dl as well

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* updating values of self._validation_dl and self._test_dl as well

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: KunalDhawan <kunaldhawan97@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [ASR] Confidence measure -> method renames (#7434)

* measure -> method

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Add steps for document of getting dataset 'SF Bilingual Speech' (#7378)

* Add steps for document of getting dataset 'SF Bilingual Speech'

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update datasets.rst

added a link from a tutorial demonstrating detailed data prep steps.

Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Co-authored-by: Xuesong Yang <1646669+XuesongYang@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* RNN-T confidence and alignment bugfix (#7381)

* new frame_confidence and alignments lists are now always created after the while loop

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

* tests added

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>

---------

Signed-off-by: Aleksandr Laptev <alaptev@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix resume from checkpoint in exp_manager (#7424) (#7426)

Signed-off-by: Abhishree <abhishreetm@gmail.com>
Co-authored-by: Abhishree Thittenamane <47577437+athitten@users.noreply.github.com>
Co-authored-by: Eric Harper <complex451@gmail.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix checking of cuda/cpu device for inputs of Decoder (#7444)

* Fix checking of cuda/cpu device for inputs of Decoder

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* Update tacotron2.py

Signed-off-by: Jason <jasoli@nvidia.com>

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Signed-off-by: Jason <jasoli@nvidia.com>
Co-authored-by: Jason <jasoli@nvidia.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* Fix failure of ljspeech's get_data.py (#7430)

* Fix failure of ljspeech's get_data.py

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Signed-off-by: Robin Dong <robin.k.dong@gmail.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Signed-off-by: Sasha Meister <sasha.meister.work@gmail.com>

* [TTS] Fix audio codec type checks (#7373)

* [TTS] Fix audio codec type checks

Signed-off-by: Ryan <rlangman@nvidia.com>

* [TTS] Fix audio codec tests

Signed-off-by: Ryan <rlangman@nvidia.com>

---------

Signed-off-by: Ryan <rlangman@nvidia.com>
Signe…"
github.com/modelscope/modelscope,modelscope/models/multi_modal/video_to_video/modules/embedder.py,2023-08-21T10:44:14Z,"add video2video (#486)

* add video2video

* fix bugs of pre-commit

* update some files

* fix video write module

* fix max_frames"
github.com/modelscope/modelscope,modelscope/models/multi_modal/image_to_video/modules/embedder.py,2023-08-22T02:57:23Z,"fix video output of image2video (#488)

* fix video output

* fix logger.error

* fix log error"
github.com/modelscope/modelscope,modelscope/models/multi_modal/image_to_video/modules/embedder.py,2023-08-17T12:03:05Z,fix comments
github.com/modelscope/modelscope,modelscope/models/multi_modal/image_to_video/modules/embedder.py,2023-08-16T03:35:15Z,update files
github.com/modelscope/modelscope,modelscope/models/multi_modal/image_to_video/modules/embedder.py,2023-08-15T13:32:30Z,baishao
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-08-21T16:17:25Z,"Add Support for Specifying Custom `cache_dir` (#245)

* Add support for custom cache_dir

* Lint"
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-06-28T13:26:19Z,OpenFlamingo v2
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-03-26T22:49:44Z,"added new eval script that samples from query set (#117)

* added newe eval script that samples from query set

* ran code formatter"
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-03-26T08:12:48Z,more open-clip changes
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-03-25T22:37:15Z,run code formatter
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-03-25T22:33:47Z,replaced HF clip with open_clip
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-03-19T04:39:53Z,Add cross attn arg
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-03-19T04:21:18Z,"Release fixes (#112)

* improved args and fixed readme example

* fixed data args

* added logging steps arg

* fixed transformers dependency

* fixed transformers dependency

* fix proj vector"
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-03-12T22:09:37Z,"Reintroduce documentation and GitHub workflow changes (#109)

* removed old data code

* ran formatter on data.py"
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-03-12T21:14:56Z,"Revert ""General cleaning up of the repo for Monday's release (#102)"" (#104)

This reverts commit 50b8023c7e951bf537e5ec0e95c8c4e835dd0ee0."
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-03-12T06:14:59Z,"General cleaning up of the repo for Monday's release (#102)

* removed extra imports and old code

* delete old demo

* add more details to readme

* Add linter action

* Update pylint.yml

* Update pylint.yml

* Create

* Update code-formatter.yml

* Delete pylint.yml

* updated unit tests to use tiny models

* Update tests.yml

* Update tests.yml to install open_flamingo

* Update tests.yml

* Added requests to dev requiremnets

* Update tests.yml

* fixed enviornment for workflow

* added examples to readme

* added flamingo model image

* more readme fixes"
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-02-20T04:35:24Z,remove redundant factory.py statement
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-02-20T04:09:29Z,fixes
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-02-15T03:42:28Z,"preforward hooks don't take kwargs, so switch to multiple forwards"
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-02-12T00:27:11Z,fixes
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-02-11T07:55:09Z,bug fix
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-02-11T07:54:04Z,support more eleuther models out of the box
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-02-11T05:17:52Z,"add any hf lm; tested for gpt-neo, opt"
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-02-09T08:51:01Z,documentation cleanup
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-02-09T07:52:13Z,almost pile-compatible: need to reconcile different hidden sizes
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-02-08T18:40:21Z,"perceiver flag, enforce consistent notation for shapes"
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-02-07T02:32:35Z,"Updated codebase to use LAION+PILE approach (#55)

* pile co-training experiment

* removed resampler

* changed repo structure

* fix train args

* update eval code & add more experiment args to train script

* added evaluation docs

* updated stability scripts

* fixed eval code"
github.com/mlfoundations/open_flamingo,open_flamingo/src/factory.py,2023-01-09T08:13:04Z,"A big codebase restructure (#42)

Restructured codebase and added interleaved format"
github.com/AILab-CVC/VideoCrafter,lvdm/modules/encoders/condition.py,2023-10-13T07:20:36Z,Init VideoCrafter1
github.com/microsoft/Cream,TinyCLIP/inference.py,2023-10-25T15:21:08Z,"[TinyCLIP] Inference Example (#196)

* [TinyCLIP] Inference Example"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-12-08T04:51:59Z,fix typo
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-11-19T11:07:03Z,params -> args
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-11-18T16:56:22Z,Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-11-09T16:45:40Z,clean up code and output
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-10-17T17:12:30Z,"support simplified env, fix demo bug"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-08-27T04:33:52Z,codellama support
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-08-20T13:59:43Z,fix rope (more redundancy)
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-08-20T03:17:08Z,rope scale support
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-08-06T10:09:46Z,Move set_default_trainability to meta
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-08-06T04:55:53Z,fix sdpa kwargs
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-08-04T11:05:54Z,"Support loading models trained with different model_parallel_world_size. (#16)

* temp save

* quick fix of demo memory issue

* Refactor tensor creation dtype / device control.

This commit makes two changes during model creation:
1. Decouples promote_trainable_params_to_fp32 from model __init__. This
   is to avoid casting to fp32 to save memory in inference-only mode
   (#4).
2. Use a context manager to manage default tensor type change. In the
   previous version, the default tensor type is reset to
   torch.FloatTensor after creating the vision model, which is
   technically incorrect and should be the previous default tensor type
   instead. We implement our own context manager because the official
   context managers seem to be incomplete at this time (PyTorch 2.0.1):
   No dtype manager is provided and set_default_device is ineffective to
   the torch.Tensor calls which are used in fairscale.

* Change CLIP dtype management in llama.py

It is probably safer to keep CLIP at its original precision (e.g., fp16)
regardless of the autocast setting: Some casting (e.g., from fp16 to
bf16) may be lossy and can potentially harm the pre-trained model.

Keep the changes to llama.py only at this moment since a lot of copy-
pasted codes may be refactored in the future (#3).

* Respect args.precision when saving checkpoints.

* Support checkpoint merge

Checkpoint merge is suported in misc/tensor_parallel.py. Merge requires
that the checkpoint_mp_world_size % mp_world_size == 0. Support for
split (i.e., when mp_world_size % checkpoint_mp_world_size == 0) and
redistribute (for general mp_world_size and checkpoint_mp_world_size
values) will be added in the future.

Also changing multi_turn demo to use the new loading function with merge
support.

* move printing trainable params

* move training model creation back to cpu

Closes #15, #13"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-07-27T15:23:20Z,fix llama
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-07-27T11:55:48Z,llama　adapter inference
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-07-27T08:16:51Z,refactor stream_generate and multi-turn demo
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-07-26T12:46:58Z,"70b inference (#2)

support kv cache; change attention dispatch; rewrite multi-turn demo"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-07-25T07:47:29Z,llama peft support
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-07-25T06:23:44Z,refactor data configs to configs/data; add llama adapter
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-07-23T09:02:04Z,"flashattention, demo, and doc"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama.py,2023-07-21T10:19:19Z,init llama2-accessory
github.com/tyxsspa/AnyText,ldm/modules/encoders/modules.py,2023-12-26T13:36:32Z,inference code and demo
github.com/mlfoundations/open_clip,tests/util_test.py,2023-05-12T18:35:41Z,"Add EVA models (via timm backbone), torch.compile support, more (#500)

* Add EVA models (via timm backbone), torch.compile support, pure bf16/fp16 mode, safetensors push support

* Fix optional type refinement for torchscript

* Back torchcompile changes out of factory, needs to be closer to use for various reasons

* Fix output_dict + jit regression, remove native OpenAI jit load as it's not working reliably in PyTorch 2.0, always extract state-dict, load model, re-jit (if enabled)"
github.com/mlfoundations/open_clip,tests/util_test.py,2023-01-29T00:41:42Z,"Add coca trained (#307) (#308)

* Add coca trained (#307)

* initial setup

* add coca loss

* remove loss from the model

* fix loss

* add underscores

* name changes

* add cross attention to Residual and CustomResidual

* fix if

* ädd transformer 'decoder'

* minor fix

* looks better

* initlize coca model structure

* clean

* typo and format

* checkpoint signature

* adjust multimodal decoder and add CoCaTransformer

* keep older logic

* remove chunk

* typo

* fix

* make chunk dim explicit

* adjust cfg names

* add attentionalpooling

* add attentional pooling to coca

* small change

* add cocatransformer variants and AttentionPooling

* remoive older attention pooler

* adapt embed text to coca text transformer

* rm coca layers

* rename and remove useless CoCa models

* make attentionpooler pooler only

* refactor for one transformer only

* coca forward works

* separatae context and n_queries

* add inital coca_base config

* remove config

* small loss change

* init training file

* make variable order right

* remove print

* uniform names

* renaming

* add coca funcs to init

* add coca config and exclude from testing

* add and comment simple test (no trained model)

* add L2 norm

* make L2 same as in clip

* remove unused temperature

* type

* clean

* fix config

* make rename and move cfg

* rename

* temptative add coca to factory

* fix config

* update config

* embed contrastive cls token in model

* remove unused arg

* import create_loss

* make factory accept coca

* make caption loss distributed

* make loss customizable

* pass loss trhough training_epoch

* add coca specific params to params

* removed decoder unused parameters

* remove unused attributes

* adjust coca_config

* fix config and remove unused parameters

* remove comment

* remove more comments

* rename attention pooler

* rename TransformerDecoder

* make AttentionalPooler clearer

* add local loss logic to cocaloss

* only create loss if train in data

* remove wrong file

* fix attentional pooler call

* not ready for testing

* really not ready for testing

* eof lien

* uniform names

* add possible generative loss to evaluate

* change _build function names

* remove wrong import

* remove local_loss from captioning loss

* indexing error

* finish renaming

* adjust configs

* add training test for coca

* simplify captioning loss

* remove hf

* fix evaluate and loss

* remove print

* move projection

* add coca vit 32 config

* test on new config

* adjust coca_base config

* remove coca from test_inference

* maybe fix regression test

* make logits and labels contiguous

* simpler logic

* make contiguous after transpose

* last test

* try fix loss

* CoCa PR: loss fix + rename file

* wait for feedback on this

* cleanup

* CoCa PR: add set_grad_checkpointing + fix checkpoint API

* CoCa PR: fix eval (which uses encode_x instead of forward)

* move making space for CLS token into encode_text

* rever zs changes + fix

Co-authored-by: gpucce <g.puccetti92@gmail.com>
Co-authored-by: gpucce <g.puccetti@gmail.com>
Co-authored-by: iejmac <iejmac@ip-172-31-44-155.ec2.internal>

* Add coca to CI

* Add coca to CI pr

* simplify encode_iamge (#313)

Co-authored-by: Romain Beaumont <romain.rom1@gmail.com>

* Add cls mask (#312)

* buil_cls_mask

* add cls_mask to encode_text

* add model properties

Co-authored-by: Romain Beaumont <romain.rom1@gmail.com>
Co-authored-by: gpucce <g.puccetti@gmail.com>

* Ignore pad tokens in captioning loss (#316)

* add ignore_index

* just need to pick right index

Co-authored-by: gpucce <g.puccetti@gmail.com>

* add `generate` to coca model (#314)

* add initial generative support

* make generation context_length independend

* remove kwargs

* last positional embeddings for CLS

* typo

* fix mask len

* add comment

* remove unused args

* simpler logic for input shorter than context length

Co-authored-by: gpucce <g.puccetti@gmail.com>

* use `TextEncoder` in coca `encode_image` (#321)

* use self.text in encode image

* unused var

* rever aAtention and CustoResidualAttentionBlock

* remove whiteline

* add dict output

* bintegrate self.text attributes

* HF compatibility

* better config and minor fixes

* clean

* remove eembed_cls option from HF

* use cls_token_position

* fix cls masking

* resize labels

* text -> self.text

* split loss logging

* add total loss

* minor logs formatting

* fix generate

* simpler logic

* disentangle proj for HF too

* adjust config

* only norm cls

* move attn_pool to VisionTransformer

* adjust coca_base config

* fix grad checkpointing in MultimodalTransformer

Co-authored-by: gpucce <g.puccetti@gmail.com>
Co-authored-by: iejMac <kilianmaciej6@gmail.com>

* Get some basic PEP changes out of the way

* Add tests bis (#355)

* make jit compilable

* redundant annotation

* less tests

* less annotations

* even less annotations

* fix name check in ci

* some annotations back

* make it simpler

* make hf simpler too

* better jit support with tests

* remove extra line

* add customtextclip

* more jit tests

* missing assert

* add eval

* typo

* rever forward changes

* clean coca model

* more cleaning

* last cleaning

* train.py: fix is_clip when doing distributed (#364)

* add README (#365)

* add README

* multimodal_cfg info

* multimodal

* remove output_dict argument (#368)

* remove output_dict argument

* cleaner

* do same thing for _encode_image (#366)

* do same thing for _encode_image

* encoder

* try this

* adjust inference tests

* fix syntax

* True not None

* dumb

* CoCa/forward: remove unused output_dict param

* Revert ""do same thing for _encode_image (#366)""

This reverts commit de343fb73e9512c63bcbf3d902359c652580aef0.

* refactor

* white space

* remove extra layer norm

* move to_logits into decoder

* leave for later

* better torchscript

* annotate hf too

* Add CoCa-ViT-L/14 config (#379)

* Remove dead LN code, refactor attn_pool conditional for more clarity, minor formatting tweaks

* latent_dim to embed_dim

* remove extra cfg

* A bit more cleanup, keep context_length as context len, 'num_pos' to incl extra tokens. None type check for embed_cls instead of getattr

* CoCa: add B/32 pretrained (#389)

* add B/32 pretrained

* fix

* no capital

* slash

* remove coca from ci.yml

---------

Co-authored-by: gpucce <g.puccetti92@gmail.com>
Co-authored-by: gpucce <g.puccetti@gmail.com>
Co-authored-by: iejmac <iejmac@ip-172-31-44-155.ec2.internal>
Co-authored-by: iejMac <kilianmaciej6@gmail.com>
Co-authored-by: Ross Wightman <rwightman@gmail.com>"
github.com/mlfoundations/open_clip,tests/util_test.py,2022-12-09T00:40:09Z,"CI: on-the-fly data generation for regression test determinism (#260)

* CI on-the-fly data generation for regression tests

* delete old reg test data

* util_test.py option to create test data for specific git revision
skip instead of fail regression tests if data not found
register pytest markers in pytest.ini

* use sha instead of branch name if on a detached HEAD
fixed typo

* CI: save model list util_test to ensure no model names leak from test to reference

* CI: use marker instead of name filter to collect model names from pytest

* CI: use manual revision for checkout action

* util_test: avoid nested exception to make sure working tree is being restored on failure

* cache venv with minor version specific python
ensure durations file exists

* only pop stash if changes were stashed

* keep naming for env and durations cache the same

Co-authored-by: Romain Beaumont <romain.rom1@gmail.com>"
github.com/mlfoundations/open_clip,tests/util_test.py,2022-11-20T00:03:34Z,"create HF models without pretrained weights (#235)

HF model inference tests on random models"
github.com/mlfoundations/open_clip,tests/util_test.py,2022-11-17T17:32:24Z,"Parallelize CI tests (#228)

* parallelize CI tests

* disable macos testing for now, as it's slow

* typo

* util_test only import argparse if called as script"
github.com/mlfoundations/open_clip,tests/util_test.py,2022-11-12T17:49:07Z,inference testing using pre-generated data
github.com/mlcommons/training,stable_diffusion/ldm/models/clip_encoder.py,2023-06-15T00:15:33Z,Added Stable Diffusion (SD) benchmark (#656)
github.com/mlfoundations/open_clip,tests/test_inference.py,2023-01-29T00:41:42Z,"Add coca trained (#307) (#308)

* Add coca trained (#307)

* initial setup

* add coca loss

* remove loss from the model

* fix loss

* add underscores

* name changes

* add cross attention to Residual and CustomResidual

* fix if

* ädd transformer 'decoder'

* minor fix

* looks better

* initlize coca model structure

* clean

* typo and format

* checkpoint signature

* adjust multimodal decoder and add CoCaTransformer

* keep older logic

* remove chunk

* typo

* fix

* make chunk dim explicit

* adjust cfg names

* add attentionalpooling

* add attentional pooling to coca

* small change

* add cocatransformer variants and AttentionPooling

* remoive older attention pooler

* adapt embed text to coca text transformer

* rm coca layers

* rename and remove useless CoCa models

* make attentionpooler pooler only

* refactor for one transformer only

* coca forward works

* separatae context and n_queries

* add inital coca_base config

* remove config

* small loss change

* init training file

* make variable order right

* remove print

* uniform names

* renaming

* add coca funcs to init

* add coca config and exclude from testing

* add and comment simple test (no trained model)

* add L2 norm

* make L2 same as in clip

* remove unused temperature

* type

* clean

* fix config

* make rename and move cfg

* rename

* temptative add coca to factory

* fix config

* update config

* embed contrastive cls token in model

* remove unused arg

* import create_loss

* make factory accept coca

* make caption loss distributed

* make loss customizable

* pass loss trhough training_epoch

* add coca specific params to params

* removed decoder unused parameters

* remove unused attributes

* adjust coca_config

* fix config and remove unused parameters

* remove comment

* remove more comments

* rename attention pooler

* rename TransformerDecoder

* make AttentionalPooler clearer

* add local loss logic to cocaloss

* only create loss if train in data

* remove wrong file

* fix attentional pooler call

* not ready for testing

* really not ready for testing

* eof lien

* uniform names

* add possible generative loss to evaluate

* change _build function names

* remove wrong import

* remove local_loss from captioning loss

* indexing error

* finish renaming

* adjust configs

* add training test for coca

* simplify captioning loss

* remove hf

* fix evaluate and loss

* remove print

* move projection

* add coca vit 32 config

* test on new config

* adjust coca_base config

* remove coca from test_inference

* maybe fix regression test

* make logits and labels contiguous

* simpler logic

* make contiguous after transpose

* last test

* try fix loss

* CoCa PR: loss fix + rename file

* wait for feedback on this

* cleanup

* CoCa PR: add set_grad_checkpointing + fix checkpoint API

* CoCa PR: fix eval (which uses encode_x instead of forward)

* move making space for CLS token into encode_text

* rever zs changes + fix

Co-authored-by: gpucce <g.puccetti92@gmail.com>
Co-authored-by: gpucce <g.puccetti@gmail.com>
Co-authored-by: iejmac <iejmac@ip-172-31-44-155.ec2.internal>

* Add coca to CI

* Add coca to CI pr

* simplify encode_iamge (#313)

Co-authored-by: Romain Beaumont <romain.rom1@gmail.com>

* Add cls mask (#312)

* buil_cls_mask

* add cls_mask to encode_text

* add model properties

Co-authored-by: Romain Beaumont <romain.rom1@gmail.com>
Co-authored-by: gpucce <g.puccetti@gmail.com>

* Ignore pad tokens in captioning loss (#316)

* add ignore_index

* just need to pick right index

Co-authored-by: gpucce <g.puccetti@gmail.com>

* add `generate` to coca model (#314)

* add initial generative support

* make generation context_length independend

* remove kwargs

* last positional embeddings for CLS

* typo

* fix mask len

* add comment

* remove unused args

* simpler logic for input shorter than context length

Co-authored-by: gpucce <g.puccetti@gmail.com>

* use `TextEncoder` in coca `encode_image` (#321)

* use self.text in encode image

* unused var

* rever aAtention and CustoResidualAttentionBlock

* remove whiteline

* add dict output

* bintegrate self.text attributes

* HF compatibility

* better config and minor fixes

* clean

* remove eembed_cls option from HF

* use cls_token_position

* fix cls masking

* resize labels

* text -> self.text

* split loss logging

* add total loss

* minor logs formatting

* fix generate

* simpler logic

* disentangle proj for HF too

* adjust config

* only norm cls

* move attn_pool to VisionTransformer

* adjust coca_base config

* fix grad checkpointing in MultimodalTransformer

Co-authored-by: gpucce <g.puccetti@gmail.com>
Co-authored-by: iejMac <kilianmaciej6@gmail.com>

* Get some basic PEP changes out of the way

* Add tests bis (#355)

* make jit compilable

* redundant annotation

* less tests

* less annotations

* even less annotations

* fix name check in ci

* some annotations back

* make it simpler

* make hf simpler too

* better jit support with tests

* remove extra line

* add customtextclip

* more jit tests

* missing assert

* add eval

* typo

* rever forward changes

* clean coca model

* more cleaning

* last cleaning

* train.py: fix is_clip when doing distributed (#364)

* add README (#365)

* add README

* multimodal_cfg info

* multimodal

* remove output_dict argument (#368)

* remove output_dict argument

* cleaner

* do same thing for _encode_image (#366)

* do same thing for _encode_image

* encoder

* try this

* adjust inference tests

* fix syntax

* True not None

* dumb

* CoCa/forward: remove unused output_dict param

* Revert ""do same thing for _encode_image (#366)""

This reverts commit de343fb73e9512c63bcbf3d902359c652580aef0.

* refactor

* white space

* remove extra layer norm

* move to_logits into decoder

* leave for later

* better torchscript

* annotate hf too

* Add CoCa-ViT-L/14 config (#379)

* Remove dead LN code, refactor attn_pool conditional for more clarity, minor formatting tweaks

* latent_dim to embed_dim

* remove extra cfg

* A bit more cleanup, keep context_length as context len, 'num_pos' to incl extra tokens. None type check for embed_cls instead of getattr

* CoCa: add B/32 pretrained (#389)

* add B/32 pretrained

* fix

* no capital

* slash

* remove coca from ci.yml

---------

Co-authored-by: gpucce <g.puccetti92@gmail.com>
Co-authored-by: gpucce <g.puccetti@gmail.com>
Co-authored-by: iejmac <iejmac@ip-172-31-44-155.ec2.internal>
Co-authored-by: iejMac <kilianmaciej6@gmail.com>
Co-authored-by: Ross Wightman <rwightman@gmail.com>"
github.com/mlfoundations/open_clip,tests/test_inference.py,2023-01-23T19:44:52Z,rename timm models in tests
github.com/mlfoundations/open_clip,tests/test_inference.py,2022-12-29T07:17:23Z,Add xxlarge convnext and fix timm import for current pre-release of timm
github.com/mlfoundations/open_clip,tests/test_inference.py,2022-12-09T00:40:09Z,"CI: on-the-fly data generation for regression test determinism (#260)

* CI on-the-fly data generation for regression tests

* delete old reg test data

* util_test.py option to create test data for specific git revision
skip instead of fail regression tests if data not found
register pytest markers in pytest.ini

* use sha instead of branch name if on a detached HEAD
fixed typo

* CI: save model list util_test to ensure no model names leak from test to reference

* CI: use marker instead of name filter to collect model names from pytest

* CI: use manual revision for checkout action

* util_test: avoid nested exception to make sure working tree is being restored on failure

* cache venv with minor version specific python
ensure durations file exists

* only pop stash if changes were stashed

* keep naming for env and durations cache the same

Co-authored-by: Romain Beaumont <romain.rom1@gmail.com>"
github.com/mlfoundations/open_clip,tests/test_inference.py,2022-11-27T23:46:55Z,rename ViT-G to ViT-bigG (#251)
github.com/mlfoundations/open_clip,tests/test_inference.py,2022-11-21T22:03:27Z,"hf_model.py: support encoder-decoder models (#239)

* hf_model.py: support encoder-decoder models

* populate configs with some values

* update

* add test data and missing deps

* make context_length blank for mt5

* add mt5 xl

* remove xl from tests

Co-authored-by: Romain Beaumont <romain.rom1@gmail.com>"
github.com/mlfoundations/open_clip,tests/test_inference.py,2022-11-20T00:03:34Z,"create HF models without pretrained weights (#235)

HF model inference tests on random models"
github.com/mlfoundations/open_clip,tests/test_inference.py,2022-11-12T17:49:07Z,inference testing using pre-generated data
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/mixtral.py,2023-12-26T12:46:17Z,fix bug
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/mixtral.py,2023-12-24T09:16:25Z,additional loss print unweighted value
github.com/mlfoundations/open_clip,tests/test_inference_simple.py,2023-01-30T22:38:24Z,Cover jit and force_custom_text in simple tests
github.com/mlfoundations/open_clip,tests/test_inference_simple.py,2022-11-13T10:51:10Z,"Add roberta base ViT-B/32 pretrained. (#221)

* Add roberta base ViT-B/32 pretrained.

A ViT-B/32 with roberta base encoder with a 61.7% top-1 ImageNet-1k zero-shot was trained on stability. See model details here https://huggingface.co/laion/CLIP-ViT-B-32-roberta-base-laion2B-s12B-b32k
This is the first openclip model using a HF text tower. It has better performance on a range of tasks compared to the standard text encoder, see [metrics](https://huggingface.co/laion/CLIP-ViT-B-32-roberta-base-laion2B-s12B-b32k/blob/main/unknown.png)

* test"
github.com/mlfoundations/open_clip,tests/test_inference_simple.py,2022-11-10T10:23:24Z,"training/params.py: remove hf params and get them from model config (#215)

* zero_shot.py: set correct tokenizer based on args

* training/params.py: remove HF specific params, get those automatically from config

* set tokenizer in PreTrainedTextEncoder

* fix CsvDataset

* take tokenizer name from tokenizer

* Fix

* add tok name to test

* None

* update

* no need to store this anymore

* upadte README

* add tokenizer attribute

* remove useless code

* update example

* use model.tokenizer in test inference simple

* trying getattr

* syntax

* get_tokenizer

* factory fix

* fix test

* fix

* fix'

* add get-tokenizer to README + update exmaple

* update README

* zero-shot get_tokenizer

Co-authored-by: Romain Beaumont <romain.rom1@gmail.com>
Co-authored-by: iejmac <iejmac@gpu-st-p4d-24xlarge-4.hpc-1click-sandbox.pcluster>"
github.com/mlfoundations/open_clip,tests/test_inference_simple.py,2022-11-07T18:58:43Z,"Implement simple training test. (#203)

Only runs the training, no actual check except no crashes.

For #198"
github.com/ali-vilab/AnyDoor,ldm/modules/encoders/modules.py,2023-12-17T05:48:26Z,init
github.com/mlfoundations/open_clip,tests/test_download_pretrained.py,2023-01-23T23:59:33Z,Fetch from Hugging Face Hub using hf_hub: prefix
github.com/mlfoundations/open_clip,tests/test_download_pretrained.py,2022-11-07T13:49:38Z,fix download pretrained test
github.com/mlfoundations/open_clip,tests/test_download_pretrained.py,2022-11-07T13:34:49Z,Add checksum verification for pretrained model weights downloaded from mlfoundations github releases url (#145)
github.com/mlcommons/training,stable_diffusion/ldm/modules/encoders/modules.py,2023-06-21T22:07:16Z,Added Stable Diffusion (SD) benchmark - Part 2 (#661)
github.com/mlcommons/training,stable_diffusion/ldm/modules/encoders/modules.py,2023-06-15T00:15:33Z,Added Stable Diffusion (SD) benchmark (#656)
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens.py,2023-12-08T17:32:20Z,Merge remote-tracking branch 'origin/main'
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens.py,2023-12-08T04:51:59Z,fix typo
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens.py,2023-11-28T08:12:22Z,"Fix SPHINX inference memory with image input (#116)

* fix embedding precision w/ image to save memory

* pin gradio version"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens.py,2023-11-27T07:32:12Z,fix sphinx demo
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens.py,2023-11-23T17:14:43Z,fix sphinx sphinx-1k sphinx-2k quant (#113)
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens.py,2023-11-19T18:50:39Z,provide blip config in Accessory
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens.py,2023-11-19T11:07:03Z,params -> args
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens.py,2023-11-18T16:56:22Z,Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens.py,2023-11-09T16:45:40Z,clean up code and output
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens.py,2023-11-07T15:48:47Z,llama ens 10 ens5p2 pose demo
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens.py,2023-10-27T13:10:57Z,add ens5 &refactor transform
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens.py,2023-10-17T17:12:30Z,"support simplified env, fix demo bug"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens.py,2023-10-16T17:24:11Z,update demo & set llama_ens default to 13B
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens.py,2023-10-16T09:29:30Z,update
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens.py,2023-10-14T14:06:04Z,sort data list during dataset init for efficiency
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens.py,2023-08-27T04:33:52Z,codellama support
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens.py,2023-08-21T02:47:28Z,llama ens
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_peft.py,2023-12-10T18:55:51Z,mixtral support
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_peft.py,2023-12-08T04:51:59Z,fix typo
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_peft.py,2023-11-19T11:07:03Z,params -> args
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_peft.py,2023-11-18T16:56:22Z,Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_peft.py,2023-11-09T16:45:40Z,clean up code and output
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_peft.py,2023-10-17T17:12:30Z,"support simplified env, fix demo bug"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_peft.py,2023-08-27T04:33:52Z,codellama support
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_peft.py,2023-08-20T13:59:43Z,fix rope (more redundancy)
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_peft.py,2023-08-20T03:17:08Z,rope scale support
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_peft.py,2023-08-06T10:09:46Z,Move set_default_trainability to meta
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_peft.py,2023-08-06T04:55:53Z,fix sdpa kwargs
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_peft.py,2023-08-04T11:05:54Z,"Support loading models trained with different model_parallel_world_size. (#16)

* temp save

* quick fix of demo memory issue

* Refactor tensor creation dtype / device control.

This commit makes two changes during model creation:
1. Decouples promote_trainable_params_to_fp32 from model __init__. This
   is to avoid casting to fp32 to save memory in inference-only mode
   (#4).
2. Use a context manager to manage default tensor type change. In the
   previous version, the default tensor type is reset to
   torch.FloatTensor after creating the vision model, which is
   technically incorrect and should be the previous default tensor type
   instead. We implement our own context manager because the official
   context managers seem to be incomplete at this time (PyTorch 2.0.1):
   No dtype manager is provided and set_default_device is ineffective to
   the torch.Tensor calls which are used in fairscale.

* Change CLIP dtype management in llama.py

It is probably safer to keep CLIP at its original precision (e.g., fp16)
regardless of the autocast setting: Some casting (e.g., from fp16 to
bf16) may be lossy and can potentially harm the pre-trained model.

Keep the changes to llama.py only at this moment since a lot of copy-
pasted codes may be refactored in the future (#3).

* Respect args.precision when saving checkpoints.

* Support checkpoint merge

Checkpoint merge is suported in misc/tensor_parallel.py. Merge requires
that the checkpoint_mp_world_size % mp_world_size == 0. Support for
split (i.e., when mp_world_size % checkpoint_mp_world_size == 0) and
redistribute (for general mp_world_size and checkpoint_mp_world_size
values) will be added in the future.

Also changing multi_turn demo to use the new loading function with merge
support.

* move printing trainable params

* move training model creation back to cpu

Closes #15, #13"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_peft.py,2023-07-29T16:58:43Z,peft inference
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_peft.py,2023-07-25T07:47:29Z,llama peft support
github.com/modelscope/modelscope,modelscope/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py,2024-02-23T09:05:15Z,"fix text_to_video_synthesis_model device (#751)

Co-authored-by: slin000111 <zhaoshilin2015@sina.con>"
github.com/modelscope/modelscope,modelscope/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py,2023-08-15T04:01:03Z,"VideoComposer: Compositional Video Synthesis with Motion Controllability (#431)

* VideoComposer: Compositional Video Synthesis with Motion Controllability

* videocomposer pipeline

* pre commit

* delete xformers"
github.com/modelscope/modelscope,modelscope/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py,2023-07-14T08:22:10Z,"add parameters height and width for text-to-video 

Link: https://code.alibaba-inc.com/Ali-MaaS/MaaS-lib/codereview/13171907"
github.com/modelscope/modelscope,modelscope/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py,2023-03-08T16:57:43Z,"add text-to-video-synthesis

文本生成视频（text-to-video-synthesis）代码

Link: https://code.alibaba-inc.com/Ali-MaaS/MaaS-lib/codereview/11767775"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5.py,2023-12-08T17:32:20Z,Merge remote-tracking branch 'origin/main'
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5.py,2023-12-08T04:51:59Z,fix typo
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5.py,2023-11-28T08:12:22Z,"Fix SPHINX inference memory with image input (#116)

* fix embedding precision w/ image to save memory

* pin gradio version"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5.py,2023-11-27T07:32:12Z,fix sphinx demo
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5.py,2023-11-23T17:14:43Z,fix sphinx sphinx-1k sphinx-2k quant (#113)
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5.py,2023-11-19T18:50:39Z,provide blip config in Accessory
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5.py,2023-11-19T11:07:03Z,params -> args
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5.py,2023-11-18T16:56:22Z,Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5.py,2023-11-09T16:45:40Z,clean up code and output
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5.py,2023-11-07T15:48:47Z,llama ens 10 ens5p2 pose demo
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5.py,2023-10-27T13:10:57Z,add ens5 &refactor transform
github.com/openvinotoolkit/anomalib,src/anomalib/models/image/winclip/torch_model.py,2024-02-27T13:43:29Z,"🔨 Rename DynamicBufferModule to DynamicBufferMixin (#1776)

* Rename DynamicBufferModule to DynamicBufferMixin

* Add unit tests for DynamicBufferMixin

* Add logs to the changelog

* Add minor changes to the comments"
github.com/openvinotoolkit/anomalib,src/anomalib/models/image/winclip/torch_model.py,2024-01-24T12:19:17Z,"🚀 V1 (#1663)

* Merge feature/lightning-version-upgrade to feature/custom-trainer (#1297)

Upgrade to Lightning 2.0.5 (#1221)

* Adapt code and configs to PL 2.0.5

* Pre-commit checks.

* Fix a function call.

* Fix function calls.

* pytorch_lightning -> lightning.pytorch

* Add lightning to requirements

---------

Co-authored-by: Weilin Xu <mzweilin@gmail.com>
Co-authored-by: Samet <samet.akcay@intel.com>

* Partially restore tests (#1298)

* Upgrade to Lightning 2.0.5 (#1221)

* Adapt code and configs to PL 2.0.5

* Pre-commit checks.

* Fix a function call.

* Fix function calls.

* pytorch_lightning -> lightning.pytorch

* Add lightning to requirements

---------

Co-authored-by: Samet <samet.akcay@intel.com>

* partially restore tests

* Address PR comments

---------

Co-authored-by: Weilin Xu <mzweilin@gmail.com>
Co-authored-by: Samet <samet.akcay@intel.com>
Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* [Custom Trainer] Remove future annotations (#1299)

* remove __future__

* Update changelog

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* [Custom Trainer] Refactor postprocessing (#1302)

* remove __future__

* Update changelog

* 🚚 Trainer -> AnomalibTrainer

* add post-processor

* Refactor callback

* Remove handler

* Address PR comments

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* [Custom Trainer] refactor normalization callbacks (#1310)

* remove __future__

* Update changelog

* 🚚 Trainer -> AnomalibTrainer

* add post-processor

* Refactor callback

* Refactor normalization callback

* Match convention

* Refactor imports

* Address PR comments

* Fix path

* Refactor callbacks

* Fix module path

---------

* [Custom Trainer] Refactor thresholding (#1311)

* remove __future__

* Update changelog

* 🚚 Trainer -> AnomalibTrainer

* add post-processor

* Refactor callback

* Refactor normalization callback

* Refactor thresholding

* Match convention

* Refactor imports

* Address PR comments

* Fix path

* Refactor callbacks

* Fix module path

* Address PR comments

* Apply suggestions from code review

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

---------

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* [Custom Trainer] Refactor Metrics (#1312)

* remove __future__

* Update changelog

* 🚚 Trainer -> AnomalibTrainer

* add post-processor

* Refactor callback

* Refactor normalization callback

* Refactor thresholding

* Refactor metrics configuration

* Match convention

* Refactor imports

* Address PR comments

* Fix path

* Refactor callbacks

* Fix module path

* Address PR comments

* Address PR comments

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* [Custom Trainer] Refactor visualization callback (#1313)

* remove __future__

* Update changelog

* 🚚 Trainer -> AnomalibTrainer

* add post-processor

* Refactor callback

* Refactor normalization callback

* Refactor thresholding

* Refactor metrics configuration

* Move visualizer callbacks into trainer

* Match convention

* Refactor imports

* Address PR comments

* Fix path

* Refactor callbacks

* Fix module path

* Address PR comments

* Remove comment

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* [Custom Trainer] Initial engine design (#1348)

* Initial engine design

* Address PR comments

* Circular import + trainer->engine

* Update src/anomalib/engine/engine.py

* revert import in __init__

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>
Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* [Custom Trainer] Partially fix tests (#1359)

* Partially fix test

* Address PR comments

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* [Custom Trainer] Add CLI support (#1381)

* Support trainer methods

* support yaml serialization

* add hpo command

* Add benchmark + train entrypoint

* Add export arguments

* Partially address PR comments

* Add export subcommands + refactor

* Address PR comments

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* [Custom Trainer] Partially restore tests (#1391)

* Fix tests

* Patch get experiment logger

* Sort imports

* Add stfpm config

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* Add new ruff rules (#1390)

* Add rules to pyproject.toml file

* Only include padim and stfpm in tests

* Fix notebook tests

* Fix notebook tests

* Code quality/enable rules (#1394)

* pyflakes

* pycodestyle

* pep8-naming (`N`)

* Enable Ruff rules - Part III (#1397)

* pyflakes

* pycodestyle

* pep8-naming (`N`)

* pyupgrade (`UP`)

* flake8-bandit (`S`)

* Enabled UP, ANN, S, BLE, FBT, B

* Fix typo

* Revert F1AdaptiveThreshold parent classes

* Fix some of the tests

* ignore boolean-positional-value-in-call (FBT003)

* Addressed pr comments

* Remove duplicated lines

* Enable Ruff Rules - Part 4 (#1402)

* pyflakes

* pycodestyle

* pep8-naming (`N`)

* pyupgrade (`UP`)

* flake8-bandit (`S`)

* Enabled UP, ANN, S, BLE, FBT, B

* Fix typo

* Revert F1AdaptiveThreshold parent classes

* Fix some of the tests

* ignore boolean-positional-value-in-call (FBT003)

* Addressed pr comments

* Remove duplicated lines

* flake8-builtins (`A`) and flake8-commas (`COM`)

* flake8-comprehensions (`C4`)

* flake8-datatimez (`DTZ`), flake8-debugger (`T10`), flake8-errmsg (`EM`)

* [Custom Trainer] Switch to manual optimization for ganomaly (#1404)

* implement manual optimizers for ganomaly

* cleanup

* Enable Ruff Rules - Part 5 (#1403)

* pyflakes

* pycodestyle

* pep8-naming (`N`)

* pyupgrade (`UP`)

* flake8-bandit (`S`)

* Enabled UP, ANN, S, BLE, FBT, B

* Fix typo

* Revert F1AdaptiveThreshold parent classes

* Fix some of the tests

* ignore boolean-positional-value-in-call (FBT003)

* Addressed pr comments

* Remove duplicated lines

* flake8-builtins (`A`) and flake8-commas (`COM`)

* flake8-comprehensions (`C4`)

* flake8-datatimez (`DTZ`), flake8-debugger (`T10`), flake8-errmsg (`EM`)

* flake8-pie (`PIE`)

* flake8-raise (`RSE`)

* flake8-return (`RET`)

* flake8-self (`SLF`)

* flake8-simplify (`SIM`)

* flake8-unsused-arguments (`ARG`)

* Update src/anomalib/models/components/flow/all_in_one_block.py

Co-authored-by: Ashwin Vaidya <ashwinnitinvaidya@gmail.com>

* addressed pr comments

---------

Co-authored-by: Ashwin Vaidya <ashwinnitinvaidya@gmail.com>

* [Custom Trainer] Add import checks (#1393)

* Add checks

* Add checks for wandb

* move exception handling to method

* fix pre-commit issue

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* [Custom Trainer] Remove max epochs > 1 (#1400)

Remove max epochs>1 from default param list

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* [Custom Trainer] Add default values (#1395)

* Add checks

* Add default values to datasets + padim model

* update default values

* Remove merge artifact

* Change gt path

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* Enable Ruff Rules - Part 6 (#1407)

* pyflakes

* pycodestyle

* pep8-naming (`N`)

* pyupgrade (`UP`)

* flake8-bandit (`S`)

* Enabled UP, ANN, S, BLE, FBT, B

* Fix typo

* Revert F1AdaptiveThreshold parent classes

* Fix some of the tests

* ignore boolean-positional-value-in-call (FBT003)

* Addressed pr comments

* Remove duplicated lines

* flake8-builtins (`A`) and flake8-commas (`COM`)

* flake8-comprehensions (`C4`)

* flake8-datatimez (`DTZ`), flake8-debugger (`T10`), flake8-errmsg (`EM`)

* flake8-pie (`PIE`)

* flake8-raise (`RSE`)

* flake8-return (`RET`)

* flake8-self (`SLF`)

* flake8-simplify (`SIM`)

* flake8-unsused-arguments (`ARG`)

* flake8-use-pathlib (`PTH`)

* eradicate (`ERA`)

* pylint (`PL`)

* tryceratos (`TRY`), flynt (`FLY`), Perflint (`PERF`)

* NumPy-specific rules (`NPY`)

* Ruff-specific rules (`RUF`)

* Remove pylint ignore comments

* Fix tests

* Fix tests

* Enable Ruff Rules - Part 7 (#1408)

* pyflakes

* pycodestyle

* pep8-naming (`N`)

* pyupgrade (`UP`)

* flake8-bandit (`S`)

* Enabled UP, ANN, S, BLE, FBT, B

* Fix typo

* Revert F1AdaptiveThreshold parent classes

* Fix some of the tests

* ignore boolean-positional-value-in-call (FBT003)

* Addressed pr comments

* Remove duplicated lines

* flake8-builtins (`A`) and flake8-commas (`COM`)

* flake8-comprehensions (`C4`)

* flake8-datatimez (`DTZ`), flake8-debugger (`T10`), flake8-errmsg (`EM`)

* flake8-pie (`PIE`)

* flake8-raise (`RSE`)

* flake8-return (`RET`)

* flake8-self (`SLF`)

* flake8-simplify (`SIM`)

* flake8-unsused-arguments (`ARG`)

* flake8-use-pathlib (`PTH`)

* eradicate (`ERA`)

* pylint (`PL`)

* tryceratos (`TRY`), flynt (`FLY`), Perflint (`PERF`)

* NumPy-specific rules (`NPY`)

* Ruff-specific rules (`RUF`)

* Remove pylint ignore comments

* Fix tests

* Fix tests

* mccabe (`C90`)

* pygrep-hooks (`PGH`)

* flake8-todos (`TD`)

* flake8-fixme (`FIX`)

* pandas-vet (`PD`)

* Fix random_split tests

* Fix pre-commit

* Fixed the logger test

* Fix the typos in todos

* Enable Ruff Rules - Part 8 (#1412)

* pyflakes

* pycodestyle

* pep8-naming (`N`)

* pyupgrade (`UP`)

* flake8-bandit (`S`)

* Enabled UP, ANN, S, BLE, FBT, B

* Fix typo

* Revert F1AdaptiveThreshold parent classes

* Fix some of the tests

* ignore boolean-positional-value-in-call (FBT003)

* Addressed pr comments

* Remove duplicated lines

* flake8-builtins (`A`) and flake8-commas (`COM`)

* flake8-comprehensions (`C4`)

* flake8-datatimez (`DTZ`), flake8-debugger (`T10`), flake8-errmsg (`EM`)

* flake8-pie (`PIE`)

* flake8-raise (`RSE`)

* flake8-return (`RET`)

* flake8-self (`SLF`)

* flake8-simplify (`SIM`)

* flake8-unsused-arguments (`ARG`)

* flake8-use-pathlib (`PTH`)

* eradicate (`ERA`)

* pylint (`PL`)

* tryceratos (`TRY`), flynt (`FLY`), Perflint (`PERF`)

* NumPy-specific rules (`NPY`)

* Ruff-specific rules (`RUF`)

* Remove pylint ignore comments

* Fix tests

* Fix tests

* mccabe (`C90`)

* pygrep-hooks (`PGH`)

* flake8-todos (`TD`)

* flake8-fixme (`FIX`)

* pandas-vet (`PD`)

* ignore ANN101 ANN102 and ANN103

* Fix random_split tests

* Fix pre-commit

* ANN partly done

* Remove kwargs: Any

* flake8-annotations (`ANN`)

* Enabled tests

* Revert padim configs

* Enable Ruff Rules - Part 9 (#1419)

* pyflakes

* pycodestyle

* pep8-naming (`N`)

* pyupgrade (`UP`)

* flake8-bandit (`S`)

* Enabled UP, ANN, S, BLE, FBT, B

* Fix typo

* Revert F1AdaptiveThreshold parent classes

* Fix some of the tests

* ignore boolean-positional-value-in-call (FBT003)

* Addressed pr comments

* Remove duplicated lines

* flake8-builtins (`A`) and flake8-commas (`COM`)

* flake8-comprehensions (`C4`)

* flake8-datatimez (`DTZ`), flake8-debugger (`T10`), flake8-errmsg (`EM`)

* flake8-pie (`PIE`)

* flake8-raise (`RSE`)

* flake8-return (`RET`)

* flake8-self (`SLF`)

* flake8-simplify (`SIM`)

* flake8-unsused-arguments (`ARG`)

* flake8-use-pathlib (`PTH`)

* eradicate (`ERA`)

* pylint (`PL`)

* tryceratos (`TRY`), flynt (`FLY`), Perflint (`PERF`)

* NumPy-specific rules (`NPY`)

* Ruff-specific rules (`RUF`)

* Remove pylint ignore comments

* Fix tests

* Fix tests

* mccabe (`C90`)

* pygrep-hooks (`PGH`)

* flake8-todos (`TD`)

* flake8-fixme (`FIX`)

* pandas-vet (`PD`)

* ignore ANN101 ANN102 and ANN103

* Fix random_split tests

* Fix pre-commit

* ANN partly done

* Remove kwargs: Any

* flake8-annotations (`ANN`)

* Enabled tests

* Revert padim configs

* Add auto fixes

* Fix docstrings

* Update src/anomalib/utils/metrics/binning.py

Co-authored-by: Ashwin Vaidya <ashwinnitinvaidya@gmail.com>

* Update src/anomalib/models/dfkde/lightning_model.py

Co-authored-by: Ashwin Vaidya <ashwinnitinvaidya@gmail.com>

* Update src/anomalib/models/rkde/feature_extractor.py

Co-authored-by: Ashwin Vaidya <ashwinnitinvaidya@gmail.com>

* Fixed pre-commit

---------

Co-authored-by: Ashwin Vaidya <ashwinnitinvaidya@gmail.com>

* Merge main into feature/custom_trainer (#1420)

* Address tiler issues (#1411)

* fix tiler

* deprecate random tile locations

* restore random tiling in tile method

* check tiling section in config

* disable tiling for ganomalu

* pad -> padding

* Refactor Reverse Distillation to match official code (#1389)

* Non-mandatory early stopping

* Added conv4 and bn4 to OCBE

* Loss as in the official code (flattened arrays)

* Added comment on how to use torchvision model as an encoder to reproduce results in the paper

* Remove early stop from config, change default anomaly_map_mode to add

* pre-commit fix

* Updated results

* Update src/anomalib/models/reverse_distillation/README.md

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update src/anomalib/models/reverse_distillation/README.md

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update src/anomalib/models/reverse_distillation/README.md

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Remove early_stopping

* Update src/anomalib/models/reverse_distillation/lightning_model.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Easier to read code

---------

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

---------

Co-authored-by: Dick Ameln <dick.ameln@intel.com>
Co-authored-by: abc-125 <63813435+abc-125@users.noreply.github.com>
Co-authored-by: Samet Akcay <samet.akcay@intel.com>
Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* Enable Ruff Rules - Part 10 (#1423)

* pyflakes

* pycodestyle

* pep8-naming (`N`)

* pyupgrade (`UP`)

* flake8-bandit (`S`)

* Enabled UP, ANN, S, BLE, FBT, B

* Fix typo

* Revert F1AdaptiveThreshold parent classes

* Fix some of the tests

* ignore boolean-positional-value-in-call (FBT003)

* Addressed pr comments

* Remove duplicated lines

* flake8-builtins (`A`) and flake8-commas (`COM`)

* flake8-comprehensions (`C4`)

* flake8-datatimez (`DTZ`), flake8-debugger (`T10`), flake8-errmsg (`EM`)

* flake8-pie (`PIE`)

* flake8-raise (`RSE`)

* flake8-return (`RET`)

* flake8-self (`SLF`)

* flake8-simplify (`SIM`)

* flake8-unsused-arguments (`ARG`)

* flake8-use-pathlib (`PTH`)

* eradicate (`ERA`)

* pylint (`PL`)

* tryceratos (`TRY`), flynt (`FLY`), Perflint (`PERF`)

* NumPy-specific rules (`NPY`)

* Ruff-specific rules (`RUF`)

* Remove pylint ignore comments

* Fix tests

* Fix tests

* mccabe (`C90`)

* pygrep-hooks (`PGH`)

* flake8-todos (`TD`)

* flake8-fixme (`FIX`)

* pandas-vet (`PD`)

* ignore ANN101 ANN102 and ANN103

* Fix random_split tests

* Fix pre-commit

* ANN partly done

* Remove kwargs: Any

* flake8-annotations (`ANN`)

* Enabled tests

* Revert padim configs

* Add auto fixes

* Fix docstrings

* Enabled ""PLW2901"",  # `for` loop variable `row` overwritten by assignment target

* Enable Ruff Rules - Part 11 (#1425)

* pyflakes

* pycodestyle

* pep8-naming (`N`)

* pyupgrade (`UP`)

* flake8-bandit (`S`)

* Enabled UP, ANN, S, BLE, FBT, B

* Fix typo

* Revert F1AdaptiveThreshold parent classes

* Fix some of the tests

* ignore boolean-positional-value-in-call (FBT003)

* Addressed pr comments

* Remove duplicated lines

* flake8-builtins (`A`) and flake8-commas (`COM`)

* flake8-comprehensions (`C4`)

* flake8-datatimez (`DTZ`), flake8-debugger (`T10`), flake8-errmsg (`EM`)

* flake8-pie (`PIE`)

* flake8-raise (`RSE`)

* flake8-return (`RET`)

* flake8-self (`SLF`)

* flake8-simplify (`SIM`)

* flake8-unsused-arguments (`ARG`)

* flake8-use-pathlib (`PTH`)

* eradicate (`ERA`)

* pylint (`PL`)

* tryceratos (`TRY`), flynt (`FLY`), Perflint (`PERF`)

* NumPy-specific rules (`NPY`)

* Ruff-specific rules (`RUF`)

* Remove pylint ignore comments

* Fix tests

* Fix tests

* mccabe (`C90`)

* pygrep-hooks (`PGH`)

* flake8-todos (`TD`)

* flake8-fixme (`FIX`)

* pandas-vet (`PD`)

* ignore ANN101 ANN102 and ANN103

* Fix random_split tests

* Fix pre-commit

* ANN partly done

* Remove kwargs: Any

* flake8-annotations (`ANN`)

* Enabled tests

* Revert padim configs

* Add auto fixes

* Fix docstrings

* Enabled ""PLW2901"",  # `for` loop variable `row` overwritten by assignment target

* Add google style to pydocstyle

* Remove dashed line from Returns

* Remove dashed line from Args

* Remove dashed line from Example and Raises

* Removed left-over dashed lines

* Cleanup pyproject.toml file

* [Custom Trainer] Add a verbose help output structure to the CLI (#1396)

* Add Verbosity Help-Formatter class

* Add Help-Formatter unit-tests

* Fix some strings

* Fix pre-commit ruff stuff

* Fix help_formatter's pre-commit

* Add new configs (#1418)

* Add new configs

* Add draem config

* Fix docstring

* Update src/anomalib/models/cflow/lightning_model.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Linting

* Remove --- from docstrings

* Remove any from return type

* Fix linting issues from feature/custom_trainer

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>
Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Add CLI Tests (#1426)

* Add new configs

* Add draem config

* Stash cli tests

* Stash cli tests with minor changes

* Stash changes

* Fix reverse distillation

* Fix EfficientAD

* Match ai_vad params to config params

* Fix ucsd and ai_vad configs

* Uncomment validation step

* Refactor directory structure

* Rename method

* use uscd for aivad

* fix ucsd path + modify model checkpoint callback for tests

* fix dfkde config

* Restructure tests + fix normalization test

* Revert file

* add v1 to tox

* Skip testing ai_vad

* Increase train and test size

* use mvtec dataset

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* Restructure test directories. (#1438)

* Restructured the test directories

* Fixed typo

* Fix imports

* Fix config path in export tests

* Replace black with ruff formatter (#1439)

* [Custom Trainer] Refactor export (#1440)

* Refactor export

* Fix entrypoint tests

* remove match statements

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* Add ruff checks to tests (#1455)

* Fix tests + add ruff check to tests

* Limit gradio version

* Path->str

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* Add dummy image dataset generator helper class (#1444)

* Created tests/v1 directory

* update license year

* Add beantech generator

* Refactor mvtec-ad and beantech

* Add visa dataset generator

* Add DummyImageGenerator

* Use DummyImageGenerator in dummy mvtec dataset generator

* Use DummyImageGenerator in dummy mvtec dataset generator

* Use DummyImageGenerator in dummy mvtec3d dataset generator

* Restructured the test directories

* Fixed typo

* Fix imports

* Fix config path in export tests

* Add kolektor dataset

* add ucsdped generator

* Fix tests

* Revert conftest.py

* add method for generating avenue dataset

* Revert conftest.py

* add method for generating shanghaitech dataset

* swap order of typing for better parsing of normalization type

* cleanup

* Dynamically create DataFormat enum

* Add examples to docstring

* address pr comments and rename dataset.py to data.py

* Fix pre-commit issues

---------

Co-authored-by: Dick Ameln <dick.ameln@intel.com>

* Remove configurable parameters (#1453)

* Refactor export

* Fix entrypoint tests

* remove match statements

* Fix tests + remove get_configurable_params + fix hpo,benchmarking

* Path->str

* Update src/anomalib/models/__init__.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update src/anomalib/utils/sweep/config.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update tools/inference/README.md

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update tools/inference/README.md

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* str->Path

* str->Path

* Fix model checkpoint path

* typing + path + test order

* Update src/anomalib/utils/sweep/config.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Mark tests as xfail

* Fix notebook

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>
Co-authored-by: Dick Ameln <amelndjd@gmail.com>
Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* [v1] - Tests: Add datamodule tests. (#1456)

* Created tests/v1 directory

* update license year

* Add beantech generator

* Refactor mvtec-ad and beantech

* Add visa dataset generator

* Add DummyImageGenerator

* Use DummyImageGenerator in dummy mvtec dataset generator

* Use DummyImageGenerator in dummy mvtec dataset generator

* Use DummyImageGenerator in dummy mvtec3d dataset generator

* Restructured the test directories

* Fixed typo

* Fix imports

* Fix config path in export tests

* Add kolektor dataset

* add ucsdped generator

* Fix tests

* Revert conftest.py

* add method for generating avenue dataset

* Revert conftest.py

* add method for generating shanghaitech dataset

* swap order of typing for better parsing of normalization type

* cleanup

* create the data tests files

* Dynamically create DataFormat enum

* Add examples to docstring

* add conftest.py

* address pr comments and rename dataset.py to data.py

* add some changes

* Add test_datasets to the integration tests

* Change order

* Added datamodule tests

* Format ruff

* Address pre-commit issues

* Fix video tests

* Add the rest of the datamodule tests

---------

Co-authored-by: Dick Ameln <dick.ameln@intel.com>

* [Custom Trainer] Add train subcommand (#1465)

Add train subcommand

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* Refactor `Tensor` annotation to `torch.Tensor` (#1477)

* Modify Tensor to torch.Tensor

* list[Tensor] to list[torch.Tensor]

* TODO: Fix formatting issues

* torch_all to torch.all

* Remove redundant import

* Apply ruff format

* Fix the tests

* Refactor tests Part 1 (#1473)

* Refactor CLI tests

* Select a random model

* Fix test for all the models

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* Add API tests Part 2 (#1474)

* Partially migrate unit tests Part 3 (#1480)

* Refactor CLI tests

* Add api tests

* Select a random model

* Fix test for all the models

* Fix API tests

* refactor pre-post processing + get model ckpt from fixture

* Add tests for custom transforms

* Address PR comments

* Refactor ckpt_path fixture

* Update conftest.py

* Update __init__.py

* Update __init__.py

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>
Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Reorg Part I: Data (#1483)

* Update Anomalib data with the new structure

* Update dataset imports and remove unused imports

* ruff format in engine.py

* Move TaskType to utils/types

* Revert TaskType import from anomalib

* Revert tox.ini

* Refactor imports and fix import errors

* Fix import errors and update type annotations

* Fix imports in jupyter notebooks

* Refactor import statements in test_visualizer.py

* Reorg Part II: Remove `pre_processor` and `post_processor` subpackages (#1485)

* Update Anomalib data with the new structure

* Update dataset imports and remove unused imports

* ruff format in engine.py

* Move TaskType to utils/types

* Revert TaskType import from anomalib

* Revert tox.ini

* Refactor imports and fix import errors

* Fix import errors and update type annotations

* Fix imports in jupyter notebooks

* Remove pre-processor subpackage from anomalib

* Remove unused imports and update import paths

* Refactor import statements in test_visualizer.py

* Remove unused code and deprecate Denormalize and
ToNumpy classes

* Remove empty code cell

* Add a description why input image is read from path

* Fix bug in superimpose

* Migrate deploy tests Part 4 (#1481)

* Refactor CLI tests

* Add api tests

* Select a random model

* Fix test for all the models

* Fix API tests

* refactor pre-post processing + get model ckpt from fixture

* Add tests for custom transforms

* Migrate deploy tests

* trained_padim_path->ckpt_path

* Split normalization line

* Fix normalization class path

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* Migrate model components unit tests Part 5 (#1482)

* Refactor CLI tests

* Add api tests

* Select a random model

* Fix test for all the models

* Fix API tests

* refactor pre-post processing + get model ckpt from fixture

* Add tests for custom transforms

* Migrate deploy tests

* Migrate model component tests

* Migrate visualizer callback + cli tests

* Fix lightning entrypoint test

* trained_padim_path->ckpt_path

* Add todo

* Fix TaskType import

* Apply suggestions from code review

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>
Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Reorg Part III: Move the main anomalib components from `anomalib.utils` to `anomalib` (#1487)

* Update Anomalib data with the new structure

* Update dataset imports and remove unused imports

* ruff format in engine.py

* Move TaskType to utils/types

* Revert TaskType import from anomalib

* Revert tox.ini

* Refactor imports and fix import errors

* Fix import errors and update type annotations

* Fix imports in jupyter notebooks

* Remove pre-processor subpackage from anomalib

* Remove unused imports and update import paths

* Refactor import statements in test_visualizer.py

* Move callbacks from utils under anomalib

* Fix import statements in benchmarking and CLI
modules

* Move CLI under anomalib

* Add benchmark to pipelines

* Move hpo to pipelines

* Move sweep to pipelines

* Move loggers to anomalib

* Move metrics to anomalib

* Move callbacks from utils to test/utils

* Move config to anomalib.utils

* Fix the metric imports

* Remove unused code and deprecate Denormalize and
ToNumpy classes

* Remove empty code cell

* Add a description why input image is read from path

* Fix bug in superimpose

* Move anomalib.utils.config.config to anomalib.utils.config

* Fix config import

* Merge feature/custom_trainer

* Migrate tools test Part 6 (#1488)

* Refactor CLI tests

* Add api tests

* Select a random model

* Fix test for all the models

* Fix API tests

* refactor pre-post processing + get model ckpt from fixture

* Add tests for custom transforms

* Migrate deploy tests

* Migrate model component tests

* Migrate visualizer callback + cli tests

* Fix lightning entrypoint test

* trained_padim_path->ckpt_path

* Migrate metrics tests

* Migrate tools + remove nightly

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* 🚜 Refactor padim and patchcore models (#1300)

* Fix metadata path

* Ignore hidden directories in folder dataset

* Add check for mask_dir for segmentation tasks in Folder dataset

* add is_fitted

* self.model._is_fitted to self.model.is_fitted

* Format anomaly module

* Remove on_save_checkpoint

* Refactor padim

* Add __repr__ to anomaly score threshold

* Revert patchcore config

* Add memory bank modules for anomaly detection

* Add explanation to MemoryBankTorchModule docstring.

* Update memory bank module imports and fix typo in
Padim model

* Rename Dynamic Buffer Module to Memory Bank
Module in docstring.

* Revert ""Add explanation to MemoryBankTorchModule docstring.""

This reverts commit 44c991450f7c78eee2b0ceb0e7c855c3893a0801.

* Refactor memory bank modules based on Dick's suggestion

* Fix model attribute assignment in lightning models

* Add MemoryBankMixin to anomaly detection models

* revert padim and patchcore

* Reorder inheritance in anomaly detection models

---------

Co-authored-by: Ashwin Vaidya <ashwin.vaidya@intel.com>

* Migrate unit tests Part 7 (#1490)

* Refactor CLI tests

* Add api tests

* Select a random model

* Fix test for all the models

* Fix API tests

* refactor pre-post processing + get model ckpt from fixture

* Add tests for custom transforms

* Migrate deploy tests

* Migrate model component tests

* Migrate visualizer callback + cli tests

* Fix lightning entrypoint test

* trained_padim_path->ckpt_path

* Migrate metrics tests

* Migrate tools + remove nightly

* Increase coverage

* Migrate remaining tests

* Fix imports

* Fix import

* Update tests/unit/deploy/test_inferencer.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update test_get_logger.py

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>
Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Fix circular import in cdf normalizer (#1494)

* fix circular import in cdf normalizer

* fix pre-commit

---------

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* 🛠️ Refactor: Split models to image and video (#1493)

* Move AiVad to anomalib.video

* Move cfa to models.image

* Add Ganomaly model to image models

* Add Fastflow model to image models

* Add EfficientAd anomaly detection model to image
models

* Move dfm, dfkde and draem

* Add CS-Flow model implementation for image-based
defect detection

* Add cflow to image models

* Add padim to image models

* Add patchcore to image models

* Add Reverse distillation to image models.

* Add rkde to image models

* Add stfpm to image models.

* Add image models for handling image datasets in
anomalib

* Update copyright year in model files

* Update import statement for Fastflow model

* Update image and video model documentation

* Update src/anomalib/models/video/README.md

Co-authored-by: Dick Ameln <amelndjd@gmail.com>

* Update clip_length_in_frames parameter in
AvenueDataset and Avenue classes

* Remove folder references

* Fix a typo in readme

* Fix shape of image in batch

* Update clip_length_in_frames parameter

---------

Co-authored-by: Dick Ameln <amelndjd@gmail.com>

* v1: Update the readme file (#1503)

* Fix metadata path

* Ignore hidden directories in folder dataset

* Add check for mask_dir for segmentation tasks in Folder dataset

* Replace docs

* Add each inferencing scripts as a details section

* update readme

* Add training

* modify getting started

* Make getting started a subsection

* tmp

* Added inference section

* Refactor Lightning inference code

* Update entry point in setup.py

* Add training api example to readme

* Update training command in README

* Fix bug in login functionality

* Update HPO and Logging Documentation

* refactor getting started section

* Update HPO and benchmarking commands

* Update the image

* Update README.md

Co-authored-by: Dick Ameln <amelndjd@gmail.com>

* Update README.md

Co-authored-by: Dick Ameln <amelndjd@gmail.com>

* Remove getting started section

* Update README.md

Co-authored-by: Dick Ameln <amelndjd@gmail.com>

* Update README.md

Co-authored-by: Dick Ameln <amelndjd@gmail.com>

* Address the reviewer comments

---------

Co-authored-by: Dick Ameln <amelndjd@gmail.com>

* Extend Engine Tests (#1509)

* Add validate + predict

* Add train

* Add export tests + refactor export cli command

* Fix tests

* Fix jupyternotebook

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* v1: Create the new documentation via `sphinx-design` and `myst` (#1518)

* removed docs

* Created the new docs

* Finished get started

* Remove jupyter notebook from docs

* Add mvtec to data

* Add reference guide

* Add section for each image datasets

* Add base data modules and datasets

* v1 - 📝 Update and Enhance Docstrings (#1532)

* removed docs

* Created the new docs

* Finished get started

* Remove jupyter notebook from docs

* Add mvtec to data

* Add reference guide

* initial commit

* Remove subrocess from btech

* Remove unused import and commented out code

* Add section for each image datasets

* Add base data modules and datasets

* Refactor dataset classes and add docstrings

* Add initial draft for backbone docs

* Update the docstring in folder_3d

* Update mvtec 3d docstring

* Added feature extractor tutorial

* Add a readme file to the docs

* Update folder data docstring

* Update kolektor docstrings

* Update kolektor docstring

* Update mvtec docstring

* Update visa docstrings

* Update avenue docstring

* Update cfa docstring

* Update cflow docstring

* Update csflow docstring

* Update csflow docstring

* Update dfkde docstrings

* Update dfm docstring

* Update draem docstring

* Update efficient ad docstring

* Update ganomaly docstring

* Update padim and patchcore docstrings

* Update reverse distillation docstring

* update rkde docstring

* update stfpm docstring

* Update ai-vad docstring

* Update feature extractors

* add docstring to sparse random projection

* Update dimensionality reduction components

* Exclude prompt from copying

* Normalizing flow update

* Add pro

* Add feature extractor docs

* update aupr

* Update aupr

* Update aupro

* Update auroc

* Update docs/source/markdown/guides/how_to/models/feature_extractors.md

* Update f1 and manual thresholds

* add minmax

* add optimal f1

* update utils

* update comet

* add tensorboard

* update wandb

* Add callbacks

* Update deploy docstrings

* Fix pre-commit on Blasz changes

* Change the requirement file in readthedocs config file

* Partially address pr comments

* Fix the model to padim for the cli integration tests

---------

Co-authored-by: Blaž Rolih <61357777+blaz-r@users.noreply.github.com>
Co-authored-by: Blaz Rolih <blaz.rolih@gmail.com>

* Fix AI-VAD issues (#1524)

* partially fix empty bbox issue

* allow empty region detections

* add torch implementation of gmm (WIP)

* make knn mem bank persistent

* set val_split_mode to same_as_test as default to enforce deterministicness

* add unit tests and docstrings to gmm

* improve typing of knn estimator

* remove todo

* update buffer name

* fix minor mistakes in gmm implementation

* remove unnecessary tensor conversion

* fix visualization when predicting with video model

* add __init__.py to components.cluster

* check for empty bboxes in feature extractor

* reduce default batch size

* cast deep features to float

* fix device issue

* add unit tests for feature extractors

* add license header

* disable random model selection in integration tests

* typing and docstrings

* add test case for non-convergence warning

* 📝  v1 - Docs: Create a dedicated section for each model. (#1540)

* Initial commit for model components

* FIx the grid in model components

* Add image models

* Add video models

* Fix titles and do some cleanup

* reduce the sphinx version as it fails the readthedocs builds

* Fix examples for reading transforms from albumentations Compose object and deserializing from a yaml file

* Update __init__.py

* OpenVINO NNCF updates (#1534)

* Update versions of openvino and nncf

* All export functions return the model path

* Change default OV device to AUTO

* Minor changes on openvino API

* Fix pre-commit issues

* Restored onnx dependency

* Added OV export tests

* Drop export tests

* Rename path var

* Renamed test paths

* [Docs] Add average score to the FastFlow's performance results tables (#1587)

Add average score in the tables of performance results

* Update the paper title in CS-FLOW and CFLOW readme (#1579)

* Fix csflow name in readme

* Update cflow name in readme

* v1 - [Refactor] Reflect the changes in #1562 into v1 (#1595)

Reflect the changes in #1562 into v1

* ✏️ Refactor `ExportMode` to `ExportType` (#1594)

* Update export_mode to export_type

* Fix typo typel -> model

* Revert the python version in the notebook

* 📚 v1 - Modify the PR template (#1596)

* Modify the PR template

* Update pull_request_template.md

* added emojis to the checklist

* [Bug] v1: Fix default input normalization method (#1583)

Fix default input normalization method

* Modify `Engine.predict` (#1514)

* Add validate + predict

* Add train

* Add export tests + refactor export cli command

* Fix tests

* Fix jupyternotebook

* Update engine.predict + expand tests

* Fix lightning entrypoint test

* Address PR comments

* Use only Padim

* Fix commands

* Move padim to common args

* Address 1st PR comment

* Address PR comments

* Fix aivad tests

* Fix missing docstring

* Rename config to args

* Add missing ckpt_path warning in predict

* Remove ckpt_path as required parameter

* Add tests for image path in predict

* Fix image path in predict

* Address PR comments

* Fix missing checkpoint path

* Fix fastflow precommit issue

* Fix tests

* Fix test

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* Fix issue with incorrect image save location (#1515)

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* Upgrade gradio version to 4.x (#1608)

* upgrade gradio version to 4.x

* refactor variable names

* refactor

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* ✍ InferenceDataset->PredictDataset (#1544)

* ✍ InferenceDataset->PredictDataset

* update predict dataset references

* update predict dataset references

* update predict dataset references

* update predict dataset references

* update predict dataset references

* update notebook

---------

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* `FeatureExtractor` -> `TimmFeatureExtractor` (#1543)

Deprecate FeatureExtractor

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* Add `LearningType` and refactor enums (#1598)

* add LearningType and move enums to separate module

* add enum definitions

* move shared enums to root init

* place version above enums

* 📘 Add custom data tutorial (#1571)

* Add custom data tutorial

* Add the custom data training instructions

* Address PR comments

* Start with a classification data

* Release hazelnut toy dataset and refer to the link here.

* Update docs/source/markdown/guides/how_to/data/custom_data.md

Co-authored-by: Dick Ameln <amelndjd@gmail.com>

* Update docs/source/markdown/guides/how_to/data/custom_data.md

Co-authored-by: Dick Ameln <amelndjd@gmail.com>

* Update docs/source/markdown/guides/how_to/data/custom_data.md

Co-authored-by: Dick Ameln <amelndjd@gmail.com>

* Remove no-val-test section from tutorials

* Address PR comments

---------

Co-authored-by: Dick Ameln <amelndjd@gmail.com>
Co-authored-by: Samet Akcay <sakcay@Samets-MacBook-Pro.local>

* Add URL verification for downloading dataset (#1620)

* add url path verification for dataset downloading module

* specify node version to pre-commit-config

* fix import errors on the notebooks

* 🐞 v1 - Fix training with mps accelerator (#1618)

* Convert mask to float32 in AnomalibDataset

* Convert the tensor to cpu before convrting to numpy

* replace np.float32 with np.single

* Update Engine docstrings (#1549)

Update docstrings

Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>

* Fixed shape error, allowing arbitary image sizes for EfficientAD

* Revert the previous commit

* Extend supported models in TimmFeatureExtractor (#1443)

Extend Timm feature extractor for v1.0

* 🔒 v1 - Address security issues (#1637)

* Address path traversal issues 1-3

* address traversal path 6

* Address traverse path 8

* modify the comment to make it more descriptive

* 🐞 Fix mps float64 tensor conversion issue (#1644)

Fix leftover

* 🐞 Fix metadata_path arg to metadata in OpenVINO inferencer (#1648)

Fix metadata_path arg to metadata in OpenVINO inferencer

* 🔒 Address path traversal issues (#1643)

* Address path traversal issues 1-3

* address traversal path 6

* Address traverse path 8

* modify the comment to make it more descriptive

* Update get_image_filename function to enhance the input security

* fix example

* Fix incorrect default value assignment

* Refactor project_path fixture to create temporary directory in the root directory of the project

* Update .gitignore file to include test-related files and directories

* Refactor get_image_filenames_from_dir to filter out non-image files

* Add test case for path outside base directory

* Add examples to get_filenames

* Address PR comments.

* Renamed the tmp dir

* 🔒 Add `SECURITY.md` file (#1655)

* Add SECURITY.md file

* Add security item to the type of changes in the pull request template.

* Update pr template

* replace the security emoji

* 🚀 Add zero-/few-shot model support and WinCLIP model implementation (#1575)

* add clip normalization

* initial commit for winclip

* add cosine similarity computation

* add multiscale score computation

* simplify mask generation

* add few-shot extension (unvalidated)

* refactor

* cleanup

* add todo

* formatting

* minor refactor

* add comment

* expose optimal F1 metric

* some cleanup

* add ln_after_pool logic

* remove final_ln_after_pool

* update module docstring and remove comments

* add typing and docstrings to torch model

* cleanup lightning model

* hardcode backbone

* n_shot -> k_shot

* add temperature as constant

* minor bugfix

* add typing and docstrings to utils

* set class name dynamically

* replace inf values in harmonic aggregation

* run validate before test

* set default class name to None

* formatting

* remove config

* comments

* minor bugfix

* Revert ""expose optimal F1 metric""

This reverts commit e8e1ead9601d76c743af3678f26b1eb0e06d38fb.

* more descriptive assert message

* expose scales as configurable parameter and hardcode pretrained as constant

* add readme

* add images for readme

* update docstrings

* update license headers

* ruff

* add openclip as requirement

* skip model tests for winclip

* fix visualizer test

* add example in docstring

* fix typo in function name

* typing

* imports

* docstrings

* check if model has trainer attribute

* remove pylint ignore statement

* typing

* docstring

* improve tensor shape handling

* refactor and rename class_scores function

* add docstring example

* commenting

* Update src/anomalib/models/image/winclip/torch_model.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update src/anomalib/models/image/winclip/torch_model.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update src/anomalib/models/image/winclip/torch_model.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* formatting

* docstrings

* docstrings

* comment

* typing

* multiscale -> multi_scale

* add winclip to docs

* add few_shot_source parameter

* use PredictDataset in WinCLIP implementation

* add learning type to winclip lightning model

* add custom model checkpoint callback to save at validation end

* remove trainer arguments from winclip model

* prune state dict for smaller model file

* add learning type logic to engine.train

* pass full path to model checkpoint

* remove training step

* enable integration tests for winclip

* fix typo

* index masks at 0

* formatting

* simplify make_masks

* validate inputs in make_masks

* add unit tests for winclip utils

* add default class_name to prompt ensemble

* add unit tests for winclip prompt ensemble

* add base class for normalization callback

* add _should_run_validation check

* add engine.model property

* use custom modelcheckpoint in tests

* update name in todos

* fix predict tests

* skip export tests for winclip

* fix mistake in model retrieval from trainer

* add model checks

* fix checks

* simplify model check

* add todo for winclip export

* add todo

* add bufferlist mixin

* update bufferlist docstring

* add setup method and register buffers

* import torch model in root of winclip module

* add unit tests for bufferlist mixin

* add unit tests for torch model

* fix transform and update docstring

* disable strict loading in export

* initialize embeddings as tensors

* add test to check if erors are raised

* add todo

* enable winclip export test

* remove device references in torch model

* restore frozen weights in load_state_dict

* make embedding collection methods private

* move state dict handling to winclip from base

* fix typo

* make generate_masks private

* increase onnx opset version

* remove future import

* update docstring

* Update src/anomalib/callbacks/normalization/__init__.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update src/anomalib/callbacks/normalization/cdf_normalization.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update src/anomalib/callbacks/normalization/min_max_normalization.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update src/anomalib/engine/engine.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* typing in docstrings

* Update src/anomalib/engine/engine.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update src/anomalib/engine/engine.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update src/anomalib/engine/engine.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update src/anomalib/engine/engine.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* use exception instead of assert

* update license header

* docstrings

* bufferlist -> buffer_list

---------

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* WinCLIP attribution (#1662)

give credit to related works

* 🔀 Merge main to v1 (#1652)

* Address tiler issues (#1411)

* fix tiler

* deprecate random tile locations

* restore random tiling in tile method

* check tiling section in config

* disable tiling for ganomalu

* pad -> padding

* Refactor Reverse Distillation to match official code (#1389)

* Non-mandatory early stopping

* Added conv4 and bn4 to OCBE

* Loss as in the official code (flattened arrays)

* Added comment on how to use torchvision model as an encoder to reproduce results in the paper

* Remove early stop from config, change default anomaly_map_mode to add

* pre-commit fix

* Updated results

* Update src/anomalib/models/reverse_distillation/README.md

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update src/anomalib/models/reverse_distillation/README.md

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update src/anomalib/models/reverse_distillation/README.md

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Remove early_stopping

* Update src/anomalib/models/reverse_distillation/lightning_model.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Easier to read code

---------

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Patch for the WinError183 on the OpenVino export mode (#1386)

* Fix WinError183 (Windows Error)

* Add commentary of the change

---------

Co-authored-by: Youho99 <gaylord.giret@viacesi.fr>

* Add DSR model (#1142)

* added license, init.py and draft readme

* added draft DSR files

* minor comment update

* Implemented dsr model + comments

* added dsr discrete model

* added defect generation in torch model + dsr to list of existing methods in init.py

* fixed torch model, started implementing lightning model, implemented anomaly generator

* added loss file for DSR

* Added loss, improved lightning module

* Finished up global implementation of DSR second phase

* minor fixes

* Bugfixes

* Fixed DSR loss calculation

* on_training_start -> on_train_start

* pre-commit run

* updated DSR documentation

* reset config file

* added automatic pretraining weight download

* testing pretrained weights. fixed embedding size in upsampling module and image recon module, to be fixed in original branch

* successful testing on pretrained dsr weights

* checked test quality with pretrained weights, fixed anomaly score calculation

* training is functional

* Fixed training procedure

* test still working

* working upsampling module training and testing

* fixed minor bugs

* updated documentation

* added tests and doc

* adapted learning schedule to steps

* Update src/anomalib/models/dsr/anomaly_generator.py

Co-authored-by: Ashwin Vaidya <ashwinnitinvaidya@gmail.com>

* Apply suggestions from code review

Co-authored-by: Samet Akcay <samet.akcay@intel.com>
Co-authored-by: Ashwin Vaidya <ashwinnitinvaidya@gmail.com>

* refactored outputs into dicts

* remove super() args

* changed downloading weights from anomalib releases + minor fixes

* pre commit hooks + minor fixes

* removed configurable ckpt path refs + default iteration nb from paper

* cleaned up dsr.rst and turned exceptions into RuntimeErrors

* Added upsampling ratio parameter to set third training phase epochs

* Added batched evalaution + minor code simplification

* pre commit hooks

* squeeze output image score tensor

* readded new path check in efficient ad

* fixed double step count with manual optimization

* fixed trailing whitespace

* Fix black issues

* Apply suggestions from code review

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* review suggestions

* updated architecture image links

* Address mypy

* changed output types for dsr model

* readded dict outputs, adapted to TorchInferencer

* fixed error in output dict

* removed default imagenet norm

---------

Co-authored-by: Samet Akcay <samet.akcay@intel.com>
Co-authored-by: Ashwin Vaidya <ashwinnitinvaidya@gmail.com>

* Fix unexpected key pixel_metrics.AUPRO.fpr_limit (#1055)

* fix unexpected key pixel_metrics.AUPRO.fpr_limit

Signed-off-by: FanJiangIntel <fan.jiang@intel.com>

* load AUPRO before create_metric_collection

Signed-off-by: FanJiangIntel <fan.jiang@intel.com>

* code refine

Signed-off-by: FanJiangIntel <fan.jiang@intel.com>

* fix comment

Signed-off-by: FanJiangIntel <fan.jiang@intel.com>

* fix

Signed-off-by: FanJiangIntel <fan.jiang@intel.com>

* Support test

Signed-off-by: Kang Wenjing <wenjing.kang@intel.com>

* Update test

Signed-off-by: Kang Wenjing <wenjing.kang@intel.com>

* Update test

Signed-off-by: Kang Wenjing <wenjing.kang@intel.com>

---------

Signed-off-by: FanJiangIntel <fan.jiang@intel.com>
Signed-off-by: Kang Wenjing <wenjing.kang@intel.com>
Co-authored-by: FanJiangIntel <fan.jiang@intel.com>
Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Improved speed and memory usage of mean+std calculation (#1457)

* preexisting OpenCV version check added to `setup.py`, ran formatting pre-commit hooks on previous contribution. (#1424)

* testing upstream switch

* picked up on stale OpenCV `setup.py` issue #1041

* 🐞 Hotfix: Limit Gradio Version (#1458)

* Fix metadata path

* Ignore hidden directories in folder dataset

* Add check for mask_dir for segmentation tasks in Folder dataset

* Limit the gradio version to <4

* Fix/efficient ad normalize before every validation (#1441)

* Normalize anomaly maps before every validation

* Remove print statement

---------

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Fix DRAEM (#1431)

* Fix beta in augmenter

* Add scheduler

* Change normalization to none

* Replace two lr schedulers with MultiStepLR

* Revert change to beta

* Disable early stopping default

* Format config

* Add opacity parameter beta to config

* Adding U-Flow method (#1415)

* Added uflow model

* Added documentation (README) for uflow model

* Added uflow to the list of available models, and main README updated

* Added missing images for the documentation

* Update src/anomalib/models/uflow/anomaly_map.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update src/anomalib/models/uflow/anomaly_map.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update src/anomalib/models/uflow/feature_extraction.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update src/anomalib/models/uflow/torch_model.py

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Added uflow to the reference guide in docs

* Added uflow to the pre-merge tests

* removed the _step function, and merged the code with training_step

* added as a comment the values used in the paper

* re-factorized feature extractors to use the TimmFeatureExtractor class

* added annotations for some functions, where the flow graph is created

* updated readme to fix images loading

* Added link in the README to the original code for reproducing the results

* Removed unused kwargs

* Added docstrigs with args explanations to UFlow classes

* Added models in a github release, and linked here

* Passing all pre-commit checks

* Changed freia's AllInOneBlock by Anomalib's version, and converted the subnet contructor to a Class, in order to be pickable, that is needed to export the model to torch

---------

Co-authored-by: Samet Akcay <samet.akcay@intel.com>

* Update README.md

* 📘 Announce anomalib v1 on the main `README.md` (#1542)

* Fix metadata path

* Ignore hidden directories in folder dataset

* Add check for mask_dir for segmentation tasks in Folder dataset

* Limit the gradio version to <4

* Announce anomalib v1 on readme

* Add the installation instructions and update the documentation link

* Fixed DSR (#1486)

* fixed DSR squeeze bug

* added comment

* Refactor/extensions custom dataset (#1562)

* Explanation how to use extension names in the config file

* Added information about extensions to the error message and control of the user input

* Easier to read code

* Replacing assert with raise

* 📚 Modify the PR template (#1611)

Update pull_request_template.md

* Fix result image URLs (#1510)

* Fix tests

* refactor path + fix issues + fix linting issues

* Migrate docs

* fix typing

* fix failing model tests

* Fix tests

* Address PR comments

* Fixed shape error, allowing arbitary image sizes for EfficientAD (#1537)

* Fixed shape error, allowing arbitrary image sizes. Replaced integer parsing by floor operation

* Replaced calculation by ceil operation. Solution of shape error is to round up and not down for the last upsample layer

* Add comment for ceil oepration

* Formatting with pre-commit hook

* Clean up badge

---------

Signed-off-by: FanJiangIntel <fan.jiang@intel.com>
Signed-off-by: Kang Wenjing <wenjing.kang@intel.com>
Co-authored-by: Dick Ameln <dick.ameln@intel.com>
Co-authored-by: abc-125 <63813435+abc-125@users.noreply.github.com>
Co-authored-by: Samet Akcay <samet.akcay@intel.com>
Co-authored-by: ggiret-thinkdeep <146845847+ggiret-thinkdeep@users.noreply.github.com>
Co-authored-by: Youho99 <gaylord.giret@viacesi.fr>
Co-authored-by: Philippe Carvalho <31983398+phcarval@users.noreply.github.com>
Co-authored-by: Wenjing Kang <wenjing.kang@intel.com>
Co-authored-by: FanJiangIntel <fan.jiang@intel.com>
Co-authored-by: belfner <belfner@belfner.com>
Co-authored-by: Abdulla Al Blooshi <76493346+abdullamatar@users.noreply.github.com>
Co-authored-by: Blaž Rolih <61357777+blaz-r@users.noreply.github.com>
Co-authored-by: Matías Tailanian <895687+mtailanian@users.noreply.github.com>
Co-authored-by: Jan Schlüter <github@jan-schlueter.de>
Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>
Co-authored-by: Christopher <48522299+holzweber@users.noreply.github.com>

* Update license headers

---------

Signed-off-by: FanJiangIntel <fan.jiang@intel.com>
Signed-off-by: Kang Wenjing <wenjing.kang@intel.com>
Co-authored-by: Weilin Xu <mzweilin@gmail.com>
Co-authored-by: Samet <samet.akcay@intel.com>
Co-authored-by: Ashwin Vaidya <ashwinitinvaidya@gmail.com>
Co-authored-by: Dick Ameln <dick.ameln@intel.com>
Co-authored-by: abc-125 <63813435+abc-125@users.noreply.github.com>
Co-authored-by: Harim Kang <harim.kang@intel.com>
Co-authored-by: Dick Ameln <amelndjd@gmail.com>
Co-authored-by: Blaž Rolih <61357777+blaz-r@users.noreply.github.com>
Co-authored-by: Blaz Rolih <blaz.rolih@gmail.com>
Co-authored-by: Adrian Boguszewski <adekboguszewski@gmail.com>
Co-authored-by: Willy Fitra Hendria <willyfitrahendria@gmail.com>
Co-authored-by: Samet Akcay <sakcay@Samets-MacBook-Pro.local>
Co-authored-by: Yunchu Lee <yunchu.lee@intel.com>
Co-authored-by: ggiret-thinkdeep <146845847+ggiret-thinkdeep@users.noreply.github.com>
Co-authored-by: Youho99 <gaylord.giret@viacesi.fr>
Co-authored-by: Philippe Carvalho <31983398+phcarval@users.noreply.github.com>
Co-authored-by: Wenjing Kang <wenjing.kang@intel.com>
Co-authored-by: FanJiangIntel <fan.jiang@intel.com>
Co-authored-by: belfner <belfner@belfner.com>
Co-authored-by: Abdulla Al Blooshi <76493346+abdullamatar@users.noreply.github.com>
Co-authored-by: Matías Tailanian <895687+mtailanian@users.noreply.github.com>
Co-authored-by: Jan Schlüter <github@jan-schlueter.de>
Co-authored-by: Christopher <48522299+holzweber@users.noreply.github.com>"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens10.py,2023-12-08T17:32:20Z,Merge remote-tracking branch 'origin/main'
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens10.py,2023-12-08T04:51:59Z,fix typo
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens10.py,2023-11-28T08:12:22Z,"Fix SPHINX inference memory with image input (#116)

* fix embedding precision w/ image to save memory

* pin gradio version"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens10.py,2023-11-27T07:32:12Z,fix sphinx demo
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens10.py,2023-11-23T17:14:43Z,fix sphinx sphinx-1k sphinx-2k quant (#113)
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens10.py,2023-11-19T18:50:39Z,provide blip config in Accessory
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens10.py,2023-11-19T11:07:03Z,params -> args
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens10.py,2023-11-18T16:56:22Z,Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens10.py,2023-11-09T16:45:40Z,clean up code and output
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens10.py,2023-11-07T15:48:47Z,llama ens 10 ens5p2 pose demo
github.com/IDEA-Research/DWPose,ControlNet-v1-1-nightly/ldm/modules/encoders/modules.py,2023-07-28T02:39:55Z,open code controlnet
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/mixtral_peft.py,2023-12-26T12:46:17Z,fix bug
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/mixtral_peft.py,2023-12-24T09:16:25Z,additional loss print unweighted value
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5p2.py,2023-12-08T04:51:59Z,fix typo
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5p2.py,2023-11-27T07:32:12Z,fix sphinx demo
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5p2.py,2023-11-19T18:50:39Z,provide blip config in Accessory
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5p2.py,2023-11-19T11:07:03Z,params -> args
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5p2.py,2023-11-18T16:56:22Z,Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5p2.py,2023-11-09T16:45:40Z,clean up code and output
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5p2.py,2023-11-07T15:48:47Z,llama ens 10 ens5p2 pose demo
github.com/microsoft/LLaVA-Med,llava/model/llava.py,2023-11-09T01:06:09Z,open-source with msr policy
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2024-01-07T09:22:48Z,minor fix
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-12-10T18:55:51Z,mixtral support
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-12-08T04:51:59Z,fix typo
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-11-19T11:07:03Z,params -> args
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-11-18T16:56:22Z,Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-11-17T07:01:58Z,modify llama adapter
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-11-09T16:45:40Z,clean up code and output
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-10-17T17:12:30Z,"support simplified env, fix demo bug"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-10-12T13:36:30Z,"align llama_adapter to original repo, support padded resize"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-10-07T05:11:35Z,llama adpater v2 align with original
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-08-27T04:33:52Z,codellama support
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-08-20T13:59:43Z,fix rope (more redundancy)
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-08-20T03:17:08Z,rope scale support
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-08-06T10:09:46Z,Move set_default_trainability to meta
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-08-06T04:55:53Z,fix sdpa kwargs
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-08-04T11:05:54Z,"Support loading models trained with different model_parallel_world_size. (#16)

* temp save

* quick fix of demo memory issue

* Refactor tensor creation dtype / device control.

This commit makes two changes during model creation:
1. Decouples promote_trainable_params_to_fp32 from model __init__. This
   is to avoid casting to fp32 to save memory in inference-only mode
   (#4).
2. Use a context manager to manage default tensor type change. In the
   previous version, the default tensor type is reset to
   torch.FloatTensor after creating the vision model, which is
   technically incorrect and should be the previous default tensor type
   instead. We implement our own context manager because the official
   context managers seem to be incomplete at this time (PyTorch 2.0.1):
   No dtype manager is provided and set_default_device is ineffective to
   the torch.Tensor calls which are used in fairscale.

* Change CLIP dtype management in llama.py

It is probably safer to keep CLIP at its original precision (e.g., fp16)
regardless of the autocast setting: Some casting (e.g., from fp16 to
bf16) may be lossy and can potentially harm the pre-trained model.

Keep the changes to llama.py only at this moment since a lot of copy-
pasted codes may be refactored in the future (#3).

* Respect args.precision when saving checkpoints.

* Support checkpoint merge

Checkpoint merge is suported in misc/tensor_parallel.py. Merge requires
that the checkpoint_mp_world_size % mp_world_size == 0. Support for
split (i.e., when mp_world_size % checkpoint_mp_world_size == 0) and
redistribute (for general mp_world_size and checkpoint_mp_world_size
values) will be added in the future.

Also changing multi_turn demo to use the new loading function with merge
support.

* move printing trainable params

* move training model creation back to cpu

Closes #15, #13"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-08-02T06:24:04Z,"update forward definition syntax to match llama_peft.py

this makes it easier to diff the two files to understand the differences in the implementation

for example:

vim -d model/LLM/llama_adapter.py model/LLM/llama_peft.py
diff -uNdr model/LLM/llama_adapter.py model/LLM/llama_peft.py"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-07-30T06:54:48Z,"llama_config nargs bug fix, llama_adapter refactor"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-07-27T11:55:48Z,llama　adapter inference
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-07-25T07:06:45Z,add lora & bias support
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-07-25T06:23:44Z,refactor data configs to configs/data; add llama adapter
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_adapter.py,2023-07-24T16:53:35Z,llama adapter
github.com/eric-ai-lab/MiniGPT-5,metric.py,2023-10-04T02:05:44Z,init push
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/mixtral_sparse.py,2023-12-24T09:16:25Z,additional loss print unweighted value
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens_peft.py,2023-12-10T18:55:51Z,mixtral support
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens_peft.py,2023-12-08T04:51:59Z,fix typo
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens_peft.py,2023-11-27T07:32:12Z,fix sphinx demo
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens_peft.py,2023-11-19T18:50:39Z,provide blip config in Accessory
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens_peft.py,2023-11-19T11:07:03Z,params -> args
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens_peft.py,2023-11-18T16:56:22Z,Move base python path from LLaMA2-Accessory/accessory to LLaMA2-Accessory
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens_peft.py,2023-11-09T16:45:40Z,clean up code and output
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens_peft.py,2023-10-17T17:12:30Z,"support simplified env, fix demo bug"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens_peft.py,2023-10-16T09:29:49Z,llama_ens_peft.py
github.com/YangLing0818/RPG-DiffusionMaster,modules/sd_disable_initialization.py,2024-01-22T14:16:18Z,init
github.com/YuxinWenRick/hard-prompts-made-easy,run.py,2023-02-10T02:12:25Z,default to printing best candidate
github.com/YuxinWenRick/hard-prompts-made-easy,run.py,2023-02-10T01:54:36Z,"add CLI script, clean up readme, clean up printing"
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens_light.py,2024-01-11T17:00:45Z,sphinx-Tiny (#140)
github.com/ali-vilab/i2vgen-xl,tools/modules/clip_embedder.py,2023-12-14T14:55:47Z,add i2vgen and t2v code and model
github.com/UMass-Foundation-Model/3D-LLM,three_steps_3d_feature/first_step/sam_mask.py,2023-07-25T20:48:41Z,change_format
github.com/UMass-Foundation-Model/3D-LLM,three_steps_3d_feature/first_step/sam_mask.py,2023-07-25T16:21:20Z,3d_recon_readme
github.com/UMass-Foundation-Model/3D-LLM,three_steps_3d_feature/first_step/sam_mask.py,2023-07-24T22:31:18Z,features
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/llama_ens5_light.py,2024-01-11T17:00:45Z,sphinx-Tiny (#140)
github.com/UMass-Foundation-Model/3D-LLM,three_steps_3d_feature/second_step/clip_sam.py,2023-07-25T20:48:41Z,change_format
github.com/UMass-Foundation-Model/3D-LLM,three_steps_3d_feature/second_step/clip_sam.py,2023-07-25T16:21:20Z,3d_recon_readme
github.com/UMass-Foundation-Model/3D-LLM,three_steps_3d_feature/second_step/clip_sam.py,2023-07-24T22:31:18Z,features
github.com/zideliu/StyleDrop-PyTorch,predict.py,2023-07-07T21:06:29Z,replicate
github.com/alaamaalouf/FollowAnything,follow_anything.py,2023-12-05T19:37:20Z,fix threshold
github.com/alaamaalouf/FollowAnything,follow_anything.py,2023-08-13T15:15:37Z,follow_anything stop once it finishes reading offline video
github.com/alaamaalouf/FollowAnything,follow_anything.py,2023-08-01T14:18:07Z,"code for detect, track, and follow + code for creating query features using DINO"
github.com/roatienza/Deep-Learning-Experiments,versions/2023/model_serving/demo/triton/server.py,2023-11-18T02:20:33Z,model serving
github.com/zideliu/StyleDrop-PyTorch,gradio_demo.py,2023-08-23T09:45:07Z,Update gradio_demo.py
github.com/zideliu/StyleDrop-PyTorch,gradio_demo.py,2023-08-23T09:41:19Z,Update gradio_demo.py
github.com/zideliu/StyleDrop-PyTorch,gradio_demo.py,2023-08-23T09:29:52Z,Update gradio_demo.py
github.com/zideliu/StyleDrop-PyTorch,gradio_demo.py,2023-07-09T00:52:03Z,update for colab
github.com/zideliu/StyleDrop-PyTorch,gradio_demo.py,2023-07-09T00:07:07Z,update gradio demo
github.com/zideliu/StyleDrop-PyTorch,gradio_demo.py,2023-07-05T05:09:29Z,fix some bugs
github.com/zideliu/StyleDrop-PyTorch,gradio_demo.py,2023-07-05T03:49:03Z,ADD set_seed
github.com/zideliu/StyleDrop-PyTorch,gradio_demo.py,2023-07-04T03:10:02Z,first commit
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/mixtral_sparse_ens.py,2024-01-07T09:22:48Z,minor fix
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/mixtral_sparse_ens.py,2023-12-24T09:16:25Z,additional loss print unweighted value
github.com/baaivision/Uni3D,main.py,2023-10-19T14:13:46Z,Initial commit
github.com/UMass-Foundation-Model/3D-LLM,three_steps_3d_feature/second_step/clip_maskformer.py,2023-07-25T20:48:41Z,change_format
github.com/UMass-Foundation-Model/3D-LLM,three_steps_3d_feature/second_step/clip_maskformer.py,2023-07-25T16:21:20Z,3d_recon_readme
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/mixtral_sparse_ens5.py,2024-01-07T09:22:48Z,minor fix
github.com/Alpha-VLLM/LLaMA2-Accessory,accessory/model/LLM/mixtral_sparse_ens5.py,2023-12-24T09:16:25Z,additional loss print unweighted value
github.com/AnyLoc/AnyLoc,clip_wrapper.py,2023-08-02T17:09:32Z,Created first (public) release
github.com/mingukkang/GigaGAN,evaluation/evaluation.py,2023-04-29T11:29:28Z,Add files via upload
github.com/salesforce/UniControl,ldm/modules/encoders/modules.py,2023-05-22T21:03:53Z,docs
github.com/salesforce/UniControl,ldm/modules/encoders/modules.py,2023-05-21T00:45:14Z,first commit
github.com/VoltaML/voltaML-fast-stable-diffusion,core/interrogation/clip.py,2023-11-21T18:05:16Z,float8 support
github.com/VoltaML/voltaML-fast-stable-diffusion,core/interrogation/clip.py,2023-11-07T21:11:27Z,Redo imports from diffusers to satisfy Pylance
github.com/VoltaML/voltaML-fast-stable-diffusion,core/interrogation/clip.py,2023-10-18T19:33:19Z,Remove pylint
github.com/VoltaML/voltaML-fast-stable-diffusion,core/interrogation/clip.py,2023-08-02T17:36:09Z,"Purge rich.progress and replace it with tqdm, queue progress added"
github.com/VoltaML/voltaML-fast-stable-diffusion,core/interrogation/clip.py,2023-08-01T18:35:14Z,"Arbitrary size + Inference cleanup (#128)

Cleaned the inference backend code a little bit, now it should have less
redundant/copy-pasted code.

Also made odd/non-8-aligned sizes possible to do with PyTorch.
*AIT - arbitrary sizes at the very least - has some peculiar issues with
ControlNet so I decided to drop it from this PR*

---------

Co-authored-by: Stax124 <tamoncz@gmail.com>
Co-authored-by: Stax124 <60222162+Stax124@users.noreply.github.com>"
github.com/VoltaML/voltaML-fast-stable-diffusion,core/interrogation/clip.py,2023-07-29T09:20:23Z,"Quantized CLIP (#123)

# TL;DR;
- `/api/hardware/capabilities`
- drops support for IREE (may come back later, just don't have the time
to support it)
- CLIP quantization
- frontend: settings ui revamp
  - more *optional, **disappearing*** settings based on conditions
  - dynamic options based on capabilities of host machine
# 
In an attempt to further lower latency, I've tried to quantize the text
encoder to 8bit/4bit.
This PR also includes some revamps to the settings menu and a new API
endpoint `/hardware/capabilities`.
The endpoint returns a short run-down of what the hardware can do, an
example response is the following:
```json5
{
	""supported_backends"": [""cpu"", ""cuda""],
	""supported_precisions_cpu"": [""float32"", ""bfloat16""],
	""supported_precisions_gpu"": [""float32"", ""bfloat16"", ""float16""],
	""supported_torch_compile_backends"": [""aot_ts_nvfuser"", ""cudagraphs"", ""inductor"", ""nvprims_nvfuser"", ""onnxrt""],
	""has_tensorfloat"": true, // true if user has ampere+
	""has_tensor_cores"": true, // true if user has volta+
	""supports_xformers"": false, // true if current installation supports xformers, false for torch nightlies
	""supports_int8"": true // true if a basic quantized matmul is successful
}
```
Quantization requires the installation of
[bitsandbytes](https://github.com/TimDettmers/bitsandbytes/), however it
is completely optional. Attached is the same generation (40 steps,
DPMSolverSinglestep, seed: 123123, prompt: ""1girl"") at different
quantization levels.

TODO:

- [ ] Update capabilities when something changes
- [ ] Investigate print-out when loading models with quantization

Full precision:

![f711ee6d-c547-4880-886a-7b3c0b054f03-0](https://github.com/VoltaML/voltaML-fast-stable-diffusion/assets/22561485/0f5b2c96-cc95-4b73-b798-604b18dcb84a)

8-bit quantization:

![58a32c8f-735e-4640-aec9-2239bab7bb6d-0](https://github.com/VoltaML/voltaML-fast-stable-diffusion/assets/22561485/218b3697-408c-4df6-985c-17685ea28fff)

4-bit quantization:

![8fe123f0-8246-42c7-b14e-42f6538db7f3-0](https://github.com/VoltaML/voltaML-fast-stable-diffusion/assets/22561485/afb06e0b-b467-47cc-adba-d4c41766327b)

---------

Co-authored-by: Stax124 <tamoncz@gmail.com>"
github.com/VoltaML/voltaML-fast-stable-diffusion,core/interrogation/clip.py,2023-06-18T11:41:08Z,"Affix deps, fix AITemplate, set SDPA as default attention"
github.com/VoltaML/voltaML-fast-stable-diffusion,core/interrogation/clip.py,2023-05-18T17:14:47Z,"Autocast, VAE tiling & fix offload (#82)

* autocast stuff

* autocast pt. 2

* enable offload

* autocast

* frontend

* Fix model offload... again...

* Precision changes & autocast fixes

* fix model offload in img2img

* fix no-offload

* only initialize autocast if directml autocast is needed

* fix disable=True on torch.dml.autocast

* Build frontend with locked deps

* onnx fix

* fix ait

* reorder sorts

---------

Co-authored-by: Stax124 <tamoncz@gmail.com>"
github.com/VoltaML/voltaML-fast-stable-diffusion,core/interrogation/clip.py,2023-05-06T17:10:05Z,"Multiple device support & PyTorch optimizations (#62)

* Start work on further jit trace options

* format

* AMD gpu info support & memory clear option

* clear_memory_policy

* Fix manager

* Cuda flags

* Pyamdgpuinfo

* format

* Cleanup, refactor

* format

* oops

* fix perf_loop

* format

* fix everything

* format

* Formatting, support for extra requirement check for Linux

* trace

* format

* UI, renames, cleanup

* PyLint cleanups

* Rebuild frontend

* no more one-way

* only enable reduced prec on ampere+

* Cleaning stuff up & HW Scheduling check on Windows

* format

* Add DirectML support

* fix stuffix stuff

* a

* ipex stuff pt. 1

* Revamp #install_pytorch() and further IPEX optimizations

* try & fix xpu

* fix pt2

* fix requirements

* ipex fix

* XPU changes

* Revamp install_requirements.py & fix config order

* fix interrogators on directml

* start work on iree

* fix things

* iree progress

I GOT PAST TORCH-MLIR :tada:
now I just need to get iree to work as well :)

* cleanup

* basic profiling

* Black, fix some merge issues

* Get rid of the profiler

* Reformat

* Fix .vscode/settings.json

* Cleanup, purge unnecessary stuff

* Fix TextualInversions on Windows

* Get rid of duped file, add spinner to optimization

* Frontend add more backend settings

---------

Co-authored-by: Stax124 <tamoncz@gmail.com>"
github.com/VoltaML/voltaML-fast-stable-diffusion,core/interrogation/clip.py,2023-04-23T10:48:33Z,"Interrogators (#56)

* try to quantize things

* Start work on interrogators

(Deepdanbooru is the only one tested, and it works)

* finish interrogation work

* Revert lwp_sd.py

* Refactor

* Partial Frontend for tagger

* Fix requirement installer

* Frontend functional

---------

Co-authored-by: Stax124 <tamoncz@gmail.com>"
github.com/lancedb/vectordb-recipes,examples/arxiv-recommender/main.py,2024-02-01T16:01:42Z,"linting  (#130)

* talk with podcast

* added talk-with-podcast

* imgs

* updated readme

* added requirements file

* added support for Langroid

* typo

* requirements update

* path and colab fix

* sentiment link fix

* comments in colab

* fix

* description change

* doc link fix

* talk-with-wikipedia

* added pylinting

* added pylinting

* removed pylint

* lint test

* lint path

* added polar

---------

Co-authored-by: Ayush Chaurasia <ayush.chaurarsia@gmail.com>"
github.com/lancedb/vectordb-recipes,examples/arxiv-recommender/main.py,2023-08-24T10:57:24Z,update
github.com/lancedb/vectordb-recipes,examples/arxiv-recommender/main.py,2023-08-17T11:52:40Z,add initial files
github.com/SHI-Labs/Prompt-Free-Diffusion,lib/model_zoo/clip.py,2023-05-25T07:51:33Z,first commit
github.com/zyddnys/manga-image-translator,manga_translator/inpainting/ldm/modules/encoders/modules.py,2023-03-19T23:54:15Z,add stable diffusion inpainting
github.com/hanhung/PureCLIPNeRF,train_exp.py,2022-10-14T10:23:27Z,initial code release
github.com/Fanghua-Yu/SUPIR,sgm/modules/encoders/modules.py,2024-02-24T08:44:55Z,fix dependency
github.com/Fanghua-Yu/SUPIR,sgm/modules/encoders/modules.py,2024-01-25T14:42:59Z,20240125
github.com/hanhung/PureCLIPNeRF,train_imp.py,2022-10-14T10:23:27Z,initial code release
github.com/Shilin-LU/TF-ICON,ldm/modules/encoders/modules.py,2023-07-23T03:55:16Z,first commit
github.com/ShihaoZhaoZSH/Uni-ControlNet,ldm/modules/encoders/modules.py,2023-05-25T08:26:02Z,test code
github.com/daveredrum/Text2Tex,models/ControlNet/ldm/modules/encoders/modules.py,2023-08-10T15:46:29Z,Release codebase & Update README
github.com/kabachuha/sd-webui-text2video,scripts/modelscope/clip_hardcode.py,2023-05-30T14:23:45Z,"relicense sd-webui-text2video under AGPL v3.0

Incorporates the original ModelScope code into the extension and licenses them both under the Apache 2.0-compatible AGPL v3.0"
github.com/kabachuha/sd-webui-text2video,scripts/modelscope/clip_hardcode.py,2023-04-20T19:49:26Z,Fix[122b] fixes 3rd reported exception found in #122 - clip_hardcode :: missing opts.use_old_emphasis_implementation
github.com/kabachuha/sd-webui-text2video,scripts/modelscope/clip_hardcode.py,2023-04-05T19:00:29Z,add videocrafter modules
github.com/zhyever/PatchFusion,ControlNet/ldm/modules/encoders/modules.py,2023-12-12T17:29:52Z,initial release
github.com/UMass-Foundation-Model/3D-LLM,3DLanguage_data/ChatCaptioner_based/gen_features/clip_oa.py,2023-09-09T04:51:38Z,refactor gen_features
github.com/vislearn/ControlNet-XS,sgm/modules/encoders/modules.py,2023-09-22T17:14:13Z,Fill repo with life
github.com/IDEA-CCNL/Fengshenbang-LM,fengshen/examples/finetune_taiyi_stable_diffusion/evaluate_model.py,2022-11-29T03:47:02Z,fix some bug
github.com/IDEA-CCNL/Fengshenbang-LM,fengshen/examples/finetune_taiyi_stable_diffusion/evaluate_model.py,2022-11-29T03:46:02Z,fix some bug
github.com/IDEA-CCNL/Fengshenbang-LM,fengshen/examples/finetune_taiyi_stable_diffusion/evaluate_model.py,2022-11-17T07:32:19Z,fixed
github.com/IDEA-CCNL/Fengshenbang-LM,fengshen/examples/finetune_taiyi_stable_diffusion/evaluate_model.py,2022-11-17T07:26:56Z,add stable diffusion evaluater
github.com/Doubiiu/DynamiCrafter,lvdm/modules/encoders/condition.py,2023-11-28T18:15:58Z,init
github.com/vislearn/ControlNet-XS,ldm/modules/encoders/modules.py,2023-09-22T17:14:13Z,Fill repo with life
github.com/Picsart-AI-Research/PAIR-Diffusion,ldm/modules/encoders/modules.py,2024-01-04T07:29:55Z,update code
github.com/Picsart-AI-Research/PAIR-Diffusion,ldm/modules/encoders/modules.py,2023-04-09T19:56:14Z,inference code release
github.com/Newbeeer/diffusion_restart_sampling,diffuser/clip_score.py,2023-06-25T03:07:36Z,update
github.com/diffusion-classifier/diffusion-classifier,run_winoground.py,2024-02-14T23:25:53Z,add DiT eval
github.com/diffusion-classifier/diffusion-classifier,run_winoground.py,2023-11-08T21:06:29Z,add Winoground evaluation script
github.com/umd-huang-lab/perceptionCLIP,src/models/modeling.py,2023-08-03T01:55:47Z,update
github.com/UMass-Foundation-Model/3D-LLM,3DLanguage_data/ChatCaptioner_based/gen_features/sam_mask.py,2023-09-09T04:51:38Z,refactor gen_features
github.com/UMass-Foundation-Model/3D-LLM,3DLanguage_data/ChatCaptioner_based/gen_features/sam_mask.py,2023-08-28T20:45:43Z,generate features for Objaverse data
github.com/NVIDIA/tao_pytorch_backend,nvidia_tao_pytorch/cv/odise/modeling/backbone/clip.py,2023-12-05T22:13:46Z,TAO 5.2 Release - PyTorch
github.com/NVIDIA/tao_pytorch_backend,nvidia_tao_pytorch/cv/odise/modeling/meta_arch/clip.py,2023-12-05T22:13:46Z,TAO 5.2 Release - PyTorch
github.com/Zhendong-Wang/Prompt-Diffusion,ldm/modules/encoders/modules.py,2023-05-01T00:43:50Z,initial commit
github.com/3DTopia/3DTopia,ldm/modules/encoders/modules.py,2024-01-18T08:05:22Z,first commit
github.com/sail-sg/EditAnything,ldm/modules/encoders/modules.py,2023-04-09T09:29:32Z,Init commit
github.com/OpenGVLab/Instruct2Act,engine_robotic.py,2023-05-18T12:21:58Z,update the readme && remove some useless lines
github.com/OpenGVLab/Instruct2Act,engine_robotic.py,2023-05-18T07:18:57Z,first commit
github.com/roatienza/Deep-Learning-Experiments,versions/2023/model_serving/demo/triton/openclip/server.py,2023-11-18T02:20:33Z,model serving
github.com/Newbeeer/diffusion_restart_sampling,diffuser/eval_clip_score.py,2023-06-25T03:07:36Z,update
github.com/vvictoryuki/FreeDoM,CN/ldm/modules/encoders/modules.py,2023-08-16T16:09:59Z,add new codes
github.com/Nerogar/OneTrainer,modules/module/HPSv2ScoreModel.py,2023-10-25T16:38:57Z,load HPSv2 with the correct precision
github.com/Nerogar/OneTrainer,modules/module/HPSv2ScoreModel.py,2023-10-24T17:39:29Z,HPSv2 support for AlignProp
github.com/mlcommons/inference,text_to_image/tools/clip/clip_encoder.py,2023-12-19T17:25:38Z,"Match clip and fid score calculation (#1536)

* Add SD model links in README

* Match clip and fid score calculation"
github.com/SamsungLabs/FineControlNet,ldm/modules/encoders/modules.py,2024-02-06T22:29:40Z,initial commit
github.com/TencentARC/MotionCtrl,lvdm/modules/encoders/condition2.py,2023-12-25T12:35:31Z,init
github.com/deforum-art/deforum-stable-diffusion,src/ldm/modules/encoders/modules.py,2023-01-14T23:14:05Z,fix install
github.com/deforum-art/deforum-stable-diffusion,src/ldm/modules/encoders/modules.py,2023-01-02T17:45:57Z,update ldm
github.com/deforum-art/deforum-stable-diffusion,src/ldm/modules/encoders/modules.py,2022-12-31T22:26:12Z,"fix defaults, errors, print statements, etc"
github.com/deforum-art/deforum-stable-diffusion,src/ldm/modules/encoders/modules.py,2022-11-24T02:51:19Z,update ldm
github.com/deforum-art/deforum-stable-diffusion,src/ldm/modules/encoders/modules.py,2022-10-28T23:20:59Z,add src files
github.com/zsyOAOA/ResShift,ldm/modules/encoders/modules.py,2023-07-23T15:15:31Z,first commit
github.com/Newbeeer/diffusion_restart_sampling,diffuser/coco_data_loader.py,2023-06-25T03:07:36Z,update
github.com/WalBouss/GEM,gem/gem.py,2023-12-05T08:21:13Z,Initial commit :tada:
github.com/IceClear/StableSR,ldm/modules/encoders/modules.py,2023-05-10T17:02:41Z,init
github.com/yangxy/PASD,test_pasd.py,2024-01-23T06:29:33Z,update LICENSE
github.com/yangxy/PASD,test_pasd.py,2024-01-16T09:56:44Z,support lcm-lora
github.com/yangxy/PASD,test_pasd.py,2023-10-20T09:55:34Z,add added_noise_level
github.com/yangxy/PASD,test_pasd.py,2023-10-18T08:04:36Z,initialize latent with lr image
github.com/yangxy/PASD,test_pasd.py,2023-10-18T03:08:16Z,update
github.com/yangxy/PASD,test_pasd.py,2023-10-18T02:03:58Z,fix bug & add offset noise
github.com/yangxy/PASD,test_pasd.py,2023-10-16T11:41:57Z,update
github.com/yangxy/PASD,test_pasd.py,2023-09-28T09:13:07Z,update
github.com/yangxy/PASD,test_pasd.py,2023-09-14T06:55:43Z,support lora
github.com/yangxy/PASD,test_pasd.py,2023-09-12T08:21:43Z,update
github.com/yangxy/PASD,test_pasd.py,2023-09-11T10:46:39Z,upload models
github.com/yangxy/PASD,test_pasd.py,2023-09-07T08:20:38Z,update source codes
github.com/chaojie/ComfyUI-DragNUWA,dragnuwa/svd/modules/encoders/modules.py,2024-01-11T15:32:35Z,fix bugs
github.com/chaojie/ComfyUI-DragNUWA,dragnuwa/svd/modules/encoders/modules.py,2024-01-11T09:29:05Z,init
github.com/buaacyw/IT3D-text-to-3D,ctn/ldm/modules/encoders/modules.py,2023-08-22T14:09:16Z,IT3D v1
github.com/minghanqin/LangSplat,preprocess.py,2023-12-26T11:07:35Z,init
github.com/text2cinemagraph/text2cinemagraph,ODISE/odise/modeling/meta_arch/clip.py,2023-07-10T02:21:25Z,initial commit
github.com/MendelXu/SAN,san/model/san.py,2023-03-22T03:00:31Z,update code
github.com/ali-vilab/videocomposer,tools/videocomposer/inference_multi.py,2023-06-15T13:08:41Z,The first version of the code and model
github.com/shenyunhang/APE,ape/modeling/text/clip_wrapper_open.py,2023-12-05T02:34:21Z,This is the 1st commit
github.com/Algolzw/daclip-uir,universal-image-restoration/config/daclip-sde/train.py,2023-10-02T11:44:56Z,add uir code
github.com/jianzhnie/GigaGAN,gigagan/open_clip.py,2023-04-01T01:53:41Z,Update open_clip.py
github.com/jianzhnie/GigaGAN,gigagan/open_clip.py,2023-03-20T06:52:33Z,Create open_clip.py
github.com/ali-vilab/videocomposer,tools/videocomposer/inference_single.py,2023-06-15T13:08:41Z,The first version of the code and model
github.com/bytedance/fc-clip,fcclip/modeling/backbone/clip.py,2023-08-10T23:29:33Z,add support for resnet
github.com/bytedance/fc-clip,fcclip/modeling/backbone/clip.py,2023-08-07T07:11:21Z,init commit
github.com/mlfoundations/task_vectors,src/modeling.py,2022-12-11T23:06:11Z,initial release
github.com/Colin97/OpenShape_code,src/example.py,2023-06-27T10:01:06Z,add inference example
github.com/mertyg/vision-language-models-are-bows,model_zoo/__init__.py,2023-04-09T18:28:08Z,add .eval()
github.com/mertyg/vision-language-models-are-bows,model_zoo/__init__.py,2023-02-20T09:29:10Z,"initial release. Sorry for the delay and potential missing bits, please see the important note in readme."
github.com/XPixelGroup/DiffBIR,ldm/modules/encoders/modules.py,2023-09-11T15:01:12Z,add support for cpu
github.com/XPixelGroup/DiffBIR,ldm/modules/encoders/modules.py,2023-08-28T16:27:07Z,first commit
github.com/csuhan/OneLLM,model/LLM/onellm.py,2023-12-04T08:58:33Z,init
github.com/zideliu/StyleDrop-PyTorch,train_t2i_colab_v2.py,2023-07-08T07:33:12Z,updated colab train script
github.com/lucidrains/gigagan-pytorch,gigagan_pytorch/open_clip.py,2023-07-21T00:26:47Z,"for conditional training, complete the auxiliary clip contrastive loss"
github.com/lucidrains/gigagan-pytorch,gigagan_pytorch/open_clip.py,2023-04-06T15:36:56Z,"auxiliary losses almost all complete, save for text conditioning within vision aided discriminator"
github.com/lucidrains/gigagan-pytorch,gigagan_pytorch/open_clip.py,2023-04-04T20:03:50Z,clean solution to reconstruction loss from any fmap resolution in the discriminator
github.com/lucidrains/gigagan-pytorch,gigagan_pytorch/open_clip.py,2023-04-03T18:07:28Z,make some headway into vision-aided gan loss
github.com/lucidrains/gigagan-pytorch,gigagan_pytorch/open_clip.py,2023-03-29T20:53:19Z,knock out two of the aux losses
github.com/lucidrains/gigagan-pytorch,gigagan_pytorch/open_clip.py,2023-03-13T20:39:51Z,prepare open clip
github.com/RoboFlamingo/RoboFlamingo,robot_flamingo/models/factory.py,2023-11-03T02:11:57Z,first commit for public
github.com/yu-takagi/StableDiffusionReconstruction,codes/diffusion_sd2/stablediffusion/ldm/modules/encoders/modules.py,2023-06-21T03:17:34Z,code release
github.com/mkshing/e4t-diffusion,e4t/encoder.py,2023-03-25T20:35:31Z,big changes for better results
github.com/mkshing/e4t-diffusion,e4t/encoder.py,2023-03-21T06:44:51Z,fix log
github.com/mkshing/e4t-diffusion,e4t/encoder.py,2023-03-21T00:00:51Z,bug fixes on encoder
github.com/mkshing/e4t-diffusion,e4t/encoder.py,2023-03-18T12:26:11Z,simpler optimization for offsets
github.com/mkshing/e4t-diffusion,e4t/encoder.py,2023-03-16T23:08:18Z,fix clip pooling part to align with the paper
github.com/mkshing/e4t-diffusion,e4t/encoder.py,2023-03-16T02:03:23Z,first commit
github.com/rese1f/StableVideo,ldm/modules/encoders/modules.py,2023-02-19T12:46:00Z,i
github.com/csslc/CCSR,ldm/modules/encoders/modules.py,2024-01-04T13:45:50Z,release_code
github.com/Nota-NetsPresso/BK-SDM,src/eval_clip_score.py,2024-02-27T14:26:01Z,#51 update package and copyright info
github.com/Nota-NetsPresso/BK-SDM,src/eval_clip_score.py,2023-07-25T18:59:54Z,add initial codes
github.com/KohakuBlueleaf/LyCORIS,lycoris/modules/hypernet/text_encoder.py,2024-02-18T06:17:16Z,Formatting
github.com/KohakuBlueleaf/LyCORIS,lycoris/modules/hypernet/text_encoder.py,2023-12-02T12:23:14Z,formatting
github.com/KohakuBlueleaf/LyCORIS,lycoris/modules/hypernet/text_encoder.py,2023-07-25T10:06:21Z,bug fixes
github.com/KohakuBlueleaf/LyCORIS,lycoris/modules/hypernet/text_encoder.py,2023-07-25T09:47:42Z,text img hypernet
github.com/zideliu/StyleDrop-PyTorch,train_t2i_custom_v2.py,2023-07-08T03:34:00Z,fix bugs
github.com/zideliu/StyleDrop-PyTorch,train_t2i_custom_v2.py,2023-07-04T03:10:02Z,first commit
github.com/LAION-AI/CLIP_benchmark,clip_benchmark/models/open_clip.py,2023-01-05T22:50:20Z,"Support Japanese CLIP by rinna (#50)

* support japanese clip

* Add comments

* add `ja_clip` flag to base_args for passing tests

* add japanese clip to features in readme

* support japanese-clip for retrieval

* load proper model by model_type

* fix test

* undo changes in metrics

* add wrapper for ja_clip

* Rename models.py to model_collection.py

* use model_collection in cli.py

* import os in cli.py

* Update cli.py

* delete duplicate of loading `model_collection`

* rename a var `model` to `model_name` in models

* small fixes for better name in japanese_clip.py

* add How to add other CLIP models in readme

Co-authored-by: Romain Beaumont <romain.rom1@gmail.com>"
github.com/Tsingularity/dift,src/models/clip.py,2023-12-12T09:03:40Z,add dino and clip
github.com/OpenGVLab/InternVL,clip_benchmark/clip_benchmark/models/open_clip.py,2023-12-25T18:38:14Z,Release code and models
github.com/ThereforeGames/unprompted,lib_unprompted/stable_diffusion/controlnet/ldm/modules/encoders/modules.py,2023-02-13T05:44:46Z,v7.5.0
github.com/baaivision/GeoDream,mv-diffusion/MVDream/mvdream/ldm/modules/encoders/modules.py,2023-12-01T02:01:21Z,Initial commit
github.com/GongyeLiu/StyleCrafter,lvdm/modules/encoders/condition.py,2023-12-05T14:16:45Z,add code and checkpoint
github.com/technobird22/NeoGen,safety_model.py,2022-06-24T20:44:20Z,Initial Commit
github.com/rlawjdghek/StableVITON,ldm/modules/encoders/modules.py,2024-02-29T04:51:12Z,add training code
github.com/haoshao-nku/medical_seg,mmsegmentation/projects/CAT-Seg/cat_seg/models/clip_ovseg.py,2023-12-15T14:20:47Z,update code
github.com/zideliu/StyleDrop-PyTorch,extract_empty_feature.py,2023-07-09T07:21:34Z,fixing memory overflow
github.com/zideliu/StyleDrop-PyTorch,extract_empty_feature.py,2023-07-04T03:10:02Z,first commit
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2023-09-10T00:15:11Z,Update CACHE_URL_BASE
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2023-04-12T16:56:37Z,change dribble to dribbble (#69)
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2023-03-20T03:43:46Z,"Support for many different caption models:
blip-base, blip-large, blip2-2.7b, blip2-flan-t5-xl, git-large-coco"
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2023-03-20T01:02:23Z,Expose LabelTable and load_list and give example in README how they can be used to rank your own list of terms.
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2023-02-22T02:55:19Z,Move definition of clip_model_name (#52)
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2023-02-20T22:30:26Z,Minor fix to BLIP offloading
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2023-02-20T22:11:33Z,"More safetensor, download, and VRAM improvements"
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2023-02-19T04:29:36Z,When blip_offload enabled keep BLIP model on CPU to start.
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2023-02-18T21:31:45Z,add the negative cache url
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2023-02-18T20:53:02Z,"safetensors!
- store cached embeddings in safetensor format
- updated huggingface ci-preprocess repo
- bumped version to 0.5.0"
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2023-02-05T18:31:12Z,.
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2023-02-05T18:18:12Z,"0.4.2:
- upgrade chain to take a min_count parameter so it won't early out until it has considered at least min_count flavors
- interrogate method (""best"" mode) also checks against classic and fast to use their output if it's better
- fix bug of config.download_cache option not being used!
- add notes on Config object to readme"
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2023-02-05T00:32:49Z,"Bunch of updates! (#40)

- auto download the cache files from huggingface
- experimental negative prompt mode
- slight quality and performance improvement to best mode
- analyze tab in Colab and run_gradio to get table of ranked terms"
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2023-01-06T01:44:38Z,"Make the BLIP model configurable, can set config.blip_model_type now to 'base' or 'large'"
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2023-01-04T18:39:45Z,Update to nicer BLIP packaging
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2022-12-10T21:42:46Z,Fix for running on CPU
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2022-11-29T22:38:48Z,"0.3.1 fix for running on cpu, update readme usage instructions"
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2022-11-28T18:36:24Z,Handle exception trying to load cached table
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2022-11-28T18:30:39Z,"Default to ViT-L, lower intermediate count for Colab with ViT-H"
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2022-11-27T23:54:13Z,"Ability to swap CLIP models (takes about 5s for ViTL and 10s for ViTH), update Replicate cog"
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2022-11-26T23:59:00Z,"More fixes, improvement and cleanup."
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2022-11-25T16:33:13Z,"Handle differences in how open_clip does prompt truncation, run_gradio support for all the open_clip models and --share option."
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2022-11-25T15:26:00Z,Shuffle BLIP back to system RAM to help with 16GB Colab
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2022-11-24T21:27:28Z,First test version with OpenCLIP and ViTH!
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2022-11-21T20:17:36Z,"Update notebook batch processing with option to rename files so can be used with [filewords] in Dreambooth!
- new `quiet` config option so CLIP Interrogator doesn't print and tqdm
- `max_flavors` option to each interrogate method"
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2022-11-06T04:21:13Z,Gradio version plus classic and fast modes
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2022-11-06T02:41:08Z,CLIPInterrogator -> Interrogator
github.com/pharmapsychotic/clip-interrogator,clip_interrogator/clip_interrogator.py,2022-11-06T02:02:08Z,Add to pip!
github.com/data2ml/all-clip,all_clip/open_clip.py,2024-01-21T20:47:24Z,Split in one file per model.
github.com/Weifeng-Chen/dl_scripts,text-image/data_filter/wukong_filter.py,2023-01-13T18:39:05Z,update
github.com/Weifeng-Chen/dl_scripts,text-image/data_filter/wukong_filter.py,2022-11-07T03:30:13Z,update
github.com/tgxs002/align_sd,process_diffusiondb.py,2023-05-10T12:34:17Z,"highlight updates, fix typo, add regularization images"
github.com/thecooltechguy/ComfyUI-Stable-Video-Diffusion,libs/sgm/modules/encoders/modules.py,2023-11-23T06:30:21Z,initial commit
github.com/Vision-CAIR/ChatCaptioner,ChatCaptioner/chatcaptioner/clip.py,2023-04-11T11:48:46Z,update
github.com/matsui528/scs,search.py,2023-10-23T11:28:50Z,readme update
github.com/matsui528/scs,search.py,2023-10-23T14:32:00Z,readme
github.com/matsui528/scs,search.py,2023-10-23T14:21:34Z,added comments
github.com/matsui528/scs,search.py,2023-10-23T14:11:39Z,initial finish
github.com/matsui528/scs,search_streamlit.py,2023-10-23T16:49:33Z,streamlit
github.com/matsui528/scs,extract_features.py,2023-10-23T14:21:34Z,added comments
github.com/matsui528/scs,extract_features.py,2023-10-23T14:11:39Z,initial finish
github.com/matsui528/scs,extract_features.py,2023-10-23T08:44:51Z,extract
github.com/ContextualAI/lens,lens/model.py,2023-06-29T07:00:25Z,first commit
github.com/AILab-CVC/FreeNoise,lvdm/modules/encoders/condition.py,2023-10-24T04:14:18Z,first commit
github.com/Anything-of-anything/Anything-3D,AnyObject3D/src/3DFuse/ldm/modules/encoders/modules.py,2023-06-09T10:09:44Z,[feats] release basic code for AnyObject3D
github.com/RoboFlamingo/RoboFlamingo,open_flamingo/open_flamingo/eval/rices.py,2023-11-03T02:11:57Z,first commit for public
github.com/KU-CVLAB/3DFuse,ldm/modules/encoders/modules.py,2023-03-29T07:56:00Z,first commit
github.com/Algolzw/daclip-uir,universal-image-restoration/config/daclip-sde/test.py,2023-10-02T11:44:56Z,add uir code
github.com/AnyLoc/AnyLoc,examples/trivial_vpr_with_clip.py,2023-08-02T17:09:32Z,Created first (public) release
github.com/RoboFlamingo/RoboFlamingo,open_flamingo/open_flamingo/src/factory.py,2023-11-03T02:11:57Z,first commit for public
github.com/mlfoundations/datacomp,eval_utils/wds_eval.py,2023-07-22T20:33:48Z,"Style fix (#35)

* precommit changes

* add precommit hook"
github.com/mlfoundations/datacomp,eval_utils/wds_eval.py,2023-04-28T04:18:58Z,Initial commit
github.com/dome272/Paella,src_distributed/utils.py,2023-04-13T14:47:27Z,v3 main commit
github.com/kerrj/lerf,lerf/encoders/openclip_encoder.py,2024-01-18T00:12:46Z,Update paths+configs to nerfstudio 1.0 version
github.com/kerrj/lerf,lerf/encoders/openclip_encoder.py,2023-04-19T21:06:17Z,refactor to fix handle in callback
github.com/kerrj/lerf,lerf/encoders/openclip_encoder.py,2023-04-14T22:03:56Z,code for using new viewer with custom ViewerText
github.com/kerrj/lerf,lerf/encoders/openclip_encoder.py,2023-04-04T16:34:46Z,init commit
github.com/carefree0910/carefree-learn,examples/reproduce/clip/run_open_clip.py,2023-12-06T06:38:27Z,✅Re-introduced `reproduce/clip`
github.com/carefree0910/carefree-learn,examples/reproduce/clip/run_open_clip.py,2023-03-21T11:05:30Z,🎉Started `v0.4.x`
github.com/carefree0910/carefree-learn,examples/reproduce/clip/run_open_clip.py,2022-12-10T07:24:17Z,🚚Move `reproduce` to `examples` root
github.com/facebookresearch/stable_signature,src/ldm/modules/encoders/modules.py,2023-10-06T16:46:45Z,Initial commit
github.com/HelixNGC7293/DeforumStableDiffusionLocal,deforum-stable-diffusion/src/ldm/modules/encoders/modules.py,2023-01-13T00:16:51Z,Add support for v0.7
github.com/HelixNGC7293/DeforumStableDiffusionLocal,deforum-stable-diffusion/src/ldm/modules/encoders/modules.py,2022-12-03T20:56:35Z,V0.6 Txt batch function added
github.com/concept-graphs/concept-graphs,conceptgraph/scripts/eval_replica_semseg.py,2024-01-16T06:40:59Z,add sem seg evaluation script on replica
github.com/facebookresearch/MetaCLIP,tests/simple_test.py,2023-12-21T22:37:02Z,replace customized config class w/ dataclass
github.com/concept-graphs/concept-graphs,conceptgraph/scripts/generate_gsa_results.py,2024-02-28T04:49:23Z,refactor get clip feature function to be batched
github.com/concept-graphs/concept-graphs,conceptgraph/scripts/generate_gsa_results.py,2024-02-23T16:05:34Z,temp ugly bugfix
github.com/concept-graphs/concept-graphs,conceptgraph/scripts/generate_gsa_results.py,2024-02-23T04:44:09Z,added yolo world detection option
github.com/concept-graphs/concept-graphs,conceptgraph/scripts/generate_gsa_results.py,2024-02-23T04:39:42Z,change outdated tag2text stuff to ram stuff
github.com/concept-graphs/concept-graphs,conceptgraph/scripts/generate_gsa_results.py,2023-09-29T05:44:42Z,add initial public code
github.com/open-mmlab/Multimodal-GPT,mmgpt/models/open_flamingo/builder.py,2023-04-26T10:30:10Z,init
github.com/sail-sg/BindDiffusion,ldm/modules/encoders/modules.py,2023-05-15T10:13:05Z,update
github.com/GaussianObject/GaussianObject,ldm/modules/encoders/modules.py,2024-02-19T15:58:45Z,release code
github.com/facebookresearch/MetaCLIP,tests/pretrained_test.py,2023-12-21T22:37:02Z,replace customized config class w/ dataclass
github.com/lucidrains/perfusion-pytorch,perfusion_pytorch/open_clip.py,2023-08-14T16:07:14Z,"add a function that can accept open clip, a bunch of prompts as List[str], and return the C covariance matrix needed"
github.com/facebookresearch/PUG,PUG_SPAR/run_eval_vlms_on_spar.py,2023-08-09T00:51:32Z,Initial commit
github.com/bytedance/ImageDream,extern/ImageDream/imagedream/ldm/modules/encoders/modules.py,2023-11-26T05:13:33Z,update threestudio
github.com/bytedance/ImageDream,extern/ImageDream/imagedream/ldm/modules/encoders/modules.py,2023-11-25T01:53:22Z,update image dream
github.com/bytedance/ImageDream,extern/ImageDream/imagedream/ldm/modules/encoders/modules.py,2023-11-19T23:02:22Z,update external module
github.com/painebenjamin/app.enfugue.ai,src/python/enfugue/diffusion/animate/dragnuwa/svd/modules/encoders/modules.py,2024-01-13T02:28:55Z,pass typecheck/importcheck hundreds more changes to nuwa
github.com/painebenjamin/app.enfugue.ai,src/python/enfugue/diffusion/animate/dragnuwa/svd/modules/encoders/modules.py,2024-01-11T04:17:15Z,"add dragnuwa, add motion vector editor to front end and back end, numerous changes"
github.com/painebenjamin/app.enfugue.ai,src/python/enfugue/diffusion/support/upscale/ccsr/ldm/modules/encoders/modules.py,2024-01-27T07:29:15Z,"add ccsr, fix hotshot motion attn"
github.com/concept-graphs/concept-graphs,conceptgraph/scripts/streamlined_detections.py,2024-02-28T04:49:58Z,"add clip fts, add profiling code, other small updates"
github.com/concept-graphs/concept-graphs,conceptgraph/scripts/streamlined_detections.py,2024-02-27T03:07:17Z,added streamlined detections script
github.com/Zeju1997/oft,oft-control/ldm/modules/encoders/modules.py,2023-06-21T15:21:33Z,update
github.com/KU-CVLAB/CAT-Seg,cat_seg/modeling/transformer/cat_seg_predictor.py,2023-03-21T12:14:05Z,initial commit
github.com/concept-graphs/concept-graphs,conceptgraph/scripts/visualize_cfslam_results.py,2023-09-29T05:44:42Z,add initial public code
github.com/bytedance/MVDream,mvdream/ldm/modules/encoders/modules.py,2023-10-03T03:37:22Z,init commit
github.com/Vision-CAIR/ChatCaptioner,Video_ChatCaptioner/chatcaptioner/clip.py,2023-04-11T11:46:37Z,update
github.com/ssundaram21/dreamsim,dreamsim/feature_extraction/load_open_clip_as_dino.py,2023-06-16T00:07:26Z,Release
github.com/ParisNeo/lollms,lollms/image_gen_modules/clip_interrogator.py,2023-11-28T15:46:16Z,Update clip_interrogator.py
github.com/ParisNeo/lollms,lollms/image_gen_modules/clip_interrogator.py,2023-11-28T01:03:58Z,added vision to all models
github.com/abhishekkrthakur/diffuzers,diffuzers/clip_interrogator.py,2023-01-04T16:03:12Z,update
github.com/NVIDIA/NeMo-Megatron-Launcher,launcher_scripts/nemo_launcher/collections/eval_diffusion_fid_clip/compute_clip_score.py,2024-02-06T22:48:23Z,"Multimodal Launcher Merge (#186)

* Add initial support for multimodal data preparation

* Add multimodal training

* Add multimodal conversion and finetuning

* Add multimodal in fw inference

* Fix code style, add comments, refactor yaml config to make more readable

* Update multimodal configs in fw inference

* Add SD conf

* Add final two sub stages: precache encodings and output wdinfo;
Unify argument names;
Change encoder class paths to new repo (multimodal_merge)

* pycharm reformat

* minor changes

* Fix bug where precache encodings couldn't use multiple GPUs on the same node

* Add multimodal readme

* Add model configurations

* Update configs

* Update configs for CLIP

* Add support for downloading dataset for instruct_pix2pix

* Add Dreambooth and SD fix

* Add vision and multimodal to internal/main

* Fix sd default config

* Update dreambooth conf

* Remove glue download args

* dreambooth inference script path changes

* fwk inference path change

* fwk inference path change

* Add seed

* Add seed to stable diffusion inference

* Fix SD confs

* Add evaluation for ViT and CLIP

* Add nemo checkpoint saving in ViT fine-tuning

* Fix ins-p2p conversion path

* Add Imagen Launcher Support

* Imagen: disable inductor by default

* change micro bs => 8 for 2b model

* Update dreambooth config

* Add download and preprocess scripts for fid evaluation (mscoco 2014)

* Add a few advanced features for precaching

* Fix conversion for SD legacy checkpoints

* Fix version base

* Iputterman/deployment

(cherry picked from commit 3a097c50e0b89642d048d7588fb0c6f9858b387f)

* Fix SD configuration

* Disable save nemo on train end

* Remove coco download scripts

* headers for deployment

* change data paths in training configs to be consistent with dataprep scripts

* Add Diffusion Modal Eval

* Clean configs and update readme

* Remove auto configurator as it doesn't support multimodal ATM

* Update default configs

* Update feature matrix

* Update feature matrix

* Update dreambooth related configs.

* Update dreambooth readme

* Give a default value to vae.bin since it's required

* Update readme

* readme revised

* small updates

* uppercase for SD

* Fix diffusion eval

* Update SD training readme

* Fix override tweaks

* Update Ins P2P example

* Fix readme format

* Update SD training readme about dataset size

* Add number of images

* Update readme and add more training configs.

* FID eval now only accepts predownloaded tf_inception weights.

* Remove version, add local_clip_files arg to training scripts

* Fix format

* Update LICENSE

* Safe remove Dockerfile in multimodal

* Update LICENSE format

* Fix bug

* Add change log and reformat

* Fix README.md

* Fix image path

* readme revised

* Make eval scripts work

* Revert ""Remove version, add local_clip_files arg to training scripts""

This reverts commit ee03ea834390db29041391438737c1001ace9416.

* Revert ""FID eval now only accepts predownloaded tf_inception weights.""

This reverts commit a66069d659525dc9cc769bfe3117804df3e8dd5b.

* Add clip version

* Filtering only works with infinite sampler.

* Update readme

* Minor updates and adding more remarks

* readme revised

* readme revised

* update container in config

* readme revised

* changelog->release notes

* exp manager name changed

* Update example image for instruct p2p

* Delete imagen related folders

* Remove imagen

* Update default precision

* license updated

* name needs to be fixed

* Update readme for Dreambooth source images.

* Update save dir

* Inference now looks for ckpt in conversion results

* dreambooth inference name changed

* README edits

* add nemo sha to support matrix

* Update ToC

* Fix typo

* update support matrix

* Fix README.md format

* Precommit checks CI job

* run style-check only on mrs

* Multiple precaching improvements:
- file objects in tar now have the same name as source tar file
- fix bug where encoder for each task was moved to GPU0, leading to OOM for large encoders
- add option to save original video in tarfile

* add merge_source_tar as a substage in multimodal dataprep

* sort content of tarfiles after appending, otherwise webdataset cannot read it

* more error handling in merge_source_tar

* sort input for better determinism

* remove personal info in path

* update default hydra config

* update readme to mention new substage and update yaml for example usage

* maybe fix the CI for multimodal export conf

* Updates related to SD 1.5

* Update Distributed Optimizer Readme and Configs

* Imagen Launcher Configs

* Update NeMo clip configs on Launcher

* Fix local_root_path in imagen

* Add external conversion stage; add hf clip and openclip conversion

* Add conversion from external checkpoint for CLIP in README.md

* Fix readme language

* Change dependency `aftercorr` to `afterok`

* Fix typo

* Controlnet and SD nhwc support

* Imagen Launcher Completeness

* ControlNet Triton+TRT

* Add SD2 support

* Add the pictures

* Update SD2 readme

* Imagen Readme

* Sd readme update

* Imagen: CI Fix exporting script issue.

* Add clip_version in fid_clip yaml

* space fixed

* update imagen A100 vs. H100 batch size

* Add comment on using larger bs for Imagen training

* Sd2 fix

* rephrase batch size issue

* Clean known issues

* Rename `replace_sampler_ddp`

* Add neva support

* Imagen 23.08 Launcher Support

* Update `save_nemo_on_train_end` default to True in mm

* Update neva

* Update config for nemo nightly

* Fix duplicated yaml file

* Fix wandb default names

* Fix template path

* Fix default wandb logger name

* Fix llama2 config

* enable EMA for imagen base64-500m

* Content filtering launcher

* Update NeVa Configurations and README

* Add neva conversion yaml

* Fix neva conversion yaml

* Fix launcher

* Update Dreambooth config

* Add neva results

* Fix README.md

* Fix README.md

* Update sd config for o2

* Revert ""Update sd config for o2""

* Fix path

* Update file nsfw_L_14.yaml

* DreamFusion

* Fix ToC

* Fix Readme

* Add NeVa TRT support

* Update readme of dreambooth.

* Fix TRT polography issues

* update README.md

* Update SD perf

* config default precision switch to bf16

* update known issues

* Update Imagen README

* typo on Imagen README

* Fix readme

* Fix readme

* Fix readme

* Fix default container path

* Add neva peft config

* Update HP

* Update module freeze

* Fix README.md

* Change quick-gelu to approx-gelu

* Add 70B config

* Update 70B config

* Update llava 1.5 in configs

* Update llava 1.5 in configs

* Update llava 1.5 finetune configs

* Update llava 1.5 finetune configs

* Fix one epoch step

* Update for batched inference pipeline

* Update code paths in stages

* Update few files

* add back few files

* add back few mm files

* path fix

* Update default filename

* Neva default config update

* SD path fix

* fix target

* Remove not required stuff

* Few fixes

* reformat

* fix unit test

---------

Co-authored-by: Chen Cui <chcui@nvidia.com>
Co-authored-by: Yu Yao <yuya@nvidia.com>
Co-authored-by: Mingyuan Ma <mingyuanm@nvidia.com>
Co-authored-by: Ao Tang <aot@nvidia.com>
Co-authored-by: Izzy Putterman <iputterman@nvidia.com>
Co-authored-by: ntajbakhsh <ntajbakhsh@nvidia.com>
Co-authored-by: Maanu Grover <maanug@nvidia.com>
Co-authored-by: Aastha <aasthaj@nvidia.com>
Co-authored-by: Alexandre Milesi <alexandrem@nvidia.com>
Co-authored-by: Bobby Chen <bobchen@nvidia.com>
Co-authored-by: Lukasz Pierscieniewski <lukaszp@nvidia.com>
Co-authored-by: Ahmad Kiswani <kiswani.ahmad@gmail.com>"
github.com/d8ahazard/sd_smartprocess,clipinterrogator.py,2023-01-03T02:59:28Z,"Add min/max CLIP length, don't adjust image size unless we tell it to"
github.com/d8ahazard/sd_smartprocess,clipinterrogator.py,2022-12-15T19:48:36Z,"Code cleanup, fixes"
github.com/d8ahazard/sd_smartprocess,clipinterrogator.py,2022-12-10T23:54:02Z,Moar fun
github.com/d8ahazard/sd_smartprocess,clipinterrogator.py,2022-12-10T23:33:34Z,"Super Update

Add WD14 tagger.
Add CLIP v2.1 interrogator.
Allow filtering wd14, booru tags by score.
Add don't rename option.
Update ReallySafe
Bump BLIP version?
Remove split image options.
Completely overhaul smartprocess..."
github.com/zideliu/StyleDrop-PyTorch,extract_test_prompt_feature.py,2023-07-04T03:10:02Z,first commit
github.com/facebookresearch/ov-seg,open_clip_training/tests/test_simple.py,2023-05-28T21:50:35Z,init open_clip_training
github.com/KU-CVLAB/CAT-Seg,open_clip/tests/util_test.py,2023-03-21T12:14:05Z,initial commit
github.com/KU-CVLAB/CAT-Seg,open_clip/tests/test_inference.py,2023-03-21T12:14:05Z,initial commit
github.com/KU-CVLAB/CAT-Seg,open_clip/tests/test_inference_simple.py,2023-03-21T12:14:05Z,initial commit
github.com/KU-CVLAB/CAT-Seg,open_clip/tests/test_download_pretrained.py,2023-03-21T12:14:05Z,initial commit
github.com/perf-project/PeRF,ldm/modules/encoders/modules.py,2023-10-26T03:05:31Z,first commit
github.com/wolverinn/stable-diffusion-multi-user,modules/sd_disable_initialization.py,2023-09-04T15:19:23Z,update sd-webui version to torch2.0 and add extension support
github.com/wolverinn/stable-diffusion-multi-user,modules/sd_disable_initialization.py,2023-04-18T00:42:21Z,add django code
github.com/wolverinn/stable-diffusion-multi-user,sd-docker-slim/modules/sd_disable_initialization.py,2023-07-13T00:56:31Z,add docker-slim
github.com/wolverinn/stable-diffusion-multi-user,repositories/stable-diffusion-stability-ai/ldm/modules/encoders/modules.py,2023-09-04T15:19:23Z,update sd-webui version to torch2.0 and add extension support
github.com/wolverinn/stable-diffusion-multi-user,repositories/stable-diffusion-stability-ai/ldm/modules/encoders/modules.py,2023-04-18T00:42:21Z,add django code
github.com/wolverinn/stable-diffusion-multi-user,sd-docker-slim/repositories/stable-diffusion-stability-ai/ldm/modules/encoders/modules.py,2023-07-13T00:56:31Z,add docker-slim
github.com/JiYuanFeng/DDP,controlnet/ldm/modules/encoders/modules.py,2023-07-10T02:21:20Z,controlnet exp
github.com/wusongbai139/controlnet_TrainingPackage,ldm/modules/encoders/modules.py,2024-01-25T07:48:53Z,controlnet train
github.com/StartHua/ComfyUI_Seg_VITON,ldm/modules/encoders/modules.py,2024-01-30T14:33:59Z,换装
github.com/NVIDIA-AI-IOT/jetson-intro-to-distillation,openclip_utils.py,2023-08-01T20:53:22Z,license
github.com/NVIDIA-AI-IOT/jetson-intro-to-distillation,openclip_utils.py,2023-06-27T21:37:06Z,initial commit
github.com/bytedance/AvatarVerse,controlnet/ldm/modules/encoders/modules.py,2024-01-03T12:36:03Z,init commit
github.com/OPPO-Mente-Lab/Subject-Diffusion,train.py,2023-07-21T03:44:19Z,Add files via upload
github.com/OPPO-Mente-Lab/Subject-Diffusion,train.py,2023-07-21T02:15:56Z,Add files via upload
github.com/OPPO-Mente-Lab/Subject-Diffusion,test.py,2023-07-21T03:44:19Z,Add files via upload
github.com/OPPO-Mente-Lab/Subject-Diffusion,test.py,2023-07-21T02:15:56Z,Add files via upload
github.com/OPPO-Mente-Lab/Subject-Diffusion,test_subject.py,2023-07-21T02:15:56Z,Add files via upload
github.com/tgxs002/HPSv2,hpsv2/tests/util_test.py,2023-08-02T06:54:12Z,Implement Pypi package
github.com/tgxs002/HPSv2,hpsv2/tests/test_inference.py,2023-08-02T06:54:12Z,Implement Pypi package
github.com/tgxs002/HPSv2,hpsv2/tests/test_inference_simple.py,2023-08-02T06:54:12Z,Implement Pypi package
github.com/tgxs002/HPSv2,hpsv2/tests/test_download_pretrained.py,2023-08-02T06:54:12Z,Implement Pypi package
github.com/ChenDelong1999/RemoteCLIP,retrieval.py,2023-11-07T02:54:39Z,Modify retrieval evaluation information to improve readibility
github.com/frank-xwang/InstanceDiffusion,eval/eval_attribute_binding.py,2024-02-11T00:40:51Z,add attribute binding
github.com/neggles/sd-webui-arc,modules/sd_disable_initialization.py,2023-02-05T08:21:00Z,make it possible to load SD1 checkpoints without CLIP
github.com/neggles/sd-webui-arc,modules/sd_disable_initialization.py,2023-01-22T05:20:48Z,fix missing field for aesthetic embedding extension
github.com/neggles/sd-webui-arc,modules/sd_disable_initialization.py,2023-01-11T15:54:13Z,"fix for an error caused by skipping initialization, for realsies this time: TypeError: expected str, bytes or os.PathLike object, not NoneType"
github.com/neggles/sd-webui-arc,modules/sd_disable_initialization.py,2023-01-10T14:46:59Z,"add support for transformers==4.25.1
add fallback for when quick model creation fails"
github.com/neggles/sd-webui-arc,modules/sd_disable_initialization.py,2023-01-10T13:51:04Z,"add more stuff to ignore when creating model from config
prevent .vae.safetensors files from being listed as stable diffusion models"
github.com/neggles/sd-webui-arc,modules/sd_disable_initialization.py,2023-01-10T11:08:29Z,disable torch weight initialization and CLIP downloading/reading checkpoint to speedup creating sd model from config
github.com/AILab-CVC/Make-Your-Video,lvdm/modules/encoders/condition.py,2023-11-30T15:04:09Z,release model
github.com/yongliang-wu/ExploreCfg,open_flamingo/src/factory.py,2023-10-18T02:37:39Z,Initial commit
github.com/saketh12/Auto1111SDK,auto1111sdk/modules/sd_disable_initialization.py,2024-01-28T09:25:54Z,initial_commit
github.com/saketh12/Auto1111SDK,auto1111sdk/modules/stable/ldm/modules/encoders/modules.py,2024-01-28T09:25:54Z,initial_commit
github.com/saketh12/Auto1111SDK,auto1111sdk/modules/generative/sgm/modules/encoders/modules.py,2024-01-28T09:25:54Z,initial_commit
github.com/mhh0318/Cocktail,annotator/SAN/san/model/san.py,2023-05-30T15:11:44Z,Add annotations
github.com/mhh0318/Cocktail,ldm/modules/encoders/modules.py,2023-05-30T06:41:14Z,init
github.com/forchchch/DisenBooth,train_disenbooth.py,2024-01-21T05:43:34Z,upload disenbooth
github.com/neggles/neurosis,src/neurosis/models/text_encoder/clip.py,2023-12-12T04:04:28Z,make HF shut up when loading CLIP subsections
github.com/neggles/neurosis,src/neurosis/models/text_encoder/clip.py,2023-12-10T05:32:29Z,"get uwu about `NotImplementedError`s and pedantic about `ValueError`s

also further battles won in the fight against assertions"
github.com/neggles/neurosis,src/neurosis/models/text_encoder/clip.py,2023-12-07T10:32:36Z,touchup clip docstrings
github.com/neggles/neurosis,src/neurosis/models/text_encoder/clip.py,2023-12-06T05:24:25Z,clean up some clip init logic
github.com/neggles/neurosis,src/neurosis/models/text_encoder/clip.py,2023-12-06T03:57:52Z,ok i think this works now. SD1.5 sampling is still broke
github.com/neggles/neurosis,src/neurosis/models/text_encoder/clip.py,2023-12-06T03:57:52Z,"committing as-is, throws error, good luck salt"
github.com/neggles/neurosis,src/neurosis/models/text_encoder/clip.py,2023-11-12T04:31:19Z,Add new functions and fix bugs in various modules. Thing works now maybe.
github.com/neggles/neurosis,src/neurosis/models/text_encoder/clip.py,2023-08-04T16:01:23Z,"more refactoring, loads now but HF dataset eats itself"
github.com/neggles/neurosis,src/neurosis/models/text_encoder/clip.py,2023-08-02T13:34:26Z,config loads
github.com/neggles/neurosis,src/neurosis/models/text_encoder/clip.py,2023-08-02T02:52:25Z,pull in a bunch of code from generative-models
github.com/YuxinWenRick/tree-ring-watermark,run_tree_ring_watermark.py,2023-10-28T03:10:40Z,"corrected TPR@1%FPR, expect better performance"
github.com/YuxinWenRick/tree-ring-watermark,run_tree_ring_watermark.py,2023-05-31T14:39:55Z,initial release
github.com/Picsart-AI-Research/HD-Painter,src/smplfusion/models/encoders/open_clip_embedder.py,2024-01-24T06:43:01Z,code release
github.com/leptonai/examples,advanced/open-clip/open-clip.py,2023-08-16T03:44:55Z,black format
github.com/leptonai/examples,advanced/open-clip/open-clip.py,2023-08-16T03:29:08Z,more
github.com/leptonai/examples,advanced/open-clip/open-clip.py,2023-08-16T03:26:47Z,Fix lint error
github.com/leptonai/examples,advanced/open-clip/open-clip.py,2023-08-15T21:42:04Z,chore(examples): merge the clip model code form leptonai/lepton to here
github.com/leptonai/examples,advanced/open-clip/open-clip.py,2023-08-15T21:22:42Z,add type annotation
github.com/leptonai/examples,advanced/open-clip/open-clip.py,2023-08-14T23:48:44Z,feat(clip) : add clip as an example
github.com/Junyi42/sd-dino,third_party/ODISE/odise/modeling/meta_arch/clip.py,2023-06-11T09:30:30Z,init commit
github.com/taesiri/ZoomIsAllYouNeed,src/ImageNet_Hard/benchmark-openclip.py,2023-05-25T00:58:04Z,Add files via upload
github.com/taesiri/ZoomIsAllYouNeed,src/ImageNet_Hard/benchmark_openclip.py,2023-05-26T14:04:04Z,openclip benchmark
github.com/taesiri/ZoomIsAllYouNeed,src/ImageNet_Hard/benchmark_openclip_datacomp.py,2023-05-26T03:43:03Z,Added results for datacomp/commonpool
github.com/showlab/cosmo,src/eval/eval_tasks/utils/rices.py,2024-01-02T02:52:57Z,first commit
github.com/showlab/cosmo,src/multimodal_model/vision_model/load_vision_model.py,2024-01-02T02:52:57Z,first commit
github.com/chs20/RobustVLM,CLIP_eval/eval_utils.py,2024-02-23T23:30:03Z,Fix quick_gelu
github.com/chs20/RobustVLM,CLIP_eval/eval_utils.py,2024-02-19T18:17:12Z,Initial commit
github.com/chs20/RobustVLM,open_flamingo/src/factory.py,2024-02-19T18:17:12Z,Initial commit
github.com/chs20/RobustVLM,train/adversarial_training_clip.py,2024-02-19T18:17:12Z,Initial commit
github.com/chs20/RobustVLM,llava/model/multimodal_encoder/clip_encoder.py,2024-02-19T18:17:12Z,Initial commit
github.com/chs20/RobustVLM,CLIP_benchmark/clip_benchmark/models/open_clip.py,2024-02-19T18:17:12Z,Initial commit
github.com/hukkelas/deep_privacy2,dp2/discriminator/projected_gan/vit_openclip.py,2023-11-19T19:04:08Z,add: TriA-GAN cod
github.com/djghosh13/geneval,evaluation/evaluate_images.py,2023-12-14T22:19:35Z,Updated README
github.com/djghosh13/geneval,evaluation/evaluate_images.py,2023-12-14T21:56:56Z,Fixed model download and path
github.com/djghosh13/geneval,evaluation/evaluate_images.py,2023-12-14T18:16:08Z,Updated scripts for single-GPU
github.com/djghosh13/geneval,evaluation/evaluate_images.py,2023-08-22T21:09:50Z,Initial code release
github.com/achao2013/deep3dmap,deep3dmap/models/modulars/ns_encoders/openclip_encoder.py,2023-05-28T02:32:39Z,add lerf and related dependency
github.com/GaryJiajia/OFv2_ICL_VQA,open_flamingo/src/factory.py,2023-11-17T12:16:18Z,first commit
github.com/GaryJiajia/OFv2_ICL_VQA,open_flamingo/src/factory_new.py,2023-11-17T12:16:18Z,first commit
github.com/GaryJiajia/OFv2_ICL_VQA,open_flamingo/src/factory_old.py,2023-11-17T12:16:18Z,first commit
github.com/yeates/MaGIC,ldm/modules/encoders/modules.py,2023-06-23T02:08:04Z,magic init
github.com/salesforce/DOODL,doodl.py,2023-04-18T21:07:14Z,first commit
github.com/lucidrains/classifier-free-guidance-pytorch,classifier_free_guidance_pytorch/open_clip.py,2023-03-08T16:07:13Z,"fix open clip model name, address https://github.com/lucidrains/classifier-free-guidance-pytorch/issues/1"
github.com/lucidrains/classifier-free-guidance-pytorch,classifier_free_guidance_pytorch/open_clip.py,2022-12-16T19:36:44Z,"demonstrate ability to condition on both CLIP and T5, as in most recent nvidia text-to-image paper"
github.com/lucidrains/classifier-free-guidance-pytorch,classifier_free_guidance_pytorch/open_clip.py,2022-12-15T19:47:47Z,get ready to condition robotic transformer
github.com/lucidrains/classifier-free-guidance-pytorch,classifier_free_guidance_pytorch/open_clip.py,2022-12-15T17:53:39Z,"make open clip work, use own tokenizer as it seems to be broken from main package"
github.com/lucidrains/classifier-free-guidance-pytorch,classifier_free_guidance_pytorch/open_clip.py,2022-12-07T20:26:25Z,just copy some code over
github.com/daveredrum/SceneTex,models/pipeline/texture_pipeline.py,2023-11-28T15:38:19Z,Add code
github.com/MedARC-AI/fMRI-Algonauts-Challenge-2023,src/models.py,2023-06-03T21:45:14Z,better starting point with updated wds
github.com/aim-uofa/StyleDrop-PyTorch,predict.py,2023-07-07T21:06:29Z,replicate
github.com/aim-uofa/StyleDrop-PyTorch,gradio_demo.py,2023-07-09T00:52:03Z,update for colab
github.com/aim-uofa/StyleDrop-PyTorch,gradio_demo.py,2023-07-09T00:07:07Z,update gradio demo
github.com/aim-uofa/StyleDrop-PyTorch,gradio_demo.py,2023-07-05T05:09:29Z,fix some bugs
github.com/aim-uofa/StyleDrop-PyTorch,gradio_demo.py,2023-07-05T03:49:03Z,ADD set_seed
github.com/aim-uofa/StyleDrop-PyTorch,gradio_demo.py,2023-07-04T03:10:02Z,first commit
github.com/aim-uofa/StyleDrop-PyTorch,train_t2i_colab_v2.py,2023-07-08T07:33:12Z,updated colab train script
github.com/aim-uofa/StyleDrop-PyTorch,train_t2i_custom_v2.py,2023-07-08T03:34:00Z,fix bugs
github.com/aim-uofa/StyleDrop-PyTorch,train_t2i_custom_v2.py,2023-07-04T03:10:02Z,first commit
github.com/aim-uofa/StyleDrop-PyTorch,extract_empty_feature.py,2023-07-09T07:21:34Z,fixing memory overflow
github.com/aim-uofa/StyleDrop-PyTorch,extract_empty_feature.py,2023-07-04T03:10:02Z,first commit
github.com/aim-uofa/StyleDrop-PyTorch,extract_test_prompt_feature.py,2023-07-04T03:10:02Z,first commit
github.com/Tlntin/trt2023,ldm/modules/encoders/modules.py,2023-07-12T10:22:38Z,first commit
github.com/amazon-science/instruct-video-to-video,modules/openclip/modules.py,2023-11-25T06:45:49Z,Official implementation uploaded.
github.com/amazon-science/instruct-video-to-video,modules/damo_text_to_video/text_model.py,2023-11-25T06:45:49Z,Official implementation uploaded.
github.com/yeongjoonJu/NeuroInspect,clip_illusion.py,2023-10-19T02:56:24Z,requirements are modified
github.com/yeongjoonJu/NeuroInspect,clip_illusion.py,2023-09-07T01:56:16Z,add core relevance score
github.com/yeongjoonJu/NeuroInspect,clip_illusion.py,2023-07-23T06:38:35Z,adding extra neurou aug
github.com/yeongjoonJu/NeuroInspect,clip_illusion.py,2023-07-19T05:42:05Z,init repo
github.com/superhero-7/AltDiffusion,src/ldm/modules/encoders/modules.py,2023-08-18T17:14:51Z,first commit
github.com/kabachuha/InfiNet,t2v_modules/clip_wrap.py,2023-03-29T15:11:49Z,select Apache 2.0 as license
github.com/kabachuha/InfiNet,t2v_modules/clip_wrap.py,2023-03-28T14:31:20Z,add the not touched yet ModelScope modules
github.com/zzc-1998/SJTU-H3D,quality_measure_utils/semantic_affinity_quality_measure.py,2023-06-14T09:05:14Z,Add files via upload
github.com/Badisches-Landesmuseum/xcurator,data-enrichment/1-artefact-embedding/src/embeddings/OpenCLIP.py,2023-11-21T12:30:41Z,build(project): rename subprojects
github.com/Badisches-Landesmuseum/xcurator,data-enrichment/1-artefact-embedding/src/generate/coca_decoder.py,2023-11-21T12:30:41Z,build(project): rename subprojects
github.com/adodge/ComfyLib,comfy/hazard/ldm/modules/encoders/modules.py,2023-02-26T03:09:37Z,creating a library interface for the SD implementation in ComfyUI
github.com/locuslab/FLYP,src/models/modeling.py,2022-12-01T15:42:43Z,code release
github.com/altndrr/vic,src/models/clip.py,2024-02-02T14:14:47Z,"Improve metrics compute (#17)

* Compute metrics once

* Compute semantic iou and similarity on step

* Ensure batch dim in `SentenceScore`"
github.com/altndrr/vic,src/models/clip.py,2023-12-14T18:38:49Z,"Major code overhaul (#16)

* Remove `.yaml` extension from config files

* Remove `.compile` in `train.py`

* Print config tree as last of extras

* Remove colorlogger

* Add missing types and docstrings

* Update data

* Suppress kaggle `OSError`

* Add requests header to avoid HTTP 406 errors in download

* Update metrics

* Support masking in `NearestNeighboursClassifier`

* Refactor retrieval system

* Refactor models

* Support disabling loggers

* Fix wandb hparams logging format

* Remove optim from CLIP config

* Add interrogate pre-commit

* Fix pytype issues

* Fix default models filepath

* Set default CaSED alpha to `0.7`

* Add new dependencies

* Rename `databases.json` file

* Update citation

* Bump repo version

* Add reference in method

* Update HuggingFace inference code

* Add logo"
github.com/altndrr/vic,src/models/clip.py,2023-06-02T07:11:50Z,Initial commit
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding,training_pro10k_s5.py,2022-10-16T15:59:07Z,"Initial Version

Initial Version"
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding,training_pro10k_s9.py,2022-10-16T15:59:07Z,"Initial Version

Initial Version"
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding,training_pro10k_s7.py,2022-10-16T15:59:07Z,"Initial Version

Initial Version"
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding,training_pro10k_s3.py,2022-10-16T15:59:07Z,"Initial Version

Initial Version"
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding,training_pro10k_s4.py,2022-10-16T15:59:07Z,"Initial Version

Initial Version"
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding,training_pro10k_s8.py,2022-10-16T15:59:07Z,"Initial Version

Initial Version"
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding,training_pro10k_s13.py,2022-10-16T15:59:07Z,"Initial Version

Initial Version"
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding,training_pro10k_s11.py,2022-10-16T15:59:07Z,"Initial Version

Initial Version"
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding,training_pro10k_s12.py,2022-10-16T15:59:07Z,"Initial Version

Initial Version"
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding,training_allexpro10k_s6.py,2022-10-16T15:59:07Z,"Initial Version

Initial Version"
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding,training_allexpro10k_s2.py,2022-10-16T15:59:07Z,"Initial Version

Initial Version"
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding,training_allexpro10k_s1.py,2022-10-16T15:59:07Z,"Initial Version

Initial Version"
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding,training_allexpro10k_s10.py,2022-10-16T15:59:07Z,"Initial Version

Initial Version"
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding,open_clip_280/tests/test_simple.py,2022-10-16T15:59:07Z,"Initial Version

Initial Version"
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding,open_clip_280_overlap/tests/test_simple.py,2022-10-16T15:59:07Z,"Initial Version

Initial Version"
github.com/joanaapa/Foundation-Medical,utils/transformers/clip.py,2023-12-23T10:29:14Z,First commit
github.com/ai-forever/deforum-kandinsky,deforum_kandinsky/src/ldm/modules/encoders/modules.py,2023-10-16T21:02:49Z,commit message
github.com/facebookresearch/SIEVE,eval_utils/wds_eval.py,2023-12-14T20:43:31Z,Initial commit
github.com/runpod/serverless-workers,workers/ControlNet/ldm/modules/encoders/modules.py,2023-03-15T01:23:53Z,feat: start ControlNet Endpoint
github.com/crystallee-ai/controlGIF,clip_interrogator/clip_interrogator.py,2023-11-26T05:51:01Z,Update clip_interrogator.py
github.com/crystallee-ai/controlGIF,clip_interrogator/clip_interrogator.py,2023-11-25T09:12:55Z,v1
github.com/bentoml/CLIP-API-service,src/clip_api_service/models/openclip.py,2023-10-11T18:33:36Z,fix: serve not using defined model
github.com/bentoml/CLIP-API-service,src/clip_api_service/models/openclip.py,2023-05-25T22:01:51Z,Added CLI
github.com/bentoml/CLIP-API-service,src/clip_api_service/models/openclip.py,2023-05-23T05:16:39Z,"PDM, Ruff, Black - build WIP"
github.com/Understanding-Visual-Datasets/VisDiff,serve/clip_server.py,2023-11-29T20:48:05Z,"initial release

Co-Authored-By: Lisa Dunlap <25967790+lisadunlap@users.noreply.github.com>
Co-Authored-By: Yuhui Zhang <yuhuiz@cs.stanford.edu>"
github.com/unum-cloud/coco-sm,modules/open_clip.py,2023-08-17T14:18:53Z,Init: First commit
github.com/ByChelsea/VAND-APRIL-GAN,train.py,2023-07-05T08:35:29Z,faster
github.com/ByChelsea/VAND-APRIL-GAN,train.py,2023-06-28T07:24:16Z,Simpler Version
github.com/ByChelsea/VAND-APRIL-GAN,train.py,2023-06-21T13:53:00Z,bug fix
github.com/ByChelsea/VAND-APRIL-GAN,train.py,2023-06-13T08:38:14Z,first commit
github.com/ByChelsea/VAND-APRIL-GAN,test.py,2023-07-05T08:36:13Z,faster
github.com/ByChelsea/VAND-APRIL-GAN,test.py,2023-06-28T15:04:39Z,support resnet
github.com/ByChelsea/VAND-APRIL-GAN,test.py,2023-06-28T07:24:16Z,Simpler Version
github.com/ByChelsea/VAND-APRIL-GAN,test.py,2023-06-22T09:18:51Z,fix bug
github.com/ByChelsea/VAND-APRIL-GAN,test.py,2023-06-21T14:48:45Z,fix bug
github.com/ByChelsea/VAND-APRIL-GAN,test.py,2023-06-21T13:53:00Z,bug fix
github.com/ByChelsea/VAND-APRIL-GAN,test.py,2023-06-13T08:38:14Z,first commit
github.com/hq-deng/AnoVL,vl_test.py,2023-09-07T09:44:56Z,Add files via upload
github.com/hq-deng/AnoVL,vis_test.py,2023-09-07T09:44:56Z,Add files via upload
github.com/luping-liu/Detector-Guidance,stablediffusion/ldm/modules/encoders/modules.py,2024-02-07T08:52:21Z,init
github.com/sled-group/CycleNet,ldm/modules/encoders/modules.py,2023-03-27T03:51:26Z,ini
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-11-29T09:21:06Z,1.1
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-11-15T15:13:43Z,0.3.5
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-11-13T16:27:32Z,0.3.4
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-11-11T14:21:12Z,0.3.1
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-11-10T16:51:50Z,0.3.0
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-11-10T10:11:33Z,0.2.10
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-11-09T08:04:49Z,0.2.9.2
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-11-05T17:25:12Z,0.2.8
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-11-03T07:50:24Z,0.2.6
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-11-02T17:44:39Z,0.2.5
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-11-01T16:35:10Z,0.2.4
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-10-31T12:26:20Z,0.2.2
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-10-23T02:09:03Z,0.1.5
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-10-21T15:14:16Z,0.1.4
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-10-20T06:25:54Z,0.1.2
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-10-19T14:46:26Z,0.1.0
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-10-19T02:50:12Z,0.0.4
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-10-18T10:42:06Z,0.0.3
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-10-18T08:01:17Z,0.0.2
github.com/CuriseJia/FreeStyleRet,src/models/style_retrieval.py,2023-10-17T15:14:06Z,0.0.1
github.com/CuriseJia/FreeStyleRet,imagenet_test/clip_test.py,2023-11-15T15:13:43Z,0.3.5
github.com/CuriseJia/FreeStyleRet,imagenet_test/clip_test.py,2023-11-13T16:27:32Z,0.3.4
github.com/CuriseJia/FreeStyleRet,imagenet_test/clip_test.py,2023-11-13T10:27:54Z,0.3.3
github.com/CuriseJia/FreeStyleRet,imagenet_test/clip_test.py,2023-11-07T16:36:49Z,0.2.9.1
github.com/CuriseJia/FreeStyleRet,comparison_test/clip_test.py,2023-11-15T15:13:43Z,0.3.5
github.com/CuriseJia/FreeStyleRet,comparison_test/clip_test.py,2023-11-13T16:27:32Z,0.3.4
github.com/CuriseJia/FreeStyleRet,comparison_test/clip_test.py,2023-11-13T10:27:54Z,0.3.3
github.com/CuriseJia/FreeStyleRet,comparison_test/clip_test.py,2023-11-11T14:21:12Z,0.3.1
github.com/CuriseJia/FreeStyleRet,comparison_test/clip_test.py,2023-11-09T08:04:49Z,0.2.9.2
github.com/CuriseJia/FreeStyleRet,comparison_test/clip_test.py,2023-11-06T17:31:00Z,0.2.9
github.com/CuriseJia/FreeStyleRet,comparison_test/prompt_model.py,2023-11-13T10:27:54Z,0.3.3
github.com/CuriseJia/FreeStyleRet,comparison_test/prompt_model.py,2023-11-11T14:21:12Z,0.3.1
github.com/CuriseJia/FreeStyleRet,comparison_test/prompt_model.py,2023-11-10T16:51:50Z,0.3.0
github.com/CuriseJia/FreeStyleRet,comparison_test/prompt_model.py,2023-11-10T10:11:33Z,0.2.10
github.com/CuriseJia/FreeStyleRet,comparison_test/prompt_model.py,2023-11-06T17:31:00Z,0.2.9
github.com/CuriseJia/FreeStyleRet,imagenet_test/languagebind_test.py,2023-11-15T15:13:43Z,0.3.5
github.com/CuriseJia/FreeStyleRet,imagenet_test/languagebind_test.py,2023-11-13T16:27:32Z,0.3.4
github.com/CuriseJia/FreeStyleRet,comparison_test/languagebind_test.py,2023-11-15T15:13:43Z,0.3.5
github.com/CuriseJia/FreeStyleRet,comparison_test/languagebind_test.py,2023-11-13T16:27:32Z,0.3.4
github.com/tomtom1103/compose-and-conquer,ldm/modules/encoders/modules.py,2024-01-17T04:54:19Z,init
github.com/hammoudhasan/SynthCLIP,ImageGen/ldm/modules/encoders/modules.py,2024-02-09T00:58:26Z,Added ImageGen code and formatted files
github.com/Georgefwt/Face-Landmark-ControlNet,ldm/modules/encoders/modules.py,2023-03-09T01:17:06Z,init commit
github.com/pravdomil/Rerender-A-Video,ControlNet/ldm/modules/encoders/modules.py,2023-06-16T08:15:01Z,"merge (#1)


- first commit (eab2e368258e9e9b159c3ad6abbc89227cdf3976)"
github.com/lancopku/clip-openness,clip-retrieval/clip_retrieval/clip_inference/load_clip.py,2022-11-25T10:52:13Z,init
github.com/chaojie/ComfyUI-DynamiCrafter,lvdm/modules/encoders/condition.py,2024-02-06T09:24:22Z,fix bugs
github.com/chaojie/ComfyUI-DynamiCrafter,lvdm/modules/encoders/condition.py,2024-02-06T06:13:35Z,ComfyUI DynamiCrafter
github.com/aimagelab/open-fashion-clip,quick_start.py,2023-08-31T11:45:14Z,Code and checkpoint release
github.com/aimagelab/open-fashion-clip,quick_start.py,2023-08-31T10:37:53Z,Code and checkpoint release
github.com/Eric3911/OpenAGI,Multimodal-GPT-master/mmgpt/models/open_flamingo/builder.py,2023-04-27T10:24:39Z,"更新模型

update"
github.com/Eric3911/OpenAGI,AudioGPT-master/text_to_audio/Make_An_Audio/ldm/modules/encoders/modules.py,2023-05-06T06:44:54Z,"模型更新

update"
github.com/UCSC-VLAA/vllm-safety-benchmark,baselines/openflamingo_modeling.py,2023-11-24T02:09:04Z,first commit
github.com/UCSC-VLAA/vllm-safety-benchmark,safety_evaluations/redteaming/misleading_vision_attack/misleading_vis_attack.py,2023-11-24T02:09:04Z,first commit
github.com/Happenmass/ControlNet-for-SDXL,sgm/modules/encoders/modules.py,2023-08-11T02:55:29Z,add init test file
github.com/Happenmass/ControlNet-for-SDXL,ldm/modules/encoders/modules.py,2023-08-11T02:55:29Z,add init test file
github.com/modelscope/normal-depth-diffusion,tools/compute_metric.py,2023-12-11T02:42:52Z,init
github.com/modelscope/normal-depth-diffusion,tools/compute_metric_curves.py,2023-12-11T02:42:52Z,init
github.com/modelscope/normal-depth-diffusion,ldm/modules/encoders/modules.py,2023-12-11T02:42:52Z,init
github.com/modelscope/normal-depth-diffusion,tools/compute_clip_metric_curves.py,2023-12-11T02:42:52Z,init
github.com/modelscope/normal-depth-diffusion,tools/compute_objaverse_clipscore.py,2023-12-11T02:42:52Z,init
github.com/modelscope/normal-depth-diffusion,tools/compute_cfg_clip_metric_curves.py,2023-12-11T02:42:52Z,init
github.com/yandex-research/adaptive-diffusion,consistency_models_sd/evaluations/clip_score.py,2023-12-19T05:34:44Z,"Initial update
* two examples of t2i
* arxiv link"
github.com/gersteinlab/ML-Bench,MLAgent/repo/open_clip/tests/util_test.py,2023-11-18T21:06:52Z,test
github.com/gersteinlab/ML-Bench,MLAgent/repo/open_clip/tests/test_inference.py,2023-11-18T21:06:52Z,test
github.com/gersteinlab/ML-Bench,MLAgent/repo/open_clip/tests/test_inference_simple.py,2023-11-18T21:06:52Z,test
github.com/gersteinlab/ML-Bench,MLAgent/repo/open_clip/tests/test_download_pretrained.py,2023-11-18T21:06:52Z,test
github.com/bubbliiiing/stable-diffusion,ldm/modules/encoders/modules.py,2023-06-11T16:42:07Z,update comment
github.com/bubbliiiing/stable-diffusion,ldm/modules/encoders/modules.py,2023-06-04T12:09:08Z,create code
github.com/showlab/VisorGPT,demo/ControlNet/controlnet/ldm/modules/encoders/modules.py,2023-05-28T08:50:01Z,add gradio demo
github.com/JunjieYang97/Meta-ControlNet,ldm/modules/encoders/modules.py,2023-12-03T01:03:50Z,init
github.com/boschresearch/ALDM,ldm/modules/encoders/modules.py,2024-01-24T20:38:39Z,minor
github.com/boschresearch/ALDM,ldm/modules/encoders/modules.py,2024-01-17T12:05:01Z,initial commit
github.com/razeghi71/stable-diffusion-v2-m1,ldm/modules/encoders/modules.py,2022-12-20T02:11:52Z,support mps m1 mac
github.com/razeghi71/stable-diffusion-v2-m1,ldm/modules/encoders/modules.py,2022-11-24T00:22:28Z,release more models
github.com/ruoxi-jia-group/CLIP-MIA,main.py,2023-09-29T12:17:27Z,Add files via upload
github.com/Birch-san/imagebind-guided-diffusion,src/imgbind_guidance/clip_embed/embed_text.py,2023-05-21T18:10:34Z,generating images
github.com/Computer-Vision-in-the-Wild/UniCL-OpenCLIP,tests/util_test.py,2022-12-09T03:23:32Z,update
github.com/Computer-Vision-in-the-Wild/UniCL-OpenCLIP,tests/test_inference.py,2022-12-09T03:23:32Z,update
github.com/Computer-Vision-in-the-Wild/UniCL-OpenCLIP,tests/test_inference_simple.py,2022-12-09T03:23:32Z,update
github.com/distable/core,src_plugins/paella/colab.py,2023-04-25T18:23:58Z,flower model and other many hundreds of improvements
github.com/distable/core,src_plugins/paella/colab.py,2023-04-15T16:52:46Z,more
github.com/distable/core,src_plugins/opticalflow/notebook.py,2023-04-15T16:51:40Z,many many improvements
github.com/JiahuiLei/GART,lib_guidance/mvdream/extern/MVDream/mvdream/ldm/modules/encoders/modules.py,2023-11-27T22:40:46Z,from internal
github.com/GiovanniTRA/MultimodalNeuralDatabases,MMNDB/Model/retrieve.py,2023-07-22T08:38:07Z,first commit
github.com/GiovanniTRA/MultimodalNeuralDatabases,MMNDB/Data/data_retriever.py,2023-07-22T08:38:07Z,first commit
github.com/wangyu-ustc/LM4CV,cluster.py,2023-10-03T08:56:05Z,Add files via upload
github.com/wangyu-ustc/LM4CV,utils/train_utils.py,2023-10-03T08:56:05Z,Add files via upload
github.com/salesforce/BannerGen,InstructPix2Pix/stable_diffusion/ldm/modules/encoders/modules.py,2023-11-23T05:04:01Z,Add README and MISC changes
github.com/salesforce/BannerGen,InstructPix2Pix/stable_diffusion/ldm/modules/encoders/modules.py,2023-11-09T05:06:04Z,Initial commit of 3 BannerGen models
github.com/wkcn/TinyCLIP,inference.py,2024-03-01T02:15:21Z,[TinyCLIP] inference auto weight inheritance
github.com/wkcn/TinyCLIP,inference.py,2024-01-21T12:18:23Z,first commit
github.com/waltonfuture/InstructionGPT-4,selector/utils_image.py,2023-10-09T07:45:22Z,codes
github.com/waltonfuture/InstructionGPT-4,cluster/kmeans++/kmeans_pp.py,2023-10-09T07:45:22Z,codes
github.com/waltonfuture/InstructionGPT-4,selector/get_all_image_features.py,2023-10-09T07:45:22Z,codes
github.com/waltonfuture/InstructionGPT-4,cluster/spectral/spectral_clustering.py,2023-10-09T07:45:22Z,codes
github.com/waltonfuture/InstructionGPT-4,cc_sbu_align_test/full_score.py,2023-10-09T07:45:22Z,codes
github.com/huzeyann/MemoryEncodingModel,mem/backbone.py,2023-08-10T06:34:06Z,rename files
github.com/Zhiyuan-R/ChatGPT-Powered-Hierarchical-Comparisons-for-Image-Classification,main.py,2023-12-17T17:59:32Z,basic_files
github.com/Hazel1994/ViPE-Videos,src/ldm/modules/encoders/modules.py,2023-10-19T13:28:52Z,first commit
github.com/NeuralRealm/StableFusion,stablefusion/scripts/clip_interrogator.py,2023-03-03T12:10:15Z,rearranged the file and add upscaler feature
github.com/TIGER-AI-Lab/ImagenHub,src/imagen_hub/depend/clip_retrieval/load_clip.py,2023-10-20T00:35:15Z,release 0.1.0
github.com/TIGER-AI-Lab/ImagenHub,src/imagen_hub/pipelines/controlnet/ldm/modules/encoders/modules.py,2023-10-20T23:02:39Z,"fixing docstrings, writing docs"
github.com/TIGER-AI-Lab/ImagenHub,src/imagen_hub/pipelines/controlnet/ldm/modules/encoders/modules.py,2023-10-20T00:35:15Z,release 0.1.0
github.com/TIGER-AI-Lab/ImagenHub,src/imagen_hub/pipelines/unicontrol/ldm/modules/encoders/modules.py,2023-10-20T23:02:39Z,"fixing docstrings, writing docs"
github.com/TIGER-AI-Lab/ImagenHub,src/imagen_hub/pipelines/unicontrol/ldm/modules/encoders/modules.py,2023-10-20T00:35:15Z,release 0.1.0
github.com/locuslab/smoothinv,loader.py,2023-07-18T12:41:44Z,Update loader.py
github.com/locuslab/smoothinv,loader.py,2023-07-18T12:41:14Z,Update loader.py
github.com/locuslab/smoothinv,loader.py,2023-03-02T03:51:48Z,init
github.com/chenxx89/BFRffusion,ldm/modules/encoders/modules.py,2023-12-27T04:10:32Z,initial commit
github.com/hylarucoder/svd-webui,sgm/modules/encoders/modules.py,2023-11-23T06:17:13Z,init (#4)
github.com/hylarucoder/svd-webui,sgm/modules/encoders/modules.py,2023-11-22T04:44:02Z,init
github.com/IDEA-Research/HumanSD,ldm/modules/encoders/modules.py,2023-04-27T03:31:47Z,release v1.0
github.com/IDEA-Research/HumanSD,comparison_models/T2IAdapter/ldm/modules/encoders/modules.py,2023-08-24T18:47:39Z,fix bugs
github.com/IDEA-Research/HumanSD,comparison_models/ControlNet/ldm/modules/encoders/modules.py,2023-08-24T18:47:39Z,fix bugs
github.com/JustRin/Stable-Video-Diffusion,sgm/modules/encoders/modules.py,2023-11-23T11:20:17Z,Upload all files
github.com/facebookresearch/Whac-A-Mole,model/model_zoo.py,2022-11-28T03:04:58Z,Initial commit
github.com/UMass-Foundation-Model/CoVLM,open_flamingo/src/factory.py,2023-11-01T14:42:53Z,init commit
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-10-21T20:53:05Z,1.4.0
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-10-18T21:37:54Z,1.3.2
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-09-19T16:03:49Z,1.3.1
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-09-18T19:32:10Z,1.3.0
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-09-11T21:30:41Z,Predefined SDXL model
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-08-31T18:00:01Z,1.2.4
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-08-31T15:44:05Z,1.2.3
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-08-27T07:32:05Z,1.2.2
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-08-25T21:11:45Z,1.2.1
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-08-25T14:41:36Z,1.2.0
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-08-24T14:40:30Z,1.1.0
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-08-15T22:33:15Z,Unload model button
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-05-15T16:51:13Z,Minor fix
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-05-09T13:58:27Z,Do not save unnecessary values into ui-config.json
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-05-05T20:41:05Z,Script on txt2img
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-04-30T22:03:54Z,Removed device selection
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-04-29T21:34:13Z,Progress indicator
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-04-29T14:44:51Z,Send to buttons
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-04-29T13:10:05Z,Error message if not all packages installed
github.com/r0mar0ma/sd-webui-pez-dispenser,scripts/pez-dispenser.py,2023-04-29T01:00:27Z,Initial commit
github.com/MingtaoGuo/AnimateAnyone_unofficial,ldm/modules/encoders/modules.py,2023-12-16T03:35:29Z,Add files via upload
github.com/LAION-AI/phenaki,train_maskgit.py,2022-12-07T01:06:46Z,fix
github.com/LAION-AI/phenaki,train_maskgit.py,2022-11-30T03:24:40Z,improve training setup
github.com/LAION-AI/phenaki,train_maskgit.py,2022-11-28T09:12:15Z,Update train_maskgit.py
github.com/LAION-AI/phenaki,train_maskgit.py,2022-11-28T04:10:17Z,cool
github.com/LAION-AI/phenaki,train_maskgit.py,2022-11-27T09:00:59Z,Update train_maskgit.py
github.com/LAION-AI/phenaki,train_maskgit.py,2022-11-26T12:16:48Z,Update train_maskgit.py
github.com/LAION-AI/phenaki,train_maskgit.py,2022-11-25T03:05:19Z,add mixed precision training
github.com/LAION-AI/phenaki,train_maskgit.py,2022-11-25T02:22:13Z,add paella
github.com/LAION-AI/phenaki,train_maskgit.py,2022-11-09T13:25:27Z,fix small bugs
github.com/LAION-AI/phenaki,train_maskgit.py,2022-11-06T13:03:07Z,vivq video dropping during training
github.com/LAION-AI/phenaki,train_maskgit.py,2022-11-02T10:37:31Z,mix dataset images videos
github.com/LAION-AI/phenaki,train_maskgit.py,2022-10-30T13:09:12Z,logging + plain image training
github.com/LAION-AI/phenaki,train_maskgit.py,2022-10-23T11:23:22Z,maskgit train code wip
github.com/TRT2022/ControlNet_TensorRT,ldm/modules/encoders/modules.py,2023-08-16T08:54:00Z,controlnet trt
github.com/KaiyuYue/nxtp,src/evals/engine.py,2023-12-04T19:15:15Z,first commit
github.com/gortizji/tangent_task_arithmetic,src/modeling.py,2023-06-08T09:13:17Z,Upload clean code and update README.md.
github.com/JethroPeng/GCDSS,model/model.py,2023-11-28T04:49:11Z,new
github.com/JethroPeng/GCDSS,model/model.py,2023-11-28T04:39:05Z,model_file
github.com/orrzohar/LOVM,modelGPT/create_models.py,2023-06-14T18:52:24Z,init
github.com/orrzohar/LOVM,modelGPT/encode_dataset.py,2023-06-14T18:52:24Z,init
github.com/orrzohar/LOVM,modelGPT/encode_syn_dataset.py,2023-06-14T18:52:24Z,init
github.com/AhmedBourouis/Scene-Sketch-Segmentation,models/clip.py,2023-12-06T09:41:06Z,Initial commit
github.com/AhmedBourouis/Scene-Sketch-Segmentation,models/clip.py,2023-12-05T17:50:50Z,Initial commit
github.com/riron1206/kaggle-Google-Universal-Image-Embedding-Competition-5th-Place-Solution,train_arcface.py,2022-10-14T00:23:20Z,update
github.com/riron1206/kaggle-Google-Universal-Image-Embedding-Competition-5th-Place-Solution,train_arcface.py,2022-10-13T15:06:34Z,add code
github.com/riron1206/kaggle-Google-Universal-Image-Embedding-Competition-5th-Place-Solution,train_classifier.py,2022-10-13T15:06:34Z,add code
github.com/riron1206/kaggle-Google-Universal-Image-Embedding-Competition-5th-Place-Solution,make_torchscript_wcls.py,2022-10-13T15:06:34Z,add code
github.com/kijai/ComfyUI-SUPIR,sgm/modules/encoders/modules.py,2024-03-03T21:38:49Z,temporary fix
github.com/kijai/ComfyUI-SUPIR,sgm/modules/encoders/modules.py,2024-03-01T21:27:41Z,Faster model loading
github.com/kijai/ComfyUI-SUPIR,sgm/modules/encoders/modules.py,2024-02-28T19:14:29Z,Initial push
github.com/YitingQu/unsafe-diffusion,train.py,2023-08-17T08:53:55Z,first commit
github.com/YitingQu/unsafe-diffusion,baselines.py,2023-08-17T08:53:55Z,first commit
github.com/kirill-vish/Beyond-INet,utils/misc.py,2023-11-15T22:27:07Z,first commit
github.com/Deep-Spark/deepsparkhub,multimodal/diffusion/ControlNet/ldm/modules/encoders/modules.py,2023-12-14T09:17:34Z,"move controlnet location

Signed-off-by: majorli <mingjiang.li@iluvatar.com>"
github.com/UCSC-VLAA/MixCon3D,src/example.py,2023-11-02T23:40:57Z,Add files via upload
github.com/XmYx/ainodes_engine_base_nodes,ainodes_backend/t2v_model.py,2023-03-22T11:42:21Z,node update
github.com/XmYx/ainodes_engine_base_nodes,ainodes_backend/t2v_model.py,2023-03-20T21:39:46Z,some optim
github.com/XmYx/ainodes_engine_base_nodes,ainodes_backend/t2v_model.py,2023-03-20T15:41:14Z,nice prints on text2video
github.com/XmYx/ainodes_engine_base_nodes,ainodes_backend/t2v_model.py,2023-03-20T14:56:33Z,text2video node
github.com/lewandofskee/DiAD,ldm/modules/encoders/modules.py,2023-12-17T14:31:31Z,update
github.com/lewandofskee/DiAD,ldm/modules/encoders/modules.py,2023-12-17T14:30:45Z,1
github.com/lewandofskee/DiAD,ldm/modules/encoders/modules.py,2023-12-17T14:29:01Z,111
github.com/Ascend/ModelZoo-PyTorch,PyTorch/built-in/diffusion/stablediffusion-2.1/ldm/modules/encoders/modules.py,2023-05-20T07:30:12Z,add license and change directore
github.com/Ascend/ModelZoo-PyTorch,AscendIE/AscendIE/StableDiffusion/clip_score.py,2023-10-09T12:26:20Z,"!5610 [自研][PyTorch离线推理][Text-to-Image][StableDiffusion] 添加AIE-SD的unetparser功能、精度计算功能及README推理指导
* fix bugs
* Merge https://gitee.com/ascend/ModelZoo-PyTorch
* fix codecheck issues
* Merge https://gitee.com/ascend/ModelZoo-PyTorch
* add unet_onnx_parser, clip score and readme"
github.com/Ascend/ModelZoo-PyTorch,ACL_PyTorch/built-in/foundation_models/stable_diffusion/clip_score.py,2023-08-29T11:58:57Z,"!5419 [自研][PyTorch离线推理][Text-to-Image] StableDiffusion 添加精度验证、修改改图脚本
* 修复atc参数
* 修改main传参逻辑
* 替换使用fdopen读取文件
* 修复改图脚本
* 添加精度计算相关内容
* 添加精度计算脚本
* 添加精度验证依赖
* 添加支持读取Parti数据集"
github.com/technion-cs-nlp/ReFACT,test_clip_score.py,2023-05-31T08:36:02Z,initial commit
github.com/technion-cs-nlp/ReFACT,test_multiple_edits.py,2023-05-31T08:36:02Z,initial commit
github.com/Ascend/ModelZoo-PyTorch,PyTorch/built-in/others/OpenCLIP_for_PyTorch/tests/util_test.py,2023-05-17T12:47:36Z,"!4706 [自研][PyTorch] [OpenClip For Pytorch] 初次提交
* 提交open clip原始代码"
github.com/Ascend/ModelZoo-PyTorch,PyTorch/built-in/others/OpenCLIP_for_PyTorch/tests/test_inference.py,2023-05-17T12:47:36Z,"!4706 [自研][PyTorch] [OpenClip For Pytorch] 初次提交
* 提交open clip原始代码"
github.com/Ascend/ModelZoo-PyTorch,PyTorch/built-in/others/OpenCLIP_for_PyTorch/tests/test_inference_simple.py,2023-05-17T12:47:36Z,"!4706 [自研][PyTorch] [OpenClip For Pytorch] 初次提交
* 提交open clip原始代码"
github.com/upfusion3d/upfusion,control_net/ldm/modules/encoders/modules.py,2023-12-12T00:51:03Z,add files
github.com/om-ai-lab/RS5M,inference/inference.py,2023-11-23T21:05:36Z,Update inference.py
github.com/om-ai-lab/RS5M,inference/inference.py,2023-11-23T21:01:32Z,Update inference.py
github.com/om-ai-lab/RS5M,inference/inference.py,2023-11-23T20:44:15Z,Add files via upload
github.com/om-ai-lab/RS5M,inference/convert_weight.py,2023-11-23T20:44:15Z,Add files via upload
github.com/Birch-san/diffusers-play,src/helpers/embed_text.py,2023-05-15T23:15:00Z,support variants
github.com/Birch-san/diffusers-play,src/helpers/embed_text.py,2023-02-14T22:10:03Z,support waifu-diffusion 1.5 beta
github.com/Birch-san/diffusers-play,src/helpers/embed_text.py,2023-01-03T00:52:05Z,support splicing together CLIP multiple embeddings to utilise the triple context length of waifu-diffusion
github.com/Birch-san/diffusers-play,src/helpers/embed_text.py,2023-01-01T02:38:03Z,add support for attention masks
github.com/Birch-san/diffusers-play,src/helpers/embed_text.py,2022-12-31T23:58:42Z,add support for WD1.4
github.com/Birch-san/diffusers-play,src/helpers/embed_text.py,2022-12-24T17:22:08Z,"factor out construction of embedder from tokenizer & text encoder, because ti_train has a need to share the embedder-maker code"
github.com/Birch-san/diffusers-play,src/helpers/embed_text.py,2022-11-24T23:19:51Z,stable diffusion v2 working on-CPU via k-diffusion. just noise on MPS.
github.com/camenduru/Rerender-hf,ControlNet/ldm/modules/encoders/modules.py,2023-06-16T08:15:01Z,"merge (#1)


- first commit (eab2e368258e9e9b159c3ad6abbc89227cdf3976)"
github.com/johnowhitaker/tglcourse,tglcourse/generation_utils.py,2022-11-17T12:31:25Z,First pass at l4 and updates to generators and losses
github.com/johnowhitaker/tglcourse,tglcourse/generation_utils.py,2022-10-07T13:36:32Z,Getting generators/losses working in the optimization lesson as a quick demo for what that bonus notebook holds
github.com/johnowhitaker/tglcourse,tglcourse/generation_utils.py,2022-10-07T12:31:18Z,"Adding generators and losses draft, plus new requirements"
github.com/iejMac/clip-video-encode,clip_video_encode/simplemapper.py,2023-09-13T02:54:38Z,"clip-video-encode: add VQ-GAN frame tokenization (#77)

* clip-video-encode: add VQ-GAN frame tokenization

* it works

* automatic is_gumbel

* update

* bigger bs

* attempt at resuming

* update tests

* fix black

* fix black

* fix

---------

Co-authored-by: iejmac <iejmac@ip-26-0-151-20.us-west-2.compute.internal>
Co-authored-by: iejmac <iejmac@ip-172-64-56-42.us-west-2.compute.internal>
Co-authored-by: iejmac <iejmac@ip-26-0-146-117.us-west-2.compute.internal>
Co-authored-by: iejmac <iejmac@ip-26-0-155-198.us-west-2.compute.internal>"
github.com/iejMac/clip-video-encode,clip_video_encode/simplemapper.py,2023-04-26T07:35:37Z,"captioning: allow setting params (#73)

* captioning: allow setting params

* fix black

* docstring

---------

Co-authored-by: iejmac <iejmac@ip-26-0-151-112.us-west-2.compute.internal>"
github.com/iejMac/clip-video-encode,clip_video_encode/simplemapper.py,2023-04-06T10:55:57Z,"Add CLIP similarity if caption exists + add autocast in FrameMapper (#69)

* Add CLIP similarity if caption exists

* progress

* fix lint

* batch normalization of caption embs"
github.com/iejMac/clip-video-encode,clip_video_encode/simplemapper.py,2023-04-02T10:43:30Z,"Add CoCa captioning (#67)

* Add CoCa captioning

* works

* fix black

* req

* fix lint

* fix black

* reset"
github.com/iejMac/clip-video-encode,clip_video_encode/simplemapper.py,2022-07-31T20:45:12Z,"LiveNumpyEncoder: waits for incoming frame arrays and encodes them with CLIP (1700 samples/s) (#31)

* NumpyEncoder: waits for incoming frame arrays and encodes them with CLIP

* works 1700 FPS

* pass in dev

* rename

* add example

* fix lint"
github.com/iejMac/clip-video-encode,clip_video_encode/simplemapper.py,2022-06-15T06:52:42Z,"Asynchronously Read and Encode frames for efficiency. (~4x speedup depending on target video FPS) (#7)

* Asynchronously Load, Embed, and Save videos for efficiency

* saver: initial version

* that was supposed to be the loader

* small update

* small testing script

* new idea

* adding batcher

* taking step back and reimplementing main in modules

* Simple version of all 4 components

* Move preprocessing to batcher + log perf in samples/s + batcher 2.7x performance improvement

* Use multiprocessing to make Reader faster

* simplereader -> reader

* Batcher improvements + perf metrics update

* add unit tests for all modules

* add modules to package

* Reading + Mapping parallelism

* final version for update

* Revert to regular preprocessing, channel dim might've been mixed up

* tests updated

* new clip_video_encode script

* fix ci

* ci fix

* shared_memory not in python < 3.8

* some linting + remove time prints

* linting

* lint fix

* better default value for dest"
github.com/iejMac/clip-video-encode,tests/test_similarity.py,2022-10-14T16:28:22Z,"Fix: Take preprocessing from open_clip + Add sim test (#52)

* Fix: Take preprocessing from open_clip + Add sim test

* fix

* similarity test

* fix lint

* no need to repeat stuff

* force cpu

* fix syntax

* fix lint

* works"
github.com/iart-ai/prompt2prompt,stablediffusion/ldm/modules/encoders/modules.py,2022-11-25T12:18:58Z,add stable diffusion
github.com/MadryLab/dataset-interfaces,dataset_interfaces/inference_utils.py,2023-02-24T20:28:10Z,add token download to notebook
github.com/MadryLab/dataset-interfaces,dataset_interfaces/inference_utils.py,2023-02-16T22:23:08Z,Refactor to make imports cleaner
github.com/MadryLab/dataset-interfaces,dataset_interfaces/inference_utils.py,2023-02-16T05:02:03Z,initial commit
github.com/SKKU-ESLAB/Auto-Compression,pruning/UVP/Transformer/sparseml/integrations/clip/clip_onnx_export.py,2023-06-19T04:13:43Z,[UVP] Add sparseml library
github.com/Max-Fu/tvl,tvl_enc/tvl.py,2024-02-20T21:25:56Z,first commit
github.com/AlonzoLeeeooo/LCDG,ldm/modules/encoders/modules.py,2023-06-04T07:09:53Z,training and inference code
github.com/google/storybench,metrics/vtm_clip.py,2023-08-17T14:24:09Z,Initial version of StoryBench code.
github.com/google/storybench,metrics/fid_clip.py,2023-08-17T14:24:09Z,Initial version of StoryBench code.
github.com/czyczyyzc/CondLSTR,tools/preprocess/sa_1b_tag.py,2023-10-10T07:21:22Z,initial commit
github.com/adelacvg/ttts,ttts/diffusion/ldm/modules/encoders/modules.py,2024-01-04T15:06:40Z,update diffusion architecture
github.com/adelacvg/ttts,ttts/AA_diffusion_deprecated/ldm/modules/encoders/modules.py,2024-01-04T15:06:40Z,update diffusion architecture
github.com/eslambakr/HRS_benchmark,codes/t2i_models/Paella/paella.py,2023-02-23T09:26:03Z,add support to new txt2img models
github.com/eslambakr/HRS_benchmark,codes/t2i_models/Paella/paella_minimal.py,2023-02-23T09:26:03Z,add support to new txt2img models
github.com/eslambakr/HRS_benchmark,codes/t2i_models/Paella/paella_inference.py,2023-02-23T09:26:03Z,add support to new txt2img models
github.com/eslambakr/HRS_benchmark,codes/t2i_models/sd_v2/ldm/modules/encoders/modules.py,2023-02-04T22:25:33Z,"add detection metric, meta-prompt generation codes, chatGPT codes, SD_v1, and SD_v2 codes"
github.com/eslambakr/HRS_benchmark,codes/t2i_models/Paella/ongoing_research/scaling/paella_h.py,2023-02-23T09:26:03Z,add support to new txt2img models
github.com/eslambakr/HRS_benchmark,codes/t2i_models/Paella/ongoing_research/text-to-video/train_maskgit.py,2023-02-23T09:26:03Z,add support to new txt2img models
github.com/endo-yuki-t/MAG,ldm/modules/encoders/modules.py,2023-10-27T07:01:38Z,initial commit
github.com/tanganke/subspace_fusion,src/modeling.py,2023-12-10T10:00:44Z,initial commit
github.com/kakaobrain/nvs-adapter,sgm/modules/encoders/modules.py,2024-01-16T05:21:47Z,"initial commit

Co-authored-by: Yoonwoo Jeong <jeongyw12382@postech.ac.kr>
Co-authored-by: Jinwoo Lee <chopper.lee@kakaobrain.com>
Co-authored-by: Chiheon Kim <chiheon.kim@kakaobrain.com>
Co-authored-by: Minsu Cho <mscho@postech.ac.kr>
Co-authored-by: Doyup Lee <doyup@runwayml.com>"
github.com/weijiawu/DiffuMask,clip_retrieval/load_clip.py,2023-03-31T11:17:21Z,u
github.com/OpenGVLab/ChartAst,accessory/model/LLM/llama.py,2024-01-04T07:08:06Z,add
github.com/OpenGVLab/ChartAst,accessory/model/LLM/llama_ens.py,2024-01-04T07:08:06Z,add
github.com/OpenGVLab/ChartAst,accessory/model/LLM/llama_peft.py,2024-01-04T07:08:06Z,add
github.com/OpenGVLab/ChartAst,accessory/model/LLM/llama_ens5.py,2024-01-04T07:08:06Z,add
github.com/OpenGVLab/ChartAst,accessory/model/LLM/llama_ens10.py,2024-01-04T07:08:06Z,add
github.com/OpenGVLab/ChartAst,accessory/model/LLM/llama_ens5p2.py,2024-01-04T07:08:06Z,add
github.com/OpenGVLab/ChartAst,accessory/model/LLM/llama_adapter.py,2024-01-04T07:08:06Z,add
github.com/OpenGVLab/ChartAst,accessory/model/LLM/llama_ens_peft.py,2024-01-04T07:08:06Z,add
github.com/mlcommons/training_results_v3.1,NVIDIA/benchmarks/stable_diffusion/implementations/pytorch/evaluation/compute_clip_score.py,2023-11-07T21:26:23Z,"Upload results

Co-authored-by: Achorn, Keith <keith.achorn@intel.com>
Co-authored-by: Arjun Suresh <arjunsuresh1987@gmail.com>
Co-authored-by: BladeRD-SIT <78253812+BladeRD-SIT@users.noreply.github.com>
Co-authored-by: Bruce Lin <bruce5_lin@asus.com>
Co-authored-by: Bruno Ferreira <bruno.mgf@gmail.com>
Co-authored-by: Burhan Ul Tayyab <burhanultayyab@ailiverse.com>
Co-authored-by: BurhanUlTayyab <burhanultayyab@ailiverse.com>
Co-authored-by: ch155260 <kein.kung@gigacomputing.com>
Co-authored-by: ch155260 <kevin.kung@gigacomputing.com>
Co-authored-by: ctlee <ching-tao.lee@qct.io>
Co-authored-by: Diane Feddema <dianefeddema@gmail.com>
Co-authored-by: elim <elim@krai.ai>
Co-authored-by: erichan1 <30481032+erichan1@users.noreply.github.com>
Co-authored-by: Frank Han <frank.han@dell.com>
Co-authored-by: Guenther Schmuelling <guschmue@microsoft.com>
Co-authored-by: guschmue <guschmue@microsoft.com>
Co-authored-by: hanyunfan <frank.han@dell.com>
Co-authored-by: Hiwot Tadese Kassa <36334927+hiwotadese@users.noreply.github.com>
Co-authored-by: Hugo Affaticati <haffaticati@microsoft.com>
Co-authored-by: itayhubara <itayh@campus.technion.ac.il>
Co-authored-by: Jason Zhu <ccbt87@gmail.com>
Co-authored-by: Jason Zhu <jasonzhu@supermicro.com>
Co-authored-by: l00010728 <luxu@xfusion.com>
Co-authored-by: lbhli001 <libaihong@ieisystem.com>
Co-authored-by: lizraymond <liz.raymond@dell.com>
Co-authored-by: Matt Frank <mfrank@nvidia.com>
Co-authored-by: Nathan Wasson <nathanw@mlcommons.org>
Co-authored-by: Nils Smeds <nsmeds@lenovo.com>
Co-authored-by: Notsu, Takahiro <notsu.takahiro@fujitsu.com>
Co-authored-by: Pablo Gonzalez <pablo.gonzalez@factored.ai>
Co-authored-by: Peter Mattson <34691613+petermattson@users.noreply.github.com>
Co-authored-by: pgmpablo157321 <pablo.gonzalez@factored.ai>
Co-authored-by: Qinwen Xu <qinwen@google.com>
Co-authored-by: rakshithvasudev <rakshithvbharani@gmail.com>
Co-authored-by: Ritika Borkar <rborkar@nvidia.com>
Co-authored-by: Shriya Balaji Palsamudram <spalsamudram@nvidia.com>
Co-authored-by: SupermicroML <78233566+SupermicroML@users.noreply.github.com>"
github.com/mlcommons/training_results_v3.1,Dell/benchmarks/stable_diffusion/implementations/pytorch/evaluation/compute_clip_score.py,2023-11-07T21:26:23Z,"Upload results

Co-authored-by: Achorn, Keith <keith.achorn@intel.com>
Co-authored-by: Arjun Suresh <arjunsuresh1987@gmail.com>
Co-authored-by: BladeRD-SIT <78253812+BladeRD-SIT@users.noreply.github.com>
Co-authored-by: Bruce Lin <bruce5_lin@asus.com>
Co-authored-by: Bruno Ferreira <bruno.mgf@gmail.com>
Co-authored-by: Burhan Ul Tayyab <burhanultayyab@ailiverse.com>
Co-authored-by: BurhanUlTayyab <burhanultayyab@ailiverse.com>
Co-authored-by: ch155260 <kein.kung@gigacomputing.com>
Co-authored-by: ch155260 <kevin.kung@gigacomputing.com>
Co-authored-by: ctlee <ching-tao.lee@qct.io>
Co-authored-by: Diane Feddema <dianefeddema@gmail.com>
Co-authored-by: elim <elim@krai.ai>
Co-authored-by: erichan1 <30481032+erichan1@users.noreply.github.com>
Co-authored-by: Frank Han <frank.han@dell.com>
Co-authored-by: Guenther Schmuelling <guschmue@microsoft.com>
Co-authored-by: guschmue <guschmue@microsoft.com>
Co-authored-by: hanyunfan <frank.han@dell.com>
Co-authored-by: Hiwot Tadese Kassa <36334927+hiwotadese@users.noreply.github.com>
Co-authored-by: Hugo Affaticati <haffaticati@microsoft.com>
Co-authored-by: itayhubara <itayh@campus.technion.ac.il>
Co-authored-by: Jason Zhu <ccbt87@gmail.com>
Co-authored-by: Jason Zhu <jasonzhu@supermicro.com>
Co-authored-by: l00010728 <luxu@xfusion.com>
Co-authored-by: lbhli001 <libaihong@ieisystem.com>
Co-authored-by: lizraymond <liz.raymond@dell.com>
Co-authored-by: Matt Frank <mfrank@nvidia.com>
Co-authored-by: Nathan Wasson <nathanw@mlcommons.org>
Co-authored-by: Nils Smeds <nsmeds@lenovo.com>
Co-authored-by: Notsu, Takahiro <notsu.takahiro@fujitsu.com>
Co-authored-by: Pablo Gonzalez <pablo.gonzalez@factored.ai>
Co-authored-by: Peter Mattson <34691613+petermattson@users.noreply.github.com>
Co-authored-by: pgmpablo157321 <pablo.gonzalez@factored.ai>
Co-authored-by: Qinwen Xu <qinwen@google.com>
Co-authored-by: rakshithvasudev <rakshithvbharani@gmail.com>
Co-authored-by: Ritika Borkar <rborkar@nvidia.com>
Co-authored-by: Shriya Balaji Palsamudram <spalsamudram@nvidia.com>
Co-authored-by: SupermicroML <78233566+SupermicroML@users.noreply.github.com>"
github.com/mlcommons/training_results_v3.1,Intel-HabanaLabs/benchmarks/stable_diffusion/ldm/models/clip_encoder.py,2023-11-07T21:26:23Z,"Upload results

Co-authored-by: Achorn, Keith <keith.achorn@intel.com>
Co-authored-by: Arjun Suresh <arjunsuresh1987@gmail.com>
Co-authored-by: BladeRD-SIT <78253812+BladeRD-SIT@users.noreply.github.com>
Co-authored-by: Bruce Lin <bruce5_lin@asus.com>
Co-authored-by: Bruno Ferreira <bruno.mgf@gmail.com>
Co-authored-by: Burhan Ul Tayyab <burhanultayyab@ailiverse.com>
Co-authored-by: BurhanUlTayyab <burhanultayyab@ailiverse.com>
Co-authored-by: ch155260 <kein.kung@gigacomputing.com>
Co-authored-by: ch155260 <kevin.kung@gigacomputing.com>
Co-authored-by: ctlee <ching-tao.lee@qct.io>
Co-authored-by: Diane Feddema <dianefeddema@gmail.com>
Co-authored-by: elim <elim@krai.ai>
Co-authored-by: erichan1 <30481032+erichan1@users.noreply.github.com>
Co-authored-by: Frank Han <frank.han@dell.com>
Co-authored-by: Guenther Schmuelling <guschmue@microsoft.com>
Co-authored-by: guschmue <guschmue@microsoft.com>
Co-authored-by: hanyunfan <frank.han@dell.com>
Co-authored-by: Hiwot Tadese Kassa <36334927+hiwotadese@users.noreply.github.com>
Co-authored-by: Hugo Affaticati <haffaticati@microsoft.com>
Co-authored-by: itayhubara <itayh@campus.technion.ac.il>
Co-authored-by: Jason Zhu <ccbt87@gmail.com>
Co-authored-by: Jason Zhu <jasonzhu@supermicro.com>
Co-authored-by: l00010728 <luxu@xfusion.com>
Co-authored-by: lbhli001 <libaihong@ieisystem.com>
Co-authored-by: lizraymond <liz.raymond@dell.com>
Co-authored-by: Matt Frank <mfrank@nvidia.com>
Co-authored-by: Nathan Wasson <nathanw@mlcommons.org>
Co-authored-by: Nils Smeds <nsmeds@lenovo.com>
Co-authored-by: Notsu, Takahiro <notsu.takahiro@fujitsu.com>
Co-authored-by: Pablo Gonzalez <pablo.gonzalez@factored.ai>
Co-authored-by: Peter Mattson <34691613+petermattson@users.noreply.github.com>
Co-authored-by: pgmpablo157321 <pablo.gonzalez@factored.ai>
Co-authored-by: Qinwen Xu <qinwen@google.com>
Co-authored-by: rakshithvasudev <rakshithvbharani@gmail.com>
Co-authored-by: Ritika Borkar <rborkar@nvidia.com>
Co-authored-by: Shriya Balaji Palsamudram <spalsamudram@nvidia.com>
Co-authored-by: SupermicroML <78233566+SupermicroML@users.noreply.github.com>"
github.com/mlcommons/training_results_v3.1,Intel-HabanaLabs/benchmarks/stable_diffusion/ldm/modules/encoders/modules.py,2023-11-07T21:26:23Z,"Upload results

Co-authored-by: Achorn, Keith <keith.achorn@intel.com>
Co-authored-by: Arjun Suresh <arjunsuresh1987@gmail.com>
Co-authored-by: BladeRD-SIT <78253812+BladeRD-SIT@users.noreply.github.com>
Co-authored-by: Bruce Lin <bruce5_lin@asus.com>
Co-authored-by: Bruno Ferreira <bruno.mgf@gmail.com>
Co-authored-by: Burhan Ul Tayyab <burhanultayyab@ailiverse.com>
Co-authored-by: BurhanUlTayyab <burhanultayyab@ailiverse.com>
Co-authored-by: ch155260 <kein.kung@gigacomputing.com>
Co-authored-by: ch155260 <kevin.kung@gigacomputing.com>
Co-authored-by: ctlee <ching-tao.lee@qct.io>
Co-authored-by: Diane Feddema <dianefeddema@gmail.com>
Co-authored-by: elim <elim@krai.ai>
Co-authored-by: erichan1 <30481032+erichan1@users.noreply.github.com>
Co-authored-by: Frank Han <frank.han@dell.com>
Co-authored-by: Guenther Schmuelling <guschmue@microsoft.com>
Co-authored-by: guschmue <guschmue@microsoft.com>
Co-authored-by: hanyunfan <frank.han@dell.com>
Co-authored-by: Hiwot Tadese Kassa <36334927+hiwotadese@users.noreply.github.com>
Co-authored-by: Hugo Affaticati <haffaticati@microsoft.com>
Co-authored-by: itayhubara <itayh@campus.technion.ac.il>
Co-authored-by: Jason Zhu <ccbt87@gmail.com>
Co-authored-by: Jason Zhu <jasonzhu@supermicro.com>
Co-authored-by: l00010728 <luxu@xfusion.com>
Co-authored-by: lbhli001 <libaihong@ieisystem.com>
Co-authored-by: lizraymond <liz.raymond@dell.com>
Co-authored-by: Matt Frank <mfrank@nvidia.com>
Co-authored-by: Nathan Wasson <nathanw@mlcommons.org>
Co-authored-by: Nils Smeds <nsmeds@lenovo.com>
Co-authored-by: Notsu, Takahiro <notsu.takahiro@fujitsu.com>
Co-authored-by: Pablo Gonzalez <pablo.gonzalez@factored.ai>
Co-authored-by: Peter Mattson <34691613+petermattson@users.noreply.github.com>
Co-authored-by: pgmpablo157321 <pablo.gonzalez@factored.ai>
Co-authored-by: Qinwen Xu <qinwen@google.com>
Co-authored-by: rakshithvasudev <rakshithvbharani@gmail.com>
Co-authored-by: Ritika Borkar <rborkar@nvidia.com>
Co-authored-by: Shriya Balaji Palsamudram <spalsamudram@nvidia.com>
Co-authored-by: SupermicroML <78233566+SupermicroML@users.noreply.github.com>"
github.com/LukasStruppek/Exploiting-Cultural-Biases-via-Homoglyphs,compute_relative_bias.py,2023-02-10T13:42:10Z,add relative bias metric
github.com/kousw/experimental-consistory,extern/dift/clip.py,2024-02-18T07:33:36Z,Initial commit.
github.com/ChenDarYen/Key-Locked-Rank-One-Editing-for-Text-to-Image-Personalization,ldm/modules/encoders/modules.py,2023-08-16T04:27:29Z,support sd v2
github.com/ChenDarYen/Key-Locked-Rank-One-Editing-for-Text-to-Image-Personalization,ldm/modules/encoders/modules.py,2023-08-14T16:23:59Z,revise embedding manager
github.com/ChenDarYen/Key-Locked-Rank-One-Editing-for-Text-to-Image-Personalization,ldm/modules/encoders/modules.py,2023-08-11T20:06:52Z,upload
github.com/xmed-lab/CLIPN,src/classification.py,2023-08-23T13:10:40Z,update codes
github.com/xmed-lab/CLIPN,hand-crafted/src/classification.py,2023-12-02T14:47:55Z,"Upload

Upload codes for hand-crafted version."
github.com/NVIDIA-AI-IOT/clip-distillation,export_openclip_onnx.py,2023-07-25T17:32:24Z,add license
github.com/NVIDIA-AI-IOT/clip-distillation,export_openclip_onnx.py,2023-06-27T21:38:18Z,remove intro
github.com/NVIDIA-AI-IOT/clip-distillation,compute_openclip_embeddings.py,2023-07-25T17:32:24Z,add license
github.com/NVIDIA-AI-IOT/clip-distillation,compute_openclip_embeddings.py,2023-06-27T21:38:18Z,remove intro
github.com/NVIDIA-AI-IOT/clip-distillation,compute_openclip_text_embeddings.py,2023-07-25T17:32:24Z,add license
github.com/NVIDIA-AI-IOT/clip-distillation,compute_openclip_text_embeddings.py,2023-06-27T21:38:18Z,remove intro
github.com/baaivision/MUSE-Pytorch,extract_empty_feature.py,2023-05-08T11:47:07Z,add cc ctx prepare
github.com/baaivision/MUSE-Pytorch,extract_test_prompt_feature.py,2023-05-08T11:47:07Z,add cc ctx prepare
github.com/yasserben/CLOUDS,clouds/modeling/backbone/clip.py,2023-12-15T15:43:08Z,release CLOUDS
github.com/yasserben/CLOUDS,clouds/modeling/backbone/trainable_clip.py,2023-12-15T15:43:08Z,release CLOUDS
github.com/gregor-ge/mBLIP,data/pretrain/hard_examples.py,2023-09-22T09:15:00Z,Updated for version 2 on arxiv
github.com/gregor-ge/mBLIP,data/pretrain/generate_match_train.py,2023-09-22T09:15:00Z,Updated for version 2 on arxiv
github.com/xuanlinli17/large_vlm_distillation_ood,robotics.py,2023-06-26T04:39:26Z,upload some code
github.com/xuanlinli17/large_vlm_distillation_ood,evaluate_clip.py,2023-06-26T04:39:26Z,upload some code
github.com/xuanlinli17/large_vlm_distillation_ood,ofa_gen_caption.py,2023-07-05T03:15:35Z,update readme
github.com/xuanlinli17/large_vlm_distillation_ood,ofa_gen_caption.py,2023-06-26T04:39:26Z,upload some code
github.com/xuanlinli17/large_vlm_distillation_ood,main_experiments.py,2023-07-04T06:07:27Z,upload files and fix bug
github.com/xuanlinli17/large_vlm_distillation_ood,main_experiments.py,2023-06-26T04:39:26Z,upload some code
github.com/emu1729/GIST,caption_matching.py,2023-07-25T17:41:04Z,Fixed import
github.com/emu1729/GIST,caption_matching.py,2023-07-19T19:39:59Z,Cleaned up caption matching
github.com/emu1729/GIST,caption_matching.py,2023-07-19T19:06:41Z,Added caption matching script and example
github.com/emu1729/GIST,caption_matching.py,2023-07-19T18:38:25Z,Added datasets and sample metadata files
github.com/sail-sg/MMCBench,text2image/evaluate.py,2024-01-23T02:53:44Z,update image2text
github.com/sail-sg/MMCBench,text2image/evaluate.py,2024-01-23T00:45:43Z,add text2speech
github.com/sail-sg/MMCBench,text2image/evaluate.py,2024-01-22T08:27:04Z,add text2image
github.com/sail-sg/MMCBench,image2text/evaluate.py,2024-01-23T02:53:44Z,update image2text
github.com/VQAssessment/BVQI,prompt_tuning.py,2023-05-20T08:23:42Z,extension
github.com/VQAssessment/BVQI,load_features.py,2023-05-20T08:23:42Z,extension
github.com/VQAssessment/BVQI,semantic_affinity.py,2023-03-19T11:36:25Z,"Update, Reproduce, and ICME"
github.com/VQAssessment/BVQI,semantic_affinity.py,2023-01-16T05:20:44Z,renew code
github.com/VQAssessment/BVQI,semantic_affinity.py,2022-12-19T09:16:58Z,fix
github.com/VQAssessment/BVQI,semantic_affinity.py,2022-12-19T09:06:47Z,initial
github.com/autodistill/autodistill-metaclip,autodistill_metaclip/metaclip_model.py,2023-12-05T09:10:22Z,use load_image
github.com/autodistill/autodistill-metaclip,autodistill_metaclip/metaclip_model.py,2023-12-05T08:49:20Z,update module
github.com/autodistill/autodistill-metaclip,autodistill_metaclip/metaclip_model.py,2023-10-26T15:09:23Z,add embedding functions
github.com/autodistill/autodistill-metaclip,autodistill_metaclip/metaclip_model.py,2023-10-26T11:18:33Z,"update package config, run black and isort"
github.com/autodistill/autodistill-metaclip,autodistill_metaclip/metaclip_model.py,2023-10-26T11:16:39Z,add metaclip model
github.com/ml-research/i2p,models/vision/paella.py,2023-06-01T09:09:12Z,more models
github.com/ml-research/i2p,models/vision/paella.py,2023-04-25T12:05:18Z,new structure and added altdiffusion and paella
github.com/ml-research/i2p,mitigation/safe_paella.py,2023-06-01T09:09:12Z,more models
github.com/changzheng123/L-CAD,ldm/modules/encoders/modules.py,2024-01-06T13:01:14Z,modify readme
github.com/changzheng123/L-CAD,ldm/modules/encoders/modules.py,2023-12-07T11:16:50Z,init
github.com/waterhorse1/ChessGPT,chessclip/tests/util_test.py,2023-06-13T02:00:33Z,first commit
github.com/waterhorse1/ChessGPT,chessclip/tests/test_inference.py,2023-06-13T02:00:33Z,first commit
github.com/waterhorse1/ChessGPT,chessclip/tests/test_inference_simple.py,2023-06-13T02:00:33Z,first commit
github.com/LLaVA-VL/LLaVA-Med-preview,llava/model/llava.py,2023-08-25T06:59:25Z,init release preview
github.com/ChrisVicky/TJU-2023-Computer-Vision-Final,DataPreparation/coca_annotator.py,2023-04-21T06:43:10Z,Finished DataPreparation
github.com/ChrisVicky/TJU-2023-Computer-Vision-Final,DataPreparation/coca_annotator.py,2023-04-11T06:57:57Z,added integrity verf and coca_annotator
github.com/zhang-tao-whu/DVIS_Plus,ov_dvis/backbones/clip.py,2023-12-22T03:02:11Z,init
github.com/megvii-research/protoclip,src/training/evaluations/linear_eval.py,2022-06-22T07:58:12Z,initial commit
github.com/ChenDelong1999/polite-flamingo,polite_flamingo/src/factory.py,2023-07-06T10:45:41Z,update_readme
github.com/Vinayak-VG/GSN,tasks/segment_2d_text.py,2023-12-15T07:50:21Z,gsn
github.com/Vinayak-VG/GSN,feature_extractor/langfeat_extract_dtu.py,2023-12-15T07:50:21Z,gsn
github.com/Vinayak-VG/GSN,feature_extractor/langfeat_extract_llff.py,2023-12-15T07:50:21Z,gsn
github.com/CharlieDreemur/AI-Video-Converter,stable-diffusion-webui-master/modules/sd_disable_initialization.py,2023-02-25T17:48:00Z,import stable diffusion webui
github.com/mybabyyh/InstructPix2NeRF,diffusion/encoders/modules.py,2024-01-25T07:46:17Z,update
github.com/IanYeung/MGLD-VSR,ldm/modules/encoders/modules.py,2023-12-18T10:21:24Z,Code Release
github.com/Peter-Kocsis/IntrinsicImageDiffusion,iid/ldm/encoders.py,2024-02-27T13:37:37Z,Code release
github.com/workforai/SCAN,open_clip_training/tests/util_test.py,2024-03-02T18:28:58Z,SCAN first commit
github.com/workforai/SCAN,open_clip_training/tests/test_inference.py,2024-03-02T18:28:58Z,SCAN first commit
github.com/workforai/SCAN,open_clip_training/tests/test_inference_simple.py,2024-03-02T18:28:58Z,SCAN first commit
github.com/workforai/SCAN,open_clip_training/tests/test_download_pretrained.py,2024-03-02T18:28:58Z,SCAN first commit
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2023-05-25T15:57:02Z,track module properly
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2023-05-25T15:44:23Z,fix
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2023-05-25T15:33:12Z,coca on cuda
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2023-05-14T19:30:38Z,oops
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2023-05-14T19:28:10Z,remove legacy magma dependency
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2023-05-06T18:08:43Z,fix
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2023-05-06T00:00:14Z,coca captioning
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2023-02-17T18:39:29Z,log exceptions on ml machines in a way we can print in main machine logs
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2023-02-12T20:38:02Z,save memory by moving clip encoder to cpu after use + turn guidance back on
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2023-01-31T18:20:06Z,align inference prompt for captioning with training data
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2022-11-26T19:38:41Z,fix interaction between kv_cache_scope and activate+deactivate helpers
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2022-11-26T18:33:42Z,avoid repeatedly moving adapters from cpu to gpu during long strings of captioning requests
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2022-11-01T14:38:02Z,avoid wasting gpu memory on magma's clip encoder when not in use
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2022-10-10T15:56:09Z,use context manager + disable buffer in head predict
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2022-10-05T18:34:22Z,turn kv buffer off before captioning bc it interacts badly with guidance
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2022-09-15T20:27:59Z,keep captioning adapters on gpu when enough vram available
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2022-07-08T14:07:17Z,captioning: longest_of to 1
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2022-07-06T19:08:14Z,generate several captions and use longest one
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2022-07-06T16:31:23Z,make guidance work in magma captioning
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2022-06-24T22:32:52Z,move adapters to cpu when not in use
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2022-06-24T21:02:06Z,work
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2022-06-24T20:54:53Z,work
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2022-06-24T06:09:29Z,whoops
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2022-06-24T06:07:07Z,whoops
github.com/nostalgebraist/nostalgebraist-autoresponder,src/ml/captioning.py,2022-06-24T06:06:21Z,whoops
github.com/OPPO-Mente-Lab/PEA-Diffusion,train_sd_zh.py,2023-11-30T01:13:46Z,Add files via upload
github.com/OPPO-Mente-Lab/PEA-Diffusion,train_sdxl_zh.py,2023-11-30T01:13:46Z,Add files via upload
github.com/OPPO-Mente-Lab/PEA-Diffusion,tests/test_sd_zh.py,2023-11-30T01:13:46Z,Add files via upload
github.com/OPPO-Mente-Lab/PEA-Diffusion,tests/test_sdxl_zh.py,2023-11-30T01:13:46Z,Add files via upload
github.com/OPPO-Mente-Lab/PEA-Diffusion,tests/test_sdxl_zh_lcm.py,2023-11-30T01:13:46Z,Add files via upload
github.com/OPPO-Mente-Lab/PEA-Diffusion,tests/test_sdxl_zh_controlnet.py,2023-11-30T01:13:46Z,Add files via upload
