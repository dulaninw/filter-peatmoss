repo_url,filepath,commit_date,message
github.com/speechbrain/speechbrain,tools/g2p.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,tools/g2p.py,2023-07-31T13:50:49Z,Remove sys.exit() calls in recipes and tools
github.com/speechbrain/speechbrain,tools/g2p.py,2022-07-28T00:33:47Z,G2P: Minor typo fix
github.com/speechbrain/speechbrain,tools/g2p.py,2022-07-22T01:40:21Z,fix style
github.com/speechbrain/speechbrain,tools/g2p.py,2022-07-21T04:12:33Z,"G2P: Minor edits, add support for overrides for G2P CLI when restoring a checkpoint"
github.com/speechbrain/speechbrain,tools/g2p.py,2022-07-19T02:41:01Z,G2P: Add a fallback for loading older checkpoints without PER recorded
github.com/speechbrain/speechbrain,tools/g2p.py,2022-07-09T19:16:57Z,G2P: Fixes
github.com/speechbrain/speechbrain,tools/g2p.py,2022-07-09T18:51:23Z,G2P: Updated the tool to support word embeddings
github.com/speechbrain/speechbrain,tools/g2p.py,2022-07-09T03:19:29Z,G2P: Add the ability to load checkpoints (useful for testing fresh experiments)
github.com/speechbrain/speechbrain,tools/g2p.py,2022-06-23T03:19:16Z,G2P: Changes to pass consistency tests
github.com/speechbrain/speechbrain,tools/g2p.py,2022-02-23T12:55:37Z,G2P: Refactoring and clean-up
github.com/speechbrain/speechbrain,tools/g2p.py,2022-01-15T18:38:05Z,Fix a style issue
github.com/speechbrain/speechbrain,tools/g2p.py,2022-01-15T17:56:22Z,"G2P: Move the transcribe script into tools, add documentation and examples"
github.com/speechbrain/speechbrain,recipes/CVSS/S2ST/train.py,2024-02-21T19:54:39Z,fix recipe tests - part1 (#2416)
github.com/speechbrain/speechbrain,recipes/CVSS/S2ST/train.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,recipes/CVSS/S2ST/train.py,2023-10-27T16:13:39Z,"Add speech-to-speech translation (#2044)

* Add S2ST with cvss recipe

* Refactor K-means training

* Clean quantization training and unit-to-speech training in LJSpeech recipe

* Add documentation and tests for UnitHiFiGAN

* Add inference interface for UnitHiFiGAN

* Clean U2S hparams

* Add extra requirement for k-means training

* Add ReadMe for LJSpeech S2ST recipe and update hprarams

* Resolve comments on quantization

* Resolve comments on HiFi-GAN training

* Fix authors in HifiGAN model

* Remove old stuff

* Fix LJSpeech S2ST

* Improve Wandb logger init, no longer require external yaml file

* add wandb log folder to .gitignore

* Add extra requirements to CVSS recipe

* Update CVSS S2ST

* Add verbose option to disable warnings when a model is loaded

* Refactoring and adding evaluation pipeline

* Fix ljspeech_prepare.py path according to new recipe structure

* Update codes folder construction to allow easy testing

* Add tests

* Update CVSS

* Update LJSpeech S2ST

* Update tests

* Add empty README for CVSS

* Fix pre-commit

* Fix pre-commit

* Update kmeans model name

* Update CVSS S2ST recipe & add HF pretrained vocoder model

* Update tests

* Update CVSS S2ST hparams

* Fix docstrings

* Update tests

* Revert verbose argument addition

* Revert verbose argument addition

* Add automatic resampling in Quantization recipe

* Add automatic resampling in Quantization recipe

* Add automatic resampling in extract_code

* Update README

* Update CVSS S2ST recipe

* Increase timeout in init_process_group to avoid crash during dataprep

* Update CVSS tests

* Fix transcript normalization for BLEU score

* Update LJSpeech S2ST README.md

* Update cvss_prepare.py

* Update train_fr-en.yaml

* Update cvss_prepare.py

* Fix codes folder path

* Fix file extension

* Add docstring for wandb logger

* Fix docstring for wandb logger

* Add small subset for evalution and adapt training script

* Update hparams

* Update cvss_prepare.py

* Update training scripts

* Update docstring in LJSpeech S2ST recipe

* Update docstring in LJSpeech S2ST recipe

* Add automatic resampling

* Add model weights and training logs

* Update docstring in CVSS S2ST recipe

* Add S2UT interface

* Fix HiFi-GAN GeneratorLoss forward args

* Update ljspeech_prepare path

* Fix UnitHiFiGAN interface docstring

* merged latest develop, switched to speechbrain dropbox, fixed small yaml issues

* A. README files: point 1 and 2

* B. File Organization: Relocate Quantization recipe

* B. File Organization: Relocate Unit HiFi-GAN and update symbolic link

* Sync with develop

* Update requirements

* Update README

* Fix symbolic link

* Fix merge

* Fix tests

* Fix mimport

* Fix LJSpeech tests

* Fix CVSS tests

* Fix CVSS dataprep

* Add a docstring for the process_duration function

* Fix quantization path in test_recipe_list

* Fix docstring in HifiGAN.py

* Fix docstring in HifiGAN.py

* Format interfaces.py

* Update README for hifi_gan_unit and quantization

* Update docstring

* Fix audio loading

* small fixes

* recipe test with dataset uploaded in dropbox

* remove local samples

* Update README.md

* Update README

* Update README.md

* minor changes in paths

* Update HF link

* add functions to map indices from the range [0, k] to [1, k+1] in HiFi-GAN Unit

* Update HiFi-GAN Unit interface

* Add verification for units sequence length during eval

* Add option to evaluate the S2UT model every n epochs

* Delete .gitignore

* Update train.yaml

* fix linters

* fix test

* fix test + making preparation compatible with other recipes + minor fixes

* Fix typo

* Add parameters

* some fixes on LJSpeech tests

* fix LJSpeech recipe test

* making recipe test a bit faster

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>"
github.com/speechbrain/speechbrain,tools/profiling/profile.py,2024-02-21T19:59:00Z,fix import in profile.py (#2425)
github.com/speechbrain/speechbrain,tools/profiling/profile.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,tools/profiling/profile.py,2022-06-20T21:22:49Z,update docstrings in the libraries
github.com/speechbrain/speechbrain,tools/profiling/profile.py,2022-06-01T16:18:34Z,backup of latest develop status (contents of PRs that were merged) before fixing rebase issue through another rebase
github.com/speechbrain/speechbrain,speechbrain/inference/ASR.py,2024-02-25T17:27:30Z,fix torch.no_grad with streamableASR interface
github.com/speechbrain/speechbrain,speechbrain/inference/ASR.py,2024-02-24T17:18:23Z,"Streaming ASR interfaces (#2377)

* Implemented high level streaming interfaces

More WIP

Bunch of filter properties impl

More WIP interfaces stuff

Fix type annotation in filter_analysis

more wip interfaces

wip

Fix wrong context var set

wip thoughts

Implement file transcription

* Renames and fixes

* Add transcribe_file_streaming

* Formatting fixes

* Revert accidentally introduced change to max_batch_len

* Reworking interface naming and docstring

* Use the searcher directly, forwarding extra args

* More docstrings

* Fix parameter order

* Add WIP StreamingTransducerASR example

* Formatting

* More docstrings and renames for interfaces

* Docstrings for context

* Merge the unnecessary wrapper

* Rename StreamingTransducerASR to StreamingASR

* Fix precommit

* Remove unused fea_extractor field

* Fix test error by commenting out inference stuff

* Add some docstrings to streamingfeaturewrapper

* More docs

* Formatting

* Feature extraction streaming wrapper docstrings

* Add missing file docstring for filter_analysis

* Tentative fix for docs gen error

* Fix some missing docstring args in ASR

* Allow using ffmpeg streaming with StreamingASR

* Extract stream logic into _get_audio_stream

* Docstring for _get_audio_stream

* Formatting

* Move out some streaming tokenizer logic

* Accept stupid suggestions from formatter

* Somewhat more generic StreamingASR

* Tokenizer-agnostic StreamingASR

* Add commented out tokenizer streaming hparams

* Add missing docstring

* Remove unused import from ASR

* CI and configuration fixes; use python 3.9 in CI

* Fix doctest using inconsistent left context size

* Clarify on tokenizer_context init

* Update HPARAMS_NEEDED for StreamingASR

* Improve transducer forward docs for extra args

* Fix code blocks in filter_analysis

* Linting

* fix broken indent in filter_analysis examples...

* Update author lists

* Remove currently unused has_overlap

* Clarify on fea_streaming_extractor properties

* Fix ASRStreamingContext doc wording

* Improve docstring for `get_chunk_size_frames`

* wip test

* Streaming feature wrapper test + better docs

* Improve StreamingFeatureWraper docstring

* Improve docstring and comments on spm streaming decode

* Fixed accidentally duplicated docstring

* Fix very stupid typo

* Add notice for trained streaming ASR inference

* Use LengthsCapableSequential instead of custom wrapper

* Precommit fix

* Added mechanism to inject zero chunks at the end to fix trunc

* Simplify apply in YAML

* Add decoding_function abstraction for StreamingASR

* Fix partial apply shenanigans

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>"
github.com/speechbrain/speechbrain,speechbrain/inference/ASR.py,2024-02-11T21:54:16Z,"Update WhisperASR inference interface (#2407)

* Update ASR.py

* Update ASR.py

* Update ASR.py

* Update ASR.py"
github.com/speechbrain/speechbrain,speechbrain/inference/ASR.py,2024-02-10T16:30:45Z,add kenlm (#2402)
github.com/speechbrain/speechbrain,speechbrain/inference/ASR.py,2024-01-31T16:36:46Z,pre-commit
github.com/speechbrain/speechbrain,speechbrain/inference/ASR.py,2024-01-31T16:34:10Z,update docstring
github.com/speechbrain/speechbrain,speechbrain/inference/ASR.py,2024-01-31T16:17:28Z,working interface
github.com/speechbrain/speechbrain,speechbrain/inference/ASR.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,speechbrain/inference/TTS.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2024-02-25T02:53:59Z,last fixes
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2023-10-14T12:33:53Z,pre-commit
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2023-10-14T12:32:20Z,remove related doc with distributed_launch
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2023-08-14T20:07:00Z,fixed hard-coded device
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2023-08-10T12:34:14Z,slurp
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2023-08-10T11:12:22Z,self.hparams.wer_file -> self.hparams.test_wer_file
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2023-07-25T08:35:32Z,"Merge pull request #2059 from pplantinga/feature/on-stage-end-run-all-procs

Run ""on_stage_end"" on all processes and save on only a single process"
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2023-07-20T15:52:28Z,fixed SLURP
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2023-07-07T23:38:50Z,Add if_main_process guard around writing WER files
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2022-07-21T17:02:08Z,fix distributed_launch=True in comments
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2021-11-22T23:36:27Z,correct when decodage not dict
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2021-11-18T10:44:04Z,Update train.py
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2021-11-15T16:41:28Z,add wav2vec2 encoder
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2021-03-12T05:05:35Z,local manifest + remove unnecessary columns in csv
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2021-03-11T23:32:00Z,merge develop + solved conflicts
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2021-03-11T18:20:11Z,remove pretrain tokenizer
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2021-03-11T05:43:39Z,remove pretrained folder + remove extra level (/train/)
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2021-01-20T02:48:48Z,"convert SLURP direct recipe, add downloads to data preparation"
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2021-01-19T15:33:13Z,Dataio without underscore
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2021-01-17T18:16:13Z,update latest recipes
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2020-12-20T00:33:09Z,add NLU for SLURP (train/test on gold transcripts)
github.com/speechbrain/speechbrain,recipes/SLURP/direct/train.py,2020-12-19T19:21:16Z,SLU recipe for SLURP dataset
github.com/speechbrain/speechbrain,speechbrain/inference/classifiers.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2023-10-14T12:33:53Z,pre-commit
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2023-10-14T12:32:20Z,remove related doc with distributed_launch
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2023-08-14T20:07:53Z,fixed hard-coded device
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2023-08-10T12:41:37Z,timer
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2023-08-10T11:12:22Z,self.hparams.wer_file -> self.hparams.test_wer_file
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2023-07-07T23:38:50Z,Add if_main_process guard around writing WER files
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2022-07-21T17:02:08Z,fix distributed_launch=True in comments
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2021-03-21T22:29:59Z,dont exit
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2021-03-21T21:53:08Z,"use dev synth if testing on all real data, avoid redundant"
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2021-03-21T19:36:24Z,add comment
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2021-03-21T19:20:12Z,"Remove comma preprocessing, add script for running multiple experiments, load checkpoint with best valid accuracy, add testing on all real splits"
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2021-03-12T21:29:17Z,small fixes
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2021-03-11T23:32:00Z,merge develop + solved conflicts
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2021-03-11T18:20:11Z,remove pretrain tokenizer
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2021-03-11T05:43:39Z,remove pretrained folder + remove extra level (/train/)
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2021-01-18T01:01:11Z,"librispeech: training, inference separation"
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2021-01-17T02:43:17Z,Merge branch 'collab-new-data-loading' into use-hyperyaml
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2021-01-17T00:55:59Z,converted direct recipe (timers_and_such)
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2021-01-16T22:14:35Z,"Rename ""hyperyaml"" to ""hyperpyyaml"""
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2021-01-15T19:29:13Z,Switch extended_yaml to hyperyaml
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2021-01-13T21:08:45Z,fix calling ddp_init_group
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2020-12-15T00:46:43Z,recipe conversion (data_prep in yaml) part 1
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2020-12-14T04:24:13Z,"convert all recipes (part 1, exp_file)"
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2020-12-12T19:56:29Z,add gradient check
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2020-12-08T00:32:36Z,multi-gpu support for slu recipe
github.com/speechbrain/speechbrain,recipes/timers-and-such/direct/train.py,2020-12-02T02:56:04Z,converted direct + clean up
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2024-02-23T03:43:17Z,minor fixes emerged from recipe tesys
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2023-10-26T20:45:06Z,"fix recipe tests tool (#2218)

* fix location of pretrained models

* fix a VERY annoying recipe.

* full inference tests

* pre-commit"
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2023-09-29T17:18:01Z,fix hard-coded devices (#2178)
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2023-07-31T19:35:09Z,Merge remote-tracking branch 'upstream/develop' into bugfix/remove-sys-exit
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2023-07-31T13:50:49Z,Remove sys.exit() calls in recipes and tools
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2023-07-22T17:56:37Z,realm
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2023-06-27T15:03:41Z,"Merge pull request #1808 from z-wony/loss_compare

Fix comparison order of train loss"
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2023-03-08T08:52:07Z,addressing a few recipe tests
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2023-02-06T03:26:57Z,"Remove the 'if hparams.dynamic_mixing' on real-m train.py. 

The tests pass even without the argument added in this PR on line 161 of real-m train.py."
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2023-01-18T16:33:27Z,"Fix comparison order of train loss

If batch size > 1 and all of the losses are less than threshold,
RuntimeError raised from loss comparison block."
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2022-11-24T16:41:54Z,wrapping up testing flags and minimal data for testing
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2022-11-11T19:00:45Z,availing LibriSpeech to recipe testing
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2022-11-10T17:12:48Z,TIMIT; WHAM/R & fixes - added 39 phoneme test annotation
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2022-10-20T13:14:50Z,drop phn_list from annotation test samples
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2021-11-18T12:02:30Z,Auto mix prec + noprogressbar override via hyperparams
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2021-10-20T18:42:38Z,added mixed precision training
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2021-10-20T01:44:05Z,removed hard coded links from train.py
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2021-10-19T19:43:50Z,added automatic preprocessing for whamr dynamic mixing
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2021-10-17T18:54:47Z,fixed the comments in save_results function
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2021-10-17T18:50:36Z,added comments to train.py
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2021-10-17T18:30:01Z,"removing the separate dynamic mixing file, using the one from WHAMandWHAMR recipe"
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2021-10-15T01:28:02Z,correcting loss labels
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2021-10-14T17:33:10Z,added download from HF for pretrained separators and bug fixes
github.com/speechbrain/speechbrain,recipes/REAL-M/sisnr-estimation/train.py,2021-10-14T03:47:51Z,getting done except loading separator models
github.com/speechbrain/speechbrain,recipes/LibriTTS/TTS/mstacotron2/train.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,recipes/LibriTTS/TTS/mstacotron2/train.py,2023-12-13T18:07:01Z,"multi-speaker tacotron2 enhancements (#2261)

* use chars instead of phonemes, use 16k instead of 22k, limit audio length to 10 seconds

* add inference function using char inputs"
github.com/speechbrain/speechbrain,recipes/LibriTTS/TTS/mstacotron2/train.py,2023-10-17T02:46:20Z,fix one issue wit recipe tests
github.com/speechbrain/speechbrain,recipes/LibriTTS/TTS/mstacotron2/train.py,2023-09-22T13:31:01Z,update to latest dev + small fixes
github.com/speechbrain/speechbrain,recipes/LibriTTS/TTS/mstacotron2/train.py,2023-08-13T02:38:31Z,adding zero-shot multi-speaker Tacotron2
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2023-10-27T16:13:39Z,"Add speech-to-speech translation (#2044)

* Add S2ST with cvss recipe

* Refactor K-means training

* Clean quantization training and unit-to-speech training in LJSpeech recipe

* Add documentation and tests for UnitHiFiGAN

* Add inference interface for UnitHiFiGAN

* Clean U2S hparams

* Add extra requirement for k-means training

* Add ReadMe for LJSpeech S2ST recipe and update hprarams

* Resolve comments on quantization

* Resolve comments on HiFi-GAN training

* Fix authors in HifiGAN model

* Remove old stuff

* Fix LJSpeech S2ST

* Improve Wandb logger init, no longer require external yaml file

* add wandb log folder to .gitignore

* Add extra requirements to CVSS recipe

* Update CVSS S2ST

* Add verbose option to disable warnings when a model is loaded

* Refactoring and adding evaluation pipeline

* Fix ljspeech_prepare.py path according to new recipe structure

* Update codes folder construction to allow easy testing

* Add tests

* Update CVSS

* Update LJSpeech S2ST

* Update tests

* Add empty README for CVSS

* Fix pre-commit

* Fix pre-commit

* Update kmeans model name

* Update CVSS S2ST recipe & add HF pretrained vocoder model

* Update tests

* Update CVSS S2ST hparams

* Fix docstrings

* Update tests

* Revert verbose argument addition

* Revert verbose argument addition

* Add automatic resampling in Quantization recipe

* Add automatic resampling in Quantization recipe

* Add automatic resampling in extract_code

* Update README

* Update CVSS S2ST recipe

* Increase timeout in init_process_group to avoid crash during dataprep

* Update CVSS tests

* Fix transcript normalization for BLEU score

* Update LJSpeech S2ST README.md

* Update cvss_prepare.py

* Update train_fr-en.yaml

* Update cvss_prepare.py

* Fix codes folder path

* Fix file extension

* Add docstring for wandb logger

* Fix docstring for wandb logger

* Add small subset for evalution and adapt training script

* Update hparams

* Update cvss_prepare.py

* Update training scripts

* Update docstring in LJSpeech S2ST recipe

* Update docstring in LJSpeech S2ST recipe

* Add automatic resampling

* Add model weights and training logs

* Update docstring in CVSS S2ST recipe

* Add S2UT interface

* Fix HiFi-GAN GeneratorLoss forward args

* Update ljspeech_prepare path

* Fix UnitHiFiGAN interface docstring

* merged latest develop, switched to speechbrain dropbox, fixed small yaml issues

* A. README files: point 1 and 2

* B. File Organization: Relocate Quantization recipe

* B. File Organization: Relocate Unit HiFi-GAN and update symbolic link

* Sync with develop

* Update requirements

* Update README

* Fix symbolic link

* Fix merge

* Fix tests

* Fix mimport

* Fix LJSpeech tests

* Fix CVSS tests

* Fix CVSS dataprep

* Add a docstring for the process_duration function

* Fix quantization path in test_recipe_list

* Fix docstring in HifiGAN.py

* Fix docstring in HifiGAN.py

* Format interfaces.py

* Update README for hifi_gan_unit and quantization

* Update docstring

* Fix audio loading

* small fixes

* recipe test with dataset uploaded in dropbox

* remove local samples

* Update README.md

* Update README

* Update README.md

* minor changes in paths

* Update HF link

* add functions to map indices from the range [0, k] to [1, k+1] in HiFi-GAN Unit

* Update HiFi-GAN Unit interface

* Add verification for units sequence length during eval

* Add option to evaluate the S2UT model every n epochs

* Delete .gitignore

* Update train.yaml

* fix linters

* fix test

* fix test + making preparation compatible with other recipes + minor fixes

* Fix typo

* Add parameters

* some fixes on LJSpeech tests

* fix LJSpeech recipe test

* making recipe test a bit faster

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>"
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2023-07-14T21:51:08Z,freeze spn predictor after 8 epoch and suppress warning
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2023-07-13T20:54:45Z,"add silence for punctuations, modify functions"
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2023-07-13T20:46:58Z,"spn loss equals zero after 8 epochs, threshold 0.8 for spn predictor"
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2023-07-03T18:18:28Z,unknown token fix
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2023-06-16T00:37:54Z,changes to insert silent phonemes for pace
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2023-04-07T17:04:09Z,update recipe
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2023-01-18T21:23:50Z,modifications for phoneme input
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2022-12-14T04:25:42Z,Merge branch 'fastspeech2' of https://github.com/bloodraven66/speechbrain into fastspeech2
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2022-12-14T04:22:02Z,add custom clean code to ljspeech_prepare and clean durations link to yaml
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2022-12-04T17:54:46Z,output predicted mel lengths
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2022-12-02T14:23:02Z,"generate validation audio without extracted duration, log all the losses"
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2022-11-16T23:58:05Z,fix black
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2022-11-16T23:50:01Z,add mask in train.py + fix device mismatch
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2022-11-16T04:25:35Z,pre-compute pitch + fix incompatibility with pytorch 1.13
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2022-11-15T23:01:36Z,fix durarations folder
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2022-11-15T22:10:10Z,fix device
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2022-11-13T17:07:15Z,revised duration download
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2022-11-12T22:31:06Z,fix failing tests
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2022-11-12T21:54:23Z,fix yaml
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2022-11-12T20:29:42Z,first batch of small fixes
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2022-08-10T15:17:44Z,working fastspeech2
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train.py,2022-06-20T16:17:26Z,added fastspeech2
github.com/speechbrain/speechbrain,speechbrain/inference/interpretability.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,recipes/fluent-speech-commands/direct/train.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,recipes/fluent-speech-commands/direct/train.py,2023-10-14T12:33:53Z,pre-commit
github.com/speechbrain/speechbrain,recipes/fluent-speech-commands/direct/train.py,2023-10-14T12:32:20Z,remove related doc with distributed_launch
github.com/speechbrain/speechbrain,recipes/fluent-speech-commands/direct/train.py,2023-08-14T20:07:46Z,fixed hard-coded device
github.com/speechbrain/speechbrain,recipes/fluent-speech-commands/direct/train.py,2023-08-10T12:38:41Z,remove timit line / modity fluent speech
github.com/speechbrain/speechbrain,recipes/fluent-speech-commands/direct/train.py,2023-08-10T11:12:22Z,self.hparams.wer_file -> self.hparams.test_wer_file
github.com/speechbrain/speechbrain,recipes/fluent-speech-commands/direct/train.py,2023-08-09T13:41:03Z,fix hparam wer_file never used in recipes
github.com/speechbrain/speechbrain,recipes/fluent-speech-commands/direct/train.py,2023-07-07T23:38:50Z,Add if_main_process guard around writing WER files
github.com/speechbrain/speechbrain,recipes/fluent-speech-commands/direct/train.py,2022-07-21T17:02:08Z,fix distributed_launch=True in comments
github.com/speechbrain/speechbrain,recipes/fluent-speech-commands/direct/train.py,2021-06-04T00:43:22Z,improve fsc recipe by adoption super augment
github.com/speechbrain/speechbrain,recipes/fluent-speech-commands/direct/train.py,2021-03-12T05:05:35Z,local manifest + remove unnecessary columns in csv
github.com/speechbrain/speechbrain,recipes/fluent-speech-commands/direct/train.py,2021-03-11T23:32:00Z,merge develop + solved conflicts
github.com/speechbrain/speechbrain,recipes/fluent-speech-commands/direct/train.py,2021-03-11T18:20:11Z,remove pretrain tokenizer
github.com/speechbrain/speechbrain,recipes/fluent-speech-commands/direct/train.py,2021-03-09T20:21:13Z,convert Fluent Speech Commands recipe
github.com/speechbrain/speechbrain,recipes/fluent-speech-commands/direct/train.py,2021-03-05T04:28:34Z,last fixes (see PR description)
github.com/speechbrain/speechbrain,recipes/fluent-speech-commands/direct/train.py,2021-02-07T23:37:12Z,add a simple seq2seq model recipe for Fluent Speech Commands
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train_internal_alignment.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train_internal_alignment.py,2023-10-27T16:13:39Z,"Add speech-to-speech translation (#2044)

* Add S2ST with cvss recipe

* Refactor K-means training

* Clean quantization training and unit-to-speech training in LJSpeech recipe

* Add documentation and tests for UnitHiFiGAN

* Add inference interface for UnitHiFiGAN

* Clean U2S hparams

* Add extra requirement for k-means training

* Add ReadMe for LJSpeech S2ST recipe and update hprarams

* Resolve comments on quantization

* Resolve comments on HiFi-GAN training

* Fix authors in HifiGAN model

* Remove old stuff

* Fix LJSpeech S2ST

* Improve Wandb logger init, no longer require external yaml file

* add wandb log folder to .gitignore

* Add extra requirements to CVSS recipe

* Update CVSS S2ST

* Add verbose option to disable warnings when a model is loaded

* Refactoring and adding evaluation pipeline

* Fix ljspeech_prepare.py path according to new recipe structure

* Update codes folder construction to allow easy testing

* Add tests

* Update CVSS

* Update LJSpeech S2ST

* Update tests

* Add empty README for CVSS

* Fix pre-commit

* Fix pre-commit

* Update kmeans model name

* Update CVSS S2ST recipe & add HF pretrained vocoder model

* Update tests

* Update CVSS S2ST hparams

* Fix docstrings

* Update tests

* Revert verbose argument addition

* Revert verbose argument addition

* Add automatic resampling in Quantization recipe

* Add automatic resampling in Quantization recipe

* Add automatic resampling in extract_code

* Update README

* Update CVSS S2ST recipe

* Increase timeout in init_process_group to avoid crash during dataprep

* Update CVSS tests

* Fix transcript normalization for BLEU score

* Update LJSpeech S2ST README.md

* Update cvss_prepare.py

* Update train_fr-en.yaml

* Update cvss_prepare.py

* Fix codes folder path

* Fix file extension

* Add docstring for wandb logger

* Fix docstring for wandb logger

* Add small subset for evalution and adapt training script

* Update hparams

* Update cvss_prepare.py

* Update training scripts

* Update docstring in LJSpeech S2ST recipe

* Update docstring in LJSpeech S2ST recipe

* Add automatic resampling

* Add model weights and training logs

* Update docstring in CVSS S2ST recipe

* Add S2UT interface

* Fix HiFi-GAN GeneratorLoss forward args

* Update ljspeech_prepare path

* Fix UnitHiFiGAN interface docstring

* merged latest develop, switched to speechbrain dropbox, fixed small yaml issues

* A. README files: point 1 and 2

* B. File Organization: Relocate Quantization recipe

* B. File Organization: Relocate Unit HiFi-GAN and update symbolic link

* Sync with develop

* Update requirements

* Update README

* Fix symbolic link

* Fix merge

* Fix tests

* Fix mimport

* Fix LJSpeech tests

* Fix CVSS tests

* Fix CVSS dataprep

* Add a docstring for the process_duration function

* Fix quantization path in test_recipe_list

* Fix docstring in HifiGAN.py

* Fix docstring in HifiGAN.py

* Format interfaces.py

* Update README for hifi_gan_unit and quantization

* Update docstring

* Fix audio loading

* small fixes

* recipe test with dataset uploaded in dropbox

* remove local samples

* Update README.md

* Update README

* Update README.md

* minor changes in paths

* Update HF link

* add functions to map indices from the range [0, k] to [1, k+1] in HiFi-GAN Unit

* Update HiFi-GAN Unit interface

* Add verification for units sequence length during eval

* Add option to evaluate the S2UT model every n epochs

* Delete .gitignore

* Update train.yaml

* fix linters

* fix test

* fix test + making preparation compatible with other recipes + minor fixes

* Fix typo

* Add parameters

* some fixes on LJSpeech tests

* fix LJSpeech recipe test

* making recipe test a bit faster

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>"
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train_internal_alignment.py,2023-09-21T18:12:51Z,update to latest dev + minor modifications
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train_internal_alignment.py,2023-08-16T15:54:45Z,add docstrings and examples
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train_internal_alignment.py,2023-08-16T10:22:44Z,fixes
github.com/speechbrain/speechbrain,recipes/LJSpeech/TTS/fastspeech2/train_internal_alignment.py,2023-08-11T15:08:06Z,add recipe for FastSpeech2 with internal alignment
github.com/speechbrain/speechbrain,tests/utils/refactoring_checks.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,tests/utils/refactoring_checks.py,2023-03-02T14:11:45Z,log edits
github.com/speechbrain/speechbrain,tests/utils/refactoring_checks.py,2023-02-16T11:45:41Z,code example for readme
github.com/speechbrain/speechbrain,tests/utils/refactoring_checks.py,2023-02-16T09:30:11Z,path fixes
github.com/speechbrain/speechbrain,tests/utils/refactoring_checks.py,2023-01-23T11:26:26Z,comments & path updates
github.com/speechbrain/speechbrain,tests/utils/refactoring_checks.py,2023-01-19T15:54:32Z,minor fixes
github.com/speechbrain/speechbrain,tests/utils/refactoring_checks.py,2022-12-12T15:47:48Z,linters
github.com/speechbrain/speechbrain,tests/utils/refactoring_checks.py,2022-12-09T16:07:48Z,edits to checks
github.com/speechbrain/speechbrain,tests/utils/refactoring_checks.py,2022-12-06T14:55:29Z,test util for refactoring & pretrained models
github.com/speechbrain/speechbrain,tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py,2023-07-19T17:03:21Z,fix url
github.com/speechbrain/speechbrain,tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py,2023-02-20T15:23:28Z,comments++
github.com/speechbrain/speechbrain,tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py,2023-02-14T15:50:19Z,FetchedSource & path_split
github.com/speechbrain/speechbrain,tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py,2023-02-14T11:33:19Z,FetchSource
github.com/speechbrain/speechbrain,tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py,2023-01-31T11:21:00Z,DDP for test dataloaders & an example to DDP-gather WER MetricStats results
github.com/speechbrain/speechbrain,tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py,2023-01-25T16:21:50Z,fixes
github.com/speechbrain/speechbrain,tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py,2023-01-25T15:34:39Z,lints
github.com/speechbrain/speechbrain,tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py,2023-01-25T13:58:00Z,evals using batches
github.com/speechbrain/speechbrain,tests/templates/fetching_ddp_dynbatch_finetuning/finetune.py,2023-01-24T12:56:38Z,minor fixes
github.com/speechbrain/speechbrain,tests/templates/fetching_ddp_dynbatch_finetuning/finetune_fetch_once.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,tests/templates/fetching_ddp_dynbatch_finetuning/finetune_fetch_once.py,2023-07-19T17:03:30Z,fix url
github.com/speechbrain/speechbrain,tests/templates/fetching_ddp_dynbatch_finetuning/finetune_fetch_once.py,2023-02-22T14:24:21Z,parameter transfer w/ internal ddp option
github.com/speechbrain/speechbrain,tests/templates/fetching_ddp_dynbatch_finetuning/finetune_fetch_once.py,2023-02-21T18:22:58Z,4th multi-source fetching case
github.com/speechbrain/speechbrain,tests/templates/fetching_ddp_dynbatch_finetuning/single_node_pretrained.py,2024-01-07T20:42:33Z,"Merge Unstable v0.6 into Dev (#2305)

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* rename HF's files

* fix docstrings

* fix args docstrings

* fix docstrings

* change classes' names

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Refactor HF interface, adapt recipes

* Fix docstrings

* commonvoice

* switchboard

* update readme

* update readme

* update lionk in test file

* remove unused space token

* update torchaudio

* remove deprecated language model path

* fix merge

* fix vocab

* fix switchboard

* commit

* fix test

* fix style

* remove unsued hparam

* fix consistancy blank_skip_threshold

* text frames

* CTCPrefixBeamSearcher timestamps

* pre-commit

* test

* test 2

* fix prints

* update ctcprefixbeamsearch timestamps

* remove frames from prefix bs

* ≈Revert ""remove frames from prefix bs""

This reverts commit 30900d9fb2fc16871c103c2e1b3a755e1765e85d.

* remove prefix bs

* ≈Revert ""remove prefix bs""

This reverts commit 2f0c3cd930826c8b23143012bf18c5f76d9198b5.

* Revert ""update ctcprefixbeamsearch timestamps""

This reverts commit ce09e193dc34f2ca65a0ca306230276aeacc599f.

* Revert ""fix prints""

This reverts commit bf360373555855329355c982a80be33eaae41cf6.

* Revert ""test 2""

This reverts commit 84cda948f33936e8fa9199a1c5c09af0c0f80ef8.

* Revert ""test""

This reverts commit f17349fb8255d8123e01fa110d8e1a40807e1bbd.

* Revert ""pre-commit""

This reverts commit 4e1cf0da7b70c7316db5ce10bb72ff0593c7d89b.

* Revert ""CTCPrefixBeamSearcher timestamps""

This reverts commit c3d3cf756b1c099b1919f3f28d42bab819ebfe4b.

* Revert ""text frames""

This reverts commit e67c7619d3b1bc64d087f2e2f8c69d452e82a2d2.

* Revert ""fix consistancy blank_skip_threshold""

This reverts commit f97a391f3574337f968135d41a9c2316014cb885.

* Update ctc.py

* arg / timestamps

* precommit

* timesteps -> text_frames

* ls seq2seq

* transformer ls

* fix naming

* librispeech

* aishell

* fix linter

* precommit

* switchboard

* timit

* Dynamic batching fixed

* authors

* fix conformer large

* indent

* Revert ""Fix dynamic batching"" (#2173)

* update doctest skip

* Fix dynamic batching (#2174)

* Revert ""Revert ""Fix dynamic batching"" (#2173)""

This reverts commit faa5e76c66c54192a46f21d569a87c1aa8e439a3.

* Update interfaces.py

* Update interfaces.py

* Update text_to_sequence.py

* fix w2v

* aishell

* cv

* ls transformer

* ls ssl

* switchboard

* timit

* precommit

* fix indent

* fix arg

* unit test sorting

* unittests

* remove if main

* Small fixes in averaging checkpoints (#2181)

* add ckpt avg unittest

* avoid hard-coding number of averages

* last fixes

* fix recipe test

* fix recipe test

* convert print into logger

* fix transducer recipe

* remove typing

* fix merge

* precommit

* Update LibriSpeech.csv

* update to new dynamic batching args

* Update unstable branch with new commits  (#2196)

* hyper branch/conf -former fixes

* remove ctc.py from doctest

* get back ctc.py

* remove doctest for torchaudio

* adapt gpt recipe

* adapt gpt recipe

* small follow up fix on openrir

* remove doc test (for now)

* fix issue greedy search

* docstring

* pre-commit

* Fix issues unstable (#2216)

Thank you @Adel-Moumen! I did the tests again and everything works now. As for your points on the recipe tests, I agree. We can eventually do that in another PR.

* Fix missing file / import in huggingface_transformers (#2224)

* init/imports

* comment

* add partial import

* wav2vec -> wav2vec2

* fix ci

* Text based HF (#2214)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* change authorship

* remove comments

* minor changes

* change authorship

* Fix recipe test

* add info

* Update README.md

* Update README.md

* change recipe structure

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>

* Neural LM Rescoring (#2187)

* baserescorerinterface

* add rescorers

* first attempt

* update code

* 1.57 wer

* update

* update code

* update code

* docstring example rnn

* updata loader

* docstring example

* tests

* docstring example

* update

* tmpdir

* change path

* update doc

* docstring

* docstring args

* doctest

* fix docstring example

* unnittest

* interface

* yamls update

* full_infernece tests

* model link

* readme

* yaml/inference tests

* update res

* fix wav2vec with wav2vec2

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add wrappers for Encodec and Vocos vocoders (#2231)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Semantically-Aligned Multimodal Utterance-level (SAMU) pre-training (#2223)

* add mbart

* Add tristage scheduler

* Add mbart beam search

* Add IWLST recipes

* Add new models' inteference interface

* Add info of new models

* Add nllb scores

* Add new models' info

* Add test info IWSLT recipe

* Add test info IWSLT recipe

* add docstrings for S2STransformerBeamSearcher

* Update IWSLT recipes

* Update IWSLT recipes

* fix doctest

* add requirements

* add protobuf

* fix doctest

* small fixes

* Add protobuf install

* Minor reform

* Remove protobuf

* Fix docstings

* Fix docstrings

* minor reform

* remove labse

* Add attention pooling

* Add labse

* Add info about SAMU

* add iwslt recipes with samu

* fix recipe test

* fix comments

* fix recipe test

* change recipe structure

* fix test recipe

* Add new recipes

* minor doctest change

* minor doctest change

* small changes

* add dropbox links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* fix norm (#2237)

* Discrete SSL (#2233)

* clustering training recipies for LibriSpeech for different SSL model

* add Discrete Hubert Model

* load from HF, fix minor issues

* fix hyper-param value

* fix precommit

* fix flake8

* fix batch_size and n_clus values in hyperparams

* fix typos

* fix typo and some cleaning

* fix precommit

* fix device incompatibility and memroty issue

* use fit instead of partial fit

* add README file

* add test recipies

* remove unused fields from hparams

* fix precommmit-yamllint - extra whitespace

* add docstring for load_kmeans for Discrete_hubert.py

* add discrete wavlm, wav2vec

* avoid docstring testing for discrete_ssl models

* fix docstring failed issue

* add discrete_interface to conftest.py

* fix precommit

* Fixes for Encodec (#2240)

* Add wrappers for Encodec and Vocos from Huggingface

* Encodec: Add a comment

* Encodec/Vocos: Add examples, restructure, fix masks

* Vocos: Add a comment about the open pull request

* Encodec/Vocos: Add the ability to customize save_path, fix a log message

* Encodec/Vocos: Cosmetic changes

* Vocos: Cosmetic changes

* Encodec/Vocos: Remove the mandatory Vocos requirement

* Vocos: Remove vocos from __init__.py

* fix init

* Vocos: Add a check for vocos in conftest.py

* Vocos/Encodec: Update documentation, add bandwidth control

* Fix old path in conftest.py

* Cosmetic changes

* Encodec/Vocos: Add support for embedding vectors

* Encodec: Update example

* Encodec/Vocodec: Add automatic reshaping, minor cosmetic changes

* Encodec: Decoupled token extraction, fixed CPU/GPU issues

* Encodec: Add renormalization

---------

Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactoring of the 'fit_batch' function (#2010)

* add dataclass

* turn False

* remove valid_step

* update core.py

* update core.py

* update core.py

* precommit

* self.autocast + GradScaler enabled

* freeze opt

* naming

* update core.py

* comments

* example transducer conformer

* update core.py

* small changes

* naming + skip_grad_nans

* doc

* check

* support cpu training

* precision + doctrsting

* name

* change w2v

* restore ckpt

* remove file

* remove casting

* tests

* whisper + fix tests

* seq2seq ls

* update transducer / transformer

* remove on_optimizers_step_end + comments

* update check yaml

* remove default arg

* add precision in yamls

* add precision inside of the yamls

* ckpt and scaler

* run_opt outside brain + test

* several recipe updates

* improve w2v fit_batch fn

* add arg

* update name

* timit

* context manager

* on_fit_batch_start

* update CV

* should_step with noam

* add flag precision

* naming

* aishell

* aishell

* update recipes

* so many recipes 0.0

* update recipes

* last recipes

* zero_grad

* fix grad_accumulation_factor

* update recipes

* update auto_mix_prec flag

* remove opt flag test

* librispeech

* cv ssl

* audio mnist / realm

* voicebank

* fix rescuespeech

* fix lr annealing

* libritts

* multiwoz

* slurp nlu

* should_step

* update yamls

* update yaml

* update batch smpler tedlium

* remove fit batch

* precision flag

* update sampler

* add precision inside of the yamls

* run_opt outside brain + test

* fix auto_mix_prec flag

* docstring

* grad acc

* failing test

* update unittests

* update jarod's pr

* fix removed avg_checkpoint param

* update path

* fix some recipe tests

* update samu recipe

* fix hifigan/IWSLT

* tedlium

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Refactor Augmentation (#2206)

* update

* update

* change folder

* remove unnecesary file

* update folder structure

* add noise, add rev

* augmenter refactor

* refactor augment + example in templace

* fix tests + linters

* address comments

* supporting variable-length augmentations in augmenter (e.g., speed change)

* lib refactor (splitting time and freq augmentations)

* fine tune freq drop

* refactor of specaugment (freq-domain) - part 1

* converted specaument (freq domain)

* refactor random shift

* implemented cutcat, swap, and random selection

* extended unittests + small fixes

* improvements and fixes in augment

* plugged feature augmentation + various fixes and improvements

* add sum_batch noise (similat to babble) + various fixes

* add drop bit resolution

* added coded augmentation

* added more unittests

* restore all augmentations

* making AddReveb more similar to AddNoise

* fix device mismatch + fix last batch management

* add workes to speed up AddNoise and AddRev

* improve comments in template yaml

* speed up template (sorting dev and test)

* extend augmenter by adding activation provability

* implemented enable augmentation flag (useful of hparam tuning) + other improvements

* plugged coded augment

* fixed coded augment

* remove old files

* fix integration test

* remove knowledge distill TIMIT reicpes. Too many yaml files to maintain

* convert TIMIT

* fix recipe

* converted templates using EnvCorr

* converted voxceleb

* converted GSC + fixes on voxceleb

* convrted UrbanSound8k

* converted voicebank

* converted other recipes

* converted CommonLanguage, VoxLingua, timers-and-such

* converted all recipes using envcorr

* CommonVoice

* REAL-M

* Aishell1Mix

* LibriMix

* converted all recipes!

* fix linters - part1

* fix linters - part2

* add a note in the template regarding augmentation

* fix docstring tests

* fix yamls

* remove coded tests from docstring

* revised coded tests

* fix identation in codec.py

* try to fix doc issue

* revise lib header in codec.oy

* fix doc

* fix doc attempt

* rename sections

* fix doc

* fix (most) recipe tests

* fix other recipe tests

* address comments

* fix yaml

* fix

* convert recipe

* fix recipes

* fix aug in rescoring recipes

* Delete tmpdir_vocoder directory

* Refactor Inference (files and folders) (#2252)

* refactor inference files and folders

* fix some tests

* fix some tests

* fix doctest

* import lib

* small fixes

* Fix beam search (#2253)

* fix starting pos prefix_length

* block path ctc + fix default value to the old one

* fix issue with score being -inf

* remoev print

* precommit

* Fix ctc beam search (#2263)

* fix logprobs / space_token / warnings

* fix space_token

* pre-commit

* space_token

* simplify parameters

* simplify yamls

* remove comma

* update beam search

* fix vocab/str (#2265)

* Fix blank index ctc (#2266)

* update blank_index

* whisper

* revert change

* mistake

* Cv unstable merge (#2254)

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* add fr preproccesing to Common_voice_prepare.py

* add CV , CTC, new languages

* fix precommit and test

* add transducer recipie

* add transformer recipies

* update augmentation of CTC recipies

* update seq-to-seq recipies

* fix whisper HF interface bug. (return str insted of list)

* fix recipe tests

* modify beamsearch for CTC: ar.es.pt and zh-CN

* fix interface conflict

* fix transducer interface bug

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Add warnings and fix numba (#2271)

* upperbound torch/tochaudio + remove opt dependancy

* add back automix/bf flags

* linters

* oops

* transformers back

* test requirements

* Fix Bug: CommonVoice Transformer Bug loading correct optimizer (#2278)

* fix trnsfrm bug to load correct opt:adam vs sgd

* add  data_root to the path of common_voice_prepare.py

* add epoch/_counter pretrainer to fr and it recepie

* revert releative path change

* fix opt bug without the need to add epoch_ckpt

* add log and delete launch file

* update the log message

* update WeightedSSLModel (#2272)

* update WeightedSSLModel

* requirements.txt

* fix pre-commit

* Sg/dac (#2246)

* introducing DAC

* lint errors

* black

* documenttion

* remove unused init file

* Fixing tests

* More doc strings

* More doc strings

* PR review

* PR review

* PR review

* Update dac.py

* Update dac.py

* Update dac.py

* make doctests smaller to avoid memory issues in CI

* even smaller tests

---------

Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech (#2255)

* add quantization recipies fro IEMCAP, CV, LibriSpeech and LJSpeech

* update discrete_ssl models

* add iemocap_prepare to main folder + add test

* ix test for iemocap

* fik typos

* fix test recepies,  minor dormat editting

* fix typo in coomonvoice.csv

* fix typo in yaml file

* fix doctests (those that we do not run in the CI)

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* change emdedding type from long to float to vaoid getting al zeros embedding (#2292)

* Update CVSS (#2285)

* Update CVSS

* Update train_fr-en.yaml

* Update train_fr-en.yaml

* Update HF interface (#2293)

* RNN Tranducer Numba Loss: Add FP16 and BF16 support (code from Samsung AI Cambridge) (#2296)

* Make lobes use fp32 when AMP is active (#2295)

* Added utils.autocast with a fwd_default_precision function

* Decorate all lobes to require float32 precision in AMP

* Fix trailing space in docstring

* Less confusing doc for fwd_default_precision

* Be explicit that only fp inputs are affected by fwd_default_precision

* Typo in docstring

* Remove dtype annotation that is broken for some reason

* Precommit checks will be the end of me

* Fix tests

* Add docstring to precision wrapper function

* Fix style check again..

* adding support for fp16 transducer loss numba

* adding support for fp16 transducer loss numba

* fix fp16 transducer recipe

* add note on half precision

---------

Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Fix recipe tests for TransformerASR (#2282)

* fix position embedding (#2283)

* fix position embedding

* use speechbrain internal postional encoding and generate mask from sequence lengths

* call mask function from core for tacotron

* minor fix

* fix device

* reduce training epochs

* update links

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Gradscaler flags (#2281)

* add flags for gradscaler

* add check_loss_isfinite

* update dict

* typo

* remove default

* better message

* fix pre-commit

* remove checks

* remove new arguments

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* add llama2 recipies (#2299)

* add llama2 recipies

* fix symbolic links

* fix  bug

* remove unneccary input in docstring

* fix typo

* cleaning llama2 recepies

* update readme

* update interface and add licence to readme

* fic doc string

* fix precommit

* fix extra-dependency

* remove  commented lines

* inter epoch checkpoint

* minor fixes

* add extra req info in llama.py

* fix linters

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* small fixes

* make all recipes cpu-compliant + make recipe tests passing on both cpu and gpu

* fix some broken links

* remove link to private HF repo

* remove link to private HF repo

* fix libritts recipe test

* fix ljspeech recipe test

* Streamable Conformer-Transducer ASR model for LibriSpeech (#2140)

* Introduce DCT+DCConv logic

* DDP fix?

* Batch of changes and things brought back

* Streaming fixes (successfully trains)

* WIP streaming code

* WIP functional streaming code

* Fix left context

* Fix formatting

* Cleanups and docs in streaming utils

* Better comment hparams, change seed back to orig, improve naming

* uncomment averaging stuff; it was some ipython issue

* Remove pin_memory as it was not beneficial

* More cleanups, comments on context stuff

* More comments and TODOs

* encode_streaming docstring

* Dirty TransducerBeamSearcher change for streaming GS

* Fix precommit

* Fix encoders that do not support chunk_size

* Pre-commit again

* Make chunk_size type consistent

* Fix formatting of doctest in split_wav_lens

* Remove outdated TODO

* Add hasattr streaming to retain model backcompat

* Cleanup doc and naming for transducer_greedy_decode

* Cite paper for chunked attention

* Remove lost comment

* Update comment in self-attention

* Don't apply masked fill fix in the non-bool mask case

* Added TODO README update

* Revert change to custom_tgt_module; patching model instead

* Remove added entry in README

* Fix streaming conformer conv mismatch

* More conformer conv adjustments

* Adjust context size

* Remove outdated comment

* Fixed causal conformer decoder

* Fix linting

* Gate `custom_tgt_module` creation behind the presence of decoder layers

* Re-enable checkpoint averaging

* Change averaged ckpt count to 10

* Add new model results to README

* WIP refactor: Introduce DCTConfig dataclass

* Improved notice in README

* Formatting and linting fixes

* Attempt at fixing circular import?

* utils can't depend on core it seems; move dct

* Whoops, missed file

* Add DCT test, fix issues

* Remove now obsolete yaml variables for streaming

* Formatting

* Add dummy dct_config parameter to keep unsupported encoders working

* Linting fix

* Fix typo

* Add note on runtime autocast accuracy

* Fix very bad typo from refactor in YAML

* Fix hasattr streaming check

* Remove legacy comment

* Fix left context size calculation in new mask code

* Fix causal models in TransformerASR

* Remove comment on high-level inference code

* YAML formatting + commenting dynchunktrain stuff

* Remove outdated comment about DCConv left contexts

* Remove commented out debug prints from TransformerASR

* Move DCT into utils again

* Rename all(?) mentions of DCT to explicit dynamic chunk training

* Clarify padding logic

* Remove now-useless _do_conv, fix horrible formatting

* Slightly fix formatting further

* Add docstrings to forward_streaming methods

* Add a reference on Dynamic Chunk Training

* Rework conformer docstring docs

* Update conformer author list, fix doc formatting for authors

* Fix trailing whitespace in conformer

* Improved comments in Conformer.forward

* Added random dynchunktrain sampler example

* More explicit names for mask functions in TransformerASR

* Added docstring example on encode_streaming

* Pre-commit fix

* Fix typo in conformer

* Initial streaming integration test

* Precommit fix

* Fix indent in YAML

* More consistent spelling in streaming integration test

* Update CommonVoice.csv

* Add KenLM n-gram training recepie (#2304)

* add kenlm training

* fix precommit

* update readmefile with new result

* fix pre-commit

* fix typo

* fix commit reviews

* fix bug in testing

* add docstring and fix indentation

* fix bug in ASR interface

* change encoderasr interface to support ctc beam

* add suppourt fro kenlm in enoderasr interface

* fix typo

* little changes in REAMDE files to improve clarity)

* use binaries sources in bashrc

* fix trailing-whitespace

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* Create Performance file (automatically) (#2314)

* add performance readme builder

* update recipe csv files

* update README files

* add not in prerelease test

* added performance.md

* fix linters

* update info in README

* Llama2 interface bug (#2318)

* fix llama2 interface bug

* fix minor bug

* update multiwox.csv with correct db and HF link

* New README file (#2315)

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Update README.md

* Optimize masked Dynamic Chunk Convolution (#2308)

* Reorganized some conformer convolution module to be faster

* Completely get rid of the list of slices in the conformer conv module

* Fix linter check

* Remove unused variable

* More unused variables..

* Remove unused import

* Add conformer streaming code path test

* Fix test formatting

* small fixes in tests

* Update RNNLM.yaml

* BayesSpeech (#2326)

* Create train_bayesspeech.py

* Create bayesspeech.yaml

* Update README.md

* Update LibriSpeech.csv

* add extra-req

---------

Co-authored-by: Mirco Ravanelli <mirco.ravanelli@gmail.com>

* adding new controllable exp scheduler

* adding new controllable exp scheduler

* update performance file

* Update PERFORMANCE.md

* Update README.md

---------

Co-authored-by: mhn226 <mhn.22692@gmail.com>
Co-authored-by: Adel Moumen <88119391+Adel-Moumen@users.noreply.github.com>
Co-authored-by: Adel Moumen <adelmoumen.pro@gmail.com>
Co-authored-by: Ha Nguyen <43038599+mhn226@users.noreply.github.com>
Co-authored-by: flexthink <1496671+flexthink@users.noreply.github.com>
Co-authored-by: flexthink <flexthink@users.noreply.github.com>
Co-authored-by: Pooneh Mousavi <moosavi.pooneh@gmail.com>
Co-authored-by: shubham-gupta-30 <127571426+shubham-gupta-30@users.noreply.github.com>
Co-authored-by: Shubham Gupta <shubhamgupta@Shubhams-MacBook-Pro-2.local>
Co-authored-by: Parcollet Titouan <parcollet.titouan@gmail.com>
Co-authored-by: asu <sdelang@sdelang.fr>
Co-authored-by: Titouan Parcollet/Embedded AI /SRUK/Engineer/Samsung Electronics <t.parcollet@sruk-ccn4.eu.corp.samsungelectronics.net>
Co-authored-by: Luca Della Libera <34525085+lucadellalib@users.noreply.github.com>
Co-authored-by: Yingzhi WANG <41187612+BenoitWang@users.noreply.github.com>
Co-authored-by: BenoitWang <wangyingzhi666@gmail.com>"
github.com/speechbrain/speechbrain,tests/templates/fetching_ddp_dynbatch_finetuning/single_node_pretrained.py,2023-02-14T11:33:19Z,FetchSource
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/vad/segmenter.py,2024-02-20T08:16:14Z,Release candidate for 3.0 (#741)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/vad/segmenter.py,2023-10-12T04:56:41Z,Update for japanese model (#706)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/vad/segmenter.py,2023-09-12T03:57:03Z,3.0.0a5 (#691)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/vad/segmenter.py,2023-08-30T08:27:16Z,"Further refactoring and fixes for anchor (#684)

* Further refactoring and fixes for anchor

* Update segmenting of transcripts"
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/vad/segmenter.py,2023-08-25T15:28:19Z,Fix how configuration works with threading (#681)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/vad/segmenter.py,2023-08-22T16:58:55Z,Update to use kalpy as dependency (#679)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/vad/segmenter.py,2023-03-07T06:18:32Z,2.2.4 (#576)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/vad/segmenter.py,2023-02-17T04:41:13Z,"2.2.3 (#574)

* Migrate to using rich for terminal color and formatting"
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/vad/segmenter.py,2023-02-15T06:46:13Z,"2.2.0: Add support for tokenizers (#566)

* Add support for tokenizers"
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/vad/segmenter.py,2023-02-14T04:11:32Z,2.1.6 (#562)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/vad/segmenter.py,2023-02-06T01:39:57Z,Update for PraatIO 6.0 and related fixes (#547)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/vad/segmenter.py,2023-02-05T04:48:03Z,"V2.1 (#536)

Resolves #527
Resolves #525
Resolves #522
Resolves #520
Resolves #511
Resolves #540
Resolves #541"
github.com/linto-ai/linto-stt,whisper/stt/processing/alignment_model.py,2023-11-30T16:49:13Z,fix coding style
github.com/linto-ai/linto-stt,whisper/stt/processing/alignment_model.py,2023-11-29T17:49:00Z,Isolate what is specific to Whisper in a folder
github.com/huggingface/open_asr_leaderboard,speechbrain/run_eval.py,2023-08-03T18:32:48Z,"Add Speechbrain toolkit (#4)

* speechbrain initial get_model fn

* wav2vec / run_eval.py working

* conformer.sh

* add .sh

* remove pycache

* fix batch size

* docstring

* docstring

* updt

* speechbrain requirements

* speechbrain requirements

* fix wer?

* manifest

* gitignore / remove savedir arg

* remove speechbrain/ path

* gitignore

* update wav2vec

* cv

* update scripts

* fix issue composite wer"
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/multiprocessing.py,2024-02-20T08:16:14Z,Release candidate for 3.0 (#741)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/multiprocessing.py,2023-10-12T04:56:41Z,Update for japanese model (#706)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/multiprocessing.py,2023-09-12T03:57:03Z,3.0.0a5 (#691)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/multiprocessing.py,2023-08-28T06:50:40Z,Refactor tokenization and bug fixes (#683)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/multiprocessing.py,2023-08-25T15:28:19Z,Fix how configuration works with threading (#681)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/multiprocessing.py,2023-08-22T16:58:55Z,Update to use kalpy as dependency (#679)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/multiprocessing.py,2023-03-07T06:18:32Z,2.2.4 (#576)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/multiprocessing.py,2023-02-15T06:46:13Z,"2.2.0: Add support for tokenizers (#566)

* Add support for tokenizers"
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/multiprocessing.py,2023-02-09T21:25:40Z,"2.1.4 (#555)

* Rework connections again

* Rework pgvector index creation"
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/multiprocessing.py,2023-02-09T04:35:34Z,"2.1.3 (#553)

* Rework connections

* Better cleaning of databases"
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/multiprocessing.py,2023-02-07T00:50:11Z,2.1.2 changes (#549)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/multiprocessing.py,2023-02-06T01:39:57Z,Update for PraatIO 6.0 and related fixes (#547)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/multiprocessing.py,2023-02-05T04:48:03Z,"V2.1 (#536)

Resolves #527
Resolves #525
Resolves #522
Resolves #520
Resolves #511
Resolves #540
Resolves #541"
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/speaker_diarizer.py,2024-02-20T08:16:14Z,Release candidate for 3.0 (#741)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/speaker_diarizer.py,2023-11-02T01:18:55Z,Bug fixes (#712)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/speaker_diarizer.py,2023-10-12T04:56:41Z,Update for japanese model (#706)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/speaker_diarizer.py,2023-09-12T03:57:03Z,3.0.0a5 (#691)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/speaker_diarizer.py,2023-08-30T08:27:16Z,"Further refactoring and fixes for anchor (#684)

* Further refactoring and fixes for anchor

* Update segmenting of transcripts"
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/speaker_diarizer.py,2023-08-28T06:50:40Z,Refactor tokenization and bug fixes (#683)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/speaker_diarizer.py,2023-08-25T15:28:19Z,Fix how configuration works with threading (#681)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/speaker_diarizer.py,2023-08-22T16:58:55Z,Update to use kalpy as dependency (#679)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/speaker_diarizer.py,2023-04-26T21:03:32Z,"2.2.10 (#624)

* Bug fixes"
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/speaker_diarizer.py,2023-03-07T06:18:32Z,2.2.4 (#576)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/speaker_diarizer.py,2023-02-17T04:41:13Z,"2.2.3 (#574)

* Migrate to using rich for terminal color and formatting"
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/speaker_diarizer.py,2023-02-15T06:46:13Z,"2.2.0: Add support for tokenizers (#566)

* Add support for tokenizers"
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/speaker_diarizer.py,2023-02-14T04:11:32Z,2.1.6 (#562)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/speaker_diarizer.py,2023-02-09T21:25:40Z,"2.1.4 (#555)

* Rework connections again

* Rework pgvector index creation"
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/speaker_diarizer.py,2023-02-06T01:39:57Z,Update for PraatIO 6.0 and related fixes (#547)
github.com/MontrealCorpusTools/Montreal-Forced-Aligner,montreal_forced_aligner/diarization/speaker_diarizer.py,2023-02-05T04:48:03Z,"V2.1 (#536)

Resolves #527
Resolves #525
Resolves #522
Resolves #520
Resolves #511
Resolves #540
Resolves #541"
github.com/jansel/pytorch-jit-paritybench,generated/test_speechbrain_speechbrain.py,2023-01-10T06:06:44Z,Re-crawl & re-generate test suite(1479 projects & 14307 test cases)
github.com/Ascend/ModelZoo-PyTorch,PyTorch/contrib/audio/tdnn/speechbrain/pretrained/interfaces.py,2023-07-10T07:05:29Z,"!5157 【需求】【PyTorch】【Tdnn】训推一体
* 新增训练脚本，修改相应文件
* 修改文件，添加license，添加readme
* tdnn模型上传"
github.com/Ascend/ModelZoo-PyTorch,PyTorch/contrib/audio/tdnn/speechbrain/pretrained/interfaces.py,2022-03-18T07:08:55Z,init
github.com/speechbrain/benchmarks,tests/utils/refactoring_checks.py,2023-06-29T21:21:56Z,upload files and tests
github.com/radinshayanfar/speaker-verification,snorm_embeddings.py,2022-03-16T12:01:08Z,files added.
github.com/radinshayanfar/speaker-verification,speaker_verification_cosine.py,2022-03-16T12:01:08Z,files added.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2024-02-27T11:11:47Z,"[Update] An example for Gemma model was initially added.
[Update] An example for Transformer Reinforcement Learning (TRL) library to train small LLMs (sLLMs) was initially added."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2024-02-21T12:45:57Z,[Update] Examples for DINO and DPT models were implemented in hugging_face_transformers_test.py.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2024-02-16T06:16:19Z,[Update] Placeholders for examples of Hugging Face TRL library were added.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2024-02-08T03:52:31Z,"[Update] Several examples for stable diffusion models of Stability AI were implemented.
[Update] Information about Transformer Reinforcement Learning (TRL) library was moved from hugging_face_test.py to hugging_face_transformers_test.py."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2024-01-31T08:31:27Z,[Update] A test was added to fine-tune a ResNet model using Dog/Cat dataset in pytorch_transfer_learning.py.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2024-01-28T13:07:24Z,"[Update] An example of Zephyr-7B was added in hugging_face_transformers_test.py, but was not tested.
[Update] The information about Transformer Reinforcement Learning (TRL) was described in hugging_face_test.py."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2024-01-11T04:04:23Z,"[Update] An example for retrieval-augmented generation (RAG) was added in hugging_face_transformers_test.py.
[Update] Information about TableMASTER-mmocr was removed from mmocr_usage_guide.txt."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-12-24T02:40:32Z,"[Update] A few examples for Mistral-7B and Mixtral-8x7B models were added.
[Update] The installation of TensorFlow 2 were updated."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-12-23T12:07:02Z,"[Update] An example of ORCA-2 model was added.
[Update] The examples for ViT, ViLT, BEiT, LayoutLM, and Donut models were merged respectively.
[Update] The information about data preparation, training, evaluation, visualization, and model export were supplemented in paddle_ocr_usage_guide.txt."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-11-24T08:49:41Z,"[Update] A customized version of ViT model was implemented and tested, which doesn't have classification token and head."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-11-20T04:48:59Z,"[Update] A few examples for Falcon model were initially implemented.
[Update] A few examples for StarCoder and Replit models were implemented, but yet tested."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-11-10T01:27:50Z,[Update] LLMs Yi-6B & Yi-34B were tested.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-11-06T12:24:53Z,"[Update] The forecasts of transformers.TimeSeriesTransformerForPrediction were evaluated by MASE, MAPE, sMAPE.
[Update] Metrics for evaluating ML models' performance in evaluate library were tested."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-11-03T10:46:04Z,"[Update] Two examples for phi-1 & phi-1.5 models were initially added.
[Update] A few examples for Kosmos-2 model were initially added."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-10-12T12:13:43Z,[Update] A few examples for Probabilistic time series transformer model were added.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-10-07T08:51:44Z,[Update] Several examples for Perceiver IO model were initially committed.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-09-26T10:56:44Z,"[Update] A simple example for Code Llama model was initially added.
[Update] A few commands were explained to profile Python scripts."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-09-21T12:31:58Z,[Update] A simple example for OpenLLaMA models was implemented.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-09-04T03:59:25Z,"[New] A few examples for PID, MPC, LQR using python-control library was initially added.
[Update] A simple example for trajectory transformer models was added in hugging_face_transformers_test.py."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-09-02T12:30:02Z,"[New] An example for model predictive control (MPC) was initially committed.
[Update] A test for CodeParrot model was initially implemented in hugging_face_transformers_test.py."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-08-31T06:01:24Z,"[Update] Memory footprint and computing performance (FLOPS) Hugging Face transformers models was measured.
[Update] A simple test for Hugging Face datasets was added."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-08-04T08:13:21Z,[Update] An example for OpenFlamingo library was added.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-07-25T12:07:07Z,"[Update] A few examples for Llama 2 model were added in hugging_face_transformers_test.py.
[Update] Model parallelism was tested based on Hugging Face Accelerate library in hugging_face_transformers_test.py.
[Update] Information about Hugging Face Accelerate library was reinforced."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-07-22T06:48:12Z,"[Update] Cross references about transformer and ViT models were reinforced.
[Chore] vit_test.py was moved from sw_dev/python/rnd/test/machine_learning/vit_test.py to sw_dev/python/rnd/test/machine_vision/vit_test.py.
[Update] The installation of node.js was explained."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-07-17T01:20:26Z,"[Update] Several examples for CodeBERT, CodeBERTa, CodeT5+, CodeGen2, & CodeGen2.5 models were added.
[Update] An example of SpeechT5 model was divied into 3 examples: ASR, TTS, & speech-to-speech."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-07-12T07:54:25Z,"[Update] An example for Decision Transformer was initially committed.
[Update] A few examples for NVIDIA Megatron-LM, ASR, TTS models were implemented.
[Update] An example for SegFormer model was initially added."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-06-30T14:20:26Z,"[Update] The method, chain of thoughts (CoT) was tested on two LLMs, LLaMA & MPT."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-06-27T04:15:37Z,"[Update] A few examples for MPT & TVLT models were implemented in hugging_face_transformers_test.py.
[Chore] table_generation_usage_guide.txt was moved to SWLP repository."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-06-22T14:49:33Z,"[Update] Three language models were tested: LLaMA, Galactica, & OPT models."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-06-15T07:51:37Z,[Update] The example of LLaMA model was reinforced.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-05-26T18:49:16Z,[Update] A test for data parallelism was implemented in PyTorch library.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-05-05T03:23:29Z,"[Update] Two simple tests for two Facebook's language models, OPT and Galactica were initially implemented."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-04-30T14:34:59Z,[New] A simple tutorial for MMSegmentation library was initially committed.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-04-06T03:27:45Z,"[Update] A couple of simple examples for LLaMa model were implemented, but they were not tested due to library version issue."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-04-04T11:52:41Z,"[Update] Several examples for CodeT5 and CodeGen models were implemented to generate code.
[Update] Several examples for GIT and BLIP models for vision-and-language modeling models were implemented.
[Update] A few examples for TaPEx model were implemented to understand tables."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-04-01T14:10:48Z,"[New] A couple of examples for GPT4All models were added, but they were not correctly working."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-04-01T06:26:08Z,"[New] Two simple examples for PaLM and PaLM+RLHF models were implemented, but the models were not trained in the examples."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-03-30T08:06:47Z,"[New] Several examples for table processing (Table Transformer, TATR), OCR (TrOCR), speech processing (SpeechT5) were initially added to hugging_face_transformers_test.py."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-03-29T05:25:41Z,[Update] Several examples for speech recognition (whisper) & synthesis (tacotron2 & fastspeech2) were newly implemented in hugging_face_transformers_test.py.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-03-26T07:02:13Z,"[New] A few examples for ALIGN model were implemented in hugging_face_transformers_test.py.
[Update] A couple of examples for CLIP model were added in hugging_face_transformers_test.py.
[Update] Useful information about Transformer architectures was described."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-03-24T06:24:31Z,[Update] A simple example about dataclass in Python was added.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-03-22T14:48:31Z,"[Update] A couple of examples of seq-to-seq models for LoRA & Prefix Tuning were implemented in hugging_face_test.py.
[Update] An example for CLIP model was implemented in hugging_face_transformers_test.py.
[Update] A few examples for Whisper model were implemented in hugging_face_transformers_test.py.
[New] A usage guide for Hugging Face library was added."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-03-21T07:10:38Z,"[Update] A simple example of Parameter-Efficient Fine-Tuning (PEFT) library was added to hugging_face_test.py.
[Update] A simple test of tokenizers was added to hugging_face_transformers_test.py."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-03-18T11:41:29Z,[Update] A couple of examples for diffusion models of StabilityAI and CompVis were added.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-03-18T05:09:16Z,[Update] A few examples for Flan-T5 model were reinforced in hugging_face_transformers_test.py.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-03-16T11:52:13Z,[Update] Information about Hugging Face models was supplemented.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-03-15T12:08:24Z,[Update] An example for question answering using GPT-neo was added.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-03-14T02:43:49Z,[Update] A few examples for BLOOM and Flan-T5 models were implemented.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-03-09T01:51:43Z,[Update] A test for KLUE BERT models was implemented.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-03-09T01:49:32Z,"[Update] A few examples of text summarization for Korean & English were implemented, but their results were not good.
[Update] A few examples for T5 model were added."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-03-07T17:44:21Z,[Update] A few tests were added for GPT & BERT models.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-03-01T14:37:43Z,[New] A few guides were initially committed for Hugging Face Hub library.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-01-19T10:11:50Z,"[Update] Several examples for vision, vision and language models were added in HuggingFace library."
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2023-01-19T08:06:44Z,[Update] Several examples for LayoutLM & Donut models were implemented in HugggingFace library.
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/language_processing/hugging_face_transformers_test.py,2022-04-01T07:00:58Z,[Chore] transformers_test.py was renamed to hugging_face_transformers_test.py.
github.com/CanKeles5/senh,models.py,2022-02-09T21:26:43Z,Slight refactor.
github.com/CanKeles5/senh,models.py,2022-02-07T19:34:15Z,.
github.com/CanKeles5/senh,models.py,2022-02-07T12:50:06Z,"Add files via upload

Code needs lots of refactoring."
github.com/CanKeles5/senh,models.py,2022-02-07T11:58:44Z,initial commit
github.com/Ascend/ModelZoo-PyTorch,PyTorch/dev/perf/speechbrain-tdnn/tools/g2p.py,2023-06-25T09:50:02Z,"ECAPA-TDNN NPU

NPU迁移

NPU迁移

NPU适配"
github.com/Ascend/ModelZoo-PyTorch,PyTorch/dev/perf/speechbrain-tdnn/tools/profiling/profile.py,2023-06-25T09:50:02Z,"ECAPA-TDNN NPU

NPU迁移

NPU迁移

NPU适配"
github.com/Ascend/ModelZoo-PyTorch,PyTorch/dev/perf/speechbrain-tdnn/speechbrain/pretrained/interfaces.py,2023-06-25T09:50:02Z,"ECAPA-TDNN NPU

NPU迁移

NPU迁移

NPU适配"
github.com/nuaazs/VAF,src/utils/preprocess/new_vad.py,2023-04-21T02:56:39Z,update code
github.com/amitpuri/Ask-picturize-it,Utils/TranscribeSpeechbrain.py,2023-07-04T14:20:40Z,Update
