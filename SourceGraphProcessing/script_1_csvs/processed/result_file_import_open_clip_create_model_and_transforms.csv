github.com/google-research/google-research/agile_modeling/load_clip.py
github.com/Stability-AI/stablediffusion/ldm/modules/encoders/modules.py
github.com/lllyasviel/ControlNet/ldm/modules/encoders/modules.py
github.com/langchain-ai/langchain/libs/experimental/langchain_experimental/open_clip/open_clip.py
github.com/Stability-AI/generative-models/sgm/modules/encoders/modules.py
github.com/AUTOMATIC1111/stable-diffusion-webui/modules/sd_disable_initialization.py
github.com/hpcaitech/ColossalAI/examples/images/diffusion/ldm/modules/encoders/modules.py
github.com/brycedrennan/imaginAIry/imaginairy/modules/encoders.py
github.com/Sygil-Dev/Sygil-WebUI/scripts/img2txt.py
github.com/TheLastBen/fast-stable-diffusion/Dreambooth/det.py
github.com/NVIDIA/NeMo/scripts/fid-eval-text2img/compute_clip_score.py
github.com/brycedrennan/imaginAIry/imaginairy/modules/sgm/encoders/modules.py
github.com/chroma-core/chroma/chromadb/utils/embedding_functions.py
github.com/lucidrains/DALLE2-pytorch/dalle2_pytorch/dalle2_pytorch.py
github.com/open-mmlab/mmsegmentation/projects/CAT-Seg/cat_seg/models/clip_ovseg.py
github.com/modelscope/modelscope/modelscope/models/multi_modal/videocomposer/clip.py
github.com/Sygil-Dev/Sygil-WebUI/webui/streamlit/scripts/img2txt.py
github.com/brycedrennan/imaginAIry/tests/test_guidance.py
github.com/marqo-ai/marqo/src/marqo/s2_inference/clip_utils.py
github.com/modelscope/modelscope/modelscope/models/multi_modal/clip_interrogator/model.py
github.com/jina-ai/discoart/discoart/helper.py
github.com/Docta-ai/docta/docta/core/preprocess.py
github.com/lllyasviel/ControlNet-v1-1-nightly/ldm/modules/encoders/modules.py
github.com/AIGC-Audio/AudioGPT/text_to_audio/Make_An_Audio/ldm/modules/encoders/modules.py
github.com/microsoft/onnxruntime/onnxruntime/python/tools/transformers/models/stable_diffusion/test/check_image.py
github.com/NVIDIA/NeMo/nemo/collections/multimodal/modules/stable_diffusion/encoders/modules.py
github.com/modelscope/modelscope/modelscope/models/cv/anydoor/ldm/modules/encoders/modules.py
github.com/mlfoundations/open_flamingo/open_flamingo/eval/rices.py
github.com/lllyasviel/stable-diffusion-webui-forge/modules/sd_disable_initialization.py
github.com/NVIDIA/NeMo/examples/multimodal/vision_language_foundation/clip/convert_external_clip_to_nemo.py
github.com/modelscope/modelscope/modelscope/models/multi_modal/video_to_video/modules/embedder.py
github.com/modelscope/modelscope/modelscope/models/multi_modal/image_to_video/modules/embedder.py
github.com/mlfoundations/open_flamingo/open_flamingo/src/factory.py
github.com/AILab-CVC/VideoCrafter/lvdm/modules/encoders/condition.py
github.com/microsoft/Cream/TinyCLIP/inference.py
github.com/Alpha-VLLM/LLaMA2-Accessory/accessory/model/LLM/llama.py
github.com/tyxsspa/AnyText/ldm/modules/encoders/modules.py
github.com/mlfoundations/open_clip/tests/util_test.py
github.com/mlcommons/training/stable_diffusion/ldm/models/clip_encoder.py
github.com/mlfoundations/open_clip/tests/test_inference.py
github.com/Alpha-VLLM/LLaMA2-Accessory/accessory/model/LLM/mixtral.py
github.com/mlfoundations/open_clip/tests/test_inference_simple.py
github.com/ali-vilab/AnyDoor/ldm/modules/encoders/modules.py
github.com/mlfoundations/open_clip/tests/test_download_pretrained.py
github.com/mlcommons/training/stable_diffusion/ldm/modules/encoders/modules.py
github.com/Alpha-VLLM/LLaMA2-Accessory/accessory/model/LLM/llama_ens.py
github.com/Alpha-VLLM/LLaMA2-Accessory/accessory/model/LLM/llama_peft.py
github.com/modelscope/modelscope/modelscope/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py
github.com/Alpha-VLLM/LLaMA2-Accessory/accessory/model/LLM/llama_ens5.py
github.com/openvinotoolkit/anomalib/src/anomalib/models/image/winclip/torch_model.py
github.com/Alpha-VLLM/LLaMA2-Accessory/accessory/model/LLM/llama_ens10.py
github.com/IDEA-Research/DWPose/ControlNet-v1-1-nightly/ldm/modules/encoders/modules.py
github.com/Alpha-VLLM/LLaMA2-Accessory/accessory/model/LLM/mixtral_peft.py
github.com/Alpha-VLLM/LLaMA2-Accessory/accessory/model/LLM/llama_ens5p2.py
github.com/microsoft/LLaVA-Med/llava/model/llava.py
github.com/Alpha-VLLM/LLaMA2-Accessory/accessory/model/LLM/llama_adapter.py
github.com/eric-ai-lab/MiniGPT-5/metric.py
github.com/Alpha-VLLM/LLaMA2-Accessory/accessory/model/LLM/mixtral_sparse.py
github.com/Alpha-VLLM/LLaMA2-Accessory/accessory/model/LLM/llama_ens_peft.py
github.com/YangLing0818/RPG-DiffusionMaster/modules/sd_disable_initialization.py
github.com/YuxinWenRick/hard-prompts-made-easy/run.py
github.com/Alpha-VLLM/LLaMA2-Accessory/accessory/model/LLM/llama_ens_light.py
github.com/ali-vilab/i2vgen-xl/tools/modules/clip_embedder.py
github.com/UMass-Foundation-Model/3D-LLM/three_steps_3d_feature/first_step/sam_mask.py
github.com/Alpha-VLLM/LLaMA2-Accessory/accessory/model/LLM/llama_ens5_light.py
github.com/UMass-Foundation-Model/3D-LLM/three_steps_3d_feature/second_step/clip_sam.py
github.com/zideliu/StyleDrop-PyTorch/predict.py
github.com/alaamaalouf/FollowAnything/follow_anything.py
github.com/roatienza/Deep-Learning-Experiments/versions/2023/model_serving/demo/triton/server.py
github.com/zideliu/StyleDrop-PyTorch/gradio_demo.py
github.com/Alpha-VLLM/LLaMA2-Accessory/accessory/model/LLM/mixtral_sparse_ens.py
github.com/baaivision/Uni3D/main.py
github.com/UMass-Foundation-Model/3D-LLM/three_steps_3d_feature/second_step/clip_maskformer.py
github.com/Alpha-VLLM/LLaMA2-Accessory/accessory/model/LLM/mixtral_sparse_ens5.py
github.com/AnyLoc/AnyLoc/clip_wrapper.py
github.com/mingukkang/GigaGAN/evaluation/evaluation.py
github.com/salesforce/UniControl/ldm/modules/encoders/modules.py
github.com/VoltaML/voltaML-fast-stable-diffusion/core/interrogation/clip.py
github.com/lancedb/vectordb-recipes/examples/arxiv-recommender/main.py
github.com/SHI-Labs/Prompt-Free-Diffusion/lib/model_zoo/clip.py
github.com/zyddnys/manga-image-translator/manga_translator/inpainting/ldm/modules/encoders/modules.py
github.com/hanhung/PureCLIPNeRF/train_exp.py
github.com/Fanghua-Yu/SUPIR/sgm/modules/encoders/modules.py
github.com/hanhung/PureCLIPNeRF/train_imp.py
github.com/Shilin-LU/TF-ICON/ldm/modules/encoders/modules.py
github.com/ShihaoZhaoZSH/Uni-ControlNet/ldm/modules/encoders/modules.py
github.com/daveredrum/Text2Tex/models/ControlNet/ldm/modules/encoders/modules.py
github.com/kabachuha/sd-webui-text2video/scripts/modelscope/clip_hardcode.py
github.com/zhyever/PatchFusion/ControlNet/ldm/modules/encoders/modules.py
github.com/UMass-Foundation-Model/3D-LLM/3DLanguage_data/ChatCaptioner_based/gen_features/clip_oa.py
github.com/vislearn/ControlNet-XS/sgm/modules/encoders/modules.py
github.com/IDEA-CCNL/Fengshenbang-LM/fengshen/examples/finetune_taiyi_stable_diffusion/evaluate_model.py
github.com/Doubiiu/DynamiCrafter/lvdm/modules/encoders/condition.py
github.com/vislearn/ControlNet-XS/ldm/modules/encoders/modules.py
github.com/Picsart-AI-Research/PAIR-Diffusion/ldm/modules/encoders/modules.py
github.com/Newbeeer/diffusion_restart_sampling/diffuser/clip_score.py
github.com/diffusion-classifier/diffusion-classifier/run_winoground.py
github.com/umd-huang-lab/perceptionCLIP/src/models/modeling.py
github.com/UMass-Foundation-Model/3D-LLM/3DLanguage_data/ChatCaptioner_based/gen_features/sam_mask.py
github.com/NVIDIA/tao_pytorch_backend/nvidia_tao_pytorch/cv/odise/modeling/backbone/clip.py
github.com/NVIDIA/tao_pytorch_backend/nvidia_tao_pytorch/cv/odise/modeling/meta_arch/clip.py
github.com/Zhendong-Wang/Prompt-Diffusion/ldm/modules/encoders/modules.py
github.com/3DTopia/3DTopia/ldm/modules/encoders/modules.py
github.com/sail-sg/EditAnything/ldm/modules/encoders/modules.py
github.com/OpenGVLab/Instruct2Act/engine_robotic.py
github.com/roatienza/Deep-Learning-Experiments/versions/2023/model_serving/demo/triton/openclip/server.py
github.com/Newbeeer/diffusion_restart_sampling/diffuser/eval_clip_score.py
github.com/vvictoryuki/FreeDoM/CN/ldm/modules/encoders/modules.py
github.com/Nerogar/OneTrainer/modules/module/HPSv2ScoreModel.py
github.com/mlcommons/inference/text_to_image/tools/clip/clip_encoder.py
github.com/SamsungLabs/FineControlNet/ldm/modules/encoders/modules.py
github.com/TencentARC/MotionCtrl/lvdm/modules/encoders/condition2.py
github.com/deforum-art/deforum-stable-diffusion/src/ldm/modules/encoders/modules.py
github.com/zsyOAOA/ResShift/ldm/modules/encoders/modules.py
github.com/Newbeeer/diffusion_restart_sampling/diffuser/coco_data_loader.py
github.com/WalBouss/GEM/gem/gem.py
github.com/IceClear/StableSR/ldm/modules/encoders/modules.py
github.com/yangxy/PASD/test_pasd.py
github.com/chaojie/ComfyUI-DragNUWA/dragnuwa/svd/modules/encoders/modules.py
github.com/buaacyw/IT3D-text-to-3D/ctn/ldm/modules/encoders/modules.py
github.com/minghanqin/LangSplat/preprocess.py
github.com/text2cinemagraph/text2cinemagraph/ODISE/odise/modeling/meta_arch/clip.py
github.com/MendelXu/SAN/san/model/san.py
github.com/ali-vilab/videocomposer/tools/videocomposer/inference_multi.py
github.com/shenyunhang/APE/ape/modeling/text/clip_wrapper_open.py
github.com/Algolzw/daclip-uir/universal-image-restoration/config/daclip-sde/train.py
github.com/jianzhnie/GigaGAN/gigagan/open_clip.py
github.com/ali-vilab/videocomposer/tools/videocomposer/inference_single.py
github.com/bytedance/fc-clip/fcclip/modeling/backbone/clip.py
github.com/mlfoundations/task_vectors/src/modeling.py
github.com/Colin97/OpenShape_code/src/example.py
github.com/mertyg/vision-language-models-are-bows/model_zoo/__init__.py
github.com/XPixelGroup/DiffBIR/ldm/modules/encoders/modules.py
github.com/csuhan/OneLLM/model/LLM/onellm.py
github.com/zideliu/StyleDrop-PyTorch/train_t2i_colab_v2.py
github.com/lucidrains/gigagan-pytorch/gigagan_pytorch/open_clip.py
github.com/RoboFlamingo/RoboFlamingo/robot_flamingo/models/factory.py
github.com/yu-takagi/StableDiffusionReconstruction/codes/diffusion_sd2/stablediffusion/ldm/modules/encoders/modules.py
github.com/mkshing/e4t-diffusion/e4t/encoder.py
github.com/rese1f/StableVideo/ldm/modules/encoders/modules.py
github.com/csslc/CCSR/ldm/modules/encoders/modules.py
github.com/Nota-NetsPresso/BK-SDM/src/eval_clip_score.py
github.com/KohakuBlueleaf/LyCORIS/lycoris/modules/hypernet/text_encoder.py
github.com/zideliu/StyleDrop-PyTorch/train_t2i_custom_v2.py
github.com/LAION-AI/CLIP_benchmark/clip_benchmark/models/open_clip.py
github.com/Tsingularity/dift/src/models/clip.py
github.com/OpenGVLab/InternVL/clip_benchmark/clip_benchmark/models/open_clip.py
github.com/ThereforeGames/unprompted/lib_unprompted/stable_diffusion/controlnet/ldm/modules/encoders/modules.py
github.com/baaivision/GeoDream/mv-diffusion/MVDream/mvdream/ldm/modules/encoders/modules.py
github.com/GongyeLiu/StyleCrafter/lvdm/modules/encoders/condition.py
github.com/technobird22/NeoGen/safety_model.py
github.com/rlawjdghek/StableVITON/ldm/modules/encoders/modules.py
github.com/haoshao-nku/medical_seg/mmsegmentation/projects/CAT-Seg/cat_seg/models/clip_ovseg.py
github.com/zideliu/StyleDrop-PyTorch/extract_empty_feature.py
github.com/pharmapsychotic/clip-interrogator/clip_interrogator/clip_interrogator.py
github.com/data2ml/all-clip/all_clip/open_clip.py
github.com/Weifeng-Chen/dl_scripts/text-image/data_filter/wukong_filter.py
github.com/tgxs002/align_sd/process_diffusiondb.py
github.com/thecooltechguy/ComfyUI-Stable-Video-Diffusion/libs/sgm/modules/encoders/modules.py
github.com/Vision-CAIR/ChatCaptioner/ChatCaptioner/chatcaptioner/clip.py
github.com/matsui528/scs/search.py
github.com/matsui528/scs/search_streamlit.py
github.com/matsui528/scs/extract_features.py
github.com/ContextualAI/lens/lens/model.py
github.com/AILab-CVC/FreeNoise/lvdm/modules/encoders/condition.py
github.com/Anything-of-anything/Anything-3D/AnyObject3D/src/3DFuse/ldm/modules/encoders/modules.py
github.com/RoboFlamingo/RoboFlamingo/open_flamingo/open_flamingo/eval/rices.py
github.com/KU-CVLAB/3DFuse/ldm/modules/encoders/modules.py
github.com/Algolzw/daclip-uir/universal-image-restoration/config/daclip-sde/test.py
github.com/AnyLoc/AnyLoc/examples/trivial_vpr_with_clip.py
github.com/RoboFlamingo/RoboFlamingo/open_flamingo/open_flamingo/src/factory.py
github.com/mlfoundations/datacomp/eval_utils/wds_eval.py
github.com/dome272/Paella/src_distributed/utils.py
github.com/kerrj/lerf/lerf/encoders/openclip_encoder.py
github.com/carefree0910/carefree-learn/examples/reproduce/clip/run_open_clip.py
github.com/facebookresearch/stable_signature/src/ldm/modules/encoders/modules.py
github.com/HelixNGC7293/DeforumStableDiffusionLocal/deforum-stable-diffusion/src/ldm/modules/encoders/modules.py
github.com/concept-graphs/concept-graphs/conceptgraph/scripts/eval_replica_semseg.py
github.com/facebookresearch/MetaCLIP/tests/simple_test.py
github.com/concept-graphs/concept-graphs/conceptgraph/scripts/generate_gsa_results.py
github.com/open-mmlab/Multimodal-GPT/mmgpt/models/open_flamingo/builder.py
github.com/sail-sg/BindDiffusion/ldm/modules/encoders/modules.py
github.com/GaussianObject/GaussianObject/ldm/modules/encoders/modules.py
github.com/facebookresearch/MetaCLIP/tests/pretrained_test.py
github.com/lucidrains/perfusion-pytorch/perfusion_pytorch/open_clip.py
github.com/facebookresearch/PUG/PUG_SPAR/run_eval_vlms_on_spar.py
github.com/bytedance/ImageDream/extern/ImageDream/imagedream/ldm/modules/encoders/modules.py
github.com/painebenjamin/app.enfugue.ai/src/python/enfugue/diffusion/animate/dragnuwa/svd/modules/encoders/modules.py
github.com/painebenjamin/app.enfugue.ai/src/python/enfugue/diffusion/support/upscale/ccsr/ldm/modules/encoders/modules.py
github.com/concept-graphs/concept-graphs/conceptgraph/scripts/streamlined_detections.py
github.com/Zeju1997/oft/oft-control/ldm/modules/encoders/modules.py
github.com/KU-CVLAB/CAT-Seg/cat_seg/modeling/transformer/cat_seg_predictor.py
github.com/concept-graphs/concept-graphs/conceptgraph/scripts/visualize_cfslam_results.py
github.com/bytedance/MVDream/mvdream/ldm/modules/encoders/modules.py
github.com/Vision-CAIR/ChatCaptioner/Video_ChatCaptioner/chatcaptioner/clip.py
github.com/ssundaram21/dreamsim/dreamsim/feature_extraction/load_open_clip_as_dino.py
github.com/ParisNeo/lollms/lollms/image_gen_modules/clip_interrogator.py
github.com/abhishekkrthakur/diffuzers/diffuzers/clip_interrogator.py
github.com/NVIDIA/NeMo-Megatron-Launcher/launcher_scripts/nemo_launcher/collections/eval_diffusion_fid_clip/compute_clip_score.py
github.com/d8ahazard/sd_smartprocess/clipinterrogator.py
github.com/zideliu/StyleDrop-PyTorch/extract_test_prompt_feature.py
github.com/facebookresearch/ov-seg/open_clip_training/tests/test_simple.py
github.com/KU-CVLAB/CAT-Seg/open_clip/tests/util_test.py
github.com/KU-CVLAB/CAT-Seg/open_clip/tests/test_inference.py
github.com/KU-CVLAB/CAT-Seg/open_clip/tests/test_inference_simple.py
github.com/KU-CVLAB/CAT-Seg/open_clip/tests/test_download_pretrained.py
github.com/perf-project/PeRF/ldm/modules/encoders/modules.py
github.com/wolverinn/stable-diffusion-multi-user/modules/sd_disable_initialization.py
github.com/wolverinn/stable-diffusion-multi-user/sd-docker-slim/modules/sd_disable_initialization.py
github.com/wolverinn/stable-diffusion-multi-user/repositories/stable-diffusion-stability-ai/ldm/modules/encoders/modules.py
github.com/wolverinn/stable-diffusion-multi-user/sd-docker-slim/repositories/stable-diffusion-stability-ai/ldm/modules/encoders/modules.py
github.com/JiYuanFeng/DDP/controlnet/ldm/modules/encoders/modules.py
github.com/wusongbai139/controlnet_TrainingPackage/ldm/modules/encoders/modules.py
github.com/StartHua/ComfyUI_Seg_VITON/ldm/modules/encoders/modules.py
github.com/NVIDIA-AI-IOT/jetson-intro-to-distillation/openclip_utils.py
github.com/bytedance/AvatarVerse/controlnet/ldm/modules/encoders/modules.py
github.com/OPPO-Mente-Lab/Subject-Diffusion/train.py
github.com/OPPO-Mente-Lab/Subject-Diffusion/test.py
github.com/OPPO-Mente-Lab/Subject-Diffusion/test_subject.py
github.com/tgxs002/HPSv2/hpsv2/tests/util_test.py
github.com/tgxs002/HPSv2/hpsv2/tests/test_inference.py
github.com/tgxs002/HPSv2/hpsv2/tests/test_inference_simple.py
github.com/tgxs002/HPSv2/hpsv2/tests/test_download_pretrained.py
github.com/ChenDelong1999/RemoteCLIP/retrieval.py
github.com/frank-xwang/InstanceDiffusion/eval/eval_attribute_binding.py
github.com/neggles/sd-webui-arc/modules/sd_disable_initialization.py
github.com/AILab-CVC/Make-Your-Video/lvdm/modules/encoders/condition.py
github.com/yongliang-wu/ExploreCfg/open_flamingo/src/factory.py
github.com/saketh12/Auto1111SDK/auto1111sdk/modules/sd_disable_initialization.py
github.com/saketh12/Auto1111SDK/auto1111sdk/modules/stable/ldm/modules/encoders/modules.py
github.com/saketh12/Auto1111SDK/auto1111sdk/modules/generative/sgm/modules/encoders/modules.py
github.com/mhh0318/Cocktail/annotator/SAN/san/model/san.py
github.com/mhh0318/Cocktail/ldm/modules/encoders/modules.py
github.com/forchchch/DisenBooth/train_disenbooth.py
github.com/neggles/neurosis/src/neurosis/models/text_encoder/clip.py
github.com/YuxinWenRick/tree-ring-watermark/run_tree_ring_watermark.py
github.com/Picsart-AI-Research/HD-Painter/src/smplfusion/models/encoders/open_clip_embedder.py
github.com/leptonai/examples/advanced/open-clip/open-clip.py
github.com/Junyi42/sd-dino/third_party/ODISE/odise/modeling/meta_arch/clip.py
github.com/taesiri/ZoomIsAllYouNeed/src/ImageNet_Hard/benchmark-openclip.py
github.com/taesiri/ZoomIsAllYouNeed/src/ImageNet_Hard/benchmark_openclip.py
github.com/taesiri/ZoomIsAllYouNeed/src/ImageNet_Hard/benchmark_openclip_datacomp.py
github.com/showlab/cosmo/src/eval/eval_tasks/utils/rices.py
github.com/showlab/cosmo/src/multimodal_model/vision_model/load_vision_model.py
github.com/chs20/RobustVLM/CLIP_eval/eval_utils.py
github.com/chs20/RobustVLM/open_flamingo/src/factory.py
github.com/chs20/RobustVLM/train/adversarial_training_clip.py
github.com/chs20/RobustVLM/llava/model/multimodal_encoder/clip_encoder.py
github.com/chs20/RobustVLM/CLIP_benchmark/clip_benchmark/models/open_clip.py
github.com/hukkelas/deep_privacy2/dp2/discriminator/projected_gan/vit_openclip.py
github.com/djghosh13/geneval/evaluation/evaluate_images.py
github.com/achao2013/deep3dmap/deep3dmap/models/modulars/ns_encoders/openclip_encoder.py
github.com/GaryJiajia/OFv2_ICL_VQA/open_flamingo/src/factory.py
github.com/GaryJiajia/OFv2_ICL_VQA/open_flamingo/src/factory_new.py
github.com/GaryJiajia/OFv2_ICL_VQA/open_flamingo/src/factory_old.py
github.com/yeates/MaGIC/ldm/modules/encoders/modules.py
github.com/salesforce/DOODL/doodl.py
github.com/lucidrains/classifier-free-guidance-pytorch/classifier_free_guidance_pytorch/open_clip.py
github.com/daveredrum/SceneTex/models/pipeline/texture_pipeline.py
github.com/MedARC-AI/fMRI-Algonauts-Challenge-2023/src/models.py
github.com/aim-uofa/StyleDrop-PyTorch/predict.py
github.com/aim-uofa/StyleDrop-PyTorch/gradio_demo.py
github.com/aim-uofa/StyleDrop-PyTorch/train_t2i_colab_v2.py
github.com/aim-uofa/StyleDrop-PyTorch/train_t2i_custom_v2.py
github.com/aim-uofa/StyleDrop-PyTorch/extract_empty_feature.py
github.com/aim-uofa/StyleDrop-PyTorch/extract_test_prompt_feature.py
github.com/Tlntin/trt2023/ldm/modules/encoders/modules.py
github.com/amazon-science/instruct-video-to-video/modules/openclip/modules.py
github.com/amazon-science/instruct-video-to-video/modules/damo_text_to_video/text_model.py
github.com/yeongjoonJu/NeuroInspect/clip_illusion.py
github.com/superhero-7/AltDiffusion/src/ldm/modules/encoders/modules.py
github.com/kabachuha/InfiNet/t2v_modules/clip_wrap.py
github.com/zzc-1998/SJTU-H3D/quality_measure_utils/semantic_affinity_quality_measure.py
github.com/Badisches-Landesmuseum/xcurator/data-enrichment/1-artefact-embedding/src/embeddings/OpenCLIP.py
github.com/Badisches-Landesmuseum/xcurator/data-enrichment/1-artefact-embedding/src/generate/coca_decoder.py
github.com/adodge/ComfyLib/comfy/hazard/ldm/modules/encoders/modules.py
github.com/locuslab/FLYP/src/models/modeling.py
github.com/altndrr/vic/src/models/clip.py
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding/training_pro10k_s5.py
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding/training_pro10k_s9.py
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding/training_pro10k_s7.py
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding/training_pro10k_s3.py
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding/training_pro10k_s4.py
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding/training_pro10k_s8.py
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding/training_pro10k_s13.py
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding/training_pro10k_s11.py
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding/training_pro10k_s12.py
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding/training_allexpro10k_s6.py
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding/training_allexpro10k_s2.py
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding/training_allexpro10k_s1.py
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding/training_allexpro10k_s10.py
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding/open_clip_280/tests/test_simple.py
github.com/ShihaoShao-GH/1st-Place-Solution-in-Google-Universal-Image-Embedding/open_clip_280_overlap/tests/test_simple.py
github.com/joanaapa/Foundation-Medical/utils/transformers/clip.py
github.com/ai-forever/deforum-kandinsky/deforum_kandinsky/src/ldm/modules/encoders/modules.py
github.com/facebookresearch/SIEVE/eval_utils/wds_eval.py
github.com/runpod/serverless-workers/workers/ControlNet/ldm/modules/encoders/modules.py
github.com/crystallee-ai/controlGIF/clip_interrogator/clip_interrogator.py
github.com/bentoml/CLIP-API-service/src/clip_api_service/models/openclip.py
github.com/Understanding-Visual-Datasets/VisDiff/serve/clip_server.py
github.com/unum-cloud/coco-sm/modules/open_clip.py
github.com/ByChelsea/VAND-APRIL-GAN/train.py
github.com/ByChelsea/VAND-APRIL-GAN/test.py
github.com/hq-deng/AnoVL/vl_test.py
github.com/hq-deng/AnoVL/vis_test.py
github.com/luping-liu/Detector-Guidance/stablediffusion/ldm/modules/encoders/modules.py
github.com/sled-group/CycleNet/ldm/modules/encoders/modules.py
github.com/CuriseJia/FreeStyleRet/src/models/style_retrieval.py
github.com/CuriseJia/FreeStyleRet/imagenet_test/clip_test.py
github.com/CuriseJia/FreeStyleRet/comparison_test/clip_test.py
github.com/CuriseJia/FreeStyleRet/comparison_test/prompt_model.py
github.com/CuriseJia/FreeStyleRet/imagenet_test/languagebind_test.py
github.com/CuriseJia/FreeStyleRet/comparison_test/languagebind_test.py
github.com/tomtom1103/compose-and-conquer/ldm/modules/encoders/modules.py
github.com/hammoudhasan/SynthCLIP/ImageGen/ldm/modules/encoders/modules.py
github.com/Georgefwt/Face-Landmark-ControlNet/ldm/modules/encoders/modules.py
github.com/pravdomil/Rerender-A-Video/ControlNet/ldm/modules/encoders/modules.py
github.com/lancopku/clip-openness/clip-retrieval/clip_retrieval/clip_inference/load_clip.py
github.com/chaojie/ComfyUI-DynamiCrafter/lvdm/modules/encoders/condition.py
github.com/aimagelab/open-fashion-clip/quick_start.py
github.com/Eric3911/OpenAGI/Multimodal-GPT-master/mmgpt/models/open_flamingo/builder.py
github.com/Eric3911/OpenAGI/AudioGPT-master/text_to_audio/Make_An_Audio/ldm/modules/encoders/modules.py
github.com/UCSC-VLAA/vllm-safety-benchmark/baselines/openflamingo_modeling.py
github.com/UCSC-VLAA/vllm-safety-benchmark/safety_evaluations/redteaming/misleading_vision_attack/misleading_vis_attack.py
github.com/Happenmass/ControlNet-for-SDXL/sgm/modules/encoders/modules.py
github.com/Happenmass/ControlNet-for-SDXL/ldm/modules/encoders/modules.py
github.com/modelscope/normal-depth-diffusion/tools/compute_metric.py
github.com/modelscope/normal-depth-diffusion/tools/compute_metric_curves.py
github.com/modelscope/normal-depth-diffusion/ldm/modules/encoders/modules.py
github.com/modelscope/normal-depth-diffusion/tools/compute_clip_metric_curves.py
github.com/modelscope/normal-depth-diffusion/tools/compute_objaverse_clipscore.py
github.com/modelscope/normal-depth-diffusion/tools/compute_cfg_clip_metric_curves.py
github.com/yandex-research/adaptive-diffusion/consistency_models_sd/evaluations/clip_score.py
github.com/gersteinlab/ML-Bench/MLAgent/repo/open_clip/tests/util_test.py
github.com/gersteinlab/ML-Bench/MLAgent/repo/open_clip/tests/test_inference.py
github.com/gersteinlab/ML-Bench/MLAgent/repo/open_clip/tests/test_inference_simple.py
github.com/gersteinlab/ML-Bench/MLAgent/repo/open_clip/tests/test_download_pretrained.py
github.com/bubbliiiing/stable-diffusion/ldm/modules/encoders/modules.py
github.com/showlab/VisorGPT/demo/ControlNet/controlnet/ldm/modules/encoders/modules.py
github.com/JunjieYang97/Meta-ControlNet/ldm/modules/encoders/modules.py
github.com/boschresearch/ALDM/ldm/modules/encoders/modules.py
github.com/razeghi71/stable-diffusion-v2-m1/ldm/modules/encoders/modules.py
github.com/ruoxi-jia-group/CLIP-MIA/main.py
github.com/Birch-san/imagebind-guided-diffusion/src/imgbind_guidance/clip_embed/embed_text.py
github.com/Computer-Vision-in-the-Wild/UniCL-OpenCLIP/tests/util_test.py
github.com/Computer-Vision-in-the-Wild/UniCL-OpenCLIP/tests/test_inference.py
github.com/Computer-Vision-in-the-Wild/UniCL-OpenCLIP/tests/test_inference_simple.py
github.com/distable/core/src_plugins/paella/colab.py
github.com/distable/core/src_plugins/opticalflow/notebook.py
github.com/JiahuiLei/GART/lib_guidance/mvdream/extern/MVDream/mvdream/ldm/modules/encoders/modules.py
github.com/GiovanniTRA/MultimodalNeuralDatabases/MMNDB/Model/retrieve.py
github.com/GiovanniTRA/MultimodalNeuralDatabases/MMNDB/Data/data_retriever.py
github.com/wangyu-ustc/LM4CV/cluster.py
github.com/wangyu-ustc/LM4CV/utils/train_utils.py
github.com/salesforce/BannerGen/InstructPix2Pix/stable_diffusion/ldm/modules/encoders/modules.py
github.com/wkcn/TinyCLIP/inference.py
github.com/waltonfuture/InstructionGPT-4/selector/utils_image.py
github.com/waltonfuture/InstructionGPT-4/cluster/kmeans++/kmeans_pp.py
github.com/waltonfuture/InstructionGPT-4/selector/get_all_image_features.py
github.com/waltonfuture/InstructionGPT-4/cluster/spectral/spectral_clustering.py
github.com/waltonfuture/InstructionGPT-4/cc_sbu_align_test/full_score.py
github.com/huzeyann/MemoryEncodingModel/mem/backbone.py
github.com/Zhiyuan-R/ChatGPT-Powered-Hierarchical-Comparisons-for-Image-Classification/main.py
github.com/Hazel1994/ViPE-Videos/src/ldm/modules/encoders/modules.py
github.com/NeuralRealm/StableFusion/stablefusion/scripts/clip_interrogator.py
github.com/TIGER-AI-Lab/ImagenHub/src/imagen_hub/depend/clip_retrieval/load_clip.py
github.com/TIGER-AI-Lab/ImagenHub/src/imagen_hub/pipelines/controlnet/ldm/modules/encoders/modules.py
github.com/TIGER-AI-Lab/ImagenHub/src/imagen_hub/pipelines/unicontrol/ldm/modules/encoders/modules.py
github.com/locuslab/smoothinv/loader.py
github.com/chenxx89/BFRffusion/ldm/modules/encoders/modules.py
github.com/hylarucoder/svd-webui/sgm/modules/encoders/modules.py
github.com/IDEA-Research/HumanSD/ldm/modules/encoders/modules.py
github.com/IDEA-Research/HumanSD/comparison_models/T2IAdapter/ldm/modules/encoders/modules.py
github.com/IDEA-Research/HumanSD/comparison_models/ControlNet/ldm/modules/encoders/modules.py
github.com/JustRin/Stable-Video-Diffusion/sgm/modules/encoders/modules.py
github.com/facebookresearch/Whac-A-Mole/model/model_zoo.py
github.com/UMass-Foundation-Model/CoVLM/open_flamingo/src/factory.py
github.com/r0mar0ma/sd-webui-pez-dispenser/scripts/pez-dispenser.py
github.com/MingtaoGuo/AnimateAnyone_unofficial/ldm/modules/encoders/modules.py
github.com/LAION-AI/phenaki/train_maskgit.py
github.com/TRT2022/ControlNet_TensorRT/ldm/modules/encoders/modules.py
github.com/KaiyuYue/nxtp/src/evals/engine.py
github.com/gortizji/tangent_task_arithmetic/src/modeling.py
github.com/JethroPeng/GCDSS/model/model.py
github.com/orrzohar/LOVM/modelGPT/create_models.py
github.com/orrzohar/LOVM/modelGPT/encode_dataset.py
github.com/orrzohar/LOVM/modelGPT/encode_syn_dataset.py
github.com/AhmedBourouis/Scene-Sketch-Segmentation/models/clip.py
github.com/riron1206/kaggle-Google-Universal-Image-Embedding-Competition-5th-Place-Solution/train_arcface.py
github.com/riron1206/kaggle-Google-Universal-Image-Embedding-Competition-5th-Place-Solution/train_classifier.py
github.com/riron1206/kaggle-Google-Universal-Image-Embedding-Competition-5th-Place-Solution/make_torchscript_wcls.py
github.com/kijai/ComfyUI-SUPIR/sgm/modules/encoders/modules.py
github.com/YitingQu/unsafe-diffusion/train.py
github.com/YitingQu/unsafe-diffusion/baselines.py
github.com/kirill-vish/Beyond-INet/utils/misc.py
github.com/Deep-Spark/deepsparkhub/multimodal/diffusion/ControlNet/ldm/modules/encoders/modules.py
github.com/UCSC-VLAA/MixCon3D/src/example.py
github.com/XmYx/ainodes_engine_base_nodes/ainodes_backend/t2v_model.py
github.com/lewandofskee/DiAD/ldm/modules/encoders/modules.py
github.com/Ascend/ModelZoo-PyTorch/PyTorch/built-in/diffusion/stablediffusion-2.1/ldm/modules/encoders/modules.py
github.com/Ascend/ModelZoo-PyTorch/AscendIE/AscendIE/StableDiffusion/clip_score.py
github.com/Ascend/ModelZoo-PyTorch/ACL_PyTorch/built-in/foundation_models/stable_diffusion/clip_score.py
github.com/technion-cs-nlp/ReFACT/test_clip_score.py
github.com/technion-cs-nlp/ReFACT/test_multiple_edits.py
github.com/Ascend/ModelZoo-PyTorch/PyTorch/built-in/others/OpenCLIP_for_PyTorch/tests/util_test.py
github.com/Ascend/ModelZoo-PyTorch/PyTorch/built-in/others/OpenCLIP_for_PyTorch/tests/test_inference.py
github.com/Ascend/ModelZoo-PyTorch/PyTorch/built-in/others/OpenCLIP_for_PyTorch/tests/test_inference_simple.py
github.com/upfusion3d/upfusion/control_net/ldm/modules/encoders/modules.py
github.com/om-ai-lab/RS5M/inference/inference.py
github.com/om-ai-lab/RS5M/inference/convert_weight.py
github.com/Birch-san/diffusers-play/src/helpers/embed_text.py
github.com/camenduru/Rerender-hf/ControlNet/ldm/modules/encoders/modules.py
github.com/johnowhitaker/tglcourse/tglcourse/generation_utils.py
github.com/iejMac/clip-video-encode/clip_video_encode/simplemapper.py
github.com/iejMac/clip-video-encode/tests/test_similarity.py
github.com/iart-ai/prompt2prompt/stablediffusion/ldm/modules/encoders/modules.py
github.com/MadryLab/dataset-interfaces/dataset_interfaces/inference_utils.py
github.com/SKKU-ESLAB/Auto-Compression/pruning/UVP/Transformer/sparseml/integrations/clip/clip_onnx_export.py
github.com/Max-Fu/tvl/tvl_enc/tvl.py
github.com/AlonzoLeeeooo/LCDG/ldm/modules/encoders/modules.py
github.com/google/storybench/metrics/vtm_clip.py
github.com/google/storybench/metrics/fid_clip.py
github.com/czyczyyzc/CondLSTR/tools/preprocess/sa_1b_tag.py
github.com/adelacvg/ttts/ttts/diffusion/ldm/modules/encoders/modules.py
github.com/adelacvg/ttts/ttts/AA_diffusion_deprecated/ldm/modules/encoders/modules.py
github.com/eslambakr/HRS_benchmark/codes/t2i_models/Paella/paella.py
github.com/eslambakr/HRS_benchmark/codes/t2i_models/Paella/paella_minimal.py
github.com/eslambakr/HRS_benchmark/codes/t2i_models/Paella/paella_inference.py
github.com/eslambakr/HRS_benchmark/codes/t2i_models/sd_v2/ldm/modules/encoders/modules.py
github.com/eslambakr/HRS_benchmark/codes/t2i_models/Paella/ongoing_research/scaling/paella_h.py
github.com/eslambakr/HRS_benchmark/codes/t2i_models/Paella/ongoing_research/text-to-video/train_maskgit.py
github.com/endo-yuki-t/MAG/ldm/modules/encoders/modules.py
github.com/tanganke/subspace_fusion/src/modeling.py
github.com/kakaobrain/nvs-adapter/sgm/modules/encoders/modules.py
github.com/weijiawu/DiffuMask/clip_retrieval/load_clip.py
github.com/OpenGVLab/ChartAst/accessory/model/LLM/llama.py
github.com/OpenGVLab/ChartAst/accessory/model/LLM/llama_ens.py
github.com/OpenGVLab/ChartAst/accessory/model/LLM/llama_peft.py
github.com/OpenGVLab/ChartAst/accessory/model/LLM/llama_ens5.py
github.com/OpenGVLab/ChartAst/accessory/model/LLM/llama_ens10.py
github.com/OpenGVLab/ChartAst/accessory/model/LLM/llama_ens5p2.py
github.com/OpenGVLab/ChartAst/accessory/model/LLM/llama_adapter.py
github.com/OpenGVLab/ChartAst/accessory/model/LLM/llama_ens_peft.py
github.com/mlcommons/training_results_v3.1/NVIDIA/benchmarks/stable_diffusion/implementations/pytorch/evaluation/compute_clip_score.py
github.com/mlcommons/training_results_v3.1/Dell/benchmarks/stable_diffusion/implementations/pytorch/evaluation/compute_clip_score.py
github.com/mlcommons/training_results_v3.1/Intel-HabanaLabs/benchmarks/stable_diffusion/ldm/models/clip_encoder.py
github.com/mlcommons/training_results_v3.1/Intel-HabanaLabs/benchmarks/stable_diffusion/ldm/modules/encoders/modules.py
github.com/LukasStruppek/Exploiting-Cultural-Biases-via-Homoglyphs/compute_relative_bias.py
github.com/kousw/experimental-consistory/extern/dift/clip.py
github.com/ChenDarYen/Key-Locked-Rank-One-Editing-for-Text-to-Image-Personalization/ldm/modules/encoders/modules.py
github.com/xmed-lab/CLIPN/src/classification.py
github.com/xmed-lab/CLIPN/hand-crafted/src/classification.py
github.com/NVIDIA-AI-IOT/clip-distillation/export_openclip_onnx.py
github.com/NVIDIA-AI-IOT/clip-distillation/compute_openclip_embeddings.py
github.com/NVIDIA-AI-IOT/clip-distillation/compute_openclip_text_embeddings.py
github.com/baaivision/MUSE-Pytorch/extract_empty_feature.py
github.com/baaivision/MUSE-Pytorch/extract_test_prompt_feature.py
github.com/yasserben/CLOUDS/clouds/modeling/backbone/clip.py
github.com/yasserben/CLOUDS/clouds/modeling/backbone/trainable_clip.py
github.com/gregor-ge/mBLIP/data/pretrain/hard_examples.py
github.com/gregor-ge/mBLIP/data/pretrain/generate_match_train.py
github.com/xuanlinli17/large_vlm_distillation_ood/robotics.py
github.com/xuanlinli17/large_vlm_distillation_ood/evaluate_clip.py
github.com/xuanlinli17/large_vlm_distillation_ood/ofa_gen_caption.py
github.com/xuanlinli17/large_vlm_distillation_ood/main_experiments.py
github.com/emu1729/GIST/caption_matching.py
github.com/sail-sg/MMCBench/text2image/evaluate.py
github.com/sail-sg/MMCBench/image2text/evaluate.py
github.com/VQAssessment/BVQI/prompt_tuning.py
github.com/VQAssessment/BVQI/load_features.py
github.com/VQAssessment/BVQI/semantic_affinity.py
github.com/autodistill/autodistill-metaclip/autodistill_metaclip/metaclip_model.py
github.com/ml-research/i2p/models/vision/paella.py
github.com/ml-research/i2p/mitigation/safe_paella.py
github.com/changzheng123/L-CAD/ldm/modules/encoders/modules.py
github.com/waterhorse1/ChessGPT/chessclip/tests/util_test.py
github.com/waterhorse1/ChessGPT/chessclip/tests/test_inference.py
github.com/waterhorse1/ChessGPT/chessclip/tests/test_inference_simple.py
github.com/MoroccoAI/2023-GenAI-Hackathon/SehhaTech/Source%20Code/vlm_model.py
github.com/LLaVA-VL/LLaVA-Med-preview/llava/model/llava.py
github.com/ChrisVicky/TJU-2023-Computer-Vision-Final/DataPreparation/coca_annotator.py
github.com/zhang-tao-whu/DVIS_Plus/ov_dvis/backbones/clip.py
github.com/megvii-research/protoclip/src/training/evaluations/linear_eval.py
github.com/ChenDelong1999/polite-flamingo/polite_flamingo/src/factory.py
github.com/Vinayak-VG/GSN/tasks/segment_2d_text.py
github.com/Vinayak-VG/GSN/feature_extractor/langfeat_extract_dtu.py
github.com/Vinayak-VG/GSN/feature_extractor/langfeat_extract_llff.py
github.com/CharlieDreemur/AI-Video-Converter/stable-diffusion-webui-master/modules/sd_disable_initialization.py
github.com/mybabyyh/InstructPix2NeRF/diffusion/encoders/modules.py
github.com/IanYeung/MGLD-VSR/ldm/modules/encoders/modules.py
github.com/Peter-Kocsis/IntrinsicImageDiffusion/iid/ldm/encoders.py
github.com/workforai/SCAN/open_clip_training/tests/util_test.py
github.com/workforai/SCAN/open_clip_training/tests/test_inference.py
github.com/workforai/SCAN/open_clip_training/tests/test_inference_simple.py
github.com/workforai/SCAN/open_clip_training/tests/test_download_pretrained.py
github.com/nostalgebraist/nostalgebraist-autoresponder/src/ml/captioning.py
github.com/OPPO-Mente-Lab/PEA-Diffusion/train_sd_zh.py
github.com/OPPO-Mente-Lab/PEA-Diffusion/train_sdxl_zh.py
github.com/OPPO-Mente-Lab/PEA-Diffusion/tests/test_sd_zh.py
github.com/OPPO-Mente-Lab/PEA-Diffusion/tests/test_sdxl_zh.py
github.com/OPPO-Mente-Lab/PEA-Diffusion/tests/test_sdxl_zh_lcm.py
github.com/OPPO-Mente-Lab/PEA-Diffusion/tests/test_sdxl_zh_controlnet.py
github.com/KU-BIG/KUBIG_2024_SPRING/KUBIG%20CONTEST/CV/CV2%ED%8C%80/open_flamingo/eval/rices.py
github.com/KU-BIG/KUBIG_2024_SPRING/KUBIG%20CONTEST/CV/CV2%ED%8C%80/open_flamingo/src/factory.py
